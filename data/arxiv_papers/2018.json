[
  {
    "id": "http://arxiv.org/abs/1812.11613v1",
    "title": "The Device War - The War Between IOT Brands In A Household",
    "authors": [
      "Marius C. Silaghi",
      "Arianit Maraj",
      "Timothy Atkinson"
    ],
    "author_ids": [],
    "abstract": "Users buy compatible IOT devices from different brands with an expectation\nthat their cooperation is smooth, but while function may superficially look\nfriendly, cohabitation can subversively cause early battery depletion in\ncompetitor devices. The Wi-Fi Direct standard was introduced with the intention\nof simplifying peer-to-peer connections in home applications while helping\ndevices to save power through centralization of effort into a single group\nowner device negotiated on start-up. Attacks on the group formation stage can\nbe based on manipulating a victim device to frequently end up being assigned\nthe group owner function, thereby depleting its batteries at faster rates than\nits peer devices. This manipulation is made easy by the group formation\nmechanism adopted by the standard. We show that group formation procedures\ncould be better secured with features ensuring fairness by relying on\ncommitments and by learning about the behavior observed for peer devices in the\npast. Simulations are used to quantify the resistance achieved against several\nattack strategies.",
    "published_date": "2018-12-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11613v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.11501v2",
    "title": "CoSpace: Common Subspace Learning from Hyperspectral-Multispectral Correspondences",
    "authors": [
      "Danfeng Hong",
      "Naoto Yokoya",
      "Jocelyn Chanussot",
      "Xiao Xiang Zhu"
    ],
    "author_ids": [],
    "abstract": "With a large amount of open satellite multispectral imagery (e.g., Sentinel-2\nand Landsat-8), considerable attention has been paid to global multispectral\nland cover classification. However, its limited spectral information hinders\nfurther improving the classification performance. Hyperspectral imaging enables\ndiscrimination between spectrally similar classes but its swath width from\nspace is narrow compared to multispectral ones. To achieve accurate land cover\nclassification over a large coverage, we propose a cross-modality feature\nlearning framework, called common subspace learning (CoSpace), by jointly\nconsidering subspace learning and supervised classification. By locally\naligning the manifold structure of the two modalities, CoSpace linearly learns\na shared latent subspace from hyperspectral-multispectral(HS-MS)\ncorrespondences. The multispectral out-of-samples can be then projected into\nthe subspace, which are expected to take advantages of rich spectral\ninformation of the corresponding hyperspectral data used for learning, and thus\nleads to a better classification. Extensive experiments on two simulated HSMS\ndatasets (University of Houston and Chikusei), where HS-MS data sets have\ntrade-offs between coverage and spectral resolution, are performed to\ndemonstrate the superiority and effectiveness of the proposed method in\ncomparison with previous state-of-the-art methods.",
    "published_date": "2018-12-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11501v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.11490v1",
    "title": "Optimal User Pairing for Achieving Rate Fairness in Downlink NOMA Networks",
    "authors": [
      "Van-Phuc Bui",
      "Phu X. Nguyen",
      "Hieu V. Nguyen",
      "Van-Dinh Nguyen",
      "Oh-Soon Shin"
    ],
    "author_ids": [],
    "abstract": "In this paper, a downlink non-orthogonal multiple access (NOMA) network is\nstudied. We investigate the problem of jointly optimizing user pairing and\nbeamforming design to maximize the minimum rate among all users. The considered\nproblem belongs to a difficult class of mixed-integer nonconvex optimization\nprogramming. We first relax the binary constraints and adopt sequential convex\napproximation method to solve the relaxed problem, which is guaranteed to\nconverge at least to a locally optimal solution. Numerical results show that\nthe proposed method attains higher rate fairness among users, compared with\ntraditional beamforming solutions, i.e., random pairing NOMA and beamforming\nsystems.",
    "published_date": "2018-12-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11490v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.11317v1",
    "title": "Support Vector Guided Softmax Loss for Face Recognition",
    "authors": [
      "Xiaobo Wang",
      "Shuo Wang",
      "Shifeng Zhang",
      "Tianyu Fu",
      "Hailin Shi",
      "Tao Mei"
    ],
    "author_ids": [],
    "abstract": "Face recognition has witnessed significant progresses due to the advances of\ndeep convolutional neural networks (CNNs), the central challenge of which, is\nfeature discrimination. To address it, one group tries to exploit mining-based\nstrategies (\\textit{e.g.}, hard example mining and focal loss) to focus on the\ninformative examples. The other group devotes to designing margin-based loss\nfunctions (\\textit{e.g.}, angular, additive and additive angular margins) to\nincrease the feature margin from the perspective of ground truth class. Both of\nthem have been well-verified to learn discriminative features. However, they\nsuffer from either the ambiguity of hard examples or the lack of discriminative\npower of other classes. In this paper, we design a novel loss function, namely\nsupport vector guided softmax loss (SV-Softmax), which adaptively emphasizes\nthe mis-classified points (support vectors) to guide the discriminative\nfeatures learning. So the developed SV-Softmax loss is able to eliminate the\nambiguity of hard examples as well as absorb the discriminative power of other\nclasses, and thus results in more discrimiantive features. To the best of our\nknowledge, this is the first attempt to inherit the advantages of mining-based\nand margin-based losses into one framework. Experimental results on several\nbenchmarks have demonstrated the effectiveness of our approach over\nstate-of-the-arts.",
    "published_date": "2018-12-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11317v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.11268v2",
    "title": "Dependence Control at Large",
    "authors": [
      "Fengyou Sun"
    ],
    "author_ids": [],
    "abstract": "We study the dependence control theory, with a focus on the tail property and\ndependence transformability of wireless channel capacity, respectively, from\nthe perspective of an information theoretic model of the wireless channel and\nfrom the perspective of a functional of controllable and uncontrollable random\nparameter processes. We find that the light-tailed behavior is an intrinsic\nproperty of the wireless channel capacity, which is due to the passive nature\nof the wireless propagation environment and the power limitation in the\npractical systems. We observe that the manipulation of the marginal\ndistributions has a bias in favor of positive dependence and against negative\ndependence, e.g., when a parameter process bears negative dependence, the\nincreases of the means of marginals can not leads effectively to a better\nsystem performance. On the other hand, the dependence bias indicates that the\ndependence is a tradable resource, i.e., when the dependence resource is\nutilized another resource can be saved. For example, the negative dependence\ncan be traded for transmission power in terms of the performance measures.",
    "published_date": "2018-12-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11268v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.11204v1",
    "title": "Class-Aware Adversarial Lung Nodule Synthesis in CT Images",
    "authors": [
      "Jie Yang",
      "Siqi Liu",
      "Sasa Grbic",
      "Arnaud Arindra Adiyoso Setio",
      "Zhoubing Xu",
      "Eli Gibson",
      "Guillaume Chabin",
      "Bogdan Georgescu",
      "Andrew F. Laine",
      "Dorin Comaniciu"
    ],
    "author_ids": [],
    "abstract": "Though large-scale datasets are essential for training deep learning systems,\nit is expensive to scale up the collection of medical imaging datasets.\nSynthesizing the objects of interests, such as lung nodules, in medical images\nbased on the distribution of annotated datasets can be helpful for improving\nthe supervised learning tasks, especially when the datasets are limited by size\nand class balance. In this paper, we propose the class-aware adversarial\nsynthesis framework to synthesize lung nodules in CT images. The framework is\nbuilt with a coarse-to-fine patch in-painter (generator) and two class-aware\ndiscriminators. By conditioning on the random latent variables and the target\nnodule labels, the trained networks are able to generate diverse nodules given\nthe same context. By evaluating on the public LIDC-IDRI dataset, we demonstrate\nan example application of the proposed framework for improving the accuracy of\nthe lung nodule malignancy estimation as a binary classification problem, which\nis important in the lung screening scenario. We show that combining the real\nimage patches and the synthetic lung nodules in the training set can improve\nthe mean AUC classification score across different network architectures by 2%.",
    "published_date": "2018-12-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11204v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.11118v2",
    "title": "Reconciling modern machine learning practice and the bias-variance trade-off",
    "authors": [
      "Mikhail Belkin",
      "Daniel Hsu",
      "Siyuan Ma",
      "Soumik Mandal"
    ],
    "author_ids": [],
    "abstract": "Breakthroughs in machine learning are rapidly changing science and society,\nyet our fundamental understanding of this technology has lagged far behind.\nIndeed, one of the central tenets of the field, the bias-variance trade-off,\nappears to be at odds with the observed behavior of methods used in the modern\nmachine learning practice. The bias-variance trade-off implies that a model\nshould balance under-fitting and over-fitting: rich enough to express\nunderlying structure in data, simple enough to avoid fitting spurious patterns.\nHowever, in the modern practice, very rich models such as neural networks are\ntrained to exactly fit (i.e., interpolate) the data. Classically, such models\nwould be considered over-fit, and yet they often obtain high accuracy on test\ndata. This apparent contradiction has raised questions about the mathematical\nfoundations of machine learning and their relevance to practitioners.\n  In this paper, we reconcile the classical understanding and the modern\npractice within a unified performance curve. This \"double descent\" curve\nsubsumes the textbook U-shaped bias-variance trade-off curve by showing how\nincreasing model capacity beyond the point of interpolation results in improved\nperformance. We provide evidence for the existence and ubiquity of double\ndescent for a wide spectrum of models and datasets, and we posit a mechanism\nfor its emergence. This connection between the performance and the structure of\nmachine learning models delineates the limits of classical analyses, and has\nimplications for both the theory and practice of machine learning.",
    "published_date": "2018-12-28T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.11118v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.10924v1",
    "title": "Improving the Interpretability of Deep Neural Networks with Knowledge Distillation",
    "authors": [
      "Xuan Liu",
      "Xiaoguang Wang",
      "Stan Matwin"
    ],
    "author_ids": [],
    "abstract": "Deep Neural Networks have achieved huge success at a wide spectrum of\napplications from language modeling, computer vision to speech recognition.\nHowever, nowadays, good performance alone is not sufficient to satisfy the\nneeds of practical deployment where interpretability is demanded for cases\ninvolving ethics and mission critical applications. The complex models of Deep\nNeural Networks make it hard to understand and reason the predictions, which\nhinders its further progress. To tackle this problem, we apply the Knowledge\nDistillation technique to distill Deep Neural Networks into decision trees in\norder to attain good performance and interpretability simultaneously. We\nformulate the problem at hand as a multi-output regression problem and the\nexperiments demonstrate that the student model achieves significantly better\naccuracy performance (about 1\\% to 5\\%) than vanilla decision trees at the same\nlevel of tree depth. The experiments are implemented on the TensorFlow platform\nto make it scalable to big datasets. To the best of our knowledge, we are the\nfirst to distill Deep Neural Networks into vanilla decision trees on\nmulti-class datasets.",
    "published_date": "2018-12-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10924v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.10563v1",
    "title": "The Prophet Inequality Can Be Solved Optimally with a Single Set of Samples",
    "authors": [
      "Jack Wang"
    ],
    "author_ids": [],
    "abstract": "The setting of the classic prophet inequality is as follows: a gambler is\nshown the probability distributions of $n$ independent, non-negative random\nvariables with finite expectations. In their indexed order, a value is drawn\nfrom each distribution, and after every draw the gambler may choose to accept\nthe value and end the game, or discard the value permanently and continue the\ngame. What is the best performance that the gambler can achieve in comparison\nto a prophet who can always choose the highest value? Krengel, Sucheston, and\nGarling solved this problem in 1978, showing that there exists a strategy for\nwhich the gambler can achieve half as much reward as the prophet in\nexpectation. Furthermore, this result is tight.\n  In this work, we consider a setting in which the gambler is allowed much less\ninformation. Suppose that the gambler can only take one sample from each of the\ndistributions before playing the game, instead of knowing the full\ndistributions. We provide a simple and intuitive algorithm that recovers the\noriginal approximation of $\\frac{1}{2}$. Our algorithm works against even an\nalmighty adversary who always chooses a worst-case ordering, rather than the\nstandard offline adversary. The result also has implications for mechanism\ndesign -- there is much interest in designing competitive auctions with a\nfinite number of samples from value distributions rather than full\ndistributional knowledge.",
    "published_date": "2018-12-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10563v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.10520v1",
    "title": "Capacity Results for the K-User Broadcast Channel with Two Nested Multicast Messages",
    "authors": [
      "Mohamed Salman",
      "Mahesh K. Varanasi"
    ],
    "author_ids": [],
    "abstract": "The K-user discrete memoryless (DM) broadcast channel (BC) with two nested\nmulticast messages is studied in which one common message is to be multicast to\nall receivers and the second private message to a subset of receivers. The\nreceivers that must decode both messages are referred to as private receivers\nand the others that must decode only the common message as common receivers.\nFor two nested multicast messages, we establish the capacity region for several\nclasses of DM BCs characterized by the respective associated sets of pair-wise\nrelationships between and among the common and private receivers, each\ndescribed by the well-known more capable or less noisy conditions.\n  For three classes of DM BCs, the capacity region is simply achieved by\nsuperposition coding and the proofs of the converses rely on a recently found\ninformation inequality. The achievable rate region is then enhanced through the\naddition of a splitting of the private message into as many parts as there are\ncommon receivers and indirect decoding. A closed-form two-dimensional\npolyhedral description is obtained for it for a given coding distribution.\nThrough a converse result that relies on the well-known Csiszar sum lemma and\nthe information inequality, a specialization of this region that involves\nsplitting the private message into just two sub-messages is proved to be the\ncapacity region for several classes of DM BCs, beyond those for which\nsuperposition coding alone is capacity optimal, thereby underscoring the\nbenefit of rate-splitting.\n  All previously known capacity results for DM BCs with two nested multicast\nmessages for the two and three-receiver DM BCs as well as DM BCs with one\nprivate or one common receiver are included in the general framework presented\nin this work.",
    "published_date": "2018-12-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10520v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.10260v2",
    "title": "The CORAL+ Algorithm for Unsupervised Domain Adaptation of PLDA",
    "authors": [
      "Kong Aik Lee",
      "Qiongqiong Wang",
      "Takafumi Koshinaka"
    ],
    "author_ids": [],
    "abstract": "State-of-the-art speaker recognition systems comprise an x-vector (or\ni-vector) speaker embedding front-end followed by a probabilistic linear\ndiscriminant analysis (PLDA) backend. The effectiveness of these components\nrelies on the availability of a large collection of labeled training data. In\npractice, it is common that the domains (e.g., language, demographic) in which\nthe system are deployed differs from that we trained the system. To close the\ngap due to the domain mismatch, we propose an unsupervised PLDA adaptation\nalgorithm to learn from a small amount of unlabeled in-domain data. The\nproposed method was inspired by a prior work on feature-based domain adaptation\ntechnique known as the correlation alignment (CORAL). We refer to the\nmodel-based adaptation technique proposed in this paper as CORAL+. The efficacy\nof the proposed technique is experimentally validated on the recent NIST 2016\nand 2018 Speaker Recognition Evaluation (SRE'16, SRE'18) datasets.",
    "published_date": "2018-12-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10260v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.09701v1",
    "title": "Nonlinear Robust Filtering of Sampled-Data Dynamical Systems",
    "authors": [
      "Masoud Abbaszadeh",
      "Horacio J. Marquez"
    ],
    "author_ids": [],
    "abstract": "This work is concerned with robust filtering of nonlinear sampled-data\nsystems with and without exact discrete-time models. A linear matrix inequality\n(LMI) based approach is proposed for the design of robust $H_{\\infty}$\nobservers for a class of Lipschitz nonlinear systems. Two type of systems are\nconsidered, Lipschitz nonlinear discrete-time systems and Lipschitz nonlinear\nsampled-data systems with Euler approximate discrete-time models. Observer\nconvergence when the exact discrete-time model of the system is available is\nshown. Then, practical convergence of the proposed observer is proved using the\nEuler approximate discrete-time model. As an additional feature, maximizing the\nadmissible Lipschitz constant, the solution of the proposed LMI optimization\nproblem guaranties robustness against some nonlinear uncertainty. The robust\nH_infty observer synthesis problem is solved for both cases. The maximum\ndisturbance attenuation level is achieved through LMI optimization. At the end,\na path to extending the results to higher-order approximate discretizations is\nprovided.",
    "published_date": "2018-12-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY",
      "cs.LG",
      "math.OC",
      "H.3.3; I.4.3; B.5.1; J.7; C.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09701v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.09526v4",
    "title": "Functional Aggregate Queries with Additive Inequalities",
    "authors": [
      "Mahmoud Abo Khamis",
      "Ryan R. Curtin",
      "Benjamin Moseley",
      "Hung Q. Ngo",
      "XuanLong Nguyen",
      "Dan Olteanu",
      "Maximilian Schleich"
    ],
    "author_ids": [],
    "abstract": "Motivated by fundamental applications in databases and relational machine\nlearning, we formulate and study the problem of answering functional aggregate\nqueries (FAQ) in which some of the input factors are defined by a collection of\nadditive inequalities between variables. We refer to these queries as FAQ-AI\nfor short.\n  To answer FAQ-AI in the Boolean semiring, we define relaxed tree\ndecompositions and relaxed submodular and fractional hypertree width\nparameters. We show that an extension of the InsideOut algorithm using\nChazelle's geometric data structure for solving the semigroup range search\nproblem can answer Boolean FAQ-AI in time given by these new width parameters.\nThis new algorithm achieves lower complexity than known solutions for FAQ-AI.\nIt also recovers some known results in database query answering.\n  Our second contribution is a relaxation of the set of polymatroids that gives\nrise to the counting version of the submodular width, denoted by #subw. This\nnew width is sandwiched between the submodular and the fractional hypertree\nwidths. Any FAQ and FAQ-AI over one semiring can be answered in time\nproportional to #subw and respectively to the relaxed version of #subw.\n  We present three applications of our FAQ-AI framework to relational machine\nlearning: k-means clustering, training linear support vector machines, and\ntraining models using non-polynomial loss. These optimization problems can be\nsolved over a database asymptotically faster than computing the join of the\ndatabase relations.",
    "published_date": "2018-12-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB",
      "cs.DS",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09526v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.09338v3",
    "title": "Position Bias Estimation for Unbiased Learning-to-Rank in eCommerce Search",
    "authors": [
      "Grigor Aslanyan",
      "Utkarsh Porwal"
    ],
    "author_ids": [],
    "abstract": "The Unbiased Learning-to-Rank framework has been recently proposed as a\ngeneral approach to systematically remove biases, such as position bias, from\nlearning-to-rank models. The method takes two steps - estimating click\npropensities and using them to train unbiased models. Most common methods\nproposed in the literature for estimating propensities involve some degree of\nintervention in the live search engine. An alternative approach proposed\nrecently uses an Expectation Maximization (EM) algorithm to estimate\npropensities by using ranking features for estimating relevances. In this work\nwe propose a novel method to directly estimate propensities which does not use\nany intervention in live search or rely on modeling relevance. Rather, we take\nadvantage of the fact that the same query-document pair may naturally change\nranks over time. This typically occurs for eCommerce search because of change\nof popularity of items over time, existence of time dependent ranking features,\nor addition or removal of items to the index (an item getting sold or a new\nitem being listed). However, our method is general and can be applied to any\nsearch engine for which the rank of the same document may naturally change over\ntime for the same query. We derive a simple likelihood function that depends on\npropensities only, and by maximizing the likelihood we are able to get\nestimates of the propensities. We apply this method to eBay search data to\nestimate click propensities for web and mobile search and compare these with\nestimates using the EM method. We also use simulated data to show that the\nmethod gives reliable estimates of the \"true\" simulated propensities. Finally,\nwe train an unbiased learning-to-rank model for eBay search using the estimated\npropensities and show that it outperforms both baselines - one without position\nbias correction and one with position bias correction using the EM method.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09338v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.10404v1",
    "title": "Machine learning and AI research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics and Effectiveness",
    "authors": [
      "Sebastian Vollmer",
      "Bilal A. Mateen",
      "Gergo Bohner",
      "Franz J Király",
      "Rayid Ghani",
      "Pall Jonsson",
      "Sarah Cumbers",
      "Adrian Jonas",
      "Katherine S. L. McAllister",
      "Puja Myles",
      "David Granger",
      "Mark Birse",
      "Richard Branson",
      "Karel GM Moons",
      "Gary S Collins",
      "John P. A. Ioannidis",
      "Chris Holmes",
      "Harry Hemingway"
    ],
    "author_ids": [],
    "abstract": "Machine learning (ML), artificial intelligence (AI) and other modern\nstatistical methods are providing new opportunities to operationalize\npreviously untapped and rapidly growing sources of data for patient benefit.\nWhilst there is a lot of promising research currently being undertaken, the\nliterature as a whole lacks: transparency; clear reporting to facilitate\nreplicability; exploration for potential ethical concerns; and, clear\ndemonstrations of effectiveness. There are many reasons for why these issues\nexist, but one of the most important that we provide a preliminary solution for\nhere is the current lack of ML/AI- specific best practice guidance. Although\nthere is no consensus on what best practice looks in this field, we believe\nthat interdisciplinary groups pursuing research and impact projects in the\nML/AI for health domain would benefit from answering a series of questions\nbased on the important issues that exist when undertaking work of this nature.\nHere we present 20 questions that span the entire project life cycle, from\ninception, data analysis, and model evaluation, to implementation, as a means\nto facilitate project planning and post-hoc (structured) independent\nevaluation. By beginning to answer these questions in different settings, we\ncan start to understand what constitutes a good answer, and we expect that the\nresulting discussion will be central to developing an international consensus\nframework for transparent, replicable, ethical and effective research in\nartificial intelligence (AI-TREE) for health.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.AP",
      "stat.ML",
      "68T01"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10404v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.09244v3",
    "title": "Symbolic inductive bias for visually grounded learning of spoken language",
    "authors": [
      "Grzegorz Chrupała"
    ],
    "author_ids": [],
    "abstract": "A widespread approach to processing spoken language is to first automatically\ntranscribe it into text. An alternative is to use an end-to-end approach:\nrecent works have proposed to learn semantic embeddings of spoken language from\nimages with spoken captions, without an intermediate transcription step. We\npropose to use multitask learning to exploit existing transcribed speech within\nthe end-to-end setting. We describe a three-task architecture which combines\nthe objectives of matching spoken captions with corresponding images, speech\nwith text, and text with images. We show that the addition of the speech/text\ntask leads to substantial performance improvements on image retrieval when\ncompared to training the speech/image task in isolation. We conjecture that\nthis is due to a strong inductive bias transcribed speech provides to the\nmodel, and offer supporting evidence for this.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09244v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.09204v1",
    "title": "The future of statistical disclosure control",
    "authors": [
      "Mark Elliot",
      "Josep Domingo-Ferrer"
    ],
    "author_ids": [],
    "abstract": "Statistical disclosure control (SDC) was not created in a single seminal\npaper nor following the invention of a new mathematical technique, rather it\ndeveloped slowly in response to the practical challenges faced by data\npractitioners based at national statistical institutes (NSIs). SDC's subsequent\nemergence as a specialised academic field was an outcome of three interrelated\nsocio-technical changes: (i) the advent of accessible computing as a research\ntool in the 1980s meant that it became possible - and then increasingly easy -\nfor researchers to process larger quantities of data automatically; this\nnaturally increased demand for such data; (ii) it became possible for data\nholders to process and disseminate detailed data as digital files and (iii) the\nnumber of organisations holding data about individuals proliferated. This also\nmeant the number of potential adversaries with the resources to attack any\ngiven dataset increased exponentially. In this article, we describe the state\nof the art for SDC and then discuss the core issues and future challenges. In\nparticular, we touch on SDC and big data, on SDC and machine learning, and on\nSDC and anti-discrimination.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "94A60",
      "K.4.1; D.4.6; H.2.0"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09204v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1901.00429v1",
    "title": "Gender bias in academic recruitment",
    "authors": [
      "Giovanni Abramo",
      "Ciriaco Andrea D'Angelo",
      "Francesco Rosati"
    ],
    "author_ids": [],
    "abstract": "It is well known that women are underrepresented in the academic systems of\nmany countries. Gender discrimination is one of the factors that could\ncontribute to this phenomenon. This study considers a recent national academic\nrecruitment campaign in Italy, examining whether women are subject to more or\nless bias than men. The findings show that no gender-related differences occur\namong the candidates who benefit from positive bias, while among those\ncandidates affected by negative bias, the incidence of women is lower than that\nof men. Among the factors that determine success in a competition for an\nacademic position, the number of the applicant's career years in the same\nuniversity as the committee members assumes greater weight for male candidates\nthan for females. Being of the same gender as the committee president is also a\nfactor that assumes greater weight for male applicants. On the other hand, for\nfemale applicants, the presence of a full professor in the same university with\nthe same family name as the candidate assumes greater weight than for male\ncandidates.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1901.00429v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.09010v1",
    "title": "Face Hallucination Revisited: An Exploratory Study on Dataset Bias",
    "authors": [
      "Klemen Grm",
      "Martin Pernuš",
      "Leo Cluzel",
      "Walter Scheirer",
      "Simon Dobrišek",
      "Vitomir Štruc"
    ],
    "author_ids": [],
    "abstract": "Contemporary face hallucination (FH) models exhibit considerable ability to\nreconstruct high-resolution (HR) details from low-resolution (LR) face images.\nThis ability is commonly learned from examples of corresponding HR-LR image\npairs, created by artificially down-sampling the HR ground truth data. This\ndown-sampling (or degradation) procedure not only defines the characteristics\nof the LR training data, but also determines the type of image degradations the\nlearned FH models are eventually able to handle. If the image characteristics\nencountered with real-world LR images differ from the ones seen during\ntraining, FH models are still expected to perform well, but in practice may not\nproduce the desired results. In this paper we study this problem and explore\nthe bias introduced into FH models by the characteristics of the training data.\nWe systematically analyze the generalization capabilities of several FH models\nin various scenarios, where the image the degradation function does not match\nthe training setup and conduct experiments with synthetically downgraded as\nwell as real-life low-quality images. We make several interesting findings that\nprovide insight into existing problems with FH models and point to future\nresearch directions.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.09010v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.08999v2",
    "title": "Feature-Wise Bias Amplification",
    "authors": [
      "Klas Leino",
      "Emily Black",
      "Matt Fredrikson",
      "Shayak Sen",
      "Anupam Datta"
    ],
    "author_ids": [],
    "abstract": "We study the phenomenon of bias amplification in classifiers, wherein a\nmachine learning model learns to predict classes with a greater disparity than\nthe underlying ground truth. We demonstrate that bias amplification can arise\nvia an inductive bias in gradient descent methods that results in the\noverestimation of the importance of moderately-predictive \"weak\" features if\ninsufficient training data is available. This overestimation gives rise to\nfeature-wise bias amplification -- a previously unreported form of bias that\ncan be traced back to the features of a trained model. Through analysis and\nexperiments, we show that while some bias cannot be mitigated without\nsacrificing accuracy, feature-wise bias amplification can be mitigated through\ntargeted feature selection. We present two new feature selection algorithms for\nmitigating bias amplification in linear models, and show how they can be\nadapted to convolutional neural networks efficiently. Our experiments on\nsynthetic and real data demonstrate that these algorithms consistently lead to\nreduced bias without harming accuracy, in some cases eliminating predictive\nbias altogether while providing modest gains in accuracy.",
    "published_date": "2018-12-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.08999v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.08769v4",
    "title": "What are the biases in my word embedding?",
    "authors": [
      "Nathaniel Swinger",
      "Maria De-Arteaga",
      "Neil Thomas Heffernan IV",
      "Mark DM Leiserson",
      "Adam Tauman Kalai"
    ],
    "author_ids": [],
    "abstract": "This paper presents an algorithm for enumerating biases in word embeddings.\nThe algorithm exposes a large number of offensive associations related to\nsensitive features such as race and gender on publicly available embeddings,\nincluding a supposedly \"debiased\" embedding. These biases are concerning in\nlight of the widespread use of word embeddings. The associations are identified\nby geometric patterns in word embeddings that run parallel between people's\nnames and common lower-case tokens. The algorithm is highly unsupervised: it\ndoes not even require the sensitive features to be pre-specified. This is\ndesirable because: (a) many forms of discrimination--such as racial\ndiscrimination--are linked to social constructs that may vary depending on the\ncontext, rather than to categories with fixed definitions; and (b) it makes it\neasier to identify biases against intersectional groups, which depend on\ncombinations of sensitive features. The inputs to our algorithm are a list of\ntarget tokens, e.g. names, and a word embedding. It outputs a number of Word\nEmbedding Association Tests (WEATs) that capture various biases present in the\ndata. We illustrate the utility of our approach on publicly available word\nembeddings and lists of names, and evaluate its output using crowdsourcing. We\nalso show how removing names may not remove potential proxy bias.",
    "published_date": "2018-12-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.08769v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.08335v2",
    "title": "Towards Value-Sensitive Learning Analytics Design",
    "authors": [
      "Bodong Chen",
      "Haiyi Zhu"
    ],
    "author_ids": [],
    "abstract": "To support ethical considerations and system integrity in learning analytics,\nthis paper introduces two cases of applying the Value Sensitive Design\nmethodology to learning analytics design. The first study applied two methods\nof Value Sensitive Design, namely stakeholder analysis and value analysis, to a\nconceptual investigation of an existing learning analytics tool. This\ninvestigation uncovered a number of values and value tensions, leading to\ndesign trade-offs to be considered in future tool refinements. The second study\nholistically applied Value Sensitive Design to the design of a recommendation\nsystem for the Wikipedia WikiProjects. To proactively consider values among\nstakeholders, we derived a multi-stage design process that included literature\nanalysis, empirical investigations, prototype development, community\nengagement, iterative testing and refinement, and continuous evaluation. By\nreporting on these two cases, this paper responds to a need of practical means\nto support ethical considerations and human values in learning analytics\nsystems. These two cases demonstrate that Value Sensitive Design could be a\nviable approach for balancing a wide range of human values, which tend to\nencompass and surpass ethical issues, in learning analytics design.",
    "published_date": "2018-12-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.08335v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.08247v1",
    "title": "Detecting GAN-generated Imagery using Color Cues",
    "authors": [
      "Scott McCloskey",
      "Michael Albright"
    ],
    "author_ids": [],
    "abstract": "Image forensics is an increasingly relevant problem, as it can potentially\naddress online disinformation campaigns and mitigate problematic aspects of\nsocial media. Of particular interest, given its recent successes, is the\ndetection of imagery produced by Generative Adversarial Networks (GANs), e.g.\n`deepfakes'. Leveraging large training sets and extensive computing resources,\nrecent work has shown that GANs can be trained to generate synthetic imagery\nwhich is (in some ways) indistinguishable from real imagery. We analyze the\nstructure of the generating network of a popular GAN implementation, and show\nthat the network's treatment of color is markedly different from a real camera\nin two ways. We further show that these two cues can be used to distinguish\nGAN-generated imagery from camera imagery, demonstrating effective\ndiscrimination between GAN imagery and real camera images used to train the\nGAN.",
    "published_date": "2018-12-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.08247v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.07715v1",
    "title": "A Tour of Unsupervised Deep Learning for Medical Image Analysis",
    "authors": [
      "Khalid Raza",
      "Nripendra Kumar Singh"
    ],
    "author_ids": [],
    "abstract": "Interpretation of medical images for diagnosis and treatment of complex\ndisease from high-dimensional and heterogeneous data remains a key challenge in\ntransforming healthcare. In the last few years, both supervised and\nunsupervised deep learning achieved promising results in the area of medical\nimaging and image analysis. Unlike supervised learning which is biased towards\nhow it is being supervised and manual efforts to create class label for the\nalgorithm, unsupervised learning derive insights directly from the data itself,\ngroup the data and help to make data driven decisions without any external\nbias. This review systematically presents various unsupervised models applied\nto medical image analysis, including autoencoders and its several variants,\nRestricted Boltzmann machines, Deep belief networks, Deep Boltzmann machine and\nGenerative adversarial network. Future research opportunities and challenges of\nunsupervised techniques for medical image analysis have also been discussed.",
    "published_date": "2018-12-19T00:00:00",
    "year": 2018,
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.07715v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1901.02053v1",
    "title": "Detecting the Trend in Musical Taste over the Decade -- A Novel Feature Extraction Algorithm to Classify Musical Content with Simple Features",
    "authors": [
      "Anish Acharya"
    ],
    "author_ids": [],
    "abstract": "This work proposes a novel feature selection algorithm to classify Songs into\ndifferent groups. Classification of musical content is often a non-trivial job\nand still relatively less explored area. The main idea conveyed in this article\nis to come up with a new feature selection scheme that does the classification\njob elegantly and with high accuracy but with simpler but wisely chosen small\nnumber of features thus being less prone to over-fitting. This uses a very\nbasic general idea about the structure of the audio signal which is generally\nin the shape of a trapezium. So, using this general idea of the Musical\nCommunity we propose three frames to be considered and analyzed for feature\nextraction for each of the audio signal -- opening, stanzas and closing -- and\nit has been established with the help of a lot of experiments that this scheme\nleads to much efficient classification with less complex features in a low\ndimensional feature space thus is also a computationally less expensive method.\nStep by step analysis of feature extraction, feature ranking, dimensionality\nreduction using PCA has been carried in this article. Sequential Forward\nselection (SFS) algorithm is used to explore the most significant features both\nwith the raw Fisher Discriminant Ratio (FDR) and also with the significant\neigen-values after PCA. Also during classification extensive validation and\ncross validation has been done in a monte-carlo manner to ensure validity of\nthe claims.",
    "published_date": "2018-12-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1901.02053v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.07613v1",
    "title": "Proceedings of the Workshop on Social Robots in Therapy: Focusing on Autonomy and Ethical Challenges",
    "authors": [
      "Pablo G. Esteban",
      "Daniel Hernández García",
      "Hee Rin Lee",
      "Pauline Chevalier",
      "Paul Baxter",
      "Cindy L. Bethel",
      "Jainendra Shukla",
      "Joan Oliver",
      "Domènec Puig",
      "Jason R. Wilson",
      "Linda Tickle-Degnen",
      "Madeleine Bartlett",
      "Tony Belpaeme",
      "Serge Thill",
      "Kim Baraka",
      "Francisco S. Melo",
      "Manuela Veloso",
      "David Becerra",
      "Maja Matarić",
      "Eduard Fosch-Villaronga",
      "Jordi Albo-Canals",
      "Gloria Beraldo",
      "Emanuele Menegatti",
      "Valentina De Tommasi",
      "Roberto Mancin",
      "Franca Benini",
      "Zachary Henkel",
      "Kenna Baugus",
      "David C. May",
      "Lucile Dupuy",
      "Wendy A. Rogers",
      "Ronit Feingold Polak",
      "Shelly Levy-Tzedek",
      "Dagoberto Cruz-Sandoval",
      "Jesus Favela",
      "Michelle J. Johnson",
      "Mayumi Mohan",
      "Rochelle Mendonca"
    ],
    "author_ids": [],
    "abstract": "Robot-Assisted Therapy (RAT) has successfully been used in HRI research by\nincluding social robots in health-care interventions by virtue of their ability\nto engage human users both social and emotional dimensions. Research projects\non this topic exist all over the globe in the USA, Europe, and Asia. All of\nthese projects have the overall ambitious goal to increase the well-being of a\nvulnerable population. Typical work in RAT is performed using remote controlled\nrobots; a technique called Wizard-of-Oz (WoZ). The robot is usually controlled,\nunbeknownst to the patient, by a human operator. However, WoZ has been\ndemonstrated to not be a sustainable technique in the long-term. Providing the\nrobots with autonomy (while remaining under the supervision of the therapist)\nhas the potential to lighten the therapists burden, not only in the therapeutic\nsession itself but also in longer-term diagnostic tasks. Therefore, there is a\nneed for exploring several degrees of autonomy in social robots used in\ntherapy. Increasing the autonomy of robots might also bring about a new set of\nchallenges. In particular, there will be a need to answer new ethical questions\nregarding the use of robots with a vulnerable population, as well as a need to\nensure ethically-compliant robot behaviours. Therefore, in this workshop we\nwant to gather findings and explore which degree of autonomy might help to\nimprove health-care interventions and how we can overcome the ethical\nchallenges inherent to it.",
    "published_date": "2018-12-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.07613v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.07283v2",
    "title": "You Cannot Fix What You Cannot Find! An Investigation of Fault Localization Bias in Benchmarking Automated Program Repair Systems",
    "authors": [
      "Kui Liu",
      "Anil Koyuncu",
      "Tegawendé F. Bissyandé",
      "Dongsun Kim",
      "Jacques Klein",
      "Yves Le Traon"
    ],
    "author_ids": [],
    "abstract": "Properly benchmarking Automated Program Repair (APR) systems should\ncontribute to the development and adoption of the research outputs by\npractitioners. To that end, the research community must ensure that it reaches\nsignificant milestones by reliably comparing state-of-the-art tools for a\nbetter understanding of their strengths and weaknesses. In this work, we\nidentify and investigate a practical bias caused by the fault localization (FL)\nstep in a repair pipeline. We propose to highlight the different fault\nlocalization configurations used in the literature, and their impact on APR\nsystems when applied to the Defects4J benchmark. Then, we explore the\nperformance variations that can be achieved by `tweaking' the FL step.\nEventually, we expect to create a new momentum for (1) full disclosure of APR\nexperimental procedures with respect to FL, (2) realistic expectations of\nrepairing bugs in Defects4J, as well as (3) reliable performance comparison\namong the state-of-the-art APR systems, and against the baseline performance\nresults of our thoroughly assessed kPAR repair tool. Our main findings include:\n(a) only a subset of Defects4J bugs can be currently localized by commonly-used\nFL techniques; (b) current practice of comparing state-of-the-art APR systems\n(i.e., counting the number of fixed bugs) is potentially misleading due to the\nbias of FL configurations; and (c) APR authors do not properly qualify their\nperformance achievement with respect to the different tuning parameters\nimplemented in APR systems.",
    "published_date": "2018-12-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.07283v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.07568v1",
    "title": "Uniform Convergence Bounds for Codec Selection",
    "authors": [
      "Clayton Sanford",
      "Cyrus Cousins",
      "Eli Upfal"
    ],
    "author_ids": [],
    "abstract": "We frame the problem of selecting an optimal audio encoding scheme as a\nsupervised learning task. Through uniform convergence theory, we guarantee\napproximately optimal codec selection while controlling for selection bias. We\npresent rigorous statistical guarantees for the codec selection problem that\nhold for arbitrary distributions over audio sequences and for arbitrary quality\nmetrics. Our techniques can thus balance sound quality and compression ratio,\nand use audio samples from the distribution to select a codec that performs\nwell on that particular type of data. The applications of our technique are\nimmense, as it can be used to optimize for quality and bandwidth usage of\nstreaming and other digital media, while significantly outperforming approaches\nthat apply a fixed codec to all data sources.",
    "published_date": "2018-12-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.07568v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06885v2",
    "title": "Optimizing Throughput Performance in Distributed MIMO Wi-Fi Networks using Deep Reinforcement Learning",
    "authors": [
      "Neelakantan Nurani Krishnan",
      "Eric Torkildson",
      "Narayan Mandayam",
      "Dipankar Raychaudhuri",
      "Enrico-Henrik Rantala",
      "Klaus Doppler"
    ],
    "author_ids": [],
    "abstract": "This paper explores the feasibility of leveraging concepts from deep\nreinforcement learning (DRL) to enable dynamic resource management in Wi-Fi\nnetworks implementing distributed multi-user MIMO (D-MIMO). D-MIMO is a\ntechnique by which a set of wireless access points are synchronized and grouped\ntogether to jointly serve multiple users simultaneously. This paper addresses\ntwo dynamic resource management problems pertaining to D-MIMO Wi-Fi networks:\n(i) channel assignment of D-MIMO groups, and (ii) deciding how to cluster\naccess points to form D-MIMO groups, in order to maximize user throughput\nperformance. These problems are known to be NP-Hard and only heuristic\nsolutions exist in literature. We construct a DRL framework through which a\nlearning agent interacts with a D-MIMO Wi-Fi network, learns about the network\nenvironment, and is successful in converging to policies which address the\naforementioned problems. Through extensive simulations and on-line training\nbased on D-MIMO Wi-Fi networks, this paper demonstrates the efficacy of DRL in\nachieving an improvement of 20% in user throughput performance compared to\nheuristic solutions, particularly when network conditions are dynamic. This\nwork also showcases the effectiveness of DRL in meeting multiple network\nobjectives simultaneously, for instance, maximizing throughput of users as well\nas fairness of throughput among them.",
    "published_date": "2018-12-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06885v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06869v1",
    "title": "BriarPatches: Pixel-Space Interventions for Inducing Demographic Parity",
    "authors": [
      "Alexey A. Gritsenko",
      "Alex D'Amour",
      "James Atwood",
      "Yoni Halpern",
      "D. Sculley"
    ],
    "author_ids": [],
    "abstract": "We introduce the BriarPatch, a pixel-space intervention that obscures\nsensitive attributes from representations encoded in pre-trained classifiers.\nThe patches encourage internal model representations not to encode sensitive\ninformation, which has the effect of pushing downstream predictors towards\nexhibiting demographic parity with respect to the sensitive information. The\nnet result is that these BriarPatches provide an intervention mechanism\navailable at user level, and complements prior research on fair representations\nthat were previously only applicable by model developers and ML experts.",
    "published_date": "2018-12-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06869v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06745v1",
    "title": "Trichotomic Argumentation Representation",
    "authors": [
      "Merlin Göttlinger",
      "Lutz Schröder"
    ],
    "author_ids": [],
    "abstract": "The Aristotelian trichotomy distinguishes three aspects of argumentation:\nLogos, Ethos, and Pathos. Even rich argumentation representations like the\nArgument Interchange Format (AIF) are only concerned with capturing the Logos\naspect. Inference Anchoring Theory (IAT) adds the possibility to represent\nethical requirements on the illocutionary force edges linking locutions to\nillocutions, thereby allowing to capture some aspects of ethos. With the recent\nextensions AIF+ and Social Argument Interchange Format (S-AIF), which embed\ndialogue and speakers into the AIF argumentation representation, the basis for\nrepresenting all three aspects identified by Aristotle was formed. In the\npresent work, we develop the Trichotomic Argument Interchange Format (T-AIF),\nbuilding on the idea from S-AIF of adding the speakers to the argumentation\ngraph. We capture Logos in the usual known from AIF+, Ethos in form of weighted\nedges between actors representing trust, and Pathos via weighted edges from\nactors to illocutions representing their level of commitment to the\npropositions. This extended structured argumentation representation opens up\nnew possibilities of defining semantic properties on this rich graph in order\nto characterize and profile the reasoning patterns of the participating actors.",
    "published_date": "2018-12-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LO",
      "68T30"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06745v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06337v3",
    "title": "Origraph: Interactive Network Wrangling",
    "authors": [
      "Alex Bigelow",
      "Carolina Nobre",
      "Miriah Meyer",
      "Alexander Lex"
    ],
    "author_ids": [],
    "abstract": "Networks are a natural way of thinking about many datasets. The data on which\na network is based, however, is rarely collected in a form that suits the\nanalysis process, making it necessary to create and reshape networks. Data\nwrangling is widely acknowledged to be a critical part of the data analysis\npipeline, yet interactive network wrangling has received little attention in\nthe visualization research community. In this paper, we discuss a set of\noperations that are important for wrangling network datasets and introduce a\nvisual data wrangling tool, Origraph, that enables analysts to apply these\noperations to their datasets. Key operations include creating a network from\nsource data such as tables, reshaping a network by introducing new node or edge\nclasses, filtering nodes or edges, and deriving new node or edge attributes.\nOur tool, Origraph, enables analysts to execute these operations with little to\nno programming, and to immediately visualize the results. Origraph provides\nviews to investigate the network model, a sample of the network, and node and\nedge attributes. In addition, we introduce interfaces designed to aid analysts\nin specifying arguments for sensible network wrangling operations. We\ndemonstrate the usefulness of Origraph in two Use Cases: first, we investigate\ngender bias in the film industry, and then the influence of money on the\npolitical support for the war in Yemen.",
    "published_date": "2018-12-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06337v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.06227v1",
    "title": "Balanced Linear Contextual Bandits",
    "authors": [
      "Maria Dimakopoulou",
      "Zhengyuan Zhou",
      "Susan Athey",
      "Guido Imbens"
    ],
    "author_ids": [],
    "abstract": "Contextual bandit algorithms are sensitive to the estimation method of the\noutcome model as well as the exploration method used, particularly in the\npresence of rich heterogeneity or complex outcome models, which can lead to\ndifficult estimation problems along the path of learning. We develop algorithms\nfor contextual bandits with linear payoffs that integrate balancing methods\nfrom the causal inference literature in their estimation to make it less prone\nto problems of estimation bias. We provide the first regret bound analyses for\nlinear contextual bandits with balancing and show that our algorithms match the\nstate of the art theoretical guarantees. We demonstrate the strong practical\nadvantage of balanced contextual bandits on a large number of supervised\nlearning datasets and on a synthetic example that simulates model\nmisspecification and prejudice in the initial training data.",
    "published_date": "2018-12-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06227v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06135v1",
    "title": "Bias Mitigation Post-processing for Individual and Group Fairness",
    "authors": [
      "Pranay K. Lohia",
      "Karthikeyan Natesan Ramamurthy",
      "Manish Bhide",
      "Diptikalyan Saha",
      "Kush R. Varshney",
      "Ruchir Puri"
    ],
    "author_ids": [],
    "abstract": "Whereas previous post-processing approaches for increasing the fairness of\npredictions of biased classifiers address only group fairness, we propose a\nmethod for increasing both individual and group fairness. Our novel framework\nincludes an individual bias detector used to prioritize data samples in a bias\nmitigation algorithm aiming to improve the group fairness measure of disparate\nimpact. We show superior performance to previous work in the combination of\nclassification accuracy, individual fairness and group fairness on several\nreal-world datasets in applications such as credit, employment, and criminal\njustice.",
    "published_date": "2018-12-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06135v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.05988v3",
    "title": "Class Mean Vector Component and Discriminant Analysis",
    "authors": [
      "Alexandros Iosifidis"
    ],
    "author_ids": [],
    "abstract": "The kernel matrix used in kernel methods encodes all the information required\nfor solving complex nonlinear problems defined on data representations in the\ninput space using simple, but implicitly defined, solutions. Spectral analysis\non the kernel matrix defines an explicit nonlinear mapping of the input data\nrepresentations to a subspace of the kernel space, which can be used for\ndirectly applying linear methods. However, the selection of the kernel subspace\nis crucial for the performance of the proceeding processing steps. In this\npaper, we propose a component analysis method for kernel-based dimensionality\nreduction that optimally preserves the pair-wise distances of the class means\nin the feature space. We provide extensive analysis on the connection of the\nproposed criterion to those used in kernel principal component analysis and\nkernel discriminant analysis, leading to a discriminant analysis version of the\nproposed method. Our analysis also provides more insights on the properties of\nthe feature spaces obtained by applying these methods.",
    "published_date": "2018-12-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.05988v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.05980v5",
    "title": "Probabilistic Class-Specific Discriminant Analysis",
    "authors": [
      "Alexandros Iosifidis"
    ],
    "author_ids": [],
    "abstract": "In this paper we formulate a probabilistic model for class-specific\ndiscriminant subspace learning. The proposed model can naturally incorporate\nthe multi-modal structure of the negative class, which is neglected by existing\nclass-specific methods. Moreover, it can be directly used to define a\nclass-specific probabilistic classification rule in the discriminant subspace.\nWe show that existing class-specific discriminant analysis methods are special\ncases of the proposed probabilistic model and, by casting them as probabilistic\nmodels, they can be extended to class-specific classifiers. We illustrate the\nperformance of the proposed model in both verification and classification\nproblems.",
    "published_date": "2018-12-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.05980v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1901.02321v1",
    "title": "Anti-drift in electronic nose via dimensionality reduction: a discriminative subspace projection approach",
    "authors": [
      "Zhengkun Yi",
      "Cheng Li"
    ],
    "author_ids": [],
    "abstract": "Sensor drift is a well-known issue in the field of sensors and measurement\nand has plagued the sensor community for many years. In this paper, we propose\na sensor drift correction method to deal with the sensor drift problem.\nSpecifically, we propose a discriminative subspace projection approach for\nsensor drift reduction in electronic noses. The proposed method inherits the\nmerits of the subspace projection method called domain regularized component\nanalysis. Moreover, the proposed method takes the source data label information\ninto consideration, which minimizes the within-class variance of the projected\nsource samples and at the same time maximizes the between-class variance. The\nlabel information is exploited to avoid overlapping of samples with different\nlabels in the subspace. Experiments on two sensor drift datasets have shown the\neffectiveness of the proposed approach.",
    "published_date": "2018-12-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1901.02321v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.06790v1",
    "title": "Information Diffusion in Social Networks: Friendship Paradox based Models and Statistical Inference",
    "authors": [
      "Vikram Krishnamurthy",
      "Buddhika Nettasinghe"
    ],
    "author_ids": [],
    "abstract": "Dynamic models and statistical inference for the diffusion of information in\nsocial networks is an area which has witnessed remarkable progress in the last\ndecade due to the proliferation of social networks. Modeling and inference of\ndiffusion of information has applications in targeted advertising and\nmarketing, forecasting elections, predicting investor sentiment and identifying\nepidemic outbreaks. This chapter discusses three important aspects related to\ninformation diffusion in social networks: (i) How does observation bias named\nfriendship paradox (a graph theoretic consequence) and monophilic contagion\n(influence of friends of friends) affect information diffusion dynamics. (ii)\nHow can social networks adapt their structural connectivity depending on the\nstate of information diffusion. (iii) How one can estimate the state of the\nnetwork induced by information diffusion. The motivation for all three topics\nconsidered in this chapter stems from recent findings in network science and\nsocial sensing. Further, several directions for future research that arise from\nthese topics are also discussed.",
    "published_date": "2018-12-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06790v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1901.06244v1",
    "title": "Ethical Implications: The ACM/IEEE-CS Software Engineering Code applied to Tesla's \"Autopilot\" System",
    "authors": [
      "Kevin Vincent"
    ],
    "author_ids": [],
    "abstract": "On October 14, 2015, Tesla Inc. an American electric car company, released\nthe initial version of the Autopilot system. This system promised to provide\nsemi-autonomous driving using the existing hardware already installed on Tesla\nvehicles. On March 23rd, 2018, a Tesla vehicle ran into a divider at highway\nspeed, killing the driver. This occurred under the control of the Autopilot\nsystem with no driver intervention. Critics argue that though Tesla gives\ndrivers warnings in its owner's manual, it is ultimately unethical to release a\nsystem that is marketed as an Autopilot yet still makes grave mistakes that any\nhuman driver would not make. Others defend Tesla by stating that their\nadvisories are suitable and that drivers should ultimately be at fault for any\nmistakes of the Autopilot. This paper will scrutinize the ethical implications\nof Tesla's choice to develop, market, and ship a beta product that requires\nextensive testing. It will further analyze the implications of Tesla's\naggressive advertisement of the product under the name Autopilot along with\nassociated marketing materials. By applying the joint ACM/IEEE-CS Software\nEngineering Code of Ethics, this paper will show that Tesla's choices and\nactions during this event are inconsistent with the code and are unethical\nsince they are responsible for adequately testing and honestly marketing their\nproduct.",
    "published_date": "2018-12-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1901.06244v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.10424v4",
    "title": "Measuring Societal Biases from Text Corpora with Smoothed First-Order Co-occurrence",
    "authors": [
      "Navid Rekabsaz",
      "Robert West",
      "James Henderson",
      "Allan Hanbury"
    ],
    "author_ids": [],
    "abstract": "Text corpora are widely used resources for measuring societal biases and\nstereotypes. The common approach to measuring such biases using a corpus is by\ncalculating the similarities between the embedding vector of a word (like\nnurse) and the vectors of the representative words of the concepts of interest\n(such as genders). In this study, we show that, depending on what one aims to\nquantify as bias, this commonly-used approach can introduce non-relevant\nconcepts into bias measurement. We propose an alternative approach to bias\nmeasurement utilizing the smoothed first-order co-occurrence relations between\nthe word and the representative concept words, which we derive by\nreconstructing the co-occurrence estimates inherent in word embedding models.\nWe compare these approaches by conducting several experiments on the scenario\nof measuring gender bias of occupational words, according to an English\nWikipedia corpus. Our experiments show higher correlations of the measured\ngender bias with the actual gender bias statistics of the U.S. job market - on\ntwo collections and with a variety of word embedding models - using the\nfirst-order approach in comparison with the vector similarity-based approaches.\nThe first-order approach also suggests a more severe bias towards female in a\nfew specific occupations than the other approaches.",
    "published_date": "2018-12-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.10424v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.08597v1",
    "title": "Interaction Design for Explainable AI: Workshop Proceedings",
    "authors": [
      "Prashan Madumal",
      "Ronal Singh",
      "Joshua Newn",
      "Frank Vetere"
    ],
    "author_ids": [],
    "abstract": "As artificial intelligence (AI) systems become increasingly complex and\nubiquitous, these systems will be responsible for making decisions that\ndirectly affect individuals and society as a whole. Such decisions will need to\nbe justified due to ethical concerns as well as trust, but achieving this has\nbecome difficult due to the `black-box' nature many AI models have adopted.\nExplainable AI (XAI) can potentially address this problem by explaining its\nactions, decisions and behaviours of the system to users. However, much\nresearch in XAI is done in a vacuum using only the researchers' intuition of\nwhat constitutes a `good' explanation while ignoring the interaction and the\nhuman aspect. This workshop invites researchers in the HCI community and\nrelated fields to have a discourse about human-centred approaches to XAI rooted\nin interaction and to shed light and spark discussion on interaction design\nchallenges in XAI.",
    "published_date": "2018-12-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.08597v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.05362v2",
    "title": "Representation, Justification and Explanation in a Value Driven Agent: An Argumentation-Based Approach",
    "authors": [
      "Beishui Liao",
      "Michael Anderson",
      "Susan Leigh Anderson"
    ],
    "author_ids": [],
    "abstract": "Ethical and explainable artificial intelligence is an interdisciplinary\nresearch area involving computer science, philosophy, logic, the social\nsciences, etc. For an ethical autonomous system, the ability to justify and\nexplain its decision making is a crucial aspect of transparency and\ntrustworthiness. This paper takes a Value Driven Agent (VDA) as an example,\nexplicitly representing implicit knowledge of a machine learning-based\nautonomous agent and using this formalism to justify and explain the decisions\nof the agent. For this purpose, we introduce a novel formalism to describe the\nintrinsic knowledge and solutions of a VDA in each situation. Based on this\nformalism, we formulate an approach to justify and explain the decision-making\nprocess of a VDA, in terms of a typical argumentation formalism,\nAssumption-based Argumentation (ABA). As a result, a VDA in a given situation\nis mapped onto an argumentation framework in which arguments are defined by the\nnotion of deduction. Justified actions with respect to semantics from\nargumentation correspond to solutions of the VDA. The acceptance (rejection) of\narguments and their premises in the framework provides an explanation for why\nan action was selected (or not). Furthermore, we go beyond the existing version\nof VDA, considering not only practical reasoning, but also epistemic reasoning,\nsuch that the inconsistency of knowledge of the VDA can be identified, handled\nand explained.",
    "published_date": "2018-12-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.05362v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.05239v2",
    "title": "Improving fairness in machine learning systems: What do industry practitioners need?",
    "authors": [
      "Kenneth Holstein",
      "Jennifer Wortman Vaughan",
      "Hal Daumé III",
      "Miro Dudík",
      "Hanna Wallach"
    ],
    "author_ids": [],
    "abstract": "The potential for machine learning (ML) systems to amplify social inequities\nand unfairness is receiving increasing popular and academic attention. A surge\nof recent work has focused on the development of algorithmic tools to assess\nand mitigate such unfairness. If these tools are to have a positive impact on\nindustry practice, however, it is crucial that their design be informed by an\nunderstanding of real-world needs. Through 35 semi-structured interviews and an\nanonymous survey of 267 ML practitioners, we conduct the first systematic\ninvestigation of commercial product teams' challenges and needs for support in\ndeveloping fairer ML systems. We identify areas of alignment and disconnect\nbetween the challenges faced by industry practitioners and solutions proposed\nin the fair ML research literature. Based on these findings, we highlight\ndirections for future ML and HCI research that will better address industry\npractitioners' needs.",
    "published_date": "2018-12-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.LG",
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.05239v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.05161v1",
    "title": "Estimating Position Bias without Intrusive Interventions",
    "authors": [
      "Aman Agarwal",
      "Ivan Zaitsev",
      "Xuanhui Wang",
      "Cheng Li",
      "Marc Najork",
      "Thorsten Joachims"
    ],
    "author_ids": [],
    "abstract": "Presentation bias is one of the key challenges when learning from implicit\nfeedback in search engines, as it confounds the relevance signal. While it was\nrecently shown how counterfactual learning-to-rank (LTR) approaches\n\\cite{Joachims/etal/17a} can provably overcome presentation bias when\nobservation propensities are known, it remains to show how to effectively\nestimate these propensities. In this paper, we propose the first method for\nproducing consistent propensity estimates without manual relevance judgments,\ndisruptive interventions, or restrictive relevance modeling assumptions. First,\nwe show how to harvest a specific type of intervention data from historic\nfeedback logs of multiple different ranking functions, and show that this data\nis sufficient for consistent propensity estimation in the position-based model.\nSecond, we propose a new extremum estimator that makes effective use of this\ndata. In an empirical evaluation, we find that the new estimator provides\nsuperior propensity estimates in two real-world systems -- Arxiv Full-text\nSearch and Google Drive Search. Beyond these two points, we find that the\nmethod is robust to a wide range of settings in simulation studies.",
    "published_date": "2018-12-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.05161v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.04814v1",
    "title": "Linking Artificial Intelligence Principles",
    "authors": [
      "Yi Zeng",
      "Enmeng Lu",
      "Cunqing Huangfu"
    ],
    "author_ids": [],
    "abstract": "Artificial Intelligence principles define social and ethical considerations\nto develop future AI. They come from research institutes, government\norganizations and industries. All versions of AI principles are with different\nconsiderations covering different perspectives and making different emphasis.\nNone of them can be considered as complete and can cover the rest AI principle\nproposals. Here we introduce LAIP, an effort and platform for linking and\nanalyzing different Artificial Intelligence Principles. We want to explicitly\nestablish the common topics and links among AI Principles proposed by different\norganizations and investigate on their uniqueness. Based on these efforts, for\nthe long-term future of AI, instead of directly adopting any of the AI\nprinciples, we argue for the necessity of incorporating various AI Principles\ninto a comprehensive framework and focusing on how they can interact and\ncomplete each other.",
    "published_date": "2018-12-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.04814v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.04748v1",
    "title": "An efficient supervised dictionary learning method for audio signal recognition",
    "authors": [
      "Imad Rida",
      "Romain Hérault",
      "Gilles Gasso"
    ],
    "author_ids": [],
    "abstract": "Machine hearing or listening represents an emerging area. Conventional\napproaches rely on the design of handcrafted features specialized to a specific\naudio task and that can hardly generalized to other audio fields. For example,\nMel-Frequency Cepstral Coefficients (MFCCs) and its variants were successfully\napplied to computational auditory scene recognition while Chroma vectors are\ngood at music chord recognition. Unfortunately, these predefined features may\nbe of variable discrimination power while extended to other tasks or even\nwithin the same task due to different nature of clips. Motivated by this need\nof a principled framework across domain applications for machine listening, we\npropose a generic and data-driven representation learning approach. For this\nsake, a novel and efficient supervised dictionary learning method is presented.\nThe method learns dissimilar dictionaries, one per each class, in order to\nextract heterogeneous information for classification. In other words, we are\nseeking to minimize the intra-class homogeneity and maximize class\nseparability. This is made possible by promoting pairwise orthogonality between\nclass specific dictionaries and controlling the sparsity structure of the audio\nclip's decomposition over these dictionaries. The resulting optimization\nproblem is non-convex and solved using a proximal gradient descent method.\nExperiments are performed on both computational auditory scene (East Anglia and\nRouen) and synthetic music chord recognition datasets. Obtained results show\nthat our method is capable to reach state-of-the-art hand-crafted features for\nboth applications.",
    "published_date": "2018-12-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.04748v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.04275v2",
    "title": "Domain-Aware SE Network for Sketch-based Image Retrieval with Multiplicative Euclidean Margin Softmax",
    "authors": [
      "Peng Lu",
      "Gao Huang",
      "Hangyu Lin",
      "Wenming Yang",
      "Guodong Guo",
      "Yanwei Fu"
    ],
    "author_ids": [],
    "abstract": "This paper proposes a novel approach for Sketch-Based Image Retrieval (SBIR),\nfor which the key is to bridge the gap between sketches and photos in terms of\nthe data representation. Inspired by channel-wise attention explored in recent\nyears, we present a Domain-Aware Squeeze-and-Excitation (DASE) network, which\nseamlessly incorporates the prior knowledge of sample sketch or photo into SE\nmodule and make the SE module capable of emphasizing appropriate channels\naccording to domain signal. Accordingly, the proposed network can switch its\nmode to achieve a better domain feature with lower intra-class discrepancy.\nMoreover, while previous works simply focus on minimizing intra-class distance\nand maximizing inter-class distance, we introduce a loss function, named\nMultiplicative Euclidean Margin Softmax (MEMS), which introduces multiplicative\nEuclidean margin into feature space and ensure that the maximum intra-class\ndistance is smaller than the minimum inter-class distance. This facilitates\nlearning a highly discriminative feature space and ensures a more accurate\nimage retrieval result. Extensive experiments are conducted on two widely used\nSBIR benchmark datasets. Our approach achieves better results on both datasets,\nsurpassing the state-of-the-art methods by a large margin.",
    "published_date": "2018-12-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.04275v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.04069v3",
    "title": "Individual Fairness in Hindsight",
    "authors": [
      "Swati Gupta",
      "Vijay Kamble"
    ],
    "author_ids": [],
    "abstract": "Since many critical decisions impacting human lives are increasingly being\nmade by algorithms, it is important to ensure that the treatment of individuals\nunder such algorithms is demonstrably fair under reasonable notions of\nfairness. One compelling notion proposed in the literature is that of\nindividual fairness (IF), which advocates that similar individuals should be\ntreated similarly (Dwork et al. 2012). Originally proposed for offline\ndecisions, this notion does not, however, account for temporal considerations\nrelevant for online decision-making. In this paper, we extend the notion of IF\nto account for the time at which a decision is made, in settings where there\nexists a notion of conduciveness of decisions as perceived by the affected\nindividuals. We introduce two definitions: (i) fairness-across-time (FT) and\n(ii) fairness-in-hindsight (FH). FT is the simplest temporal extension of IF\nwhere treatment of individuals is required to be individually fair relative to\nthe past as well as future, while in FH, we require a one-sided notion of\nindividual fairness that is defined relative to only the past decisions. We\nshow that these two definitions can have drastically different implications in\nthe setting where the principal needs to learn the utility model. Linear regret\nrelative to optimal individually fair decisions is inevitable under FT for\nnon-trivial examples. On the other hand, we design a new algorithm: Cautious\nFair Exploration (CaFE), which satisfies FH and achieves sub-linear regret\nguarantees for a broad range of settings. We characterize lower bounds showing\nthat these guarantees are order-optimal in the worst case. FH can thus be\nembedded as a primary safeguard against unfair discrimination in algorithmic\ndeployments, without hindering the ability to take good decisions in the\nlong-run.",
    "published_date": "2018-12-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.04069v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.03980v1",
    "title": "Building Ethically Bounded AI",
    "authors": [
      "Francesca Rossi",
      "Nicholas Mattei"
    ],
    "author_ids": [],
    "abstract": "The more AI agents are deployed in scenarios with possibly unexpected\nsituations, the more they need to be flexible, adaptive, and creative in\nachieving the goal we have given them. Thus, a certain level of freedom to\nchoose the best path to the goal is inherent in making AI robust and flexible\nenough. At the same time, however, the pervasive deployment of AI in our life,\nwhether AI is autonomous or collaborating with humans, raises several ethical\nchallenges. AI agents should be aware and follow appropriate ethical principles\nand should thus exhibit properties such as fairness or other virtues. These\nethical principles should define the boundaries of AI's freedom and creativity.\nHowever, it is still a challenge to understand how to specify and reason with\nethical boundaries in AI agents and how to combine them appropriately with\nsubjective preferences and goal specifications. Some initial attempts employ\neither a data-driven example-based approach for both, or a symbolic rule-based\napproach for both. We envision a modular approach where any AI technique can be\nused for any of these essential ingredients in decision making or decision\nsupport systems, paired with a contextual approach to define their combination\nand relative weight. In a world where neither humans nor AI systems work in\nisolation, but are tightly interconnected, e.g., the Internet of Things, we\nalso envision a compositional approach to building ethically bounded AI, where\nthe ethical properties of each component can be fruitfully exploited to derive\nthose of the overall system. In this paper we define and motivate the notion of\nethically-bounded AI, we describe two concrete examples, and we outline some\noutstanding challenges.",
    "published_date": "2018-12-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.03980v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.03744v1",
    "title": "Gender and Research Publishing in India: Uniformly high inequality?",
    "authors": [
      "Mike Thelwall",
      "Carol Bailey",
      "Meiko Makita",
      "Pardeep Sud",
      "Devika P. Madalli"
    ],
    "author_ids": [],
    "abstract": "Women's access to academic careers has been historically limited by\ndiscrimination and cultural constraints. Comprehensive information about gender\ninequality within disciplines is needed to understand the problem and target\nremedial action. India is the fifth largest research producer but has a low\ninternational index of gender inequality and so is an important case. This\nstudy assesses gender inequalities in Indian journal article publishing in 2017\nfor 186 research fields. It also seeks overall gender differences in interests\nacross academia by comparing the terms used in 27,710 articles with an Indian\nmale or female first author. The data show that there are at least 1.5 male\nfirst authors per female first author in each of 26 broad fields and 2.8 male\nfirst authors per female first author overall. Compared to the USA, India has a\nmuch lower share of female first authors but smaller variations in gender\ndifferences between broad fields. Dentistry, Economics and Maths are all more\nfemale in India, but Veterinary is much less female than in the USA. There is a\ntendency for males to research thing-oriented topics and for females to\nresearch helping people and some life science topics. More initiatives to\npromote gender equality in science are needed to address the overall imbalance,\nbut care should be taken to avoid creating the larger between-field gender\ndifferences found in the USA.",
    "published_date": "2018-12-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.03744v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.03533v1",
    "title": "Propagation from Deceptive News Sources: Who Shares, How Much, How Evenly, and How Quickly?",
    "authors": [
      "Maria Glenski",
      "Tim Weninger",
      "Svitlana Volkova"
    ],
    "author_ids": [],
    "abstract": "As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.",
    "published_date": "2018-12-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.03533v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.03868v2",
    "title": "Toward the Engineering of Virtuous Machines",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringsjord",
      "Rikhiya Ghosh"
    ],
    "author_ids": [],
    "abstract": "While various traditions under the 'virtue ethics' umbrella have been studied\nextensively and advocated by ethicists, it has not been clear that there exists\na version of virtue ethics rigorous enough to be a target for machine ethics\n(which we take to include the engineering of an ethical sensibility in a\nmachine or robot itself, not only the study of ethics in the humans who might\ncreate artificial agents). We begin to address this by presenting an embryonic\nformalization of a key part of any virtue-ethics theory: namely, the learning\nof virtue by a focus on exemplars of moral virtue. Our work is based in part on\na computational formal logic previously used to formally model other ethical\ntheories and principles therein, and to implement these models in artificial\nagents.",
    "published_date": "2018-12-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.03868v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02953v1",
    "title": "Building Ethics into Artificial Intelligence",
    "authors": [
      "Han Yu",
      "Zhiqi Shen",
      "Chunyan Miao",
      "Cyril Leung",
      "Victor R. Lesser",
      "Qiang Yang"
    ],
    "author_ids": [],
    "abstract": "As artificial intelligence (AI) systems become increasingly ubiquitous, the\ntopic of AI governance for ethical decision-making by AI has captured public\nimagination. Within the AI research community, this topic remains less familiar\nto many researchers. In this paper, we complement existing surveys, which\nlargely focused on the psychological, social and legal discussions of the\ntopic, with an analysis of recent advances in technical solutions for AI\ngovernance. By reviewing publications in leading AI conferences including AAAI,\nAAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four\nareas: 1) exploring ethical dilemmas; 2) individual ethical decision\nframeworks; 3) collective ethical decision frameworks; and 4) ethics in\nhuman-AI interactions. We highlight the intuitions and key techniques used in\neach approach, and discuss promising future research directions towards\nsuccessful integration of ethical AI systems into human societies.",
    "published_date": "2018-12-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02953v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02952v2",
    "title": "From Fair Decision Making to Social Equality",
    "authors": [
      "Hussein Mozannar",
      "Mesrob I. Ohannessian",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "The study of fairness in intelligent decision systems has mostly ignored\nlong-term influence on the underlying population. Yet fairness considerations\n(e.g. affirmative action) have often the implicit goal of achieving balance\namong groups within the population. The most basic notion of balance is\neventual equality between the qualifications of the groups. How can we\nincorporate influence dynamics in decision making? How well do\ndynamics-oblivious fairness policies fare in terms of reaching equality? In\nthis paper, we propose a simple yet revealing model that encompasses (1) a\nselection process where an institution chooses from multiple groups according\nto their qualifications so as to maximize an institutional utility and (2)\ndynamics that govern the evolution of the groups' qualifications according to\nthe imposed policies. We focus on demographic parity as the formalism of\naffirmative action.\n  We then give conditions under which an unconstrained policy reaches equality\non its own. In this case, surprisingly, imposing demographic parity may break\nequality. When it doesn't, one would expect the additional constraint to reduce\nutility, however, we show that utility may in fact increase. In more realistic\nscenarios, unconstrained policies do not lead to equality. In such cases, we\nshow that although imposing demographic parity may remedy it, there is a danger\nthat groups settle at a worse set of qualifications. As a silver lining, we\nalso identify when the constraint not only leads to equality, but also improves\nall groups. This gives quantifiable insight into both sides of the mismatch\nhypothesis. These cases and trade-offs are instrumental in determining when and\nhow imposing demographic parity can be beneficial in selection processes, both\nfor the institution and for society on the long run.",
    "published_date": "2018-12-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML",
      "K.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02952v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02696v3",
    "title": "Differentially Private Fair Learning",
    "authors": [
      "Matthew Jagielski",
      "Michael Kearns",
      "Jieming Mao",
      "Alina Oprea",
      "Aaron Roth",
      "Saeed Sharifi-Malvajerdi",
      "Jonathan Ullman"
    ],
    "author_ids": [],
    "abstract": "Motivated by settings in which predictive models may be required to be\nnon-discriminatory with respect to certain attributes (such as race), but even\ncollecting the sensitive attribute may be forbidden or restricted, we initiate\nthe study of fair learning under the constraint of differential privacy. We\ndesign two learning algorithms that simultaneously promise differential privacy\nand equalized odds, a 'fairness' condition that corresponds to equalizing false\npositive and negative rates across protected groups. Our first algorithm is a\nprivate implementation of the equalized odds post-processing approach of [Hardt\net al., 2016]. This algorithm is appealingly simple, but must be able to use\nprotected group membership explicitly at test time, which can be viewed as a\nform of 'disparate treatment'. Our second algorithm is a differentially private\nversion of the oracle-efficient in-processing approach of [Agarwal et al.,\n2018] that can be used to find the optimal fair classifier, given access to a\nsubroutine that can solve the original (not necessarily fair) learning problem.\nThis algorithm is more complex but need not have access to protected group\nmembership at test time. We identify new tradeoffs between fairness, accuracy,\nand privacy that emerge only when requiring all three properties, and show that\nthese tradeoffs can be milder if group membership may be used at test time. We\nconclude with a brief experimental evaluation.",
    "published_date": "2018-12-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.GT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02696v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02630v2",
    "title": "Assigning Course Schedules: About Preference Elicitation, Fairness, and Truthfulness",
    "authors": [
      "Martin Bichler",
      "Sören Merting",
      "Aykut Uzunoglu"
    ],
    "author_ids": [],
    "abstract": "Course assignment is a wide-spread problem in education and beyond. Often\nstudents have preferences for bundles of course seats or course schedules over\nthe week, which need to be considered. The problem is a challenging distributed\nscheduling task requiring decision support. First-Come First-Served (FCFS) is\nsimple and the most widely used assignment rule in practice, but it leads to\ninefficient outcomes and envy in the allocation. Recent theoretical results\nsuggest alternatives with attractive economic and computational properties.\nBundled Probabilistic Serial (BPS) is a randomized mechanism satisfying ordinal\nefficiency, envy-freeness, and weak strategy-proofness. This mechanism also\nruns in polynomial time, which is important for the large problem instances in\nthe field. We report empirical results from a first implementation of BPS at\nthe Technical University of Munich, which allows us to provide important\nempirical metrics such as the size of the resulting matching, the average rank,\nthe profile, and the popularity of the assignments. These metrics were central\nfor the adoption of BPS. In particular, we compare these metrics to Random\nSerial Dictatorship with bundle bids (BRSD). The BRSD mechanism is used to\nsimulate the wide-spread First-Come First-Served (FCFS) mechanism and it allows\nus to compare FCFS (BRSD) and BPS. While theoretically appealing, preference\nelicitation is a major challenge when considering preferences over\nexponentially many packages. We introduce tools to elicit preferences which\nreduce the number of parameters a student needs to a manageable set. The\napproach together with BPS yields a computationally effective tool to solve\ncourse assignment problems with thousands of students, and possibly provides an\napproach for other distributed scheduling tasks in organizations.",
    "published_date": "2018-12-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.DM",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02630v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.02217v1",
    "title": "Truly Autonomous Machines Are Ethical",
    "authors": [
      "John Hooker"
    ],
    "author_ids": [],
    "abstract": "While many see the prospect of autonomous machines as threatening, autonomy\nmay be exactly what we want in a superintelligent machine. There is a sense of\nautonomy, deeply rooted in the ethical literature, in which an autonomous\nmachine is necessarily an ethical one. Development of the theory underlying\nthis idea not only reveals the advantages of autonomy, but it sheds light on a\nnumber of issues in the ethics of artificial intelligence. It helps us to\nunderstand what sort of obligations we owe to machines, and what obligations\nthey owe to us. It clears up the issue of assigning responsibility to machines\nor their creators. More generally, a concept of autonomy that is adequate to\nboth human and artificial intelligence can lead to a more adequate ethical\ntheory for both.",
    "published_date": "2018-12-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02217v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02215v1",
    "title": "Consistency for 0-1 Programming",
    "authors": [
      "Danial Davarnia",
      "J. N. Hooker"
    ],
    "author_ids": [],
    "abstract": "Concepts of consistency have long played a key role in constraint programming\nbut never developed in integer programming (IP). Consistency nonetheless plays\na role in IP as well. For example, cutting planes can reduce backtracking by\nachieving various forms of consistency as well as by tightening the linear\nprogramming (LP) relaxation. We introduce a type of consistency that is\nparticularly suited for 0-1 programming and develop the associated theory. We\ndefine a 0-1 constraint set as LP-consistent when any partial assignment that\nis consistent with its linear programming relaxation is consistent with the\noriginal 0-1 constraint set. We prove basic properties of LP-consistency,\nincluding its relationship with Chvatal-Gomory cuts and the integer hull. We\nshow that a weak form of LP-consistency can reduce or eliminate backtracking in\na way analogous to k-consistency but is easier to achieve. In so doing, we\nidentify a class of valid inequalities that can be more effective than\ntraditional cutting planes at cutting off infeasible 0-1 partial assignments.",
    "published_date": "2018-12-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02215v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01662v1",
    "title": "Feed-Forward Neural Networks Need Inductive Bias to Learn Equality Relations",
    "authors": [
      "Tillman Weyde",
      "Radha Manisha Kopparti"
    ],
    "author_ids": [],
    "abstract": "Basic binary relations such as equality and inequality are fundamental to\nrelational data structures. Neural networks should learn such relations and\ngeneralise to new unseen data. We show in this study, however, that this\ngeneralisation fails with standard feed-forward networks on binary vectors.\nEven when trained with maximal training data, standard networks do not reliably\ndetect equality.We introduce differential rectifier (DR) units that we add to\nthe network in different configurations. The DR units create an inductive bias\nin the networks, so that they do learn to generalise, even from small numbers\nof examples and we have not found any negative effect of their inclusion in the\nnetwork. Given the fundamental nature of these relations, we hypothesize that\nfeed-forward neural network learning benefits from inductive bias in other\nrelations as well. Consequently, the further development of suitable inductive\nbiases will be beneficial to many tasks in relational learning with neural\nnetworks.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01662v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01389v1",
    "title": "A multi-class structured dictionary learning method using discriminant atom selection",
    "authors": [
      "R. E. Rolón",
      "L. E. Di Persia",
      "R. D. Spies",
      "H. L. Rufiner"
    ],
    "author_ids": [],
    "abstract": "In the last decade, traditional dictionary learning methods have been\nsuccessfully applied to various pattern classification tasks. Although these\nmethods produce sparse representations of signals which are robust against\ndistortions and missing data, such representations quite often turn out to be\nunsuitable if the final objective is signal classification. In order to\novercome or at least to attenuate such a weakness, several new methods which\nincorporate discriminative information into sparse-inducing models have emerged\nin recent years. In particular, methods for discriminative dictionary learning\nhave shown to be more accurate (in terms of signal classification) than the\ntraditional ones, which are only focused on minimizing the total representation\nerror. In this work, we present both a novel multi-class discriminative measure\nand an innovative dictionary learning method. For a given dictionary, this new\nmeasure, which takes into account not only when a particular atom is used for\nrepresenting signals coming from a certain class and the magnitude of its\ncorresponding representation coefficient, but also the effect that such an atom\nhas in the total representation error, is capable of efficiently quantifying\nthe degree of discriminability of each one of the atoms. On the other hand, the\nnew dictionary construction method yields dictionaries which are highly\nsuitable for multi-class classification tasks. Our method was tested with a\nwidely used database for handwritten digit recognition and compared with three\nstate-of-the-art classification methods. The results show that our method\nsignificantly outperforms the other three achieving good recognition rates and\nadditionally, reducing the computational cost of the classifier.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01389v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01388v1",
    "title": "Bad practices in evaluation methodology relevant to class-imbalanced problems",
    "authors": [
      "Jan Brabec",
      "Lukas Machlica"
    ],
    "author_ids": [],
    "abstract": "For research to go in the right direction, it is essential to be able to\ncompare and quantify performance of different algorithms focused on the same\nproblem. Choosing a suitable evaluation metric requires deep understanding of\nthe pursued task along with all of its characteristics. We argue that in the\ncase of applied machine learning, proper evaluation metric is the basic\nbuilding block that should be in the spotlight and put under thorough\nexamination. Here, we address tasks with class imbalance, in which the class of\ninterest is the one with much lower number of samples. We encountered\nnon-insignificant amount of recent papers, in which improper evaluation methods\nare used, borrowed mainly from the field of balanced problems. Such bad\npractices may heavily bias the results in favour of inappropriate algorithms\nand give false expectations of the state of the field.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01388v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01241v1",
    "title": "Hypergraph matching for MU-MIMO user grouping in wireless LANs",
    "authors": [
      "Xiaofu Ma",
      "Qinghai Gao",
      "Vuk Marojevic",
      "Jeffrey H. Reed"
    ],
    "author_ids": [],
    "abstract": "This paper investigates the user grouping problem of downlink wireless local\narea networks (WLANs) with multi-user MIMO (MU-MIMO). Particularly, we focus on\nthe problem of whether single user transmit beamforming (SU-TxBF) or MU-MIMO\nshould be utilized, and how many users and which users should be in a\nmulti-user (MU) group. We formulate the problem for maximizing the system\nthroughput subject to the multi-user air time fairness (MU-ATF) criterion. We\nshow that hypergraphs provide a suitable mathematical model and effective tool\nfor finding the optimal or close to optimal solution. We show that the optimal\ngrouping problem can be solved efficiently for the case where only SU-TxBF and\n2-user MU groups are allowed in the system. For the general case, where any\nnumber of users can be assigned to groups of different sizes, we develop an\nefficient graph matching algorithm (GMA) based on graph theory principles. We\nevaluate the proposed algorithm in terms of system throughput using an 802.11ac\nemulator, which is created using collected channel measurements from an indoor\nenvironment and simulated channel samples for outdoor scenarios. We show that\nour GMA achieves at least 93% of the optimal system throughput in all\nconsidered test cases.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SP",
      "cs.CC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01241v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.01210v2",
    "title": "Zoom-In-to-Check: Boosting Video Interpolation via Instance-level Discrimination",
    "authors": [
      "Liangzhe Yuan",
      "Yibo Chen",
      "Hantian Liu",
      "Tao Kong",
      "Jianbo Shi"
    ],
    "author_ids": [],
    "abstract": "We propose a light-weight video frame interpolation algorithm. Our key\ninnovation is an instance-level supervision that allows information to be\nlearned from the high-resolution version of similar objects. Our experiment\nshows that the proposed method can generate state-of-the-art results across\ndifferent datasets, with fractional computation resources (time and memory) of\ncompeting methods. Given two image frames, a cascade network creates an\nintermediate frame with 1) a flow-warping module that computes coarse\nbi-directional optical flow and creates an interpolated image via flow-based\nwarping, followed by 2) an image synthesis module to make fine-scale\ncorrections. In the learning stage, object detection proposals are generated on\nthe interpolated image.Lower resolution objects are zoomed into, and the\nlearning algorithms using an adversarial loss trained on high-resolution\nobjects to guide the system towards the instance-level refinement corrects\ndetails of object shape and boundaries.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01210v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01198v2",
    "title": "Adversarial Example Decomposition",
    "authors": [
      "Horace He",
      "Aaron Lou",
      "Qingxuan Jiang",
      "Isay Katsman",
      "Serge Belongie",
      "Ser-Nam Lim"
    ],
    "author_ids": [],
    "abstract": "Research has shown that widely used deep neural networks are vulnerable to\ncarefully crafted adversarial perturbations. Moreover, these adversarial\nperturbations often transfer across models. We hypothesize that adversarial\nweakness is composed of three sources of bias: architecture, dataset, and\nrandom initialization. We show that one can decompose adversarial examples into\nan architecture-dependent component, data-dependent component, and\nnoise-dependent component and that these components behave intuitively. For\nexample, noise-dependent components transfer poorly to all other models, while\narchitecture-dependent components transfer better to retrained models with the\nsame architecture. In addition, we demonstrate that these components can be\nrecombined to improve transferability without sacrificing efficacy on the\noriginal model.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01198v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01188v1",
    "title": "Reducing Seed Bias in Respondent-Driven Sampling by Estimating Block Transition Probabilities",
    "authors": [
      "Yilin Zhang",
      "Karl Rohe",
      "Sebastien Roch"
    ],
    "author_ids": [],
    "abstract": "Respondent-driven sampling (RDS) is a popular approach to study marginalized\nor hard-to-reach populations. It collects samples from a networked population\nby incentivizing participants to refer their friends into the study. One major\nchallenge in analyzing RDS samples is seed bias. Seed bias refers to the fact\nthat when the social network is divided into multiple communities (or blocks),\nthe RDS sample might not provide a balanced representation of the different\ncommunities in the population, and such unbalance is correlated with the\ninitial participant (or the seed). In this case, the distributions of\nestimators are typically non-trivial mixtures, which are determined (1) by the\nseed and (2) by how the referrals transition from one block to another. This\npaper shows that (1) block-transition probabilities are easy to estimate with\nhigh accuracy, and (2) we can use these estimated block-transition\nprobabilities to estimate the stationary distribution over blocks and thus, an\nestimate of the block proportions. This stationary distribution on blocks has\npreviously been used in the RDS literature to evaluate whether the sampling\nprocess has appeared to `mix'. We use these estimated block proportions in a\nsimple post-stratified (PS) estimator that greatly diminishes seed bias. By\naggregating over the blocks/strata in this way, we prove that the PS estimator\nis $\\sqrt{n}$-consistent under a Markov model, even when other estimators are\nnot. Simulations show that the PS estimator has smaller Root Mean Square Error\n(RMSE) compared to the state-of-the-art estimators.",
    "published_date": "2018-12-04T00:00:00",
    "year": 2018,
    "categories": [
      "math.ST",
      "cs.SI",
      "math.PR",
      "stat.ME",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01188v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.01716v1",
    "title": "Learning to Unlearn: Building Immunity to Dataset Bias in Medical Imaging Studies",
    "authors": [
      "Ahmed Ashraf",
      "Shehroz Khan",
      "Nikhil Bhagwat",
      "Mallar Chakravarty",
      "Babak Taati"
    ],
    "author_ids": [],
    "abstract": "Medical imaging machine learning algorithms are usually evaluated on a single\ndataset. Although training and testing are performed on different subsets of\nthe dataset, models built on one study show limited capability to generalize to\nother studies. While database bias has been recognized as a serious problem in\nthe computer vision community, it has remained largely unnoticed in medical\nimaging research. Transfer learning thus remains confined to the re-use of\nfeature representations requiring re-training on the new dataset. As a result,\nmachine learning models do not generalize even when trained on imaging datasets\nthat were captured to study the same variable of interest. The ability to\ntransfer knowledge gleaned from one study to another, without the need for\nre-training, if possible, would provide reassurance that the models are\nlearning knowledge fundamental to the problem under study instead of latching\nonto the idiosyncracies of a dataset. In this paper, we situate the problem of\ndataset bias in the context of medical imaging studies. We show empirical\nevidence that such a problem exists in medical datasets. We then present a\nframework to unlearn study membership as a means to handle the problem of\ndatabase bias. Our main idea is to take the data from the original feature\nspace to an intermediate space where the data points are indistinguishable in\nterms of which study they come from, while maintaining the recognition\ncapability with respect to the variable of interest. This will promote models\nwhich learn the more general properties of the etiology under study instead of\naligning to dataset-specific peculiarities. Essentially, our proposed model\nlearns to unlearn the dataset bias.",
    "published_date": "2018-12-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01716v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.00535v3",
    "title": "Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning",
    "authors": [
      "Zhibo Wang",
      "Mengkai Song",
      "Zhifei Zhang",
      "Yang Song",
      "Qian Wang",
      "Hairong Qi"
    ],
    "author_ids": [],
    "abstract": "Federated learning, i.e., a mobile edge computing framework for deep\nlearning, is a recent advance in privacy-preserving machine learning, where the\nmodel is trained in a decentralized manner by the clients, i.e., data curators,\npreventing the server from directly accessing those private data from the\nclients. This learning mechanism significantly challenges the attack from the\nserver side. Although the state-of-the-art attacking techniques that\nincorporated the advance of Generative adversarial networks (GANs) could\nconstruct class representatives of the global data distribution among all\nclients, it is still challenging to distinguishably attack a specific client\n(i.e., user-level privacy leakage), which is a stronger privacy threat to\nprecisely recover the private data from a specific client. This paper gives the\nfirst attempt to explore user-level privacy leakage against the federated\nlearning by the attack from a malicious server. We propose a framework\nincorporating GAN with a multi-task discriminator, which simultaneously\ndiscriminates category, reality, and client identity of input samples. The\nnovel discrimination on client identity enables the generator to recover user\nspecified private data. Unlike existing works that tend to interfere the\ntraining process of the federated learning, the proposed method works\n\"invisibly\" on the server side. The experimental results demonstrate the\neffectiveness of the proposed attacking approach and the superior to the\nstate-of-the-art.",
    "published_date": "2018-12-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.00535v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.01504v4",
    "title": "Fighting Fire with Fire: Using Antidote Data to Improve Polarization and Fairness of Recommender Systems",
    "authors": [
      "Bashir Rastegarpanah",
      "Krishna P. Gummadi",
      "Mark Crovella"
    ],
    "author_ids": [],
    "abstract": "The increasing role of recommender systems in many aspects of society makes\nit essential to consider how such systems may impact social good. Various\nmodifications to recommendation algorithms have been proposed to improve their\nperformance for specific socially relevant measures. However, previous\nproposals are often not easily adapted to different measures, and they\ngenerally require the ability to modify either existing system inputs, the\nsystem's algorithm, or the system's outputs. As an alternative, in this paper\nwe introduce the idea of improving the social desirability of recommender\nsystem outputs by adding more data to the input, an approach we view as\nproviding `antidote' data to the system. We formalize the antidote data\nproblem, and develop optimization-based solutions. We take as our model system\nthe matrix factorization approach to recommendation, and we propose a set of\nmeasures to capture the polarization or fairness of recommendations. We then\nshow how to generate antidote data for each measure, pointing out a number of\ncomputational efficiencies, and discuss the impact on overall system accuracy.\nOur experiments show that a modest budget for antidote data can lead to\nsignificant improvements in the polarization or fairness of recommendations.",
    "published_date": "2018-12-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.01504v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.00993v2",
    "title": "Nonlinear Stochastic Position and Attitude Filter on the Special Euclidean Group 3",
    "authors": [
      "Hashim A. Hashim",
      "Lyndon J. Brown",
      "Kenneth McIsaac"
    ],
    "author_ids": [],
    "abstract": "This paper formulates the pose estimation problem as nonlinear stochastic\nfilter kinematics evolved directly on the Special Euclidean Group SE(3).\nProposed filter guarantees that the errors present in position and Rodriguez\nvector estimates are semi-globally uniformly ultimately bounded (SGUUB) in mean\nsquare, and that they converge to small neighborhood of the origin in\nprobability. Simulation results show the robustness and effectiveness of the\nproposed filter in presence of high levels of noise and bias associated with\nthe velocity vector as well as body-frame measurements. Keywords: Pose\nestimator, pose observer, attitude estimate, control, estimator, observer,\nNonlinear stochastic pose filter, stochastic differential equations, Brownian\nmotion process, Ito, Stratonovich, Wong Zakai, unit-quaternion, special\northogonal group, homogeneous transformation matrix, complimentary filter,\nEuler angles, Angle-axis, mapping, Parameterization, Representation, Robust,\nMultiplicative Extended Kalman Filter, Unscented Kalman Filter, Particle\nfilter, KF, EKF, IEKF, UKF, MEKF, partial derivative, small, dynamics,\nequilibrium, asymptotic, covariance, expected value, zero, unknown,\ntime-varying, global, semi-global, stable, stability, uncertain, Gaussian,\ncolored, white, noise, vectorial measurement, vector measurement, translational\nvelocity, angular velocity, singular value decomposition, rotational matrix,\nidentity, deterministic, comparison, inertial frame, rigid body, three\ndimensional, 3D, space, adjoint, Lie group, projection, landmark, feature,\nGyroscope, micro electromechanical systems, Inertial measurement units, sensor,\nIMUs, Fixed, moving, orientation, Roll, Pitch, Yaw, SVD, UAVs, QUAV, unmanned,\nunderwater vehicle, robot, Robotic System, Spacecraft, quadrotor, quadcopter,\nintegral, advantage, disadvantage, Comparative study, Review, Overview, Survey,\nautonomous, xyz, axis, SO(3), SE(3).",
    "published_date": "2018-12-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY",
      "math.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.00993v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.02573v2",
    "title": "Probabilistic Verification of Fairness Properties via Concentration",
    "authors": [
      "Osbert Bastani",
      "Xin Zhang",
      "Armando Solar-Lezama"
    ],
    "author_ids": [],
    "abstract": "As machine learning systems are increasingly used to make real world legal\nand financial decisions, it is of paramount importance that we develop\nalgorithms to verify that these systems do not discriminate against minorities.\nWe design a scalable algorithm for verifying fairness specifications. Our\nalgorithm obtains strong correctness guarantees based on adaptive concentration\ninequalities; such inequalities enable our algorithm to adaptively take samples\nuntil it has enough data to make a decision. We implement our algorithm in a\ntool called VeriFair, and show that it scales to large machine learning models,\nincluding a deep recurrent neural network that is more than five orders of\nmagnitude larger than the largest previously-verified neural network. While our\ntechnique only gives probabilistic guarantees due to the use of random samples,\nwe show that we can choose the probability of error to be extremely small.",
    "published_date": "2018-12-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02573v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.00991v1",
    "title": "Analyzing Partitioned FAIR Health Data Responsibly",
    "authors": [
      "Chang Sun",
      "Lianne Ippel",
      "Birgit Wouters",
      "Johan van Soest",
      "Alexander Malic",
      "Onaopepo Adekunle",
      "Bob van den Berg",
      "Marco Puts",
      "Ole Mussmann",
      "Annemarie Koster",
      "Carla van der Kallen",
      "David Townend",
      "Andre Dekker",
      "Michel Dumontier"
    ],
    "author_ids": [],
    "abstract": "It is widely anticipated that the use of health-related big data will enable\nfurther understanding and improvements in human health and wellbeing. Our\ncurrent project, funded through the Dutch National Research Agenda, aims to\nexplore the relationship between the development of diabetes and socio-economic\nfactors such as lifestyle and health care utilization. The analysis involves\ncombining data from the Maastricht Study (DMS), a prospective clinical study,\nand data collected by Statistics Netherlands (CBS) as part of its routine\noperations. However, a wide array of social, legal, technical, and scientific\nissues hinder the analysis. In this paper, we describe these challenges and our\nprogress towards addressing them.",
    "published_date": "2018-12-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "E.1; E.3; H.2.4; H.2.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.00991v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.06594v1",
    "title": "Computational EEG in Personalized Medicine: A study in Parkinson's Disease",
    "authors": [
      "Sebastian Mathias Keller",
      "Maxim Samarin",
      "Antonia Meyer",
      "Vitalii Kosak",
      "Ute Gschwandtner",
      "Peter Fuhr",
      "Volker Roth"
    ],
    "author_ids": [],
    "abstract": "Recordings of electrical brain activity carry information about a person's\ncognitive health. For recording EEG signals, a very common setting is for a\nsubject to be at rest with its eyes closed. Analysis of these recordings often\ninvolve a dimensionality reduction step in which electrodes are grouped into 10\nor more regions (depending on the number of electrodes available). Then an\naverage over each group is taken which serves as a feature in subsequent\nevaluation. Currently, the most prominent features used in clinical practice\nare based on spectral power densities. In our work we consider a simplified\ngrouping of electrodes into two regions only. In addition to spectral features\nwe introduce a secondary, non-redundant view on brain activity through the lens\nof Tsallis Entropy $S_{q=2}$. We further take EEG measurements not only in an\neyes closed (ec) but also in an eyes open (eo) state. For our cohort of healthy\ncontrols (HC) and individuals suffering from Parkinson's disease (PD), the\nquestion we are asking is the following: How well can one discriminate between\nHC and PD within this simplified, binary grouping? This question is motivated\nby the commercial availability of inexpensive and easy to use portable EEG\ndevices. If enough information is retained in this binary grouping, then such\nsimple devices could potentially be used as personal monitoring tools, as\nstandard screening tools by general practitioners or as digital biomarkers for\neasy long term monitoring during neurological studies.",
    "published_date": "2018-12-02T00:00:00",
    "year": 2018,
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "eess.SP",
      "q-bio.QM",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.06594v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.00194v2",
    "title": "Racial Faces in-the-Wild: Reducing Racial Bias by Information Maximization Adaptation Network",
    "authors": [
      "Mei Wang",
      "Weihong Deng",
      "Jiani Hu",
      "Xunqiang Tao",
      "Yaohai Huang"
    ],
    "author_ids": [],
    "abstract": "Racial bias is an important issue in biometric, but has not been thoroughly\nstudied in deep face recognition. In this paper, we first contribute a\ndedicated dataset called Racial Faces in-the-Wild (RFW) database, on which we\nfirmly validated the racial bias of four commercial APIs and four\nstate-of-the-art (SOTA) algorithms. Then, we further present the solution using\ndeep unsupervised domain adaptation and propose a deep information maximization\nadaptation network (IMAN) to alleviate this bias by using Caucasian as source\ndomain and other races as target domains. This unsupervised method\nsimultaneously aligns global distribution to decrease race gap at domain-level,\nand learns the discriminative target representations at cluster level. A novel\nmutual information loss is proposed to further enhance the discriminative\nability of network output without label information. Extensive experiments on\nRFW, GBU, and IJB-A databases show that IMAN successfully learns features that\ngeneralize well across different races and across different databases.",
    "published_date": "2018-12-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.00194v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12801v1",
    "title": "Generative Models for Simulating Mobility Trajectories",
    "authors": [
      "Vaibhav Kulkarni",
      "Natasa Tagasovska",
      "Thibault Vatter",
      "Benoit Garbinato"
    ],
    "author_ids": [],
    "abstract": "Mobility datasets are fundamental for evaluating algorithms pertaining to\ngeographic information systems and facilitating experimental reproducibility.\nBut privacy implications restrict sharing such datasets, as even aggregated\nlocation-data is vulnerable to membership inference attacks. Current synthetic\nmobility dataset generators attempt to superficially match a priori modeled\nmobility characteristics which do not accurately reflect the real-world\ncharacteristics. Modeling human mobility to generate synthetic yet semantically\nand statistically realistic trajectories is therefore crucial for publishing\ntrajectory datasets having satisfactory utility level while preserving user\nprivacy. Specifically, long-range dependencies inherent to human mobility are\nchallenging to capture with both discriminative and generative models. In this\npaper, we benchmark the performance of recurrent neural architectures (RNNs),\ngenerative adversarial networks (GANs) and nonparametric copulas to generate\nsynthetic mobility traces. We evaluate the generated trajectories with respect\nto their geographic and semantic similarity, circadian rhythms, long-range\ndependencies, training and generation time. We also include two sample tests to\nassess statistical similarity between the observed and simulated distributions,\nand we analyze the privacy tradeoffs with respect to membership inference and\nlocation-sequence attacks.",
    "published_date": "2018-11-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12801v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12695v1",
    "title": "An Efficient Image Retrieval Based on Fusion of Low-Level Visual Features",
    "authors": [
      "Atif Nazir",
      "Kashif Nazir"
    ],
    "author_ids": [],
    "abstract": "Due to an increase in the number of image achieves, Content-Based Image\nRetrieval (CBIR) has gained attention for research community of computer\nvision. The image visual contents are represented in a feature space in the\nform of numerical values that is considered as a feature vector of image.\nImages belonging to different classes may contain the common visuals and shapes\nthat can result in the closeness of computed feature space of two different\nimages belonging to separate classes. Due to this reason, feature extraction\nand image representation is selected with appropriate features as it directly\naffects the performance of image retrieval system. The commonly used visual\nfeatures are image spatial layout, color, texture and shape. Image feature\nspace is combined to achieve the discriminating ability that is not possible to\nachieve when the features are used separately. Due to this reason, in this\npaper, we aim to explore the low-level feature combination that are based on\ncolor and shape features. We selected color moments and color histogram to\nrepresent color while shape is represented by using invariant moments. We\nselected this combination, as these features are reported intuitive, compact\nand robust for image representation. We evaluated the performance of our\nproposed research by using the Corel, Coil and Ground Truth (GT) image\ndatasets. We evaluated the proposed low-level feature fusion by calculating the\nprecision, recall and time required for feature extraction. The precision,\nrecall and feature extraction values obtained from the proposed low-level\nfeature fusion outperforms the existing research of CBIR.",
    "published_date": "2018-11-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12695v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12642v1",
    "title": "AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG Digital Biomarker Development Using Information Geometry Machine Learning Methods",
    "authors": [
      "Tomasz M. Rutkowski",
      "Qibin Zhao",
      "Masao S. Abe",
      "Mihoko Otake"
    ],
    "author_ids": [],
    "abstract": "Dementia and especially Alzheimer's disease (AD) are the most common causes\nof cognitive decline in elderly people. A spread of the above mentioned mental\nhealth problems in aging societies is causing a significant medical and\neconomic burden in many countries around the world. According to a recent World\nHealth Organization (WHO) report, it is approximated that currently, worldwide,\nabout 47 million people live with a dementia spectrum of neurocognitive\ndisorders. This number is expected to triple by 2050, which calls for possible\napplication of AI-based technologies to support an early screening for\npreventive interventions and a subsequent mental wellbeing monitoring as well\nas maintenance with so-called digital-pharma or beyond a pill therapeutical\napproaches. This paper discusses our attempt and preliminary results of\nbrainwave (EEG) techniques to develop digital biomarkers for dementia progress\ndetection and monitoring. We present an information geometry-based\nclassification approach for automatic EEG-derived event related responses\n(ERPs) discrimination of low versus high task-load auditory or tactile stimuli\nrecognition, of which amplitude and latency variabilities are similar to those\nin dementia. The discussed approach is a step forward to develop AI, and\nespecially machine learning (ML) approaches, for the subsequent application to\nmild-cognitive impairment (MCI) and AD diagnostics.",
    "published_date": "2018-11-30T00:00:00",
    "year": 2018,
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12642v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12611v1",
    "title": "Virtual Class Enhanced Discriminative Embedding Learning",
    "authors": [
      "Binghui Chen",
      "Weihong Deng",
      "Haifeng Shen"
    ],
    "author_ids": [],
    "abstract": "Recently, learning discriminative features to improve the recognition\nperformances gradually becomes the primary goal of deep learning, and numerous\nremarkable works have emerged. In this paper, we propose a novel yet extremely\nsimple method \\textbf{Virtual Softmax} to enhance the discriminative property\nof learned features by injecting a dynamic virtual negative class into the\noriginal softmax. Injecting virtual class aims to enlarge inter-class margin\nand compress intra-class distribution by strengthening the decision boundary\nconstraint. Although it seems weird to optimize with this additional virtual\nclass, we show that our method derives from an intuitive and clear motivation,\nand it indeed encourages the features to be more compact and separable. This\npaper empirically and experimentally demonstrates the superiority of Virtual\nSoftmax, improving the performances on a variety of object classification and\nface verification tasks.",
    "published_date": "2018-11-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12611v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12450v3",
    "title": "Planning UAV Activities for Efficient User Coverage in Disaster Areas",
    "authors": [
      "Francesco Malandrino",
      "Carla-Fabiana Chiasserini",
      "Claudio Casetti",
      "Luca Chiaraviglio",
      "Andrea Senacheribbe"
    ],
    "author_ids": [],
    "abstract": "Climate changes brought about by global warming as well as man-made\nenvironmental changes are often the cause of sever natural disasters. ICT,\nwhich is itself responsible for global warming due to its high carbon\nfootprint, can play a role in alleviating the consequences of such hazards by\nproviding reliable, resilient means of communication during a disaster crisis.\nIn this paper, we explore the provision of wireless coverage through UAVs\n(Unmanned Aerial Vehicles) to complement, or replace, the traditional\ncommunication infrastructure. The use of UAVs is indeed crucial in emergency\nscenarios, as they allow for the quick and easy deployment of micro and pico\ncellular base stations where needed. We characterize the movements of UAVs and\ndefine an optimization problem to determine the best UAV coverage that\nmaximizes the user throughput, while maintaining fairness across the different\nparts of the geographical area that has been affected by the disaster. To\nevaluate our strategy, we simulate a flooding in San Francisco and the car\ntraffic resulting from people seeking safety on higher ground.",
    "published_date": "2018-11-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12450v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.12349v2",
    "title": "Combating Fake News with Interpretable News Feed Algorithms",
    "authors": [
      "Sina Mohseni",
      "Eric Ragan"
    ],
    "author_ids": [],
    "abstract": "Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.",
    "published_date": "2018-11-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12349v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12254v1",
    "title": "The Effect of Heterogeneous Data for Alzheimer's Disease Detection from Speech",
    "authors": [
      "Aparna Balagopalan",
      "Jekaterina Novikova",
      "Frank Rudzicz",
      "Marzyeh Ghassemi"
    ],
    "author_ids": [],
    "abstract": "Speech datasets for identifying Alzheimer's disease (AD) are generally\nrestricted to participants performing a single task, e.g. describing an image\nshown to them. As a result, models trained on linguistic features derived from\nsuch datasets may not be generalizable across tasks. Building on prior work\ndemonstrating that same-task data of healthy participants helps improve AD\ndetection on a single-task dataset of pathological speech, we augment an\nAD-specific dataset consisting of subjects describing a picture with multi-task\nhealthy data. We demonstrate that normative data from multiple speech-based\ntasks helps improve AD detection by up to 9%. Visualization of decision\nboundaries reveals that models trained on a combination of structured picture\ndescriptions and unstructured conversational speech have the least out-of-task\nerror and show the most potential to generalize to multiple tasks. We analyze\nthe impact of age of the added samples and if they affect fairness in\nclassification. We also provide explanations for a possible inductive bias\neffect across tasks using model-agnostic feature anchors. This work highlights\nthe need for heterogeneous datasets for encoding changes in multiple facets of\ncognition and for developing a task-independent AD detection model.",
    "published_date": "2018-11-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12254v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12231v3",
    "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
    "authors": [
      "Robert Geirhos",
      "Patricia Rubisch",
      "Claudio Michaelis",
      "Matthias Bethge",
      "Felix A. Wichmann",
      "Wieland Brendel"
    ],
    "author_ids": [],
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.",
    "published_date": "2018-11-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12231v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11819v2",
    "title": "Unsupervised Meta-Learning For Few-Shot Image Classification",
    "authors": [
      "Siavash Khodadadeh",
      "Ladislau Bölöni",
      "Mubarak Shah"
    ],
    "author_ids": [],
    "abstract": "Few-shot or one-shot learning of classifiers requires a significant inductive\nbias towards the type of task to be learned. One way to acquire this is by\nmeta-learning on tasks similar to the target task. In this paper, we propose\nUMTRA, an algorithm that performs unsupervised, model-agnostic meta-learning\nfor classification tasks. The meta-learning step of UMTRA is performed on a\nflat collection of unlabeled images. While we assume that these images can be\ngrouped into a diverse set of classes and are relevant to the target task, no\nexplicit information about the classes or any labels are needed. UMTRA uses\nrandom sampling and augmentation to create synthetic training tasks for\nmeta-learning phase. Labels are only needed at the final target task learning\nstep, and they can be as little as one sample per class. On the Omniglot and\nMini-Imagenet few-shot learning benchmarks, UMTRA outperforms every tested\napproach based on unsupervised learning of representations, while alternating\nfor the best performance with the recent CACTUs algorithm. Compared to\nsupervised model-agnostic meta-learning approaches, UMTRA trades off some\nclassification accuracy for a reduction in the required labels of several\norders of magnitude.",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11819v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11668v1",
    "title": "Racial categories in machine learning",
    "authors": [
      "Sebastian Benthall",
      "Bruce D. Haynes"
    ],
    "author_ids": [],
    "abstract": "Controversies around race and machine learning have sparked debate among\ncomputer scientists over how to design machine learning systems that guarantee\nfairness. These debates rarely engage with how racial identity is embedded in\nour social experience, making for sociological and psychological complexity.\nThis complexity challenges the paradigm of considering fairness to be a formal\nproperty of supervised learning with respect to protected personal attributes.\nRacial identity is not simply a personal subjective quality. For people labeled\n\"Black\" it is an ascribed political category that has consequences for social\ndifferentiation embedded in systemic patterns of social inequality achieved\nthrough both social and spatial segregation. In the United States, racial\nclassification can best be understood as a system of inherently unequal status\ncategories that places whites as the most privileged category while signifying\nthe Negro/black category as stigmatized. Social stigma is reinforced through\nthe unequal distribution of societal rewards and goods along racial lines that\nis reinforced by state, corporate, and civic institutions and practices. This\ncreates a dilemma for society and designers: be blind to racial group\ndisparities and thereby reify racialized social inequality by no longer\nmeasuring systemic inequality, or be conscious of racial categories in a way\nthat itself reifies race. We propose a third option. By preceding group\nfairness interventions with unsupervised learning to dynamically detect\npatterns of segregation, machine learning systems can mitigate the root cause\nof social disparities, social segregation and stratification, without further\nanchoring status categories of disadvantage.",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11668v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11611v2",
    "title": "A Generative Appearance Model for End-to-end Video Object Segmentation",
    "authors": [
      "Joakim Johnander",
      "Martin Danelljan",
      "Emil Brissman",
      "Fahad Shahbaz Khan",
      "Michael Felsberg"
    ],
    "author_ids": [],
    "abstract": "One of the fundamental challenges in video object segmentation is to find an\neffective representation of the target and background appearance. The best\nperforming approaches resort to extensive fine-tuning of a convolutional neural\nnetwork for this purpose. Besides being prohibitively expensive, this strategy\ncannot be truly trained end-to-end since the online fine-tuning procedure is\nnot integrated into the offline training of the network.\n  To address these issues, we propose a network architecture that learns a\npowerful representation of the target and background appearance in a single\nforward pass. The introduced appearance module learns a probabilistic\ngenerative model of target and background feature distributions. Given a new\nimage, it predicts the posterior class probabilities, providing a highly\ndiscriminative cue, which is processed in later network modules. Both the\nlearning and prediction stages of our appearance module are fully\ndifferentiable, enabling true end-to-end training of the entire segmentation\npipeline. Comprehensive experiments demonstrate the effectiveness of the\nproposed approach on three video object segmentation benchmarks. We close the\ngap to approaches based on online fine-tuning on DAVIS17, while operating at 15\nFPS on a single GPU. Furthermore, our method outperforms all published\napproaches on the large-scale YouTube-VOS dataset.",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11611v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1812.02308v1",
    "title": "On the Inductive Bias of Word-Character-Level Multi-Task Learning for Speech Recognition",
    "authors": [
      "Jan Kremer",
      "Lasse Borgholt",
      "Lars Maaløe"
    ],
    "author_ids": [],
    "abstract": "End-to-end automatic speech recognition (ASR) commonly transcribes audio\nsignals into sequences of characters while its performance is evaluated by\nmeasuring the word-error rate (WER). This suggests that predicting sequences of\nwords directly may be helpful instead. However, training with word-level\nsupervision can be more difficult due to the sparsity of examples per label\nclass. In this paper we analyze an end-to-end ASR model that combines a\nword-and-character representation in a multi-task learning (MTL) framework. We\nshow that it improves on the WER and study how the word-level model can benefit\nfrom character-level supervision by analyzing the learned inductive preference\nbias of each model component empirically. We find that by adding\ncharacter-level supervision, the MTL model interpolates between recognizing\nmore frequent words (preferred by the word-level model) and shorter words\n(preferred by the character-level model).",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02308v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12189v2",
    "title": "The validity of RFID badges measuring face-to-face interactions",
    "authors": [
      "Timon Elmer",
      "Krishna Chaitanya",
      "Prateek Purwar",
      "Christoph Stadtfeld"
    ],
    "author_ids": [],
    "abstract": "Face-to-face interactions are important for a variety of individual behaviors\nand outcomes. In recent years a number of human sensor technologies have been\nproposed to incorporate direct observations in behavioral studies of\nface-to-face interactions. One of the most promising emerging technologies are\nactive Radio Frequency Identification (RFID) badges. They are increasingly\napplied in behavioral studies because of their low costs, straightforward\napplicability, and moderate ethical concerns. However, despite the attention\nthat RFID badges have recently received, there is a lack of systematic tests on\nhow valid RFID badges are in measuring face-to-face interaction. With two\nstudies we aim to fill this gap. Study 1 (N = 11) compares how data assessed\nwith RFID badges correspond with video data of the same interactions (construct\nvalidity) and how this fit can be improved using straightforward data\nprocessing strategies. The analyses show that the RFID badges have a\nsensitivity of 50% that can be enhanced to 65% when flickering signals with\ngaps of less than 75 seconds are interpolated. The specificity is relatively\nless affected by this interpolation process (before interpolation 97%, after\ninterpolation 94.7%) - resulting in an improved accuracy of the measurement. In\nStudy 2 (N = 73) we show that self-report data of social interactions\ncorrespond highly with data gathered with the RFID badges (criterion validity).",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12189v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.11419v2",
    "title": "Mixture Martingales Revisited with Applications to Sequential Tests and Confidence Intervals",
    "authors": [
      "Emilie Kaufmann",
      "Wouter Koolen"
    ],
    "author_ids": [],
    "abstract": "This paper presents new deviation inequalities that are valid uniformly in\ntime under adaptive sampling in a multi-armed bandit model. The deviations are\nmeasured using the Kullback-Leibler divergence in a given one-dimensional\nexponential family, and may take into account several arms at a time. They are\nobtained by constructing for each arm a mixture martingale based on a\nhierarchical prior, and by multiplying those martingales. Our deviation\ninequalities allow us to analyze stopping rules based on generalized likelihood\nratios for a large class of sequential identification problems, and to\nconstruct tight confidence intervals for some functions of the means of the\narms.",
    "published_date": "2018-11-28T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11419v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11310v3",
    "title": "Using Attribution to Decode Dataset Bias in Neural Network Models for Chemistry",
    "authors": [
      "Kevin McCloskey",
      "Ankur Taly",
      "Federico Monti",
      "Michael P. Brenner",
      "Lucy Colwell"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks have achieved state of the art accuracy at classifying\nmolecules with respect to whether they bind to specific protein targets. A key\nbreakthrough would occur if these models could reveal the fragment\npharmacophores that are causally involved in binding. Extracting chemical\ndetails of binding from the networks could potentially lead to scientific\ndiscoveries about the mechanisms of drug actions. But doing so requires shining\nlight into the black box that is the trained neural network model, a task that\nhas proved difficult across many domains. Here we show how the binding\nmechanism learned by deep neural network models can be interrogated, using a\nrecently described attribution method. We first work with carefully constructed\nsynthetic datasets, in which the 'fragment logic' of binding is fully known. We\nfind that networks that achieve perfect accuracy on held out test datasets\nstill learn spurious correlations due to biases in the datasets, and we are\nable to exploit this non-robustness to construct adversarial examples that fool\nthe model. The dataset bias makes these models unreliable for accurately\nrevealing information about the mechanisms of protein-ligand binding. In light\nof our findings, we prescribe a test that checks for dataset bias given a\nhypothesis. If the test fails, it indicates that either the model must be\nsimplified or regularized and/or that the training dataset requires\naugmentation.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11310v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11298v3",
    "title": "Exploring Restart Distributions",
    "authors": [
      "Arash Tavakoli",
      "Vitaly Levdik",
      "Riashat Islam",
      "Christopher M. Smith",
      "Petar Kormushev"
    ],
    "author_ids": [],
    "abstract": "We consider the generic approach of using an experience memory to help\nexploration by adapting a restart distribution. That is, given the capacity to\nreset the state with those corresponding to the agent's past observations, we\nhelp exploration by promoting faster state-space coverage via restarting the\nagent from a more diverse set of initial states, as well as allowing it to\nrestart in states associated with significant past experiences. This approach\nis compatible with both on-policy and off-policy methods. However, a caveat is\nthat altering the distribution of initial states could change the optimal\npolicies when searching within a restricted class of policies. To reduce this\nunsought learning bias, we evaluate our approach in deep reinforcement learning\nwhich benefits from the high representational capacity of deep neural networks.\nWe instantiate three variants of our approach, each inspired by an idea in the\ncontext of experience replay. Using these variants, we show that performance\ngains can be achieved, especially in hard exploration problems.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11298v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11293v1",
    "title": "Questioning the assumptions behind fairness solutions",
    "authors": [
      "Rebekah Overdorf",
      "Bogdan Kulynych",
      "Ero Balsa",
      "Carmela Troncoso",
      "Seda Gürses"
    ],
    "author_ids": [],
    "abstract": "In addition to their benefits, optimization systems can have negative\neconomic, moral, social, and political effects on populations as well as their\nenvironments. Frameworks like fairness have been proposed to aid service\nproviders in addressing subsequent bias and discrimination during data\ncollection and algorithm design. However, recent reports of neglect,\nunresponsiveness, and malevolence cast doubt on whether service providers can\neffectively implement fairness solutions. These reports invite us to revisit\nassumptions made about the service providers in fairness solutions. Namely,\nthat service providers have (i) the incentives or (ii) the means to mitigate\noptimization externalities. Moreover, the environmental impact of these systems\nsuggests that we need (iii) novel frameworks that consider systems other than\nalgorithmic decision-making and recommender systems, and (iv) solutions that go\nbeyond removing related algorithmic biases. Going forward, we propose\nProtective Optimization Technologies that enable optimization subjects to\ndefend against negative consequences of optimization systems.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11293v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.11269v3",
    "title": "Generalizing semi-supervised generative adversarial networks to regression using feature contrasting",
    "authors": [
      "Greg Olmschenk",
      "Zhigang Zhu",
      "Hao Tang"
    ],
    "author_ids": [],
    "abstract": "In this work, we generalize semi-supervised generative adversarial networks\n(GANs) from classification problems to regression problems. In the last few\nyears, the importance of improving the training of neural networks using\nsemi-supervised training has been demonstrated for classification problems. We\npresent a novel loss function, called feature contrasting, resulting in a\ndiscriminator which can distinguish between fake and real data based on feature\nstatistics. This method avoids potential biases and limitations of alternative\napproaches. The generalization of semi-supervised GANs to the regime of\nregression problems of opens their use to countless applications as well as\nproviding an avenue for a deeper understanding of how GANs function. We first\ndemonstrate the capabilities of semi-supervised regression GANs on a toy\ndataset which allows for a detailed understanding of how they operate in\nvarious circumstances. This toy dataset is used to provide a theoretical basis\nof the semi-supervised regression GAN. We then apply the semi-supervised\nregression GANs to a number of real-world computer vision applications: age\nestimation, driving steering angle prediction, and crowd counting from single\nimages. We perform extensive tests of what accuracy can be achieved with\nsignificantly reduced annotated data. Through the combination of the\ntheoretical example and real-world scenarios, we demonstrate how\nsemi-supervised GANs can be generalized to regression problems.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11269v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10984v1",
    "title": "Eliminating Exposure Bias and Loss-Evaluation Mismatch in Multiple Object Tracking",
    "authors": [
      "Andrii Maksai",
      "Pascal Fua"
    ],
    "author_ids": [],
    "abstract": "Identity Switching remains one of the main difficulties Multiple Object\nTracking (MOT) algorithms have to deal with. Many state-of-the-art approaches\nnow use sequence models to solve this problem but their training can be\naffected by biases that decrease their efficiency. In this paper, we introduce\na new training procedure that confronts the algorithm to its own mistakes while\nexplicitly attempting to minimize the number of switches, which results in\nbetter training. We propose an iterative scheme of building a rich training set\nand using it to learn a scoring function that is an explicit proxy for the\ntarget tracking metric. Whether using only simple geometric features or more\nsophisticated ones that also take appearance into account, our approach\noutperforms the state-of-the-art on several MOT benchmarks.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10984v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10921v3",
    "title": "Large-scale analysis of user exposure to online advertising in Facebook",
    "authors": [
      "Aritz Arrate",
      "José González Cabañas",
      "Ángel Cuevas",
      "María Calderón",
      "Rubén Cuevas"
    ],
    "author_ids": [],
    "abstract": "Online advertising is the major source of income for a large portion of\nInternet Services. There exists a body of literature aiming at optimizing ads\nengagement, understanding the privacy and ethical implications of online\nadvertising, etc. However, to the best of our knowledge, no previous work\nanalyses at large scale the exposure of real users to online advertising. This\npaper performs a comprehensive analysis of the exposure of users to ads and\nadvertisers using a dataset including more than 7M ads from 140K unique\nadvertisers delivered to more than 5K users that was collected between October\n2016 and May 2018. The study focuses on Facebook, which is the second largest\nadvertising platform only to Google in terms of revenue, and accounts for more\nthan 2.2B monthly active users. Our analysis reveals that Facebook users are\nexposed (in median) to 70 ads per week, which come from 12 advertisers. Ads\nrepresent between 10% and 15% of all the information received in users'\nnewsfeed. A small increment of 1% in the portion of ads in the newsfeed could\nroughly represent a revenue increase of 8.17M USD per week for Facebook.\nFinally, we also reveal that Facebook users are overprofiled since in the best\ncase only 22.76% of the interests Facebook assigns to users for advertising\npurpose are actually related to the ads those users receive.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10921v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.10830v2",
    "title": "From Recognition to Cognition: Visual Commonsense Reasoning",
    "authors": [
      "Rowan Zellers",
      "Yonatan Bisk",
      "Ali Farhadi",
      "Yejin Choi"
    ],
    "author_ids": [],
    "abstract": "Visual understanding goes well beyond object recognition. With one glance at\nan image, we can effortlessly imagine the world beyond the pixels: for\ninstance, we can infer people's actions, goals, and mental states. While this\ntask is easy for humans, it is tremendously difficult for today's vision\nsystems, requiring higher-order cognition and commonsense reasoning about the\nworld. We formalize this task as Visual Commonsense Reasoning. Given a\nchallenging question about an image, a machine must answer correctly and then\nprovide a rationale justifying its answer.\n  Next, we introduce a new dataset, VCR, consisting of 290k multiple choice QA\nproblems derived from 110k movie scenes. The key recipe for generating\nnon-trivial and high-quality problems at scale is Adversarial Matching, a new\napproach to transform rich annotations into multiple choice questions with\nminimal bias. Experimental results show that while humans find VCR easy (over\n90% accuracy), state-of-the-art vision models struggle (~45%).\n  To move towards cognition-level understanding, we present a new reasoning\nengine, Recognition to Cognition Networks (R2C), that models the necessary\nlayered inferences for grounding, contextualization, and reasoning. R2C helps\nnarrow the gap between humans and machines (~65%); still, the challenge is far\nfrom solved, and we provide analysis that suggests avenues for future work.",
    "published_date": "2018-11-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10830v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10740v2",
    "title": "Mixture of Regression Experts in fMRI Encoding",
    "authors": [
      "Subba Reddy Oota",
      "Adithya Avvaru",
      "Naresh Manwani",
      "Raju S. Bapi"
    ],
    "author_ids": [],
    "abstract": "fMRI semantic category understanding using linguistic encoding models attempt\nto learn a forward mapping that relates stimuli to the corresponding brain\nactivation. Classical encoding models use linear multi-variate methods to\npredict the brain activation (all voxels) given the stimulus. However, these\nmethods essentially assume multiple regions as one large uniform region or\nseveral independent regions, ignoring connections among them. In this paper, we\npresent a mixture of experts-based model where a group of experts captures\nbrain activity patterns related to particular regions of interest (ROI) and\nalso show the discrimination across different experts. The model is trained\nword stimuli encoded as 25-dimensional feature vectors as input and the\ncorresponding brain responses as output. Given a new word (25-dimensional\nfeature vector), it predicts the entire brain activation as the linear\ncombination of multiple experts brain activations. We argue that each expert\nlearns a certain region of brain activations corresponding to its category of\nwords, which solves the problem of identifying the regions with a simple\nencoding model. We showcase that proposed mixture of experts-based model indeed\nlearns region-based experts to predict the brain activations with high spatial\naccuracy.",
    "published_date": "2018-11-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.HC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10740v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10670v1",
    "title": "AI Fairness for People with Disabilities: Point of View",
    "authors": [
      "Shari Trewin"
    ],
    "author_ids": [],
    "abstract": "We consider how fair treatment in society for people with disabilities might\nbe impacted by the rise in the use of artificial intelligence, and especially\nmachine learning methods. We argue that fairness for people with disabilities\nis different to fairness for other protected attributes such as age, gender or\nrace. One major difference is the extreme diversity of ways disabilities\nmanifest, and people adapt. Secondly, disability information is highly\nsensitive and not always shared, precisely because of the potential for\ndiscrimination. Given these differences, we explore definitions of fairness and\nhow well they work in the disability space. Finally, we suggest ways of\napproaching fairness for people with disabilities in AI applications.",
    "published_date": "2018-11-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10670v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10319v1",
    "title": "On the cost of essentially fair clusterings",
    "authors": [
      "Ioana O. Bercea",
      "Martin Groß",
      "Samir Khuller",
      "Aounon Kumar",
      "Clemens Rösner",
      "Daniel R. Schmidt",
      "Melanie Schmidt"
    ],
    "author_ids": [],
    "abstract": "Clustering is a fundamental tool in data mining. It partitions points into\ngroups (clusters) and may be used to make decisions for each point based on its\ngroup. However, this process may harm protected (minority) classes if the\nclustering algorithm does not adequately represent them in desirable clusters\n-- especially if the data is already biased.\n  At NIPS 2017, Chierichetti et al. proposed a model for fair clustering\nrequiring the representation in each cluster to (approximately) preserve the\nglobal fraction of each protected class. Restricting to two protected classes,\nthey developed both a 4-approximation for the fair $k$-center problem and a\n$O(t)$-approximation for the fair $k$-median problem, where $t$ is a parameter\nfor the fairness model. For multiple protected classes, the best known result\nis a 14-approximation for fair $k$-center.\n  We extend and improve the known results. Firstly, we give a 5-approximation\nfor the fair $k$-center problem with multiple protected classes. Secondly, we\npropose a relaxed fairness notion under which we can give bicriteria\nconstant-factor approximations for all of the classical clustering objectives\n$k$-center, $k$-supplier, $k$-median, $k$-means and facility location. The\nlatter approximations are achieved by a framework that takes an arbitrary\nexisting unfair (integral) solution and a fair (fractional) LP solution and\ncombines them into an essentially fair clustering with a weakly supervised\nrounding scheme. In this way, a fair clustering can be established belatedly,\nin a situation where the centers are already fixed.",
    "published_date": "2018-11-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10319v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.10104v2",
    "title": "50 Years of Test (Un)fairness: Lessons for Machine Learning",
    "authors": [
      "Ben Hutchinson",
      "Margaret Mitchell"
    ],
    "author_ids": [],
    "abstract": "Quantitative definitions of what is unfair and what is fair have been\nintroduced in multiple disciplines for well over 50 years, including in\neducation, hiring, and machine learning. We trace how the notion of fairness\nhas been defined within the testing communities of education and hiring over\nthe past half century, exploring the cultural and social context in which\ndifferent fairness definitions have emerged. In some cases, earlier definitions\nof fairness are similar or identical to definitions of fairness in current\nmachine learning research, and foreshadow current formal work. In other cases,\ninsights into what fairness means and how to measure it have largely gone\noverlooked. We compare past and current notions of fairness along several\ndimensions, including the fairness criteria, the focus of the criteria (e.g., a\ntest, a model, or its use), the relationship of fairness to individuals,\ngroups, and subgroups, and the mathematical method for measuring fairness\n(e.g., classification, regression). This work points the way towards future\nresearch and measurement of (un)fairness that builds from our modern\nunderstanding of fairness while incorporating insights from the past.",
    "published_date": "2018-11-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10104v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10066v1",
    "title": "Predicting Gender from Iris Texture May Be Harder Than It Seems",
    "authors": [
      "Andrey Kuehlkamp",
      "Kevin Bowyer"
    ],
    "author_ids": [],
    "abstract": "Predicting gender from iris images has been reported by several researchers\nas an application of machine learning in biometrics. Recent works on this topic\nhave suggested that the preponderance of the gender cues is located in the\nperiocular region rather than in the iris texture itself. This paper focuses on\nteasing out whether the information for gender prediction is in the texture of\nthe iris stroma, the periocular region, or both. We present a larger dataset\nfor gender from iris, and evaluate gender prediction accuracy using linear SVM\nand CNN, comparing hand-crafted and deep features. We use probabilistic\nocclusion masking to gain insight on the problem. Results suggest the\ndiscriminative power of the iris texture for gender is weaker than previously\nthought, and that the gender-related information is primarily in the periocular\nregion.",
    "published_date": "2018-11-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10066v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.09960v1",
    "title": "Intersectionality: Multiple Group Fairness in Expectation Constraints",
    "authors": [
      "Jack Fitzsimons",
      "Michael Osborne",
      "Stephen Roberts"
    ],
    "author_ids": [],
    "abstract": "Group fairness is an important concern for machine learning researchers,\ndevelopers, and regulators. However, the strictness to which models must be\nconstrained to be considered fair is still under debate. The focus of this work\nis on constraining the expected outcome of subpopulations in kernel regression\nand, in particular, decision tree regression, with application to random\nforests, boosted trees and other ensemble models. While individual constraints\nwere previously addressed, this work addresses concerns about incorporating\nmultiple constraints simultaneously. The proposed solution does not affect the\norder of computational or memory complexity of the decision trees and is easily\nintegrated into models post training.",
    "published_date": "2018-11-25T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.09960v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.09847v2",
    "title": "Robust RGB-D Face Recognition Using Attribute-Aware Loss",
    "authors": [
      "Luo Jiang",
      "Juyong Zhang",
      "Bailin Deng"
    ],
    "author_ids": [],
    "abstract": "Existing convolutional neural network (CNN) based face recognition algorithms\ntypically learn a discriminative feature mapping, using a loss function that\nenforces separation of features from different classes and/or aggregation of\nfeatures within the same class. However, they may suffer from bias in the\ntraining data such as uneven sampling density, because they optimize the\nadjacency relationship of the learned features without considering the\nproximity of the underlying faces. Moreover, since they only use facial images\nfor training, the learned feature mapping may not correctly indicate the\nrelationship of other attributes such as gender and ethnicity, which can be\nimportant for some face recognition applications. In this paper, we propose a\nnew CNN-based face recognition approach that incorporates such attributes into\nthe training process. Using an attribute-aware loss function that regularizes\nthe feature mapping using attribute proximity, our approach learns more\ndiscriminative features that are correlated with the attributes. We train our\nface recognition model on a large-scale RGB-D data set with over 100K\nidentities captured under real application conditions. By comparing our\napproach with other methods on a variety of experiments, we demonstrate that\ndepth channel and attribute-aware loss greatly improve the accuracy and\nrobustness of face recognition.",
    "published_date": "2018-11-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.09847v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.10419v1",
    "title": "Multi-Task Generative Adversarial Network for Handling Imbalanced Clinical Data",
    "authors": [
      "Mina Rezaei",
      "Haojin Yang",
      "Christoph Meinel"
    ],
    "author_ids": [],
    "abstract": "We propose a new generative adversarial architecture to mitigate imbalance\ndata problem for the task of medical image semantic segmentation where the\nmajority of pixels belong to a healthy region and few belong to lesion or\nnon-health region. A model trained with imbalanced data tends to bias towards\nhealthy data which is not desired in clinical applications. We design a new\nconditional GAN with two components: a generative model and a discriminative\nmodel to mitigate imbalanced data problem through selective weighted loss.\nWhile the generator is trained on sequential magnetic resonance images (MRI) to\nlearn semantic segmentation and disease classification, the discriminator\nclassifies whether a generated output is real or fake. The proposed\narchitecture achieved state-of-the-art results on ACDC-2017 for cardiac\nsegmentation and diseases classification. We have achieved competitive results\non BraTS-2017 for brain tumor segmentation and brain diseases classification.",
    "published_date": "2018-11-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.10419v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08982v3",
    "title": "Polarity Loss for Zero-shot Object Detection",
    "authors": [
      "Shafin Rahman",
      "Salman Khan",
      "Nick Barnes"
    ],
    "author_ids": [],
    "abstract": "Conventional object detection models require large amounts of training data.\nIn comparison, humans can recognize previously unseen objects by merely knowing\ntheir semantic description. To mimic similar behaviour, zero-shot object\ndetection aims to recognize and localize 'unseen' object instances by using\nonly their semantic information. The model is first trained to learn the\nrelationships between visual and semantic domains for seen objects, later\ntransferring the acquired knowledge to totally unseen objects. This setting\ngives rise to the need for correct alignment between visual and semantic\nconcepts, so that the unseen objects can be identified using only their\nsemantic attributes. In this paper, we propose a novel loss function called\n'Polarity loss', that promotes correct visual-semantic alignment for an\nimproved zero-shot object detection. On one hand, it refines the noisy semantic\nembeddings via metric learning on a 'Semantic vocabulary' of related concepts\nto establish a better synergy between visual and semantic domains. On the other\nhand, it explicitly maximizes the gap between positive and negative predictions\nto achieve better discrimination between seen, unseen and background objects.\nOur approach is inspired by embodiment theories in cognitive science, that\nclaim human semantic understanding to be grounded in past experiences (seen\nobjects), related linguistic concepts (word vocabulary) and visual perception\n(seen/unseen object images). We conduct extensive evaluations on MS-COCO and\nPascal VOC datasets, showing significant improvements over state of the art.",
    "published_date": "2018-11-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08982v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08690v1",
    "title": "Equality of Voice: Towards Fair Representation in Crowdsourced Top-K Recommendations",
    "authors": [
      "Abhijnan Chakraborty",
      "Gourab K Patro",
      "Niloy Ganguly",
      "Krishna P. Gummadi",
      "Patrick Loiseau"
    ],
    "author_ids": [],
    "abstract": "To help their users to discover important items at a particular time, major\nwebsites like Twitter, Yelp, TripAdvisor or NYTimes provide Top-K\nrecommendations (e.g., 10 Trending Topics, Top 5 Hotels in Paris or 10 Most\nViewed News Stories), which rely on crowdsourced popularity signals to select\nthe items. However, different sections of a crowd may have different\npreferences, and there is a large silent majority who do not explicitly express\ntheir opinion. Also, the crowd often consists of actors like bots, spammers, or\npeople running orchestrated campaigns. Recommendation algorithms today largely\ndo not consider such nuances, hence are vulnerable to strategic manipulation by\nsmall but hyper-active user groups.\n  To fairly aggregate the preferences of all users while recommending top-K\nitems, we borrow ideas from prior research on social choice theory, and\nidentify a voting mechanism called Single Transferable Vote (STV) as having\nmany of the fairness properties we desire in top-K item (s)elections. We\ndevelop an innovative mechanism to attribute preferences of silent majority\nwhich also make STV completely operational. We show the generalizability of our\napproach by implementing it on two different real-world datasets. Through\nextensive experimentation and comparison with state-of-the-art techniques, we\nshow that our proposed approach provides maximum user satisfaction, and cuts\ndown drastically on items disliked by most but hyper-actively promoted by a few\nusers.",
    "published_date": "2018-11-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08690v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.08585v2",
    "title": "Progressive Feature Alignment for Unsupervised Domain Adaptation",
    "authors": [
      "Chaoqi Chen",
      "Weiping Xie",
      "Wenbing Huang",
      "Yu Rong",
      "Xinghao Ding",
      "Yue Huang",
      "Tingyang Xu",
      "Junzhou Huang"
    ],
    "author_ids": [],
    "abstract": "Unsupervised domain adaptation (UDA) transfers knowledge from a label-rich\nsource domain to a fully-unlabeled target domain. To tackle this task, recent\napproaches resort to discriminative domain transfer in virtue of pseudo-labels\nto enforce the class-level distribution alignment across the source and target\ndomains. These methods, however, are vulnerable to the error accumulation and\nthus incapable of preserving cross-domain category consistency, as the\npseudo-labeling accuracy is not guaranteed explicitly. In this paper, we\npropose the Progressive Feature Alignment Network (PFAN) to align the\ndiscriminative features across domains progressively and effectively, via\nexploiting the intra-class variation in the target domain. To be specific, we\nfirst develop an Easy-to-Hard Transfer Strategy (EHTS) and an Adaptive\nPrototype Alignment (APA) step to train our model iteratively and\nalternatively. Moreover, upon observing that a good domain adaptation usually\nrequires a non-saturated source classifier, we consider a simple yet efficient\nway to retard the convergence speed of the source classification loss by\nfurther involving a temperature variate into the soft-max function. The\nextensive experimental results reveal that the proposed PFAN exceeds the\nstate-of-the-art performance on three UDA datasets.",
    "published_date": "2018-11-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08585v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08539v3",
    "title": "Breaking symmetries to rescue Sum of Squares in the case of makespan scheduling",
    "authors": [
      "Victor Verdugo",
      "José Verschae",
      "Andreas Wiese"
    ],
    "author_ids": [],
    "abstract": "The Sum of Squares (\\sos{}) hierarchy gives an automatized technique to\ncreate a family of increasingly tight convex relaxations for binary programs.\nThere are several problems for which a constant number of rounds of this\nhierarchy give integrality gaps matching the best known approximation\nalgorithms. For many other problems, however, ad-hoc techniques give better\napproximation ratios than \\sos{} in the worst case, as shown by corresponding\nlower bound instances. Notably, in many cases these instances are invariant\nunder the action of a large permutation group. This yields the question how\nsymmetries in a formulation degrade the performance of the relaxation obtained\nby the \\sos{} hierarchy. In this paper, we study this for the case of the\nminimum makespan problem on identical machines. Our first result is to show\nthat $\\Omega(n)$ rounds of \\sos{} applied over the \\emph{configuration linear\nprogram} yields an integrality gap of at least $1.0009$, where $n$ is the\nnumber of jobs. Our result is based on tools from representation theory of\nsymmetric groups. Then, we consider the weaker \\emph{assignment linear program}\nand add a well chosen set of symmetry breaking inequalities that removes a\nsubset of the machine permutation symmetries. We show that applying\n$2^{\\tilde{O}(1/\\varepsilon^2)}$ rounds of the SA hierarchy to this stronger\nlinear program reduces the integrality gap to $1+\\varepsilon$, which yields a\nlinear programming based polynomial time approximation scheme. Our results\nsuggest that for this classical problem, symmetries were the main barrier\npreventing the \\sos{}/ SA hierarchies to give relaxations of polynomial\ncomplexity with an integrality gap of~$1+\\varepsilon$. We leave as an open\nquestion whether this phenomenon occurs for other symmetric problems.",
    "published_date": "2018-11-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08539v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.08511v2",
    "title": "Joint association and classification analysis of multi-view data",
    "authors": [
      "Yunfeng Zhang",
      "Irina Gaynanova"
    ],
    "author_ids": [],
    "abstract": "Multi-view data, that is matched sets of measurements on the same subjects,\nhave become increasingly common with advances in multi-omics technology. Often,\nit is of interest to find associations between the views that are related to\nthe intrinsic class memberships. Existing association methods cannot directly\nincorporate class information, while existing classification methods do not\ntake into account between-views associations. In this work, we propose a\nframework for Joint Association and Classification Analysis of multi-view data\n(JACA). Our goal is not to merely improve the misclassification rates, but to\nprovide a latent representation of high-dimensional data that is both relevant\nfor the subtype discrimination and coherent across the views. We motivate the\nmethodology by establishing a connection between canonical correlation analysis\nand discriminant analysis. We also establish the estimation consistency of JACA\nin high-dimensional settings. A distinct advantage of JACA is that it can be\napplied to the multi-view data with block-missing structure, that is to cases\nwhere a subset of views or class labels is missing for some subjects. The\napplication of JACA to quantify the associations between RNAseq and miRNA views\nwith respect to consensus molecular subtypes in colorectal cancer data from The\nCancer Genome Atlas project leads to improved misclassification rates and\nstronger found associations compared to existing methods.",
    "published_date": "2018-11-20T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08511v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08489v4",
    "title": "Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations",
    "authors": [
      "Tianlu Wang",
      "Jieyu Zhao",
      "Mark Yatskar",
      "Kai-Wei Chang",
      "Vicente Ordonez"
    ],
    "author_ids": [],
    "abstract": "In this work, we present a framework to measure and mitigate intrinsic biases\nwith respect to protected variables --such as gender-- in visual recognition\ntasks. We show that trained models significantly amplify the association of\ntarget labels with gender beyond what one would expect from biased datasets.\nSurprisingly, we show that even when datasets are balanced such that each label\nco-occurs equally with each gender, learned models amplify the association\nbetween labels and gender, as much as if data had not been balanced! To\nmitigate this, we adopt an adversarial approach to remove unwanted features\ncorresponding to protected variables from intermediate representations in a\ndeep neural network -- and provide a detailed analysis of its effectiveness.\nExperiments on two datasets: the COCO dataset (objects), and the imSitu dataset\n(actions), show reductions in gender bias amplification while maintaining most\nof the accuracy of the original models.",
    "published_date": "2018-11-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08489v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.09539v2",
    "title": "State of the Art in Fair ML: From Moral Philosophy and Legislation to Fair Classifiers",
    "authors": [
      "Elias Baumann",
      "Josef Lorenz Rumberger"
    ],
    "author_ids": [],
    "abstract": "Machine learning is becoming an ever present part in our lives as many\ndecisions, e.g. to lend a credit, are no longer made by humans but by machine\nlearning algorithms. However those decisions are often unfair and\ndiscriminating individuals belonging to protected groups based on race or\ngender. With the recent General Data Protection Regulation (GDPR) coming into\neffect, new awareness has been raised for such issues and with computer\nscientists having such a large impact on peoples lives it is necessary that\nactions are taken to discover and prevent discrimination. This work aims to\ngive an introduction into discrimination, legislative foundations to counter it\nand strategies to detect and prevent machine learning algorithms from showing\nsuch behavior.",
    "published_date": "2018-11-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.09539v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08565v2",
    "title": "Can Synthetic Faces Undo the Damage of Dataset Bias to Face Recognition and Facial Landmark Detection?",
    "authors": [
      "Adam Kortylewski",
      "Bernhard Egger",
      "Andreas Morel-Forster",
      "Andreas Schneider",
      "Thomas Gerig",
      "Clemens Blumer",
      "Corius Reyneke",
      "Thomas Vetter"
    ],
    "author_ids": [],
    "abstract": "It is well known that deep learning approaches to face recognition and facial\nlandmark detection suffer from biases in modern training datasets. In this\nwork, we propose to use synthetic face images to reduce the negative effects of\ndataset biases on these tasks. Using a 3D morphable face model, we generate\nlarge amounts of synthetic face images with full control over facial shape and\ncolor, pose, illumination, and background. With a series of experiments, we\nextensively test the effects of priming deep nets by pre-training them with\nsynthetic faces. We observe the following positive effects for face recognition\nand facial landmark detection tasks: 1) Priming with synthetic face images\nimproves the performance consistently across all benchmarks because it reduces\nthe negative effects of biases in the training data. 2) Traditional approaches\nfor reducing the damage of dataset bias, such as data augmentation and transfer\nlearning, are less effective than training with synthetic faces. 3) Using\nsynthetic data, we can reduce the size of real-world datasets by 75% for face\nrecognition and by 50% for facial landmark detection while maintaining\nperformance. Thus, offering a means to focus the data collection process on\nless but higher quality data.",
    "published_date": "2018-11-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08565v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.07789v1",
    "title": "Explicit Bias Discovery in Visual Question Answering Models",
    "authors": [
      "Varun Manjunatha",
      "Nirat Saini",
      "Larry S. Davis"
    ],
    "author_ids": [],
    "abstract": "Researchers have observed that Visual Question Answering (VQA) models tend to\nanswer questions by learning statistical biases in the data. For example, their\nanswer to the question \"What is the color of the grass?\" is usually \"Green\",\nwhereas a question like \"What is the title of the book?\" cannot be answered by\ninferring statistical biases. It is of interest to the community to explicitly\ndiscover such biases, both for understanding the behavior of such models, and\ntowards debugging them. Our work address this problem. In a database, we store\nthe words of the question, answer and visual words corresponding to regions of\ninterest in attention maps. By running simple rule mining algorithms on this\ndatabase, we discover human-interpretable rules which give us unique insight\ninto the behavior of such models. Our results also show examples of unusual\nbehaviors learned by models in attempting VQA tasks.",
    "published_date": "2018-11-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.07789v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.07485v1",
    "title": "Visual-Texual Emotion Analysis with Deep Coupled Video and Danmu Neural Networks",
    "authors": [
      "Chenchen Li",
      "Jialin Wang",
      "Hongwei Wang",
      "Miao Zhao",
      "Wenjie Li",
      "Xiaotie Deng"
    ],
    "author_ids": [],
    "abstract": "User emotion analysis toward videos is to automatically recognize the general\nemotional status of viewers from the multimedia content embedded in the online\nvideo stream. Existing works fall in two categories: 1) visual-based methods,\nwhich focus on visual content and extract a specific set of features of videos.\nHowever, it is generally hard to learn a mapping function from low-level video\npixels to high-level emotion space due to great intra-class variance. 2)\ntextual-based methods, which focus on the investigation of user-generated\ncomments associated with videos. The learned word representations by\ntraditional linguistic approaches typically lack emotion information and the\nglobal comments usually reflect viewers' high-level understandings rather than\ninstantaneous emotions. To address these limitations, in this paper, we propose\nto jointly utilize video content and user-generated texts simultaneously for\nemotion analysis. In particular, we introduce exploiting a new type of\nuser-generated texts, i.e., \"danmu\", which are real-time comments floating on\nthe video and contain rich information to convey viewers' emotional opinions.\nTo enhance the emotion discriminativeness of words in textual feature\nextraction, we propose Emotional Word Embedding (EWE) to learn text\nrepresentations by jointly considering their semantics and emotions.\nAfterwards, we propose a novel visual-textual emotion analysis model with Deep\nCoupled Video and Danmu Neural networks (DCVDN), in which visual and textual\nfeatures are synchronously extracted and fused to form a comprehensive\nrepresentation by deep-canonically-correlated-autoencoder-based multi-view\nlearning. Through extensive experiments on a self-crawled real-world\nvideo-danmu dataset, we prove that DCVDN significantly outperforms the\nstate-of-the-art baselines.",
    "published_date": "2018-11-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.07485v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.07390v1",
    "title": "A Study on 3D Surface Graph Representations",
    "authors": [
      "Long Nguyen",
      "Abdullah Karim"
    ],
    "author_ids": [],
    "abstract": "Surface graphs have been used in many application domains to represent\nthree-dimensional (3D) data. Another approach to representing 3D data is making\nprojections onto two-dimensional (2D) graphs. This approach will result in\nmultiple displays, which is time-consuming in switching between different\nscreens for a different perspective. In this work, we study the performance of\n3D version of popular 2D visualization techniques for time series: horizon\ngraph, small multiple, and simple line graph. We explore discrimination tasks\nwith respect to each visualization technique that requires simultaneous\nrepresentations. We demonstrate our study by visualizing saturated thickness of\nthe Ogallala aquifer - the Southern High Plains Aquifer of Texas in multiple\nyears. For the evaluation, we design comparison and discrimination tasks and\nautomatically record result performed by a group of students at a university.\nOur results show that 3D small multiples perform well with stable accuracy over\nnumbers of occurrences. On the other hand, shared-space visualization within a\nsingle 3D coordinate system is more efficient with small number of simultaneous\ngraphs. 3D horizon graph loses its competence in the 3D coordinate system with\nthe lowest accuracy comparing to other techniques. Our demonstration of 3D\nspatial-temporal is also presented on the Southern High Plains Aquifer of Texas\nfrom 2010 to 2016.",
    "published_date": "2018-11-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.07390v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.07271v2",
    "title": "Ethical Dimensions of Visualization Research",
    "authors": [
      "Michael Correll"
    ],
    "author_ids": [],
    "abstract": "Visualizations have a potentially enormous influence on how data are used to\nmake decisions across all areas of human endeavor. However, it is not clear how\nthis power connects to ethical duties: what obligations do we have when it\ncomes to visualizations and visual analytics systems, beyond our duties as\nscientists and engineers? Drawing on historical and contemporary examples, I\naddress the moral components of the design and use of visualizations, identify\nsome ongoing areas of visualization research with ethical dilemmas, and propose\na set of additional moral obligations that we have as designers, builders, and\nresearchers of visualizations.",
    "published_date": "2018-11-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.07271v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.07255v2",
    "title": "Bayesian Modeling of Intersectional Fairness: The Variance of Bias",
    "authors": [
      "James Foulds",
      "Rashidul Islam",
      "Kamrun Keya",
      "Shimei Pan"
    ],
    "author_ids": [],
    "abstract": "Intersectionality is a framework that analyzes how interlocking systems of\npower and oppression affect individuals along overlapping dimensions including\nrace, gender, sexual orientation, class, and disability. Intersectionality\ntheory therefore implies it is important that fairness in artificial\nintelligence systems be protected with regard to multi-dimensional protected\nattributes. However, the measurement of fairness becomes statistically\nchallenging in the multi-dimensional setting due to data sparsity, which\nincreases rapidly in the number of dimensions, and in the values per dimension.\nWe present a Bayesian probabilistic modeling approach for the reliable,\ndata-efficient estimation of fairness with multi-dimensional protected\nattributes, which we apply to two existing intersectional fairness metrics.\nExperimental results on census data and the COMPAS criminal justice recidivism\ndataset demonstrate the utility of our methodology, and show that Bayesian\nmethods are valuable for the modeling and measurement of fairness in an\nintersectional context.",
    "published_date": "2018-11-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.07255v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.08291v2",
    "title": "A Two Phase Investment Game for Competitive Opinion Dynamics in Social Networks",
    "authors": [
      "Swapnil Dhamal",
      "Walid Ben-Ameur",
      "Tijani Chahed",
      "Eitan Altman"
    ],
    "author_ids": [],
    "abstract": "We propose a setting for two-phase opinion dynamics in social networks, where\na node's final opinion in the first phase acts as its initial biased opinion in\nthe second phase. In this setting, we study the problem of two camps aiming to\nmaximize adoption of their respective opinions, by strategically investing on\nnodes in the two phases. A node's initial opinion in the second phase naturally\nplays a key role in determining the final opinion of that node, and hence also\nof other nodes in the network due to its influence on them. More importantly,\nthis bias also determines the effectiveness of a camp's investment on that node\nin the second phase. To formalize this two-phase investment setting, we propose\nan extension of Friedkin-Johnsen model, and hence formulate the utility\nfunctions of the camps. There is a tradeoff while splitting the budget between\nthe two phases. A lower investment in the first phase results in worse initial\nbiases for the second phase, while a higher investment spares a lower available\nbudget for the second phase. We first analyze the non-competitive case where\nonly one camp invests, for which we present a polynomial time algorithm for\ndetermining an optimal way to split the camp's budget between the two phases.\nWe then analyze the case of competing camps, where we show the existence of\nNash equilibrium and that it can be computed in polynomial time under\nreasonable assumptions. We conclude our study with simulations on real-world\nnetwork datasets, in order to quantify the effects of the initial biases and\nthe weightage attributed by nodes to their initial biases, as well as that of a\ncamp deviating from its equilibrium strategy. Our main conclusion is that, if\nnodes attribute high weightage to their initial biases, it is advantageous to\nhave a high investment in the first phase, so as to effectively influence the\nbiases to be harnessed in the second phase.",
    "published_date": "2018-11-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.08291v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.11002v1",
    "title": "Correcting the Common Discourse Bias in Linear Representation of Sentences using Conceptors",
    "authors": [
      "Tianlin Liu",
      "João Sedoc",
      "Lyle Ungar"
    ],
    "author_ids": [],
    "abstract": "Distributed representations of words, better known as word embeddings, have\nbecome important building blocks for natural language processing tasks.\nNumerous studies are devoted to transferring the success of unsupervised word\nembeddings to sentence embeddings. In this paper, we introduce a simple\nrepresentation of sentences in which a sentence embedding is represented as a\nweighted average of word vectors followed by a soft projection. We demonstrate\nthe effectiveness of this proposed method on the clinical semantic textual\nsimilarity task of the BioCreative/OHNLP Challenge 2018.",
    "published_date": "2018-11-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.11002v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.06747v2",
    "title": "Machine Decisions and Human Consequences",
    "authors": [
      "Teresa Scantamburlo",
      "Andrew Charlesworth",
      "Nello Cristianini"
    ],
    "author_ids": [],
    "abstract": "As we increasingly delegate decision-making to algorithms, whether directly\nor indirectly, important questions emerge in circumstances where those\ndecisions have direct consequences for individual rights and personal\nopportunities, as well as for the collective good. A key problem for\npolicymakers is that the social implications of these new methods can only be\ngrasped if there is an adequate comprehension of their general technical\nunderpinnings. The discussion here focuses primarily on the case of enforcement\ndecisions in the criminal justice system, but draws on similar situations\nemerging from other algorithms utilised in controlling access to opportunities,\nto explain how machine learning works and, as a result, how decisions are made\nby modern intelligent algorithms or 'classifiers'. It examines the key aspects\nof the performance of classifiers, including how classifiers learn, the fact\nthat they operate on the basis of correlation rather than causation, and that\nthe term 'bias' in machine learning has a different meaning to common usage. An\nexample of a real world 'classifier', the Harm Assessment Risk Tool (HART), is\nexamined, through identification of its technical features: the classification\nmethod, the training data and the test data, the features and the labels,\nvalidation and performance measures. Four normative benchmarks are then\nconsidered by reference to HART: (a) prediction accuracy (b) fairness and\nequality before the law (c) transparency and accountability (d) informational\nprivacy and freedom of expression, in order to demonstrate how its technical\nfeatures have important normative dimensions that bear directly on the extent\nto which the system can be regarded as a viable and legitimate support for, or\neven alternative to, existing human decision-makers.",
    "published_date": "2018-11-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.06747v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.06693v2",
    "title": "Exploring Media Bias and Toxicity in South Asian Political Discourse",
    "authors": [
      "Adnan Qayyum",
      "Zafar Gilani",
      "Siddique Latif",
      "Junaid Qadir"
    ],
    "author_ids": [],
    "abstract": "Media outlets and political campaigners recognise social media as a means for\nwidely disseminating news and opinions. In particular, Twitter is used by\npolitical groups all over the world to spread political messages, engage their\nsupporters, drive election campaigns, and challenge their critics. Further,\nnews agencies, many of which aim to give an impression of balance, are often of\na particular political persuasion which is reflected in the content they\nproduce. Driven by the potential for political and media organisations to\ninfluence public opinion, our aim is to quantify the nature of political\ndiscourse by these organisations through their use of social media. In this\nstudy, we analyse the sentiments, toxicity, and bias exhibited by the most\nprominent Pakistani and Indian political parties and media houses, and the\npattern by which these political parties utilise Twitter. We found that media\nbias and toxicity exist in the political discourse of these two developing\nnations.",
    "published_date": "2018-11-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.06693v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.06645v2",
    "title": "Investigating Bell Inequalities for Multidimensional Relevance Judgments in Information Retrieval",
    "authors": [
      "Sagar Uprety",
      "Dimitris Gkoumas",
      "Dawei Song"
    ],
    "author_ids": [],
    "abstract": "Relevance judgment in Information Retrieval is influenced by multiple\nfactors. These include not only the topicality of the documents but also other\nuser oriented factors like trust, user interest, etc. Recent works have\nidentified these various factors into seven dimensions of relevance. In a\nprevious work, these relevance dimensions were quantified and user's cognitive\nstate with respect to a document was represented as a state vector in a Hilbert\nSpace, with each relevance dimension representing a basis. It was observed that\nrelevance dimensions are incompatible in some documents, when making a\njudgment. Incompatibility being a fundamental feature of Quantum Theory, this\nmotivated us to test the Quantum nature of relevance judgments using Bell type\ninequalities. However, none of the Bell-type inequalities tested have shown any\nviolation. We discuss our methodology to construct incompatible basis for\ndocuments from real world query log data, the experiments to test Bell\ninequalities on this dataset and possible reasons for the lack of violation.",
    "published_date": "2018-11-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.06645v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.06606v2",
    "title": "Economics of Human-AI Ecosystem: Value Bias and Lost Utility in Multi-Dimensional Gaps",
    "authors": [
      "Daniel Muller"
    ],
    "author_ids": [],
    "abstract": "In recent years, artificial intelligence (AI) decision-making and autonomous\nsystems became an integrated part of the economy, industry, and society. The\nevolving economy of the human-AI ecosystem raising concerns regarding the risks\nand values inherited in AI systems. This paper investigates the dynamics of\ncreation and exchange of values and points out gaps in perception of\ncost-value, knowledge, space and time dimensions. It shows aspects of value\nbias in human perception of achievements and costs that encoded in AI systems.\nIt also proposes rethinking hard goals definitions and cost-optimal\nproblem-solving principles in the lens of effectiveness and efficiency in the\ndevelopment of trusted machines. The paper suggests a value-driven with cost\nawareness strategy and principles for problem-solving and planning of effective\nresearch progress to address real-world problems that involve diverse forms of\nachievements, investments, and survival scenarios.",
    "published_date": "2018-11-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.06606v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.06397v2",
    "title": "Offline Biases in Online Platforms: a Study of Diversity and Homophily in Airbnb",
    "authors": [
      "Victoria Koh",
      "Weihua Li",
      "Giacomo Livan",
      "Licia Capra"
    ],
    "author_ids": [],
    "abstract": "How diverse are sharing economy platforms? Are they fair marketplaces, where\nall participants operate on a level playing field, or are they large-scale\nonline aggregators of offline human biases? Often portrayed as easy-to-access\ndigital spaces whose participants receive equal opportunities, such platforms\nhave recently come under fire due to reports of discriminatory behaviours among\ntheir users, and have been associated with gentrification phenomena that\nexacerbate preexisting inequalities along racial lines. In this paper, we focus\non the Airbnb sharing economy platform, and analyse the diversity of its user\nbase across five large cities. We find it to be predominantly young, female,\nand white. Notably, we find this to be true even in cities with a diverse\nracial composition. We then introduce a method based on the statistical\nanalysis of networks to quantify behaviours of homophily, heterophily and\navoidance between Airbnb hosts and guests. Depending on cities and property\ntypes, we do find signals of such behaviours relating both to race and gender.\nWe use these findings to provide platform design recommendations, aimed at\nexposing and possibly reducing the biases we detect, in support of a more\ninclusive growth of sharing economy platforms.",
    "published_date": "2018-11-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.06397v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.05817v2",
    "title": "ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging Synthesis with Generative Adversarial Networks",
    "authors": [
      "Xiaodan Hu",
      "Audrey G. Chung",
      "Paul Fieguth",
      "Farzad Khalvati",
      "Masoom A. Haider",
      "Alexander Wong"
    ],
    "author_ids": [],
    "abstract": "Generative Adversarial Networks (GANs) have shown considerable promise for\nmitigating the challenge of data scarcity when building machine learning-driven\nanalysis algorithms. Specifically, a number of studies have shown that\nGAN-based image synthesis for data augmentation can aid in improving\nclassification accuracy in a number of medical image analysis tasks, such as\nbrain and liver image analysis. However, the efficacy of leveraging GANs for\ntackling prostate cancer analysis has not been previously explored. Motivated\nby this, in this study we introduce ProstateGAN, a GAN-based model for\nsynthesizing realistic prostate diffusion imaging data. More specifically, in\norder to generate new diffusion imaging data corresponding to a particular\ncancer grade (Gleason score), we propose a conditional deep convolutional GAN\narchitecture that takes Gleason scores into consideration during the training\nprocess. Experimental results show that high-quality synthetic prostate\ndiffusion imaging data can be generated using the proposed ProstateGAN for\nspecified Gleason scores.",
    "published_date": "2018-11-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05817v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.05740v1",
    "title": "Neural Based Statement Classification for Biased Language",
    "authors": [
      "Christoph Hube",
      "Besnik Fetahu"
    ],
    "author_ids": [],
    "abstract": "Biased language commonly occurs around topics which are of controversial\nnature, thus, stirring disagreement between the different involved parties of a\ndiscussion. This is due to the fact that for language and its use,\nspecifically, the understanding and use of phrases, the stances are cohesive\nwithin the particular groups. However, such cohesiveness does not hold across\ngroups.\n  In collaborative environments or environments where impartial language is\ndesired (e.g. Wikipedia, news media), statements and the language therein\nshould represent equally the involved parties and be neutrally phrased. Biased\nlanguage is introduced through the presence of inflammatory words or phrases,\nor statements that may be incorrect or one-sided, thus violating such\nconsensus.\n  In this work, we focus on the specific case of phrasing bias, which may be\nintroduced through specific inflammatory words or phrases in a statement. For\nthis purpose, we propose an approach that relies on a recurrent neural networks\nin order to capture the inter-dependencies between words in a phrase that\nintroduced bias.\n  We perform a thorough experimental evaluation, where we show the advantages\nof a neural based approach over competitors that rely on word lexicons and\nother hand-crafted features in detecting biased language. We are able to\ndistinguish biased statements with a precision of P=0.92, thus significantly\noutperforming baseline models with an improvement of over 30%. Finally, we\nrelease the largest corpus of statements annotated for biased language.",
    "published_date": "2018-11-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05740v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.05594v1",
    "title": "TrolleyMod v1.0: An Open-Source Simulation and Data-Collection Platform for Ethical Decision Making in Autonomous Vehicles",
    "authors": [
      "Vahid Behzadan",
      "James Minton",
      "Arslan Munir"
    ],
    "author_ids": [],
    "abstract": "This paper presents TrolleyMod v1.0, an open-source platform based on the\nCARLA simulator for the collection of ethical decision-making data for\nautonomous vehicles. This platform is designed to facilitate experiments aiming\nto observe and record human decisions and actions in high-fidelity simulations\nof ethical dilemmas that occur in the context of driving. Targeting experiments\nin the class of trolley problems, TrolleyMod provides a seamless approach to\ncreating new experimental settings and environments with the realistic\nphysics-engine and the high-quality graphical capabilities of CARLA and the\nUnreal Engine. Also, TrolleyMod provides a straightforward interface between\nthe CARLA environment and Python to enable the implementation of custom\ncontrollers, such as deep reinforcement learning agents. The results of such\nexperiments can be used for sociological analyses, as well as the training and\ntuning of value-aligned autonomous vehicles based on social values that are\ninferred from observations.",
    "published_date": "2018-11-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05594v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.05577v2",
    "title": "Aequitas: A Bias and Fairness Audit Toolkit",
    "authors": [
      "Pedro Saleiro",
      "Benedict Kuester",
      "Loren Hinkson",
      "Jesse London",
      "Abby Stevens",
      "Ari Anisfeld",
      "Kit T. Rodolfa",
      "Rayid Ghani"
    ],
    "author_ids": [],
    "abstract": "Recent work has raised concerns on the risk of unintended bias in AI systems\nbeing used nowadays that can affect individuals unfairly based on race, gender\nor religion, among other possible characteristics. While a lot of bias metrics\nand fairness definitions have been proposed in recent years, there is no\nconsensus on which metric/definition should be used and there are very few\navailable resources to operationalize them. Therefore, despite recent\nawareness, auditing for bias and fairness when developing and deploying AI\nsystems is not yet a standard practice. We present Aequitas, an open source\nbias and fairness audit toolkit that is an intuitive and easy to use addition\nto the machine learning workflow, enabling users to seamlessly test models for\nseveral bias and fairness metrics in relation to multiple population\nsub-groups. Aequitas facilitates informed and equitable decisions around\ndeveloping and deploying algorithmic decision making systems for both data\nscientists, machine learning researchers and policymakers.",
    "published_date": "2018-11-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05577v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.05253v2",
    "title": "Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization",
    "authors": [
      "Shiyang Yan",
      "Yuan Xie",
      "Fangyu Wu",
      "Jeremy S. Smith",
      "Wenjin Lu",
      "Bailing Zhang"
    ],
    "author_ids": [],
    "abstract": "Automatically generating the descriptions of an image, i.e., image\ncaptioning, is an important and fundamental topic in artificial intelligence,\nwhich bridges the gap between computer vision and natural language processing.\nBased on the successful deep learning models, especially the CNN model and Long\nShort-Term Memories (LSTMs) with attention mechanism, we propose a hierarchical\nattention model by utilizing both of the global CNN features and the local\nobject features for more effective feature representation and reasoning in\nimage captioning. The generative adversarial network (GAN), together with a\nreinforcement learning (RL) algorithm, is applied to solve the exposure bias\nproblem in RNN-based supervised training for language problems. In addition,\nthrough the automatic measurement of the consistency between the generated\ncaption and the image content by the discriminator in the GAN framework and RL\noptimization, we make the finally generated sentences more accurate and\nnatural. Comprehensive experiments show the improved performance of the\nhierarchical attention mechanism and the effectiveness of our RL-based\noptimization method. Our model achieves state-of-the-art results on several\nimportant metrics in the MSCOCO dataset, using only greedy inference.",
    "published_date": "2018-11-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05253v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.05141v2",
    "title": "Co-Representation Learning For Classification and Novel Class Detection via Deep Networks",
    "authors": [
      "Zhuoyi Wang",
      "Zelun Kong",
      "Hemeng Tao",
      "Swarup Chandra",
      "Latifur Khan"
    ],
    "author_ids": [],
    "abstract": "One of the key challenges of performing label prediction over a data stream\nconcerns with the emergence of instances belonging to unobserved class labels\nover time. Previously, this problem has been addressed by detecting such\ninstances and using them for appropriate classifier adaptation. The fundamental\naspect of a novel-class detection strategy relies on the ability of comparison\namong observed instances to discriminate them into known and unknown classes.\nTherefore, studies in the past have proposed various metrics suitable for\ncomparison over the observed feature space. Unfortunately, these similarity\nmeasures fail to reliably identify distinct regions in observed feature spaces\nuseful for class discrimination and novel-class detection, especially in\nstreams containing high-dimensional data instances such as images and texts. In\nthis paper, we address this key challenge by proposing a semi-supervised\nmulti-task learning framework called \\sysname{} which aims to intrinsically\nsearch for a latent space suitable for detecting labels of instances from both\nknown and unknown classes. We empirically measure the performance of \\sysname{}\nover multiple real-world image and text datasets and demonstrate its\nsuperiority by comparing its performance with existing semi-supervised methods.",
    "published_date": "2018-11-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05141v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.04973v2",
    "title": "Eliminating Latent Discrimination: Train Then Mask",
    "authors": [
      "Soheil Ghili",
      "Ehsan Kazemi",
      "Amin Karbasi"
    ],
    "author_ids": [],
    "abstract": "How can we control for latent discrimination in predictive models? How can we\nprovably remove it? Such questions are at the heart of algorithmic fairness and\nits impacts on society. In this paper, we define a new operational fairness\ncriteria, inspired by the well-understood notion of omitted variable-bias in\nstatistics and econometrics. Our notion of fairness effectively controls for\nsensitive features and provides diagnostics for deviations from fair decision\nmaking. We then establish analytical and algorithmic results about the\nexistence of a fair classifier in the context of supervised learning. Our\nresults readily imply a simple, but rather counter-intuitive, strategy for\neliminating latent discrimination. In order to prevent other features proxying\nfor sensitive features, we need to include sensitive features in the training\nphase, but exclude them in the test/evaluation phase while controlling for\ntheir effects. We evaluate the performance of our algorithm on several\nreal-world datasets and show how fairness for these datasets can be improved\nwith a very small loss in accuracy.",
    "published_date": "2018-11-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.04973v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.04884v1",
    "title": "CQASUMM: Building References for Community Question Answering Summarization Corpora",
    "authors": [
      "Tanya Chowdhury",
      "Tanmoy Chakraborty"
    ],
    "author_ids": [],
    "abstract": "Community Question Answering forums such as Quora, Stackoverflow are rich\nknowledge resources, often catering to information on topics overlooked by\nmajor search engines. Answers submitted to these forums are often elaborated,\ncontain spam, are marred by slurs and business promotions. It is difficult for\na reader to go through numerous such answers to gauge community opinion. As a\nresult summarization becomes a prioritized task for CQA forums. While a number\nof efforts have been made to summarize factoid CQA, little work exists in\nsummarizing non-factoid CQA. We believe this is due to the lack of a\nconsiderably large, annotated dataset for CQA summarization. We create CQASUMM,\nthe first huge annotated CQA summarization dataset by filtering the 4.4 million\nYahoo! Answers L6 dataset. We sample threads where the best answer can double\nup as a reference summary and build hundred word summaries from them. We treat\nother answers as candidates documents for summarization. We provide a script to\ngenerate the dataset and introduce the new task of Community Question Answering\nSummarization. Multi document summarization has been widely studied with news\narticle datasets, especially in the DUC and TAC challenges using news corpora.\nHowever documents in CQA have higher variance, contradicting opinion and lesser\namount of overlap. We compare the popular multi document summarization\ntechniques and evaluate their performance on our CQA corpora. We look into the\nstate-of-the-art and understand the cases where existing multi document\nsummarizers (MDS) fail. We find that most MDS workflows are built for the\nentirely factual news corpora, whereas our corpus has a fair share of opinion\nbased instances too. We therefore introduce OpinioSumm, a new MDS which\noutperforms the best baseline by 4.6% w.r.t ROUGE-1 score.",
    "published_date": "2018-11-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.04884v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.04689v1",
    "title": "Adversarial Learning of Label Dependency: A Novel Framework for Multi-class Classification",
    "authors": [
      "Che-Ping Tsai",
      "Hung-Yi Lee"
    ],
    "author_ids": [],
    "abstract": "Recent work has shown that exploiting relations between labels improves the\nperformance of multi-label classification. We propose a novel framework based\non generative adversarial networks (GANs) to model label dependency. The\ndiscriminator learns to model label dependency by discriminating real and\ngenerated label sets. To fool the discriminator, the classifier, or generator,\nlearns to generate label sets with dependencies close to real data. Extensive\nexperiments and comparisons on two large-scale image classification benchmark\ndatasets (MS-COCO and NUS-WIDE) show that the discriminator improves\ngeneralization ability for different kinds of models",
    "published_date": "2018-11-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.04689v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.04684v2",
    "title": "Bias Scheme Reducing Transient Currents and Speeding up Read Operations for 3-D Cross Point PCM",
    "authors": [
      "Yu Lei",
      "Meng Liu",
      "Houpeng Chen",
      "Xi Li",
      "Qian Wang",
      "Zhitang Song"
    ],
    "author_ids": [],
    "abstract": "3-D cross point phase change memory (PCM) is a promising emerging memory.\nHowever, dynamic performances of 3-D cross point PCM are limited and the role\nof bias scheme is unknown. Previous studies on bias schemes for planar memories\nuse static analyses to assess static array performances. Here, a high peak\ntransient read current is found to result in a long read access time. Three\nfactors which contribute to the high peak read current are analyzed. The\nproposed 2V/3 bias scheme and a single-reference parasitic-matching sensing\ncircuit are utilized in a 64Mbit 3-D cross point PCM. The sensing time is\nreduced by 22.5%. Designing bias schemes through dynamic analyses paves the way\nfor the development of high-performance 3-D PCM technology to boost the working\nefficiency of computing systems.\n  The following contents are the listed errors as mentioned in the comments for\nreasons of withdrawal: missing labels of Fig.1, lack of the explanation of the\npeak current on the sensing speed, lack of the reason of the chosen of 2V/3\nscheme, lack of influence of the parasitic capacitors, unclear explanation of\nthe factor that contributes to a high peak read current, lack of comparisons,\nlack of the explanation of the sneak current, lack of the explanations of the\nSRPM sensing circuit, lack of the define valuables like NM_{A1}, unclear\nexplanation of comparisons of the power consumption, wrong writing of the two\nconventional circuits, writing of 3D-IC, wrong writing of number of memory\nlayers, etc. These errors may confuse a good understanding of our work.\nTherefore, we decide to withdraw this manuscript from arXiv. We will\nsignificantly rewrite it and publish the correct and complete paper in the\nfuture.",
    "published_date": "2018-11-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.ET"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.04684v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.04599v3",
    "title": "The Cinderella Complex: Word Embeddings Reveal Gender Stereotypes in Movies and Books",
    "authors": [
      "Huimin Xu",
      "Zhang Zhang",
      "Lingfei Wu",
      "Cheng-Jun Wang"
    ],
    "author_ids": [],
    "abstract": "Our analysis of thousands of movies and books reveals how these cultural\nproducts weave stereotypical gender roles into morality tales and perpetuate\ngender inequality through storytelling. Using the word embedding techniques, we\nreveal the constructed emotional dependency of female characters on male\ncharacters in stories.",
    "published_date": "2018-11-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.04599v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03764v2",
    "title": "PAC: A Novel Self-Adaptive Neuro-Fuzzy Controller for Micro Aerial Vehicles",
    "authors": [
      "Md Meftahul Ferdaus",
      "Mahardhika Pratama",
      "Sreenatha G. Anavatti",
      "Matthew A. Garratt",
      "Edwin Lughofer"
    ],
    "author_ids": [],
    "abstract": "There exists an increasing demand for a flexible and computationally\nefficient controller for micro aerial vehicles (MAVs) due to a high degree of\nenvironmental perturbations. In this work, an evolving neuro-fuzzy controller,\nnamely Parsimonious Controller (PAC) is proposed. It features fewer network\nparameters than conventional approaches due to the absence of rule premise\nparameters. PAC is built upon a recently developed evolving neuro-fuzzy system\nknown as parsimonious learning machine (PALM) and adopts new rule growing and\npruning modules derived from the approximation of bias and variance. These rule\nadaptation methods have no reliance on user-defined thresholds, thereby\nincreasing the PAC's autonomy for real-time deployment. PAC adapts the\nconsequent parameters with the sliding mode control (SMC) theory in the\nsingle-pass fashion. The boundedness and convergence of the closed-loop control\nsystem's tracking error and the controller's consequent parameters are\nconfirmed by utilizing the LaSalle-Yoshizawa theorem. Lastly, the controller's\nefficacy is evaluated by observing various trajectory tracking performance from\na bio-inspired flapping-wing micro aerial vehicle (BI-FWMAV) and a rotary wing\nmicro aerial vehicle called hexacopter. Furthermore, it is compared to three\ndistinctive controllers. Our PAC outperforms the linear PID controller and\nfeed-forward neural network (FFNN) based nonlinear adaptive controller.\nCompared to its predecessor, G-controller, the tracking accuracy is comparable,\nbut the PAC incurs significantly fewer parameters to attain similar or better\nperformance than the G-controller.",
    "published_date": "2018-11-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03764v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03763v1",
    "title": "Towards Instance-Optimal Private Query Release",
    "authors": [
      "Jaroslaw Blasiok",
      "Mark Bun",
      "Aleksandar Nikolov",
      "Thomas Steinke"
    ],
    "author_ids": [],
    "abstract": "We study efficient mechanisms for the query release problem in differential\nprivacy: given a workload of $m$ statistical queries, output approximate\nanswers to the queries while satisfying the constraints of differential\nprivacy. In particular, we are interested in mechanisms that optimally adapt to\nthe given workload. Building on the projection mechanism of Nikolov, Talwar,\nand Zhang, and using the ideas behind Dudley's chaining inequality, we propose\nnew efficient algorithms for the query release problem, and prove that they\nachieve optimal sample complexity for the given workload (up to constant\nfactors, in certain parameter regimes) with respect to the class of mechanisms\nthat satisfy concentrated differential privacy. We also give variants of our\nalgorithms that satisfy local differential privacy, and prove that they also\nachieve optimal sample complexity among all local sequentially interactive\nprivate mechanisms.",
    "published_date": "2018-11-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03763v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.03761v2",
    "title": "RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets",
    "authors": [
      "Liping Li",
      "Wei Xu",
      "Tianyi Chen",
      "Georgios B. Giannakis",
      "Qing Ling"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a class of robust stochastic subgradient methods\nfor distributed learning from heterogeneous datasets at presence of an unknown\nnumber of Byzantine workers. The Byzantine workers, during the learning\nprocess, may send arbitrary incorrect messages to the master due to data\ncorruptions, communication failures or malicious attacks, and consequently bias\nthe learned model. The key to the proposed methods is a regularization term\nincorporated with the objective function so as to robustify the learning task\nand mitigate the negative effects of Byzantine attacks. The resultant\nsubgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation\nmethods, justifying our acronym RSA used henceforth. In contrast to most of the\nexisting algorithms, RSA does not rely on the assumption that the data are\nindependent and identically distributed (i.i.d.) on the workers, and hence fits\nfor a wider class of applications. Theoretically, we show that: i) RSA\nconverges to a near-optimal solution with the learning error dependent on the\nnumber of Byzantine workers; ii) the convergence rate of RSA under Byzantine\nattacks is the same as that of the stochastic gradient descent method, which is\nfree of Byzantine attacks. Numerically, experiments on real dataset corroborate\nthe competitive performance of RSA and a complexity reduction compared to the\nstate-of-the-art alternatives.",
    "published_date": "2018-11-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.MA",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03761v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03654v2",
    "title": "How Do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness",
    "authors": [
      "Nripsuta Saxena",
      "Karen Huang",
      "Evan DeFilippis",
      "Goran Radanovic",
      "David Parkes",
      "Yang Liu"
    ],
    "author_ids": [],
    "abstract": "What is the best way to define algorithmic fairness? While many definitions\nof fairness have been proposed in the computer science literature, there is no\nclear agreement over a particular definition. In this work, we investigate\nordinary people's perceptions of three of these fairness definitions. Across\ntwo online experiments, we test which definitions people perceive to be the\nfairest in the context of loan decisions, and whether fairness perceptions\nchange with the addition of sensitive information (i.e., race of the loan\napplicants). Overall, one definition (calibrated fairness) tends to be more\npreferred than the others, and the results also provide support for the\nprinciple of affirmative action.",
    "published_date": "2018-11-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03654v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03532v1",
    "title": "Scalable Robust Kidney Exchange",
    "authors": [
      "Duncan C McElfresh",
      "Hoda Bidkhori",
      "John P Dickerson"
    ],
    "author_ids": [],
    "abstract": "In barter exchanges, participants directly trade their endowed goods in a\nconstrained economic setting without money. Transactions in barter exchanges\nare often facilitated via a central clearinghouse that must match participants\neven in the face of uncertainty---over participants, existence and quality of\npotential trades, and so on. Leveraging robust combinatorial optimization\ntechniques, we address uncertainty in kidney exchange, a real-world barter\nmarket where patients swap (in)compatible paired donors. We provide two\nscalable robust methods to handle two distinct types of uncertainty in kidney\nexchange---over the quality and the existence of a potential match. The latter\ncase directly addresses a weakness in all stochastic-optimization-based methods\nto the kidney exchange clearing problem, which all necessarily require explicit\nestimates of the probability of a transaction existing---a still-unsolved\nproblem in this nascent market. We also propose a novel, scalable kidney\nexchange formulation that eliminates the need for an exponential-time\nconstraint generation process in competing formulations, maintains provable\noptimality, and serves as a subsolver for our robust approach. For each type of\nuncertainty we demonstrate the benefits of robustness on real data from a\nlarge, fielded kidney exchange in the United States. We conclude by drawing\nparallels between robustness and notions of fairness in the kidney exchange\nsetting.",
    "published_date": "2018-11-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "I.2; G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03532v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03259v1",
    "title": "Bias and Generalization in Deep Generative Models: An Empirical Study",
    "authors": [
      "Shengjia Zhao",
      "Hongyu Ren",
      "Arianna Yuan",
      "Jiaming Song",
      "Noah Goodman",
      "Stefano Ermon"
    ],
    "author_ids": [],
    "abstract": "In high dimensional settings, density estimation algorithms rely crucially on\ntheir inductive bias. Despite recent empirical success, the inductive bias of\ndeep generative models is not well understood. In this paper we propose a\nframework to systematically investigate bias and generalization in deep\ngenerative models of images. Inspired by experimental methods from cognitive\npsychology, we probe each learning algorithm with carefully designed training\ndatasets to characterize when and how existing models generate novel attributes\nand their combinations. We identify similarities to human psychology and verify\nthat these patterns are consistent across commonly used models and\narchitectures.",
    "published_date": "2018-11-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03259v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03179v4",
    "title": "How Well Generative Adversarial Networks Learn Distributions",
    "authors": [
      "Tengyuan Liang"
    ],
    "author_ids": [],
    "abstract": "This paper studies the rates of convergence for learning distributions\nimplicitly with the adversarial framework and Generative Adversarial Networks\n(GANs), which subsume Wasserstein, Sobolev, MMD GAN, and Generalized/Simulated\nMethod of Moments (GMM/SMM) as special cases. We study a wide range of\nparametric and nonparametric target distributions under a host of objective\nevaluation metrics. We investigate how to obtain valid statistical guarantees\nfor GANs through the lens of regularization. On the nonparametric end, we\nderive the optimal minimax rates for distribution estimation under the\nadversarial framework. On the parametric end, we establish a theory for general\nneural network classes (including deep leaky ReLU networks) that characterizes\nthe interplay on the choice of generator and discriminator pair. We discover\nand isolate a new notion of regularization, called the\ngenerator-discriminator-pair regularization, that sheds light on the advantage\nof GANs compared to classical parametric and nonparametric approaches for\nexplicit distribution estimation. We develop novel oracle inequalities as the\nmain technical tools for analyzing GANs, which are of independent interest.",
    "published_date": "2018-11-07T00:00:00",
    "year": 2018,
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03179v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03157v1",
    "title": "Forensic Discrimination between Traditional and Compressive Imaging Systems",
    "authors": [
      "Ali Taimori",
      "Farokh Marvasti"
    ],
    "author_ids": [],
    "abstract": "Compressive sensing is a new technology for modern computational imaging\nsystems. In comparison to widespread conventional image sensing, the\ncompressive imaging paradigm requires specific forensic analysis techniques and\ntools. In this regards, one of basic scenarios in image forensics is to\ndistinguish traditionally sensed images from sophisticated compressively sensed\nones. To do this, we first mathematically and systematically model the imaging\nsystem based on compressive sensing technology. Afterwards, a simplified\nversion of the whole model is presented, which is appropriate for forensic\ninvestigation applications. We estimate the nonlinear system of compressive\nsensing with a linear model. Then, we model the imaging pipeline as an inverse\nproblem and demonstrate that different imagers have discriminative degradation\nkernels. Hence, blur kernels of various imaging systems have utilized as\nfootprints for discriminating image acquisition sources. In order to accomplish\nthe identification cycle, we have utilized the state-of-the-art Convolutional\nNeural Network (CNN) and Support Vector Machine (SVM) approaches to learn a\nclassification system from estimated blur kernels. Numerical experiments show\npromising identification results. Simulation codes are available for research\nand development purposes.",
    "published_date": "2018-11-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03157v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.02964v1",
    "title": "Instantly Deployable Expert Knowledge - Networks of Knowledge Engines",
    "authors": [
      "Bernhard Bergmair",
      "Thomas Buchegger",
      "Johann Hoffelner",
      "Gerald Schatz",
      "Siegfried Silber",
      "Johannes Klinglmayr"
    ],
    "author_ids": [],
    "abstract": "Knowledge and information are becoming the primary resources of the emerging\ninformation society. To exploit the potential of available expert knowledge,\ncomprehension and application skills (i.e. expert competences) are necessary.\nThe ability to acquire these skills is limited for any individual human.\nConsequently, the capacities to solve problems based on human knowledge in a\nmanual (i.e. mental) way are strongly limited. We envision a new systemic\napproach to enable scalable knowledge deployment without expert competences.\nEventually, the system is meant to instantly deploy humanity's total knowledge\nin full depth for every individual challenge. To this end, we propose a\nsocio-technical framework that transforms expert knowledge into a solution\ncreation system. Knowledge is represented by automated algorithms (knowledge\nengines). Executable compositions of knowledge engines (networks of knowledge\nengines) generate requested individual information at runtime. We outline how\nthese knowledge representations could yield legal, ethical and social\nchallenges and nurture new business and remuneration models on knowledge. We\nidentify major technological and economic concepts that are already pushing the\nboundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge\nbases, ontologies, advanced search tools, automation of knowledge work, the API\neconomy. We indicate impacts on society, economy and labour. Existing\ndevelopments are linked, including a specific use case in engineering design.",
    "published_date": "2018-11-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02964v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.02908v1",
    "title": "User Fairness Non-orthogonal Multiple Access (NOMA) for 5G Millimeter-Wave Communications with Analog Beamforming",
    "authors": [
      "Zhenyu Xiao",
      "Lipeng Zhu",
      "Zhen Gao",
      "Dapeng Oliver Wu",
      "Xiang-Gen Xia"
    ],
    "author_ids": [],
    "abstract": "The integration of non-orthogonal multiple access in millimeter-Wave\ncommunications (mmWave-NOMA) can significantly improve the spectrum efficiency\nand increase the number of users in the fifth-generation (5G) mobile\ncommunication. In this paper we consider a downlink mmWave-NOMA cellular\nsystem, where the base station is mounted with an analog beamforming phased\narray, and multiple users are served in the same time-frequency resource block.\nTo guarantee user fairness, we formulate a joint beamforming and power\nallocation problem to maximize the minimal achievable rate among the users,\ni.e., we adopt the max-min fairness. As the problem is difficult to solve due\nto the non-convex formulation and high dimension of the optimization variables,\nwe propose a sub-optimal solution, which makes use of the spatial sparsity in\nthe angle domain of the mmWave channel. In the solution, the closed-form\noptimal power allocation is obtained first, which reduces the joint\noptimization problem into an equivalent beamforming problem. Then an\nappropriate beamforming vector is designed. Simulation results show that the\nproposed solution can achieve a near-upper-bound performance in terms of\nachievable rate, which is significantly better than that of the conventional\nmmWave orthogonal multiple access (mmWave-OMA) system.",
    "published_date": "2018-11-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02908v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1812.02311v1",
    "title": "In (Stochastic) Search of a Fairer Alife",
    "authors": [
      "Dmitriy Volinskiy",
      "Lana Cuthbertson",
      "Omid Ardakanian"
    ],
    "author_ids": [],
    "abstract": "Economies and societal structures in general are complex stochastic systems\nwhich may not lend themselves well to algebraic analysis. An addition of\nsubjective value criteria to the mechanics of interacting agents will further\ncomplicate analysis. The purpose of this short study is to demonstrate\ncapabilities of agent-based computational economics to be a platform for\nfairness or equity analysis in both a broad and practical sense.",
    "published_date": "2018-11-07T00:00:00",
    "year": 2018,
    "categories": [
      "q-fin.GN",
      "cs.MA",
      "I.6.8; G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1812.02311v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.02545v1",
    "title": "Hide-and-Seek: A Data Augmentation Technique for Weakly-Supervised Localization and Beyond",
    "authors": [
      "Krishna Kumar Singh",
      "Hao Yu",
      "Aron Sarmasi",
      "Gautam Pradeep",
      "Yong Jae Lee"
    ],
    "author_ids": [],
    "abstract": "We propose 'Hide-and-Seek' a general purpose data augmentation technique,\nwhich is complementary to existing data augmentation techniques and is\nbeneficial for various visual recognition tasks. The key idea is to hide\npatches in a training image randomly, in order to force the network to seek\nother relevant content when the most discriminative content is hidden. Our\napproach only needs to modify the input image and can work with any network to\nimprove its performance. During testing, it does not need to hide any patches.\nThe main advantage of Hide-and-Seek over existing data augmentation techniques\nis its ability to improve object localization accuracy in the weakly-supervised\nsetting, and we therefore use this task to motivate the approach. However,\nHide-and-Seek is not tied only to the image localization task, and can\ngeneralize to other forms of visual input like videos, as well as other\nrecognition tasks like image classification, temporal action localization,\nsemantic segmentation, emotion recognition, age/gender estimation, and person\nre-identification. We perform extensive experiments to showcase the advantage\nof Hide-and-Seek on these various visual recognition problems.",
    "published_date": "2018-11-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02545v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.02367v2",
    "title": "Scalable Application- and User-aware Resource Allocation in Enterprise Networks Using End-host Pacing",
    "authors": [
      "Christian Sieber",
      "Susanna Schwarzmann",
      "Andreas Blenk",
      "Thomas Zinner",
      "Wolfgang Kellerer"
    ],
    "author_ids": [],
    "abstract": "Scalable user- and application-aware resource allocation for heterogeneous\napplications sharing an enterprise network is still an unresolved problem. The\nmain challenges are: (i) How to define user- and application-aware shares of\nresources? (ii) How to determine an allocation of shares of network resources\nto applications? (iii) How to allocate the shares per application in\nheterogeneous networks at scale? In this paper we propose solutions to the\nthree challenges and introduce a system design for enterprise deployment.\nDefining the necessary resource shares per application is hard, as the intended\nuse case and user's preferences influence the resource demand. Utility\nfunctions based on user experience enable a mapping of network resources in\nterms of throughput and latency budget to a common user-level utility scale. A\nmulti-objective MILP is formulated to solve the throughput- and delay-aware\nembedding of each utility function for a max-min fairness criteria. The\nallocation of resources in traditional networks with policing and scheduling\ncannot distinguish large numbers of classes. We propose a resource allocation\nsystem design for enterprise networks based on Software-Defined Networking\nprinciples to achieve delay-constrained routing in the network and application\npacing at the end-hosts. The system design is evaluated against best effort\nnetworks with applications competing for the throughput of a constrained link.\nThe competing applications belong to the five application classes web browsing,\nfile download, remote terminal work, video streaming, and Voice-over-IP. The\nresults show that the proposed methodology improves the minimum and total\nutility, minimizes packet loss and queuing delay at bottlenecks, establishes\nfairness in terms of utility between applications, and achieves predictable\napplication performance at high link utilization.",
    "published_date": "2018-11-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02367v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.02994v1",
    "title": "An exploration of algorithmic discrimination in data and classification",
    "authors": [
      "Jixue Liu",
      "Jiuyong Li",
      "Feiyue Ye",
      "Lin Liu",
      "Thuc Duy Le",
      "Ping Xiong"
    ],
    "author_ids": [],
    "abstract": "Algorithmic discrimination is an important aspect when data is used for\npredictive purposes. This paper analyzes the relationships between\ndiscrimination and classification, data set partitioning, and decision models,\nas well as correlation. The paper uses real world data sets to demonstrate the\nexistence of discrimination and the independence between the discrimination of\ndata sets and the discrimination of classification models.",
    "published_date": "2018-11-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02994v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.03435v4",
    "title": "Data Science as Political Action: Grounding Data Science in a Politics of Justice",
    "authors": [
      "Ben Green"
    ],
    "author_ids": [],
    "abstract": "In response to public scrutiny of data-driven algorithms, the field of data\nscience has adopted ethics training and principles. Although ethics can help\ndata scientists reflect on certain normative aspects of their work, such\nefforts are ill-equipped to generate a data science that avoids social harms\nand promotes social justice. In this article, I argue that data science must\nembrace a political orientation. Data scientists must recognize themselves as\npolitical actors engaged in normative constructions of society and evaluate\ntheir work according to its downstream impacts on people's lives. I first\narticulate why data scientists must recognize themselves as political actors.\nIn this section, I respond to three arguments that data scientists commonly\ninvoke when challenged to take political positions regarding their work. In\nconfronting these arguments, I describe why attempting to remain apolitical is\nitself a political stance--a fundamentally conservative one--and why data\nscience's attempts to promote \"social good\" dangerously rely on unarticulated\nand incrementalist political assumptions. I then propose a framework for how\ndata science can evolve toward a deliberative and rigorous politics of social\njustice. I conceptualize the process of developing a politically engaged data\nscience as a sequence of four stages. Pursuing these new approaches will\nempower data scientists with new methods for thoughtfully and rigorously\ncontributing to social justice.",
    "published_date": "2018-11-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03435v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.01918v2",
    "title": "On Relating Technical, Social Factors, and the Introduction of Bugs",
    "authors": [
      "Filipe Falcão",
      "Caio Barbosa",
      "Baldoino Fonseca",
      "Alessandro Garcia",
      "Márcio Ribeiro",
      "Rohit Ghey"
    ],
    "author_ids": [],
    "abstract": "As collaborative coding environments make it easier to contribute to software\nprojects, the number of developers involved in these projects keeps increasing.\nThis increase makes it more difficult for code reviewers to deal with buggy\ncontributions. Collaborative environments like GitHub provide a rich source of\ndata on developers' contributions. Such data can be used to extract information\nabout developers regarding technical (e.g., their experience) and social (e.g.,\ntheir interactions) factors. Recent studies analyzed the influence of these\nfactors on different activities of software development. However, there is\nstill room for improvement on the relation between these factors and the\nintroduction of bugs. We present a broader study, including 8 projects from\ndifferent domains and 6,537 bug reports, on relating five technical, three\nsocial factors, and the introduction of bugs. The results indicate that\ntechnical and social factors can discriminate between buggy and clean commits.\nBut, the technical factors are more determining than social ones. Particularly,\nthe developers' habits of not following technical contribution norms and the\ndeveloper's commit bugginess are associated with an increase on commit\nbugginess. On the other hand, project's establishment, ownership level of\ndevelopers' commit, and social influence are related to a lower chance of\nintroducing bugs.",
    "published_date": "2018-11-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01918v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.01802v3",
    "title": "Intervention Harvesting for Context-Dependent Examination-Bias Estimation",
    "authors": [
      "Zhichong Fang",
      "Aman Agarwal",
      "Thorsten Joachims"
    ],
    "author_ids": [],
    "abstract": "Accurate estimates of examination bias are crucial for unbiased\nlearning-to-rank from implicit feedback in search engines and recommender\nsystems, since they enable the use of Inverse Propensity Score (IPS) weighting\ntechniques to address selection biases and missing data. Unfortunately,\nexisting examination-bias estimators are limited to the Position-Based Model\n(PBM), where the examination bias may only depend on the rank of the document.\nTo overcome this limitation, we propose a Contextual Position-Based Model\n(CPBM) where the examination bias may also depend on a context vector\ndescribing the query and the user. Furthermore, we propose an effective\nestimator for the CPBM based on intervention harvesting. A key feature of the\nestimator is that it does not require disruptive interventions but merely\nexploits natural variation resulting from the use of multiple historic ranking\nfunctions. Real-world experiments on the ArXiv search engine and semi-synthetic\nexperiments on the Yahoo Learning-To-Rank dataset demonstrate the superior\neffectiveness and robustness of the new approach.",
    "published_date": "2018-11-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01802v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.01753v2",
    "title": "How deep is deep enough? -- Quantifying class separability in the hidden layers of deep neural networks",
    "authors": [
      "Achim Schilling",
      "Claus Metzner",
      "Jonas Rietsch",
      "Richard Gerum",
      "Holger Schulze",
      "Patrick Krauss"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks typically outperform more traditional machine learning\nmodels in their ability to classify complex data, and yet is not clear how the\nindividual hidden layers of a deep network contribute to the overall\nclassification performance. We thus introduce a Generalized Discrimination\nValue (GDV) that measures, in a non-invasive manner, how well different data\nclasses separate in each given network layer. The GDV can be used for the\nautomatic tuning of hyper-parameters, such as the width profile and the total\ndepth of a network. Moreover, the layer-dependent GDV(L) provides new insights\ninto the data transformations that self-organize during training: In the case\nof multi-layer perceptrons trained with error backpropagation, we find that\nclassification of highly complex data sets requires a temporal {\\em reduction}\nof class separability, marked by a characteristic 'energy barrier' in the\ninitial part of the GDV(L) curve. Even more surprisingly, for a given data set,\nthe GDV(L) is running through a fixed 'master curve', independently from the\ntotal number of network layers. Furthermore, applying the GDV to Deep Belief\nNetworks reveals that also unsupervised training with the Contrastive\nDivergence method can systematically increase class separability over tens of\nlayers, even though the system does not 'know' the desired class labels. These\nresults indicate that the GDV may become a useful tool to open the black box of\ndeep learning.",
    "published_date": "2018-11-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01753v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.01480v1",
    "title": "FairMod - Making Predictive Models Discrimination Aware",
    "authors": [
      "Jixue Liu",
      "Jiuyong Li",
      "Lin Liu",
      "Thuc Duy Le",
      "Feiyue Ye",
      "Gefei Li"
    ],
    "author_ids": [],
    "abstract": "Predictive models such as decision trees and neural networks may produce\ndiscrimination in their predictions. This paper proposes a method to\npost-process the predictions of a predictive model to make the processed\npredictions non-discriminatory. The method considers multiple protected\nvariables together. Multiple protected variables make the problem more\nchallenging than a simple protected variable. The method uses a well-cited\ndiscrimination metric and adapts it to allow the specification of explanatory\nvariables, such as position, profession, education, that describe the contexts\nof the applications. It models the post-processing of predictions problem as a\nnonlinear optimization problem to find best adjustments to the predictions so\nthat the discrimination constraints of all protected variables are all met at\nthe same time. The proposed method is independent of classification methods. It\ncan handle the cases that existing methods cannot handle: satisfying multiple\nprotected attributes at the same time, allowing multiple explanatory\nattributes, and being independent of classification model types. An evaluation\nusing four real world data sets shows that the proposed method is as\neffectively as existing methods, in addition to its extra power.",
    "published_date": "2018-11-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01480v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.01461v1",
    "title": "Bias Disparity in Recommendation Systems",
    "authors": [
      "Virginia Tsintzou",
      "Evaggelia Pitoura",
      "Panayiotis Tsaparas"
    ],
    "author_ids": [],
    "abstract": "Recommender systems have been applied successfully in a number of different\ndomains, such as, entertainment, commerce, and employment. Their success lies\nin their ability to exploit the collective behavior of users in order to\ndeliver highly targeted, personalized recommendations. Given that recommenders\nlearn from user preferences, they incorporate different biases that users\nexhibit in the input data. More importantly, there are cases where recommenders\nmay amplify such biases, leading to the phenomenon of bias disparity. In this\nshort paper, we present a preliminary experimental study on synthetic data,\nwhere we investigate different conditions under which a recommender exhibits\nbias disparity, and the long-term effect of recommendations on data bias. We\nalso consider a simple re-ranking algorithm for reducing bias disparity, and\npresent some observations for data disparity on real data.",
    "published_date": "2018-11-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01461v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.01459v3",
    "title": "Deep Metric Learning by Online Soft Mining and Class-Aware Attention",
    "authors": [
      "Xinshao Wang",
      "Yang Hua",
      "Elyor Kodirov",
      "Guosheng Hu",
      "Neil M. Robertson"
    ],
    "author_ids": [],
    "abstract": "Deep metric learning aims to learn a deep embedding that can capture the\nsemantic similarity of data points. Given the availability of massive training\nsamples, deep metric learning is known to suffer from slow convergence due to a\nlarge fraction of trivial samples. Therefore, most existing methods generally\nresort to sample mining strategies for selecting nontrivial samples to\naccelerate convergence and improve performance. In this work, we identify two\ncritical limitations of the sample mining methods, and provide solutions for\nboth of them. First, previous mining methods assign one binary score to each\nsample, i.e., dropping or keeping it, so they only selects a subset of relevant\nsamples in a mini-batch. Therefore, we propose a novel sample mining method,\ncalled Online Soft Mining (OSM), which assigns one continuous score to each\nsample to make use of all samples in the mini-batch. OSM learns extended\nmanifolds that preserve useful intraclass variances by focusing on more similar\npositives. Second, the existing methods are easily influenced by outliers as\nthey are generally included in the mined subset. To address this, we introduce\nClass-Aware Attention (CAA) that assigns little attention to abnormal data\nsamples. Furthermore, by combining OSM and CAA, we propose a novel weighted\ncontrastive loss to learn discriminative embeddings. Extensive experiments on\ntwo fine-grained visual categorisation datasets and two video-based person\nre-identification benchmarks show that our method significantly outperforms the\nstate-of-the-art.",
    "published_date": "2018-11-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01459v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.01109v1",
    "title": "The estimation of bias and variance in clustering coefficient streaming algorithms",
    "authors": [
      "Roohollah Etemadi",
      "Jianguo Lu"
    ],
    "author_ids": [],
    "abstract": "Clustering coefficient is one of the most important metrics to understand the\ncomplex structure of networks. This paper addresses the estimation of\nclustering coefficient in network streams. There have been substantial work in\nthis area, most of conducting empirical comparisons of various algorithms. The\nvariance and the bias of the estimators have not been quantified. Starting with\na simple yet powerful streaming algorithm, we derived the variance and bias for\nthe estimator, and the estimators for the variances and bias. More importantly,\nwe simplify the estimators so that it can be used in practice. The variance and\nbias estimators are verified extensively on 49 real networks.",
    "published_date": "2018-11-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "62H12 (Primary) 62D05, 05C82, 62J10 (Secondary)"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.01109v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.00982v2",
    "title": "The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale",
    "authors": [
      "Alina Kuznetsova",
      "Hassan Rom",
      "Neil Alldrin",
      "Jasper Uijlings",
      "Ivan Krasin",
      "Jordi Pont-Tuset",
      "Shahab Kamali",
      "Stefan Popov",
      "Matteo Malloci",
      "Alexander Kolesnikov",
      "Tom Duerig",
      "Vittorio Ferrari"
    ],
    "author_ids": [],
    "abstract": "We present Open Images V4, a dataset of 9.2M images with unified annotations\nfor image classification, object detection and visual relationship detection.\nThe images have a Creative Commons Attribution license that allows to share and\nadapt the material, and they have been collected from Flickr without a\npredefined list of class names or tags, leading to natural class statistics and\navoiding an initial design bias. Open Images V4 offers large scale across\nseveral dimensions: 30.1M image-level labels for 19.8k concepts, 15.4M bounding\nboxes for 600 object classes, and 375k visual relationship annotations\ninvolving 57 classes. For object detection in particular, we provide 15x more\nbounding boxes than the next largest datasets (15.4M boxes on 1.9M images). The\nimages often show complex scenes with several objects (8 annotated objects per\nimage on average). We annotated visual relationships between them, which\nsupport visual relationship detection, an emerging task that requires\nstructured reasoning. We provide in-depth comprehensive statistics about the\ndataset, we validate the quality of the annotations, we study how the\nperformance of several modern models evolves with increasing amounts of\ntraining data, and we demonstrate two applications made possible by having\nunified annotations of multiple types coexisting in the same images. We hope\nthat the scale, quality, and variety of Open Images V4 will foster further\nresearch and innovation even beyond the areas of image classification, object\ndetection, and visual relationship detection.",
    "published_date": "2018-11-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00982v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00731v2",
    "title": "The age of secrecy and unfairness in recidivism prediction",
    "authors": [
      "Cynthia Rudin",
      "Caroline Wang",
      "Beau Coker"
    ],
    "author_ids": [],
    "abstract": "In our current society, secret algorithms make important decisions about\nindividuals. There has been substantial discussion about whether these\nalgorithms are unfair to groups of individuals. While noble, this pursuit is\ncomplex and ultimately stagnating because there is no clear definition of\nfairness and competing definitions are largely incompatible. We argue that the\nfocus on the question of fairness is misplaced, as these algorithms fail to\nmeet a more important and yet readily obtainable goal: transparency. As a\nresult, creators of secret algorithms can provide incomplete or misleading\ndescriptions about how their models work, and various other kinds of errors can\neasily go unnoticed. By partially reverse engineering the COMPAS algorithm -- a\nrecidivism-risk scoring algorithm used throughout the criminal justice system\n-- we show that it does not seem to depend linearly on the defendant's age,\ndespite statements to the contrary by the algorithm's creator. Furthermore, by\nsubtracting from COMPAS its (hypothesized) nonlinear age component, we show\nthat COMPAS does not necessarily depend on race, contradicting ProPublica's\nanalysis, which assumed linearity in age. In other words, faulty assumptions\nabout a proprietary algorithm lead to faulty conclusions that go unchecked\nwithout careful reverse engineering. Were the algorithm transparent in the\nfirst place, this would likely not have occurred. The most important result in\nthis work is that we find that there are many defendants with low risk score\nbut long criminal histories, suggesting that data inconsistencies occur\nfrequently in criminal justice databases. We argue that transparency satisfies\na different notion of procedural fairness by providing both the defendants and\nthe public with the opportunity to scrutinize the methodology and calculations\nbehind risk scores for recidivism.",
    "published_date": "2018-11-02T00:00:00",
    "year": 2018,
    "categories": [
      "stat.AP",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00731v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.00700v2",
    "title": "Learning from Large-scale Noisy Web Data with Ubiquitous Reweighting for Image Classification",
    "authors": [
      "Jia Li",
      "Yafei Song",
      "Jianfeng Zhu",
      "Lele Cheng",
      "Ying Su",
      "Lin Ye",
      "Pengcheng Yuan",
      "Shumin Han"
    ],
    "author_ids": [],
    "abstract": "Many advances of deep learning techniques originate from the efforts of\naddressing the image classification task on large-scale datasets. However, the\nconstruction of such clean datasets is costly and time-consuming since the\nInternet is overwhelmed by noisy images with inadequate and inaccurate tags. In\nthis paper, we propose a Ubiquitous Reweighting Network (URNet) that learns an\nimage classification model from large-scale noisy data. By observing the web\ndata, we find that there are five key challenges, i.e., imbalanced class sizes,\nhigh intra-classes diversity and inter-class similarity, imprecise instances,\ninsufficient representative instances, and ambiguous class labels. To alleviate\nthese challenges, we assume that every training instance has the potential to\ncontribute positively by alleviating the data bias and noise via reweighting\nthe influence of each instance according to different class sizes, large\ninstance clusters, its confidence, small instance bags and the labels. In this\nmanner, the influence of bias and noise in the web data can be gradually\nalleviated, leading to the steadily improving performance of URNet.\nExperimental results in the WebVision 2018 challenge with 16 million noisy\ntraining images from 5000 classes show that our approach outperforms\nstate-of-the-art models and ranks the first place in the image classification\ntask.",
    "published_date": "2018-11-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00700v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00697v1",
    "title": "Noise Contrastive Estimation for Scalable Linear Models for One-Class Collaborative Filtering",
    "authors": [
      "Ga Wu",
      "Maksims Volkovs",
      "Chee Loong Soon",
      "Scott Sanner",
      "Himanshu Rai"
    ],
    "author_ids": [],
    "abstract": "Previous highly scalable one-class collaborative filtering methods such as\nProjected Linear Recommendation (PLRec) have advocated using fast randomized\nSVD to embed items into a latent space, followed by linear regression methods\nto learn personalized recommendation models per user. Unfortunately, naive SVD\nembedding methods often exhibit a popularity bias that skews the ability to\naccurately embed niche items. To address this, we leverage insights from Noise\nContrastive Estimation (NCE) to derive a closed-form, efficiently computable\n\"depopularized\" embedding. While this method is not ideal for direct\nrecommendation using methods like PureSVD since popularity still plays an\nimportant role in recommendation, we find that embedding followed by linear\nregression to learn personalized user models in a novel method we call\nNCE-PLRec leverages the improved item embedding of NCE while correcting for its\npopularity unbiasing in final recommendations. An analysis of the\nrecommendation popularity distribution demonstrates that NCE-PLRec uniformly\ndistributes its recommendations over the popularity spectrum while other\nmethods exhibit distinct biases towards specific popularity subranges, thus\nartificially restricting their recommendations. Empirically, NCE-PLRec\noutperforms state-of-the-art methods as well as various ablations of itself on\na variety of large-scale recommendation datasets.",
    "published_date": "2018-11-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00697v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00464v1",
    "title": "A latent topic model for mining heterogenous non-randomly missing electronic health records data",
    "authors": [
      "Yue Li",
      "Manolis Kellis"
    ],
    "author_ids": [],
    "abstract": "Electronic health records (EHR) are rich heterogeneous collection of patient\nhealth information, whose broad adoption provides great opportunities for\nsystematic health data mining. However, heterogeneous EHR data types and biased\nascertainment impose computational challenges. Here, we present mixEHR, an\nunsupervised generative model integrating collaborative filtering and latent\ntopic models, which jointly models the discrete distributions of data\nobservation bias and actual data using latent disease-topic distributions. We\napply mixEHR on 12.8 million phenotypic observations from the MIMIC dataset,\nand use it to reveal latent disease topics, interpret EHR results, impute\nmissing data, and predict mortality in intensive care units. Using both\nsimulation and real data, we show that mixEHR outperforms previous methods and\nreveals meaningful multi-disease insights.",
    "published_date": "2018-11-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00464v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00458v4",
    "title": "Bias Reduction via End-to-End Shift Learning: Application to Citizen Science",
    "authors": [
      "Di Chen",
      "Carla P. Gomes"
    ],
    "author_ids": [],
    "abstract": "Citizen science projects are successful at gathering rich datasets for\nvarious applications. However, the data collected by citizen scientists are\noften biased --- in particular, aligned more with the citizens' preferences\nthan with scientific objectives. We propose the Shift Compensation Network\n(SCN), an end-to-end learning scheme which learns the shift from the scientific\nobjectives to the biased data while compensating for the shift by re-weighting\nthe training data. Applied to bird observational data from the citizen science\nproject eBird, we demonstrate how SCN quantifies the data distribution shift\nand outperforms supervised learning models that do not address the data bias.\nCompared with competing models in the context of covariate shift, we further\ndemonstrate the advantage of SCN in both its effectiveness and its capability\nof handling massive high-dimensional data.",
    "published_date": "2018-11-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00458v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00429v2",
    "title": "Temporal Regularization in Markov Decision Process",
    "authors": [
      "Pierre Thodoroff",
      "Audrey Durand",
      "Joelle Pineau",
      "Doina Precup"
    ],
    "author_ids": [],
    "abstract": "Several applications of Reinforcement Learning suffer from instability due to\nhigh variance. This is especially prevalent in high dimensional domains.\nRegularization is a commonly used technique in machine learning to reduce\nvariance, at the cost of introducing some bias. Most existing regularization\ntechniques focus on spatial (perceptual) regularization. Yet in reinforcement\nlearning, due to the nature of the Bellman equation, there is an opportunity to\nalso exploit temporal regularization based on smoothness in value estimates\nover trajectories. This paper explores a class of methods for temporal\nregularization. We formally characterize the bias induced by this technique\nusing Markov chain concepts. We illustrate the various characteristics of\ntemporal regularization via a sequence of simple discrete and continuous MDPs,\nand show that the technique provides improvement even in high-dimensional Atari\ngames.",
    "published_date": "2018-11-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00429v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.00345v4",
    "title": "Sharp moment-entropy inequalities and capacity bounds for log-concave distributions",
    "authors": [
      "Mokshay Madiman",
      "Piotr Nayar",
      "Tomasz Tkocz"
    ],
    "author_ids": [],
    "abstract": "We show that the uniform distribution minimizes entropy among all\none-dimensional symmetric log-concave distributions with fixed variance, as\nwell as various generalizations of this fact to R\\'enyi entropies of orders\nless than 1 and with moment constraints involving $p$-th absolute moments with\n$p\\leq 2$. As consequences, we give new capacity bounds for additive noise\nchannels with symmetric log-concave noises, as well as for timing channels\ninvolving positive signal and noise where the noise has a decreasing\nlog-concave density. In particular, we show that the capacity of an additive\nnoise channel with symmetric, log-concave noise under an average power\nconstraint is at most 0.254 bits per channel use greater than the capacity of\nan additive Gaussian noise channel with the same noise power. Consequences for\nreverse entropy power inequalities and connections to the slicing problem in\nconvex geometry are also discussed.",
    "published_date": "2018-11-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR",
      "94A17 (Primary), 60E15 (Secondary)"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00345v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.00286v1",
    "title": "Interdisciplinarity: A Nobel Opportunity",
    "authors": [
      "Michael Szell",
      "Yifang Ma",
      "Roberta Sinatra"
    ],
    "author_ids": [],
    "abstract": "Interdisciplinary collaborations now sweep most fields of the natural and\nlife sciences, necessary to tackle the world's most challenging problems. Yet,\nthe scientific enterprise continues to be dominated by old stereotypes:\nInterdisciplinary science is less likely to receive funding and is\ndiscriminated at institutional levels. Ample solutions for funders,\ninstitutions and publishers have been suggested, but the most visible form of\nscientific credit has so far been ignored: How interdisciplinary is our award\nsystem? To address this question, we explore interdisciplinarity in the most\nprestigious award in science, the Nobel Prize. We document a tendency of Nobel\nPrizes to neglect interdisciplinary discoveries, especially between physics and\nthe life sciences. Given the increased growth of interdisciplinary high-impact\nresearch over the last three decades, we have reached the critical point in\ntime where the issue of recognizing outstanding interdisciplinary research has\nbecome truly pressing.",
    "published_date": "2018-11-01T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.00286v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.13407v2",
    "title": "On The Inductive Bias of Words in Acoustics-to-Word Models",
    "authors": [
      "Hao Tang",
      "James Glass"
    ],
    "author_ids": [],
    "abstract": "Acoustics-to-word models are end-to-end speech recognizers that use words as\ntargets without relying on pronunciation dictionaries or graphemes. These\nmodels are notoriously difficult to train due to the lack of linguistic\nknowledge. It is also unclear how the amount of training data impacts the\noptimization and generalization of such models. In this work, we study the\noptimization and generalization of acoustics-to-word models under different\namounts of training data. In addition, we study three types of inductive bias,\nleveraging a pronunciation dictionary, word boundary annotations, and\nconstraints on word durations. We find that constraining word durations leads\nto the most improvement. Finally, we analyze the word embedding space learned\nby the model, and find that the space has a structure dominated by the\npronunciation of words. This suggests that the contexts of words, instead of\ntheir phonetic structure, should be the future focus of inductive bias in\nacoustics-to-word models.",
    "published_date": "2018-10-31T00:00:00",
    "year": 2018,
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.13407v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.13314v2",
    "title": "Crowdsourcing with Fairness, Diversity and Budget Constraints",
    "authors": [
      "Naman Goel",
      "Boi Faltings"
    ],
    "author_ids": [],
    "abstract": "Recent studies have shown that the labels collected from crowdworkers can be\ndiscriminatory with respect to sensitive attributes such as gender and race.\nThis raises questions about the suitability of using crowdsourced data for\nfurther use, such as for training machine learning algorithms. In this work, we\naddress the problem of fair and diverse data collection from a crowd under\nbudget constraints. We propose a novel algorithm which maximizes the expected\naccuracy of the collected data, while ensuring that the errors satisfy desired\nnotions of fairness. We provide guarantees on the performance of our algorithm\nand show that the algorithm performs well in practice through experiments on a\nreal dataset.",
    "published_date": "2018-10-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.13314v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.12942v2",
    "title": "Periodic Event-triggered Control for Incrementally Quadratic Nonlinear Systems",
    "authors": [
      "Xiangru Xu",
      "Adam M. Tahir",
      "Behcet Acikmese"
    ],
    "author_ids": [],
    "abstract": "Periodic event-triggered control (PETC) evaluates the triggering rule\nperiodically and is well-suited for implementation on digital platforms. This\npaper investigates PETC design for nonlinear systems affected by external\ndisturbances under the impulsive system formulation. Sufficient conditions are\nprovided to ensure the input-to-state stability of the resulting closed-loop\nsystem for the state feedback and the observer-based output feedback\nconfigurations separately. For each configuration, the sampling period and the\ntriggering functions are provided explicitly. Sufficient conditions in the form\nof linear matrix inequalities are provided for the PETC design of incrementally\nquadratic nonlinear systems. Two examples are given to illustrate the\neffectiveness of the proposed method.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.12942v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.12847v2",
    "title": "AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing",
    "authors": [
      "Bettina Berendt"
    ],
    "author_ids": [],
    "abstract": "Recently, many AI researchers and practitioners have embarked on research\nvisions that involve doing AI for \"Good\". This is part of a general drive\ntowards infusing AI research and practice with ethical thinking. One frequent\ntheme in current ethical guidelines is the requirement that AI be good for all,\nor: contribute to the Common Good. But what is the Common Good, and is it\nenough to want to be good? Via four lead questions, I will illustrate\nchallenges and pitfalls when determining, from an AI point of view, what the\nCommon Good is and how it can be enhanced by AI. The questions are: What is the\nproblem / What is a problem?, Who defines the problem?, What is the role of\nknowledge?, and What are important side effects and dynamics? The illustration\nwill use an example from the domain of \"AI for Social Good\", more specifically\n\"Data Science for Social Good\". Even if the importance of these questions may\nbe known at an abstract level, they do not get asked sufficiently in practice,\nas shown by an exploratory study of 99 contributions to recent conferences in\nthe field. Turning these challenges and pitfalls into a positive\nrecommendation, as a conclusion I will draw on another characteristic of\ncomputer-science thinking and practice to make these impediments visible and\nattenuate them: \"attacks\" as a method for improving design. This results in the\nproposal of ethics pen-testing as a method for helping AI designs to better\ncontribute to the Common Good.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.12847v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.12845v1",
    "title": "Constraints on Multipartite Quantum Entropies",
    "authors": [
      "Christian Majenz"
    ],
    "author_ids": [],
    "abstract": "The von Neumann entropy plays a vital role in quantum information theory. The\nvon Neumann entropy determines, e.g., the capacities of quantum channels. Also,\nentropies of composite quantum systems are important for future quantum\nnetworks, and their characterization is related to the quantum marginal\nproblem. Furthermore, they play a role in quantum thermodynamics. In this\nthesis the set of quantum entropies of multipartite quantum systems is studied.\nThe problem of its characterization is not new -- however, progress has been\nsparse, indicating that the problem might be hard and that new methods might be\nneeded. Here, a variety of different and complementary approaches are taken.\n  First, I look at global properties. It is known that the von Neumann entropy\nregion -- just like its classical counterpart -- forms a convex cone. I\ndescribe the symmetries of this cone and highlight geometric similarities and\ndifferences to the classical entropy cone.\n  In a different approach, I utilize the local geometric properties of extremal\nrays of a cone. I show that quantum states whose entropy lies on such an\nextremal ray of the quantum entropy cone have a very simple structure.\n  As the set of all quantum states is very complicated, I look at a simple\nsubset called stabilizer states. I improve on previously known results by\nshowing that under a technical condition on the local dimension, entropies of\nstabilizer states respect an additional class of information inequalities that\nis valid for random variables from linear codes.\n  In a last approach I find a representation-theoretic formulation of the\nclassical marginal problem simplifying the comparison with its quantum\nmechanical counterpart. This novel correspondence yields a simplified\nformulation of the group characterization of classical entropies (IEEE Trans.\nInf. Theory, 48(7):1992-1995, 2002) in purely combinatorial terms.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.12845v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.13236v1",
    "title": "Selection committees for academic recruitment: does gender matter?",
    "authors": [
      "Giovanni Abramo",
      "Ciriaco Andrea D'Angelo",
      "Francesco Rosati"
    ],
    "author_ids": [],
    "abstract": "Underrepresentation of women in the academic system is a problem common to\nmany countries, often associated with gender discrimination. In the Italian\nacademic context in particular, favoritism is recognized as a diffuse\nphenomenon affecting hiring and career advancement. One of the questions that\nnaturally arises is whether women who do assume decisional roles, having\nwitnessed other phenomena of discrimination, would practice less favoritism\nthan men in similar positions. Our analysis refers to the particular case of\nfavoritism in the work of university selection committees responsible for\ncareer advancement. We observe a moderate positive association between\ncompetitions with expected outcomes and the fact the committee president is a\nwoman. Although committees presided by women give more weight to scientific\nmerit than those presided by men, favoritism still occurs. In fact, in the case\nthe committee president is a woman, the single most important factor for the\nsuccess of a candidate is joint research with the president; while in the case\nof male presidents, it is the years together in the same university.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.13236v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.03416v4",
    "title": "Are the Dead Taking Over Facebook? A Big Data Approach to the Future of Death Online",
    "authors": [
      "Carl Öhman",
      "David Watson"
    ],
    "author_ids": [],
    "abstract": "We project the future accumulation of profiles belonging to deceased Facebook\nusers. Our analysis suggests that a minimum of 1.4 billion users will pass away\nbefore 2100 if Facebook ceases to attract new users as of 2018. If the network\ncontinues expanding at current rates, however, this number will exceed 4.9\nbillion. In both cases, a majority of the profiles will belong to non-Western\nusers. In discussing our findings, we draw on the emerging scholarship on\ndigital preservation and stress the challenges arising from curating the\nprofiles of the deceased. We argue that an exclusively commercial approach to\ndata preservation poses important ethical and political risks that demand\nurgent consideration. We call for a scalable, sustainable, and dignified\ncuration model that incorporates the interests of multiple stakeholders.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.03416v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.12589v1",
    "title": "Key Stakeholders' Value Propositions for Feature Selection in Software-intensive Products: An Industrial Case Study",
    "authors": [
      "Pilar Rodríguez",
      "Emilia Mendes",
      "Burak Turhan"
    ],
    "author_ids": [],
    "abstract": "Numerous software companies are adopting value-based decision making.\nHowever, what does value mean for key stakeholders making decisions? How do\ndifferent stakeholder groups understand value? Without an explicit\nunderstanding of what value means, decisions are subject to ambiguity and\nvagueness, which are likely to bias them. This case study provides an in-depth\nanalysis of key stakeholders' value propositions when selecting features for a\nlarge telecommunications company's software-intensive product. Stakeholders'\nvalue propositions were elicited via interviews, which were analyzed using\nGrounded Theory coding techniques (open and selective coding). Thirty-six value\npropositions were identified and classified into six dimensions: customer\nvalue, market competitiveness, economic value/profitability, cost efficiency,\ntechnology & architecture, and company strategy. Our results show that although\npropositions in the customer value dimension were those mentioned the most, the\nconcept of value for feature selection encompasses a wide range of value\npropositions. Moreover, stakeholder groups focused on different and\ncomplementary value dimensions, calling to the importance of involving all key\nstakeholders in the decision making process. Although our results are\nparticularly relevant to companies similar to the one described herein, they\naim to generate a learning process on value-based feature selection for\npractitioners and researchers in general.",
    "published_date": "2018-10-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.12589v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1811.02627v1",
    "title": "Vehicle Tracking Using Surveillance with Multimodal Data Fusion",
    "authors": [
      "Yue Zhang",
      "Bin Song",
      "Xiaojiang Du",
      "Mohsen Guizani"
    ],
    "author_ids": [],
    "abstract": "Vehicle location prediction or vehicle tracking is a significant topic within\nconnected vehicles. This task, however, is difficult if only a single modal\ndata is available, probably causing bias and impeding the accuracy. With the\ndevelopment of sensor networks in connected vehicles, multimodal data are\nbecoming accessible. Therefore, we propose a framework for vehicle tracking\nwith multimodal data fusion. Specifically, we fuse the results of two\nmodalities, images and velocity, in our vehicle-tracking task. Images, being\nprocessed in the module of vehicle detection, provide direct information about\nthe features of vehicles, whereas velocity estimation can further evaluate the\npossible location of the target vehicles, which reduces the number of features\nbeing compared, and decreases the time consumption and computational cost.\nVehicle detection is designed with a color-faster R-CNN, which takes both the\nshape and color of the vehicles into consideration. Meanwhile, velocity\nestimation is through the Kalman filter, which is a classical method for\ntracking. Finally, a multimodal data fusion method is applied to integrate\nthese outcomes so that vehicle-tracking tasks can be achieved. Experimental\nresults suggest the efficiency of our methods, which can track vehicles using a\nseries of surveillance cameras in urban areas.",
    "published_date": "2018-10-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02627v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.11900v2",
    "title": "Cultural transmission modes of music sampling traditions remain stable despite delocalization in the digital age",
    "authors": [
      "Mason Youngblood"
    ],
    "author_ids": [],
    "abstract": "Music sampling is a common practice among hip-hop and electronic producers\nthat has played a critical role in the development of particular subgenres.\nArtists preferentially sample drum breaks, and previous studies have suggested\nthat these may be culturally transmitted. With the advent of digital sampling\ntechnologies and social media the modes of cultural transmission may have\nshifted, and music communities may have become decoupled from geography. The\naim of the current study was to determine whether drum breaks are culturally\ntransmitted through musical collaboration networks, and to identify the factors\ndriving the evolution of these networks. Using network-based diffusion analysis\nwe found strong evidence for the cultural transmission of drum breaks via\ncollaboration between artists, and identified several demographic variables\nthat bias transmission. Additionally, using network evolution methods we found\nevidence that the structure of the collaboration network is no longer biased by\ngeographic proximity after the year 2000, and that gender disparity has relaxed\nover the same period. Despite the delocalization of communities by the\ninternet, collaboration remains a key transmission mode of music sampling\ntraditions. The results of this study provide valuable insight into how\ndemographic biases shape cultural transmission in complex networks, and how the\nevolution of these networks has shifted in the digital age.",
    "published_date": "2018-10-28T00:00:00",
    "year": 2018,
    "categories": [
      "stat.AP",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11900v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.11829v2",
    "title": "On preserving non-discrimination when combining expert advice",
    "authors": [
      "Avrim Blum",
      "Suriya Gunasekar",
      "Thodoris Lykouris",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "We study the interplay between sequential decision making and avoiding\ndiscrimination against protected groups, when examples arrive online and do not\nfollow distributional assumptions. We consider the most basic extension of\nclassical online learning: \"Given a class of predictors that are individually\nnon-discriminatory with respect to a particular metric, how can we combine them\nto perform as well as the best predictor, while preserving non-discrimination?\"\nSurprisingly we show that this task is unachievable for the prevalent notion of\n\"equalized odds\" that requires equal false negative rates and equal false\npositive rates across groups. On the positive side, for another notion of\nnon-discrimination, \"equalized error rates\", we show that running separate\ninstances of the classical multiplicative weights algorithm for each group\nachieves this guarantee. Interestingly, even for this notion, we show that\nalgorithms with stronger performance guarantees than multiplicative weights\ncannot preserve non-discrimination.",
    "published_date": "2018-10-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11829v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.11809v3",
    "title": "Discrimination-aware Channel Pruning for Deep Neural Networks",
    "authors": [
      "Zhuangwei Zhuang",
      "Mingkui Tan",
      "Bohan Zhuang",
      "Jing Liu",
      "Yong Guo",
      "Qingyao Wu",
      "Junzhou Huang",
      "Jinhui Zhu"
    ],
    "author_ids": [],
    "abstract": "Channel pruning is one of the predominant approaches for deep model\ncompression. Existing pruning methods either train from scratch with sparsity\nconstraints on channels, or minimize the reconstruction error between the\npre-trained feature maps and the compressed ones. Both strategies suffer from\nsome limitations: the former kind is computationally expensive and difficult to\nconverge, whilst the latter kind optimizes the reconstruction error but ignores\nthe discriminative power of channels. To overcome these drawbacks, we\ninvestigate a simple-yet-effective method, called discrimination-aware channel\npruning, to choose those channels that really contribute to discriminative\npower. To this end, we introduce additional losses into the network to increase\nthe discriminative power of intermediate layers and then select the most\ndiscriminative channels for each layer by considering the additional loss and\nthe reconstruction error. Last, we propose a greedy algorithm to conduct\nchannel selection and parameter optimization in an iterative way. Extensive\nexperiments demonstrate the effectiveness of our method. For example, on\nILSVRC-12, our pruned ResNet-50 with 30% reduction of channels even outperforms\nthe original model by 0.39% in top-1 accuracy.",
    "published_date": "2018-10-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11809v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.11711v2",
    "title": "Regularization Effect of Fast Gradient Sign Method and its Generalization",
    "authors": [
      "Chandler Zuo"
    ],
    "author_ids": [],
    "abstract": "Fast Gradient Sign Method (FGSM) is a popular method to generate adversarial\nexamples that make neural network models robust against perturbations. Despite\nits empirical success, its theoretical property is not well understood. This\npaper develops theory to explain the regularization effect of Generalized FGSM,\na class of methods to generate adversarial examples. Motivated from the\nrelationship between FGSM and LASSO penalty, the asymptotic properties of\nGeneralized FGSM are derived in the Generalized Linear Model setting, which is\nessentially the 1-layer neural network setting with certain activation\nfunctions. In such simple neural network models, I prove that Generalized FGSM\nestimation is root n-consistent and weakly oracle under proper conditions. The\nasymptotic results are also highly similar to penalized likelihood estimation.\nNevertheless, Generalized FGSM introduces additional bias when data sampling is\nnot sign neutral, a concept I introduce to describe the balance-ness of the\nnoise signs. Although the theory in this paper is developed under simple neural\nnetwork settings, I argue that it may give insights and justification for FGSM\nin deep neural network settings as well.",
    "published_date": "2018-10-27T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH",
      "62J12",
      "F.2.3; G.3; I.2.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11711v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.11027v2",
    "title": "On the dissection of degenerate cosmologies with machine learning",
    "authors": [
      "Julian Merten",
      "Carlo Giocoli",
      "Marco Baldi",
      "Massimo Meneghetti",
      "Austin Peel",
      "Florian Lalande",
      "Jean-Luc Starck",
      "Valeria Pettorino"
    ],
    "author_ids": [],
    "abstract": "Based on the DUSTGRAIN-pathfinder suite of simulations, we investigate\nobservational degeneracies between nine models of modified gravity and massive\nneutrinos. Three types of machine learning techniques are tested for their\nability to discriminate lensing convergence maps by extracting dimensional\nreduced representations of the data. Classical map descriptors such as the\npower spectrum, peak counts and Minkowski functionals are combined into a joint\nfeature vector and compared to the descriptors and statistics that are common\nto the field of digital image processing. To learn new features directly from\nthe data we use a Convolutional Neural Network (CNN). For the mapping between\nfeature vectors and the predictions of their underlying model, we implement two\ndifferent classifiers; one based on a nearest-neighbour search and one that is\nbased on a fully connected neural network. We find that the neural network\nprovides a much more robust classification than the nearest-neighbour approach\nand that the CNN provides the most discriminating representation of the data.\nIt achieves the cleanest separation between the different models and the\nhighest classification success rate of 59% for a single source redshift. Once\nwe perform a tomographic CNN analysis, the total classification accuracy\nincreases significantly to 76% with no observational degeneracies remaining.\nVisualising the filter responses of the CNN at different network depths\nprovides us with the unique opportunity to learn from very complex models and\nto understand better why they perform so well.",
    "published_date": "2018-10-25T00:00:00",
    "year": 2018,
    "categories": [
      "astro-ph.CO",
      "cs.CV",
      "gr-qc"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11027v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.10938v3",
    "title": "Sample Efficient Algorithms for Learning Quantum Channels in PAC Model and the Approximate State Discrimination Problem",
    "authors": [
      "Kai-Min Chung",
      "Han-Hsuan Lin"
    ],
    "author_ids": [],
    "abstract": "We generalize the PAC (probably approximately correct) learning model to the\nquantum world by generalizing the concepts from classical functions to quantum\nprocesses, defining the problem of \\emph{PAC learning quantum process}, and\nstudy its sample complexity. In the problem of PAC learning quantum process, we\nwant to learn an $\\epsilon$-approximate of an unknown quantum process $c^*$\nfrom a known finite concept class $C$ with probability $1-\\delta$ using samples\n$\\{(x_1,c^*(x_1)),(x_2,c^*(x_2)),\\dots\\}$, where $\\{x_1,x_2, \\dots\\}$ are\ncomputational basis states sampled from an unknown distribution $D$ and\n$\\{c^*(x_1),c^*(x_2),\\dots\\}$ are the (possibly mixed) quantum states outputted\nby $c^*$. The special case of PAC-learning quantum process under constant input\nreduces to a natural problem which we named as approximate state\ndiscrimination, where we are given copies of an unknown quantum state $c^*$\nfrom an known finite set $C$, and we want to learn with probability $1-\\delta$\nan $\\epsilon$-approximate of $c^*$ with as few copies of $c^*$ as possible. We\nshow that the problem of PAC learning quantum process can be solved with\n$$O\\left(\\frac{\\log|C| + \\log(1/ \\delta)} { \\epsilon^2}\\right)$$ samples when\nthe outputs are pure states and $$O\\left(\\frac{\\log^3 |C|(\\log |C|+\\log(1/\n\\delta))} { \\epsilon^2}\\right)$$ samples if the outputs can be mixed. Some\nimplications of our results are that we can PAC-learn a polynomial sized\nquantum circuit in polynomial samples and approximate state discrimination can\nbe solved in polynomial samples even when concept class size $|C|$ is\nexponential in the number of qubits, an exponentially improvement over a full\nstate tomography.",
    "published_date": "2018-10-25T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10938v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.10751v4",
    "title": "Attack Graph Convolutional Networks by Adding Fake Nodes",
    "authors": [
      "Xiaoyun Wang",
      "Minhao Cheng",
      "Joe Eaton",
      "Cho-Jui Hsieh",
      "Felix Wu"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study the robustness of graph convolutional networks\n(GCNs). Previous work have shown that GCNs are vulnerable to adversarial\nperturbation on adjacency or feature matrices of existing nodes; however, such\nattacks are usually unrealistic in real applications. For instance, in social\nnetwork applications, the attacker will need to hack into either the client or\nserver to change existing links or features. In this paper, we propose a new\ntype of \"fake node attacks\" to attack GCNs by adding malicious fake nodes. This\nis much more realistic than previous attacks; in social network applications,\nthe attacker only needs to register a set of fake accounts and link to existing\nones. To conduct fake node attacks, a greedy algorithm is proposed to generate\nedges of malicious nodes and their corresponding features aiming to minimize\nthe classification accuracy on the target nodes. In addition, we introduce a\ndiscriminator to classify malicious nodes from real nodes, and propose a\nGreedy-GAN attack to simultaneously update the discriminator and the attacker,\nto make malicious nodes indistinguishable from the real ones. Our non-targeted\nattack decreases the accuracy of GCN down to 0.03, and our targeted attack\nreaches a success rate of 78% on a group of 100 nodes, and 90% on average for\nattacking a single target node.",
    "published_date": "2018-10-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10751v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.10458v1",
    "title": "Proportional fairness in wireless powered CSMA/CA based IoT networks",
    "authors": [
      "Xiaomin Chen",
      "Zhan Shu",
      "Kezhi Wang",
      "Fangmin Xu",
      "Yue Cao"
    ],
    "author_ids": [],
    "abstract": "This paper considers the deployment of a hybrid wireless data/power access\npoint in an 802.11-based wireless powered IoT network. The proportionally fair\nallocation of throughputs across IoT nodes is considered under the constraints\nof energy neutrality and CPU capability for each device. The joint optimization\nof wireless powering and data communication resources takes the CSMA/CA random\nchannel access features, e.g. the backoff procedure, collisions, protocol\noverhead into account. Numerical results show that the optimized solution can\neffectively balance individual throughput across nodes, and meanwhile\nproportionally maximize the overall sum throughput under energy constraints.",
    "published_date": "2018-10-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10458v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.10286v2",
    "title": "Learning color space adaptation from synthetic to real images of cirrus clouds",
    "authors": [
      "Qing Lyu",
      "Minghao Chen",
      "Xiang Chen"
    ],
    "author_ids": [],
    "abstract": "Cloud segmentation plays a crucial role in image analysis for climate\nmodeling. Manually labeling the training data for cloud segmentation is\ntime-consuming and error-prone. We explore to train segmentation networks with\nsynthetic data due to the natural acquisition of pixel-level labels.\nNevertheless, the domain gap between synthetic and real images significantly\ndegrades the performance of the trained model. We propose a color space\nadaptation method to bridge the gap, by training a color-sensitive generator\nand discriminator to adapt synthetic data to real images in color space.\nInstead of transforming images by general convolutional kernels, we adopt a set\nof closed-form operations to make color-space adjustments while preserving the\nlabels. We also construct a synthetic-to-real cirrus cloud dataset SynCloud and\ndemonstrate the adaptation efficacy on the semantic segmentation task of cirrus\nclouds. With our adapted synthetic data for training the semantic segmentation,\nwe achieve an improvement of 6:59% when applied to real images, superior to\nalternative methods.",
    "published_date": "2018-10-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10286v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.10076v1",
    "title": "A Statistical Approach to Adult Census Income Level Prediction",
    "authors": [
      "Navoneel Chakrabarty",
      "Sanket Biswas"
    ],
    "author_ids": [],
    "abstract": "The prominent inequality of wealth and income is a huge concern especially in\nthe United States. The likelihood of diminishing poverty is one valid reason to\nreduce the world's surging level of economic inequality. The principle of\nuniversal moral equality ensures sustainable development and improve the\neconomic stability of a nation. Governments in different countries have been\ntrying their best to address this problem and provide an optimal solution. This\nstudy aims to show the usage of machine learning and data mining techniques in\nproviding a solution to the income equality problem. The UCI Adult Dataset has\nbeen used for the purpose. Classification has been done to predict whether a\nperson's yearly income in US falls in the income category of either greater\nthan 50K Dollars or less equal to 50K Dollars category based on a certain set\nof attributes. The Gradient Boosting Classifier Model was deployed which\nclocked the highest accuracy of 88.16%, eventually breaking the benchmark\naccuracy of existing works.",
    "published_date": "2018-10-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10076v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.09988v1",
    "title": "Meta-Learning Multi-task Communication",
    "authors": [
      "Pengfei Liu",
      "Xuanjing Huang"
    ],
    "author_ids": [],
    "abstract": "In this paper, we describe a general framework: Parameters Read-Write\nNetworks (PRaWNs) to systematically analyze current neural models for\nmulti-task learning, in which we find that existing models expect to\ndisentangle features into different spaces while features learned in practice\nare still entangled in shared space, leaving potential hazards for other\ntraining or unseen tasks.\n  We propose to alleviate this problem by incorporating an inductive bias into\nthe process of multi-task learning, that each task can keep informed of not\nonly the knowledge stored in other tasks but the way how other tasks maintain\ntheir knowledge.\n  In practice, we achieve above inductive bias by allowing different tasks to\ncommunicate by passing both hidden variables and gradients explicitly.\n  Experimentally, we evaluate proposed methods on three groups of tasks and two\ntypes of settings (\\textsc{in-task} and \\textsc{out-of-task}). Quantitative and\nqualitative results show their effectiveness.",
    "published_date": "2018-10-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09988v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.11047v1",
    "title": "Viewpoint Discovery and Understanding in Social Networks",
    "authors": [
      "Mainul Quraishi",
      "Pavlos Fafalios",
      "Eelco Herder"
    ],
    "author_ids": [],
    "abstract": "The Web has evolved to a dominant platform where everyone has the opportunity\nto express their opinions, to interact with other users, and to debate on\nemerging events happening around the world. On the one hand, this has enabled\nthe presence of different viewpoints and opinions about a - usually\ncontroversial - topic (like Brexit), but at the same time, it has led to\nphenomena like media bias, echo chambers and filter bubbles, where users are\nexposed to only one point of view on the same topic. Therefore, there is the\nneed for methods that are able to detect and explain the different viewpoints.\nIn this paper, we propose a graph partitioning method that exploits social\ninteractions to enable the discovery of different communities (representing\ndifferent viewpoints) discussing about a controversial topic in a social\nnetwork like Twitter. To explain the discovered viewpoints, we describe a\nmethod, called Iterative Rank Difference (IRD), which allows detecting\ndescriptive terms that characterize the different viewpoints as well as\nunderstanding how a specific term is related to a viewpoint (by detecting other\nrelated descriptive terms). The results of an experimental evaluation showed\nthat our approach outperforms state-of-the-art methods on viewpoint discovery,\nwhile a qualitative analysis of the proposed IRD method on three different\ncontroversial topics showed that IRD provides comprehensive and deep\nrepresentations of the different viewpoints.",
    "published_date": "2018-10-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.11047v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.09683v2",
    "title": "Unsupervised Features Extraction for Binary Similarity Using Graph Embedding Neural Networks",
    "authors": [
      "Roberto Baldoni",
      "Giuseppe Antonio Di Luna",
      "Luca Massarelli",
      "Fabio Petroni",
      "Leonardo Querzoni"
    ],
    "author_ids": [],
    "abstract": "In this paper we consider the binary similarity problem that consists in\ndetermining if two binary functions are similar only considering their compiled\nform. This problem is know to be crucial in several application scenarios, such\nas copyright disputes, malware analysis, vulnerability detection, etc. The\ncurrent state-of-the-art solutions in this field work by creating an embedding\nmodel that maps binary functions into vectors in $\\mathbb{R}^{n}$. Such\nembedding model captures syntactic and semantic similarity between binaries,\ni.e., similar binary functions are mapped to points that are close in the\nvector space. This strategy has many advantages, one of them is the possibility\nto precompute embeddings of several binary functions, and then compare them\nwith simple geometric operations (e.g., dot product). In [32] functions are\nfirst transformed in Annotated Control Flow Graphs (ACFGs) constituted by\nmanually engineered features and then graphs are embedded into vectors using a\ndeep neural network architecture. In this paper we propose and test several\nways to compute annotated control flow graphs that use unsupervised approaches\nfor feature learning, without incurring a human bias. Our methods are inspired\nafter techniques used in the natural language processing community (e.g., we\nuse word2vec to encode assembly instructions). We show that our approach is\nindeed successful, and it leads to better performance than previous\nstate-of-the-art solutions. Furthermore, we report on a qualitative analysis of\nfunctions embeddings. We found interesting cases in which embeddings are\nclustered according to the semantic of the original binary function.",
    "published_date": "2018-10-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09683v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.09379v1",
    "title": "Linguistic Legal Concept Extraction in Portuguese",
    "authors": [
      "Alessandra Cid",
      "Alexandre Rademaker",
      "Bruno Cuconato",
      "Valeria de Paiva"
    ],
    "author_ids": [],
    "abstract": "This work investigates legal concepts and their expression in Portuguese,\nconcentrating on the \"Order of Attorneys of Brazil\" Bar exam. Using a corpus\nformed by a collection of multiple-choice questions, three norms related to the\nEthics part of the OAB exam, language resources (Princeton WordNet and\nOpenWordNet-PT) and tools (AntConc and Freeling), we began to investigate the\nconcepts and words missing from our repertory of concepts and words in\nPortuguese, the knowledge base OpenWordNet-PT. We add these concepts and words\nto OpenWordNet-PT and hence obtain a representation of these texts that is\n\"contained\" in the lexical knowledge base.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09379v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.09355v1",
    "title": "Fast Dual Simulation Processing of Graph Database Queries (Supplement)",
    "authors": [
      "Stephan Mennicke",
      "Jan-Christoph Kalo",
      "Denis Nagel",
      "Hermann Kroll",
      "Wolf-Tilo Balke"
    ],
    "author_ids": [],
    "abstract": "Graph database query languages feature expressive, yet computationally\nexpensive pattern matching capabilities. Answering optional query clauses in\nSPARQL for instance renders the query evaluation problem immediately\nPspace-complete. Therefore, light-weight graph pattern matching relations, such\nas simulation, have recently been investigated as promising alternatives to\nmore expensive query mechanisms like, e.g., computing subgraph isomorphism.\nStill, graph pattern matching alone lacks expressive query capabilities: all\npatterns are combined by usual join constructs, where more sophisticated\ncapabilities would be inevitable for making solutions useful to emerging\napplications. In this paper we bridge this gap by introducing a new dual\nsimulation process operating on SPARQL queries. In addition to supporting the\nfull syntactic structure of SPARQL queries, it features polynomial-time pattern\nmatching to compute an overapproximation of query results from the database.\nMoreover, to achieve runtimes competing with state-of-the-art database systems,\nwe develop a novel algorithmic solution to dual simulation graph pattern\nmatching, based on a system of inequalities that allows for several\noptimization heuristics. Finally, we achieve soundness of our process for\nSPARQL queries including UNION, AND and OPTIONAL operators not restricted to\nwell-designed patterns. Our experiments on synthetic and real-world graph data\npromise a clear gain for graph database systems when incorporating the new dual\nsimulation techniques. In this supplement paper we present in detail all\nproofs, discussions of experimental results, and complexity analysis for the\noriginal paper \"Fast Dual Simulation Processing of Graph Database Queries\"\nincluded in the Proceedings of the 35th IEEE International Conference on Data\nEngineering (ICDE 2019), Macau, China.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09355v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.09352v2",
    "title": "On The Stability of Interpretable Models",
    "authors": [
      "Riccardo Guidotti",
      "Salvatore Ruggieri"
    ],
    "author_ids": [],
    "abstract": "Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process. Bias\nin data collection and preparation, or in model's construction may severely\naffect the accountability of the design process. We conduct an experimental\nstudy of the stability of interpretable models with respect to feature\nselection, instance selection, and model selection. Our conclusions should\nraise awareness and attention of the scientific community on the need of a\nstability impact assessment of interpretable models.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09352v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.09166v1",
    "title": "Ensemble Method for Censored Demand Prediction",
    "authors": [
      "Evgeniy M. Ozhegov",
      "Daria Teterina"
    ],
    "author_ids": [],
    "abstract": "Many economic applications including optimal pricing and inventory management\nrequires prediction of demand based on sales data and estimation of sales\nreaction to a price change. There is a wide range of econometric approaches\nwhich are used to correct a bias in estimates of demand parameters on censored\nsales data. These approaches can also be applied to various classes of machine\nlearning models to reduce the prediction error of sales volume. In this study\nwe construct two ensemble models for demand prediction with and without\naccounting for demand censorship. Accounting for sales censorship is based on\nthe idea of censored quantile regression method where the model estimation is\nsplitted on two separate parts: a) prediction of zero sales by classification\nmodel; and b) prediction of non-zero sales by regression model. Models with and\nwithout accounting for censorship are based on the predictions aggregations of\nLeast squares, Ridge and Lasso regressions and Random Forest model. Having\nestimated the predictive properties of both models, we empirically test the\nbest predictive power of the model that takes into account the censored nature\nof demand. We also show that machine learning method with censorship accounting\nprovide bias corrected estimates of demand sensitivity for price change similar\nto econometric models.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09166v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.09147v5",
    "title": "Summarizing User-generated Textual Content: Motivation and Methods for Fairness in Algorithmic Summaries",
    "authors": [
      "Abhisek Dash",
      "Anurag Shandilya",
      "Arindam Biswas",
      "Kripabandhu Ghosh",
      "Saptarshi Ghosh",
      "Abhijnan Chakraborty"
    ],
    "author_ids": [],
    "abstract": "As the amount of user-generated textual content grows rapidly, text\nsummarization algorithms are increasingly being used to provide users a quick\noverview of the information content. Traditionally, summarization algorithms\nhave been evaluated only based on how well they match human-written summaries\n(e.g. as measured by ROUGE scores). In this work, we propose to evaluate\nsummarization algorithms from a completely new perspective that is important\nwhen the user-generated data to be summarized comes from different socially\nsalient user groups, e.g. men or women, Caucasians or African-Americans, or\ndifferent political groups (Republicans or Democrats). In such cases, we check\nwhether the generated summaries fairly represent these different social groups.\nSpecifically, considering that an extractive summarization algorithm selects a\nsubset of the textual units (e.g. microblogs) in the original data for\ninclusion in the summary, we investigate whether this selection is fair or not.\nOur experiments over real-world microblog datasets show that existing\nsummarization algorithms often represent the socially salient user-groups very\ndifferently compared to their distributions in the original data. More\nimportantly, some groups are frequently under-represented in the generated\nsummaries, and hence get far less exposure than what they would have obtained\nin the original data. To reduce such adverse impacts, we propose novel\nfairness-preserving summarization algorithms which produce high-quality\nsummaries while ensuring fairness among various groups. To our knowledge, this\nis the first attempt to produce fair text summarization, and is likely to open\nup an interesting research direction.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09147v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.09146v2",
    "title": "Quantitative Simulations by Matrices",
    "authors": [
      "Natsuki Urabe",
      "Ichiro Hasuo"
    ],
    "author_ids": [],
    "abstract": "We introduce notions of simulation between semiring-weighted automata as\nmodels of quantitative systems. Our simulations are instances of the\ncategorical/coalgebraic notions previously studied by Hasuo---hence soundness\nagainst language inclusion comes for free---but are concretely presented as\nmatrices that are subject to linear inequality constraints. Pervasiveness of\nthese formalisms allows us to exploit existing algorithms in: searching for a\nsimulation, and hence verifying quantitative correctness that is formulated as\nlanguage inclusion. Transformations of automata that aid search for simulations\nare introduced, too. This verification workflow is implemented for the\nplus-times and max-plus semirings. Furthermore, an extension to weighted tree\nautomata is presented and implemented.",
    "published_date": "2018-10-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09146v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.09832v1",
    "title": "Mechanism Design for Social Good",
    "authors": [
      "Rediet Abebe",
      "Kira Goldner"
    ],
    "author_ids": [],
    "abstract": "Across various domains--such as health, education, and housing--improving\nsocietal welfare involves allocating resources, setting policies, targeting\ninterventions, and regulating activities. These solutions have an immense\nimpact on the day-to-day lives of individuals, whether in the form of access to\nquality healthcare, labor market outcomes, or how votes are accounted for in a\ndemocratic society. Problems that can have an out-sized impact on individuals\nwhose opportunities have historically been limited often pose conceptual and\ntechnical challenges, requiring insights from many disciplines. Conversely, the\nlack of interdisciplinary approach can leave these urgent needs unaddressed and\ncan even exacerbate underlying socioeconomic inequalities. To realize the\nopportunities in these domains, we need to correctly set objectives and reason\nabout human behavior and actions. Doing so requires a deep grounding in the\nfield of interest and collaboration with domain experts who understand the\nsocietal implications and feasibility of proposed solutions. These insights can\nplay an instrumental role in proposing algorithmically-informed policies.\n  In this article, we describe the Mechanism Design for Social Good (MD4SG)\nresearch agenda, which involves using insights from algorithms, optimization,\nand mechanism design to improve access to opportunity. The MD4SG research\ncommunity takes an interdisciplinary, multi-stakeholder approach to improve\nsocietal welfare. We discuss three exciting research avenues within MD4SG\nrelated to improving access to opportunity in the developing world, labor\nmarkets and discrimination, and housing. For each of these, we showcase ongoing\nwork, underline new directions, and discuss potential for implementing existing\nwork in practice.",
    "published_date": "2018-10-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CY",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09832v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08842v1",
    "title": "An approximation scheme for variational inequalities with convex and coercive Hamiltonians",
    "authors": [
      "Shuo Huang"
    ],
    "author_ids": [],
    "abstract": "We propose an approximation scheme for a class of semilinear variational\ninequalities whose Hamiltonian is convex and coercive. The proposed scheme is a\nnatural extension of a previous splitting scheme proposed by Liang,\nZariphopoulou and the author for semilinear parabolic PDEs. We establish the\nconvergence of the scheme and determine the convergence rate by obtaining its\nerror bounds. The bounds are obtained by Krylov's shaking coefficients\ntechnique and Barles-Jakobsen's optimal switching approximation, in which a key\nstep is to introduce a variant switching system.",
    "published_date": "2018-10-20T00:00:00",
    "year": 2018,
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08842v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.08810v1",
    "title": "The Frontiers of Fairness in Machine Learning",
    "authors": [
      "Alexandra Chouldechova",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "The last few years have seen an explosion of academic and popular interest in\nalgorithmic fairness. Despite this interest and the volume and velocity of work\nthat has been produced recently, the fundamental science of fairness in machine\nlearning is still in a nascent state. In March 2018, we convened a group of\nexperts as part of a CCC visioning workshop to assess the state of the field,\nand distill the most promising research directions going forward. This report\nsummarizes the findings of that workshop. Along the way, it surveys recent\ntheoretical work in the field and points towards promising directions for\nresearch.",
    "published_date": "2018-10-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.GT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08810v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08759v1",
    "title": "Design of robust H_inf fuzzy output feedback controller for affine nonlinear systems:Fuzzy Lyapunov function approach",
    "authors": [
      "Leila Rajabpour",
      "Mokhtar Shasadeghi",
      "Alireza Barzegar"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a new systematic approach based on nonquadratic\nLyapunov function and technique of introducing slack matrices, for a class of\naffine nonlinear systems with disturbance. To achieve the goal, first, the\naffine nonlinear system is represented via Takagi-Sugeno (T-S) fuzzy bilinear\nmodel. Subsequently, the robust H_inf controller is designed based on parallel\ndistributed compensation (PDC) scheme. Then, the stability conditions are\nderived in terms of linear matrix inequalities (LMIs) by utilizing Lyapunov\nfunction. Moreover, some slack matrices are proposed to reduce the\nconservativeness of the LMI stability conditions. Finally, for illustrating the\nmerits and verifying the effectiveness of the proposed approach, the\napplication of an isothermal continuous stirred tank reactor (CSTR) for Van de\nVusse reactor is discussed in details.",
    "published_date": "2018-10-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08759v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08691v2",
    "title": "Audio-Based Activities of Daily Living (ADL) Recognition with Large-Scale Acoustic Embeddings from Online Videos",
    "authors": [
      "Dawei Liang",
      "Edison Thomaz"
    ],
    "author_ids": [],
    "abstract": "Over the years, activity sensing and recognition has been shown to play a key\nenabling role in a wide range of applications, from sustainability and\nhuman-computer interaction to health care. While many recognition tasks have\ntraditionally employed inertial sensors, acoustic-based methods offer the\nbenefit of capturing rich contextual information, which can be useful when\ndiscriminating complex activities. Given the emergence of deep learning\ntechniques and leveraging new, large-scaled multi-media datasets, this paper\nrevisits the opportunity of training audio-based classifiers without the\nonerous and time-consuming task of annotating audio data. We propose a\nframework for audio-based activity recognition that makes use of millions of\nembedding features from public online video sound clips. Based on the\ncombination of oversampling and deep learning approaches, our framework does\nnot require further feature processing or outliers filtering as in prior work.\nWe evaluated our approach in the context of Activities of Daily Living (ADL) by\nrecognizing 15 everyday activities with 14 participants in their own homes,\nachieving 64.2% and 83.6% averaged within-subject accuracy in terms of top-1\nand top-3 classification respectively. Individual class performance was also\nexamined in the paper to further study the co-occurrence characteristics of the\nactivities and the robustness of the framework.",
    "published_date": "2018-10-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08691v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08683v2",
    "title": "Taking Advantage of Multitask Learning for Fair Classification",
    "authors": [
      "Luca Oneto",
      "Michele Donini",
      "Amon Elders",
      "Massimiliano Pontil"
    ],
    "author_ids": [],
    "abstract": "A central goal of algorithmic fairness is to reduce bias in automated\ndecision making. An unavoidable tension exists between accuracy gains obtained\nby using sensitive information (e.g., gender or ethnic group) as part of a\nstatistical model, and any commitment to protect these characteristics. Often,\ndue to biases present in the data, using the sensitive information in the\nfunctional form of a classifier improves classification accuracy. In this paper\nwe show how it is possible to get the best of both worlds: optimize model\naccuracy and fairness without explicitly using the sensitive feature in the\nfunctional form of the model, thereby treating different individuals equally.\nOur method is based on two key ideas. On the one hand, we propose to use\nMultitask Learning (MTL), enhanced with fairness constraints, to jointly learn\ngroup specific classifiers that leverage information between sensitive groups.\nOn the other hand, since learning group specific models might not be permitted,\nwe propose to first predict the sensitive features by any learning method and\nthen to use the predicted sensitive feature to train MTL with fairness\nconstraints. This enables us to tackle fairness with a three-pronged approach,\nthat is, by increasing accuracy on each group, enforcing measures of fairness\nduring training, and protecting sensitive information during testing.\nExperimental results on two real datasets support our proposal, showing\nsubstantial improvements in both accuracy and fairness.",
    "published_date": "2018-10-19T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08683v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08591v4",
    "title": "A Modern Take on the Bias-Variance Tradeoff in Neural Networks",
    "authors": [
      "Brady Neal",
      "Sarthak Mittal",
      "Aristide Baratin",
      "Vinayak Tantia",
      "Matthew Scicluna",
      "Simon Lacoste-Julien",
      "Ioannis Mitliagkas"
    ],
    "author_ids": [],
    "abstract": "The bias-variance tradeoff tells us that as model complexity increases, bias\nfalls and variances increases, leading to a U-shaped test error curve. However,\nrecent empirical results with over-parameterized neural networks are marked by\na striking absence of the classic U-shaped test error curve: test error keeps\ndecreasing in wider networks. This suggests that there might not be a\nbias-variance tradeoff in neural networks with respect to network width, unlike\nwas originally claimed by, e.g., Geman et al. (1992). Motivated by the shaky\nevidence used to support this claim in neural networks, we measure bias and\nvariance in the modern setting. We find that both bias and variance can\ndecrease as the number of parameters grows. To better understand this, we\nintroduce a new decomposition of the variance to disentangle the effects of\noptimization and data sampling. We also provide theoretical analysis in a\nsimplified setting that is consistent with our empirical findings.",
    "published_date": "2018-10-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08591v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08540v1",
    "title": "Fairness for Whom? Critically reframing fairness with Nash Welfare Product",
    "authors": [
      "Ansh Patel"
    ],
    "author_ids": [],
    "abstract": "Recent studies on disparate impact in machine learning applications have\nsparked a debate around the concept of fairness along with attempts to\nformalize its different criteria. Many of these approaches focus on reducing\nprediction errors while maximizing sole utility of the institution. This work\nseeks to reconceptualize and critically frame the existing discourse on\nfairness by underlining the implicit biases embedded in common understandings\nof fairness in the literature and how they contrast with its corresponding\neconomic and legal definitions. This paper expands the concept of utility and\nfairness by bringing in concepts from established literature in welfare\neconomics and game theory. We then translate these concepts for the algorithmic\nprediction domain by defining a formalization of Nash Welfare Product that\nseeks to expand utility by collapsing that of the institution using the\nprediction tool and the individual subject to the prediction into one function.\nWe then apply a modulating function that makes the fairness and welfare\ntrade-offs explicit based on designated policy goals and then apply it to a\ntemporal model to take into account the effects of decisions beyond the scope\nof one-shot predictions. We apply this on a binary classification problem and\npresent results of a multi-epoch simulation based on the UCI Adult Income\ndataset and a test case analysis of the ProPublica recidivism dataset that show\nthat expanding the concept of utility results in a fairer distribution\ncorrecting for the embedded biases in the dataset without sacrificing the\nclassifier accuracy.",
    "published_date": "2018-10-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08540v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08437v2",
    "title": "Learning with privileged information via adversarial discriminative modality distillation",
    "authors": [
      "Nuno C. Garcia",
      "Pietro Morerio",
      "Vittorio Murino"
    ],
    "author_ids": [],
    "abstract": "Heterogeneous data modalities can provide complementary cues for several\ntasks, usually leading to more robust algorithms and better performance.\nHowever, while training data can be accurately collected to include a variety\nof sensory modalities, it is often the case that not all of them are available\nin real life (testing) scenarios, where a model has to be deployed. This raises\nthe challenge of how to extract information from multimodal data in the\ntraining stage, in a form that can be exploited at test time, considering\nlimitations such as noisy or missing modalities. This paper presents a new\napproach in this direction for RGB-D vision tasks, developed within the\nadversarial learning and privileged information frameworks. We consider the\npractical case of learning representations from depth and RGB videos, while\nrelying only on RGB data at test time. We propose a new approach to train a\nhallucination network that learns to distill depth information via adversarial\nlearning, resulting in a clean approach without several losses to balance or\nhyperparameters. We report state-of-the-art results on object classification on\nthe NYUD dataset and video action recognition on the largest multimodal dataset\navailable for this task, the NTU RGB+D, as well as on the Northwestern-UCLA.",
    "published_date": "2018-10-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08437v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.02887v1",
    "title": "Certified Ethical Hacker v.10 Online Course - a Case Study",
    "authors": [
      "Tam N. Nguyen"
    ],
    "author_ids": [],
    "abstract": "CEH v.10 Certification Self-study Course is an online course preparing\nlearners for one of the most prestige cyber security certifications in the\nworld - the Certified Ethical Hacker (CEH) v.10 Certification. Due to a pay\nwall and the practical rather than theoretical nature, most researchers have\nlimited exposure to this course. For the first time, this paper will analyze\nthe course's instructional design based on the highest national standards and\nrelated peer-reviewed published research works. The sole intention is to push\nthe course to a higher ground, making it the best online course for cyber\nsecurity. More importantly, the paper's instructional design evaluation\nstrategy can well be extended and applied to any other online course'\ninstructional design review and/or evaluation process.",
    "published_date": "2018-10-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.02887v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.07460v1",
    "title": "What might matter in autonomous cars adoption: first person versus third person scenarios",
    "authors": [
      "Eva Zackova",
      "Jan Romportl"
    ],
    "author_ids": [],
    "abstract": "The discussion between the automotive industry, governments, ethicists,\npolicy makers and general public about autonomous cars' moral agency is\nwidening, and therefore we see the need to bring more insight into what\nmeta-factors might actually influence the outcomes of such discussions, surveys\nand plebiscites. In our study, we focus on the psychological (personality\ntraits), practical (active driving experience), gender and rhetoric/framing\nfactors that might impact and even determine respondents' a priori preferences\nof autonomous cars' operation. We conducted an online survey (N=430) to collect\ndata that show that the third person scenario is less biased than the first\nperson scenario when presenting ethical dilemma related to autonomous cars.\nAccording to our analysis, gender bias should be explored in more extensive\nfuture studies as well. We recommend any participatory technology assessment\ndiscourse to use the third person scenario and to direct attention to the way\nany autonomous car related debate is introduced, especially in terms of\nlinguistic and communication aspects and gender.",
    "published_date": "2018-10-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07460v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.07414v2",
    "title": "Progress, Justness and Fairness",
    "authors": [
      "Rob van Glabbeek",
      "Peter Höfner"
    ],
    "author_ids": [],
    "abstract": "Fairness assumptions are a valuable tool when reasoning about systems. In\nthis paper, we classify several fairness properties found in the literature and\nargue that most of them are too restrictive for many applications. As an\nalternative we introduce the concept of justness.",
    "published_date": "2018-10-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LO",
      "F.1.2; F.3.1; F.3.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07414v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.07406v3",
    "title": "Adversarial Balancing for Causal Inference",
    "authors": [
      "Michal Ozery-Flato",
      "Pierre Thodoroff",
      "Matan Ninio",
      "Michal Rosen-Zvi",
      "Tal El-Hay"
    ],
    "author_ids": [],
    "abstract": "Biases in observational data of treatments pose a major challenge to\nestimating expected treatment outcomes in different populations. An important\ntechnique that accounts for these biases is reweighting samples to minimize the\ndiscrepancy between treatment groups. We present a novel reweighting approach\nthat uses bi-level optimization to alternately train a discriminator to\nminimize classification error, and a balancing weights generator that uses\nexponentiated gradient descent to maximize this error. This approach borrows\nprinciples from generative adversarial networks (GANs) to exploit the power of\nclassifiers for measuring two-sample divergence. We provide theoretical results\nfor conditions in which the estimation error is bounded by two factors: (i) the\ndiscrepancy measure induced by the discriminator; and (ii) the weights\nvariability. Experimental results on several benchmarks comparing to previous\nstate-of-the-art reweighting methods demonstrate the effectiveness of this\napproach in estimating causal effects.",
    "published_date": "2018-10-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07406v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.07290v1",
    "title": "An analysis of Principle 1.2 in the new ACM Code Of Ethics",
    "authors": [
      "Christoph Becker"
    ],
    "author_ids": [],
    "abstract": "The new ACM Code of Ethics is a much-needed update, but introduced changes to\na central principle that have not been discussed widely enough. This commentary\naims to contribute to an improvement of the ethical standards we want computing\nprofessionals to aspire to by analyzing how changes introduced to Principle\n1.2, Avoid Harm, affect the Code as a whole.\n  The analysis shows that the principle is now internally inconsistent in\nstructure and externally inconsistent with Principle 2.3. It condones\nintentional harm too broadly and does not oblige those responsible to seek\nexternal justification. The existing Principle 2.3 clearly suggests that\nPrinciple 1.2 is unethical.\n  As a consequence, the change introduced to Principle 1.2 in the new Code of\nEthics nullifies the good intention of the code; counteracts the many good\nchanges introduced in all three drafts; and places the ACM in a dangerous moral\nposition.\n  This short paper explains why and recommends concrete actions.",
    "published_date": "2018-10-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07290v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.07280v1",
    "title": "Gender Bias in Nobel Prizes",
    "authors": [
      "Per Lunnemann",
      "Mogens H. Jensen",
      "Liselotte Jauffred"
    ],
    "author_ids": [],
    "abstract": "Strikingly few Nobel laureates within medicine, natural and social sciences\nare women. Although it is obvious that there are fewer women researchers within\nthese fields, does this gender ratio still fully account for the low number of\nfemale Nobel laureates? We examine whether women are awarded the Nobel Prizes\nless often than the gender ratio suggests. Based on historical data across four\nscientific fields and a Bayesian hierarchical model, we quantify any possible\nbias. The model reveals, with exceedingly large confidence, that indeed women\nare strongly under-represented among Nobel laureates across all disciplines\nexamined.",
    "published_date": "2018-10-16T00:00:00",
    "year": 2018,
    "categories": [
      "stat.AP",
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07280v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.07155v3",
    "title": "Hunting for Discriminatory Proxies in Linear Regression Models",
    "authors": [
      "Samuel Yeom",
      "Anupam Datta",
      "Matt Fredrikson"
    ],
    "author_ids": [],
    "abstract": "A machine learning model may exhibit discrimination when used to make\ndecisions involving people. One potential cause for such outcomes is that the\nmodel uses a statistical proxy for a protected demographic attribute. In this\npaper we formulate a definition of proxy use for the setting of linear\nregression and present algorithms for detecting proxies. Our definition follows\nrecent work on proxies in classification models, and characterizes a model's\nconstituent behavior that: 1) correlates closely with a protected random\nvariable, and 2) is causally influential in the overall behavior of the model.\nWe show that proxies in linear regression models can be efficiently identified\nby solving a second-order cone program, and further extend this result to\naccount for situations where the use of a certain input variable is justified\nas a `business necessity'. Finally, we present empirical results on two law\nenforcement datasets that exhibit varying degrees of racial disparity in\nprediction outcomes, demonstrating that proxies shed useful light on the causes\nof discriminatory behavior in models.",
    "published_date": "2018-10-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07155v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.10333v3",
    "title": "Memorization in Overparameterized Autoencoders",
    "authors": [
      "Adityanarayanan Radhakrishnan",
      "Karren Yang",
      "Mikhail Belkin",
      "Caroline Uhler"
    ],
    "author_ids": [],
    "abstract": "The ability of deep neural networks to generalize well in the\noverparameterized regime has become a subject of significant research interest.\nWe show that overparameterized autoencoders exhibit memorization, a form of\ninductive bias that constrains the functions learned through the optimization\nprocess to concentrate around the training examples, although the network could\nin principle represent a much larger function class. In particular, we prove\nthat single-layer fully-connected autoencoders project data onto the\n(nonlinear) span of the training examples. In addition, we show that deep\nfully-connected autoencoders learn a map that is locally contractive at the\ntraining examples, and hence iterating the autoencoder results in convergence\nto the training examples. Finally, we prove that depth is necessary and provide\nempirical evidence that it is also sufficient for memorization in convolutional\nautoencoders. Understanding this inductive bias may shed light on the\ngeneralization properties of overparametrized deep neural networks that are\ncurrently unexplained by classical statistical theory.",
    "published_date": "2018-10-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.10333v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.06765v1",
    "title": "A survey of automatic de-identification of longitudinal clinical narratives",
    "authors": [
      "Vithya Yogarajan",
      "Michael Mayo",
      "Bernhard Pfahringer"
    ],
    "author_ids": [],
    "abstract": "Use of medical data, also known as electronic health records, in research\nhelps develop and advance medical science. However, protecting patient\nconfidentiality and identity while using medical data for analysis is crucial.\nMedical data can be in the form of tabular structures (i.e. tables), free-form\nnarratives, and images. This study focuses on medical data in the free form\nlongitudinal text. De-identification of electronic health records provides the\nopportunity to use such data for research without it affecting patient privacy,\nand avoids the need for individual patient consent. In recent years there is\nincreasing interest in developing an accurate, robust and adaptable automatic\nde-identification system for electronic health records. This is mainly due to\nthe dilemma between the availability of an abundance of health data, and the\ninability to use such data in research due to legal and ethical restrictions.\nDe-identification tracks in competitions such as the 2014 i2b2 UTHealth and the\n2016 CEGS N-GRID shared tasks have provided a great platform to advance this\narea. The primary reasons for this include the open source nature of the\ndataset and the fact that raw psychiatric data were used for 2016 competitions.\nThis study focuses on noticeable trend changes in the techniques used in the\ndevelopment of automatic de-identification for longitudinal clinical\nnarratives. More specifically, the shift from using conditional random fields\n(CRF) based systems only or rules (regular expressions, dictionary or\ncombinations) based systems only, to hybrid models (combining CRF and rules),\nand more recently to deep learning based systems. We review the literature and\nresults that arose from the 2014 and the 2016 competitions and discuss the\noutcomes of these systems. We also provide a list of research questions that\nemerged from this survey.",
    "published_date": "2018-10-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.06765v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.06755v2",
    "title": "Discovering Fair Representations in the Data Domain",
    "authors": [
      "Novi Quadrianto",
      "Viktoriia Sharmanska",
      "Oliver Thomas"
    ],
    "author_ids": [],
    "abstract": "Interpretability and fairness are critical in computer vision and machine\nlearning applications, in particular when dealing with human outcomes, e.g.\ninviting or not inviting for a job interview based on application materials\nthat may include photographs. One promising direction to achieve fairness is by\nlearning data representations that remove the semantics of protected\ncharacteristics, and are therefore able to mitigate unfair outcomes. All\navailable models however learn latent embeddings which comes at the cost of\nbeing uninterpretable. We propose to cast this problem as data-to-data\ntranslation, i.e. learning a mapping from an input domain to a fair target\ndomain, where a fairness definition is being enforced. Here the data domain can\nbe images, or any tabular data representation. This task would be\nstraightforward if we had fair target data available, but this is not the case.\nTo overcome this, we learn a highly unconstrained mapping by exploiting\nstatistics of residuals - the difference between input data and its translated\nversion - and the protected characteristics. When applied to the CelebA dataset\nof face images with gender attribute as the protected characteristic, our model\nenforces equality of opportunity by adjusting the eyes and lips regions.\nIntriguingly, on the same dataset we arrive at similar conclusions when using\nsemantic attribute representations of images for translation. On face images of\nthe recent DiF dataset, with the same gender attribute, our method adjusts nose\nregions. In the Adult income dataset, also with protected gender attribute, our\nmodel achieves equality of opportunity by, among others, obfuscating the wife\nand husband relationship. Analyzing those systematic changes will allow us to\nscrutinize the interplay of fairness criterion, chosen protected\ncharacteristics, and prediction performance.",
    "published_date": "2018-10-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.06755v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.06748v1",
    "title": "Assessing the Contribution of Semantic Congruency to Multisensory Integration and Conflict Resolution",
    "authors": [
      "Di Fu",
      "Pablo Barros",
      "German I. Parisi",
      "Haiyan Wu",
      "Sven Magg",
      "Xun Liu",
      "Stefan Wermter"
    ],
    "author_ids": [],
    "abstract": "The efficient integration of multisensory observations is a key property of\nthe brain that yields the robust interaction with the environment. However,\nartificial multisensory perception remains an open issue especially in\nsituations of sensory uncertainty and conflicts. In this work, we extend\nprevious studies on audio-visual (AV) conflict resolution in complex\nenvironments. In particular, we focus on quantitatively assessing the\ncontribution of semantic congruency during an AV spatial localization task. In\naddition to conflicts in the spatial domain (i.e. spatially misaligned\nstimuli), we consider gender-specific conflicts with male and female avatars.\nOur results suggest that while semantically related stimuli affect the\nmagnitude of the visual bias (perceptually shifting the location of the sound\ntowards a semantically congruent visual cue), humans still strongly rely on\nenvironmental statistics to solve AV conflicts. Together with previously\nreported results, this work contributes to a better understanding of how\nmultisensory integration and conflict resolution can be modelled in artificial\nagents and robots operating in real-world environments.",
    "published_date": "2018-10-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.HC",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.06748v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.06218v1",
    "title": "Energy Efficiency Fairness for Multi-Pair Wireless-Powered Relaying Systems",
    "authors": [
      "Kien-Giang Nguyen",
      "Quang-Doanh Vu",
      "Le-Nam Tran",
      "Markku Juntti"
    ],
    "author_ids": [],
    "abstract": "We consider a multi-pair amplify-and-forward relay network where the\nenergy-constrained relays adopting time-switching protocol harvest energy from\nthe radio frequency signals transmitted by the users for assisting user data\ntransmission. Both one-way and two-way relaying techniques are investigated.\nAiming at energy efficiency (EE) fairness among the user pairs, we construct an\nenergy consumption model incorporating rate-dependent signal processing power,\nthe dependence on output power level of power amplifiers' efficiency, and\nnonlinear energy harvesting (EH) circuits. Then we formulate the max-min EE\nfairness problems in which the data rates, users' transmit power, relays'\nprocessing coefficient, and EH time are jointly optimized under the constraints\non the quality of service and users' maximum transmit power. To achieve\nefficient suboptimal solutions to these nonconvex problems, we devise monotonic\ndescent algorithms based on the inner approximation (IA) framework, which solve\na second-order-cone program in each iteration. To further simplify the designs,\nwe propose an approach combining IA and zero-forcing beamforming, which\neliminates inter-pair interference and reduces the numbers of variables and\nrequired iterations. Finally, extensive numerical results are presented to\nvalidate the proposed approaches. More specifically, the results demonstrate\nthat ignoring the realistic aspects of power consumption might degrade the\nperformance remarkably, and jointly designing parameters involved could\nsignificantly enhance the energy efficiency.",
    "published_date": "2018-10-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.06218v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.06207v1",
    "title": "Robust descent using smoothed multiplicative noise",
    "authors": [
      "Matthew J. Holland"
    ],
    "author_ids": [],
    "abstract": "To improve the off-sample generalization of classical procedures minimizing\nthe empirical risk under potentially heavy-tailed data, new robust learning\nalgorithms have been proposed in recent years, with generalized median-of-means\nstrategies being particularly salient. These procedures enjoy performance\nguarantees in the form of sharp risk bounds under weak moment assumptions on\nthe underlying loss, but typically suffer from a large computational overhead\nand substantial bias when the data happens to be sub-Gaussian, limiting their\nutility. In this work, we propose a novel robust gradient descent procedure\nwhich makes use of a smoothed multiplicative noise applied directly to\nobservations before constructing a sum of soft-truncated gradient coordinates.\nWe show that the procedure has competitive theoretical guarantees, with the\nmajor advantage of a simple implementation that does not require an iterative\nsub-routine for robustification. Empirical tests reinforce the theory, showing\nmore efficient generalization over a much wider class of data distributions.",
    "published_date": "2018-10-15T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.06207v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.07781v2",
    "title": "Responsible team players wanted: an analysis of soft skill requirements in job advertisements",
    "authors": [
      "Federica Calanca",
      "Luiza Sayfullina",
      "Lara Minkus",
      "Claudia Wagner",
      "Eric Malmi"
    ],
    "author_ids": [],
    "abstract": "During the past decades the importance of soft skills for labour market\noutcomes has grown substantially. This carries implications for labour market\ninequality, since previous research shows that soft skills are not valued\nequally across race and gender. This work explores the role of soft skills in\njob advertisements by drawing on methods from computational science as well as\non theoretical and empirical insights from economics, sociology and psychology.\nWe present a semi-automatic approach based on crowdsourcing and text mining for\nextracting a list of soft skills. We find that soft skills are a crucial\ncomponent of job ads, especially of low-paid jobs and jobs in female-dominated\nprofessions. Our work shows that soft skills can serve as partial predictors of\nthe gender composition in job categories and that not all soft skills receive\nequal wage returns at the labour market. Especially \"female\" skills are\nfrequently associated with wage penalties. Our results expand the growing\nliterature on the association of soft skills on wage inequality and highlight\ntheir importance for occupational gender segregation at labour markets.",
    "published_date": "2018-10-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.07781v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.08091v1",
    "title": "She's Reddit: A source of statistically significant gendered interest information?",
    "authors": [
      "Mike Thelwall",
      "Emma Stuart"
    ],
    "author_ids": [],
    "abstract": "Information about gender differences in interests is necessary to disentangle\nthe effects of discrimination and choice when gender inequalities occur, such\nas in employment. This article assesses gender differences in interests within\nthe popular social news and entertainment site Reddit. A method to detect terms\nthat are statistically significantly used more by males or females in 181\nmillion comments in 100 subreddits shows that gender affects both the selection\nof subreddits and activities within most of them. The method avoids the hidden\ngender biases of topic modelling for this task. Although the method reveals\nstatistically significant gender differences in interests for topics that are\nextensively discussed on Reddit, it cannot give definitive causes, and\nimitation and sharing within the site mean that additional checking is needed\nto verify the results. Nevertheless, with care, Reddit can serve as a useful\nsource of insights into gender differences in interests.",
    "published_date": "2018-10-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.08091v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.05598v5",
    "title": "Tuning Fairness by Balancing Target Labels",
    "authors": [
      "Thomas Kehrenberg",
      "Zexun Chen",
      "Novi Quadrianto"
    ],
    "author_ids": [],
    "abstract": "The issue of fairness in machine learning models has recently attracted a lot\nof attention as ensuring it will ensure continued confidence of the general\npublic in the deployment of machine learning systems. We focus on mitigating\nthe harm incurred by a biased machine learning system that offers better\noutputs (e.g. loans, job interviews) for certain groups than for others. We\nshow that bias in the output can naturally be controlled in probabilistic\nmodels by introducing a latent target output. This formulation has several\nadvantages: first, it is a unified framework for several notions of group\nfairness such as Demographic Parity and Equality of Opportunity; second, it is\nexpressed as a marginalisation instead of a constrained problem; and third, it\nallows the encoding of our knowledge of what unbiased outputs should be.\nPractically, the second allows us to avoid unstable constrained optimisation\nprocedures and to reuse off-the-shelf toolboxes. The latter translates to the\nability to control the level of fairness by directly varying fairness target\nrates. In contrast, existing approaches rely on intermediate, arguably\nunintuitive, control parameters such as covariance thresholds.",
    "published_date": "2018-10-12T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.05598v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.05421v1",
    "title": "The use of blogs in the education field: A qualitative systematic review",
    "authors": [
      "Carlos R. del Blanco",
      "Ivan García-Magariño"
    ],
    "author_ids": [],
    "abstract": "Blogs have become one of the most successful tools of the Web 2.0 because of\ntheir ease of use and the availability of open platforms. They have quickly\nspread in the education field thanks to the many attractive qualities that have\nbeen attributed to them, such as collaboration, communication, enhancing of\nprofessional writing, and the improvement of information-gathering skills.\nHowever, many of the studies that have addressed this issue were not based on\nan empirical research, and therefore they are unreliable. On the other hand,\nthe studies that do have conducted an empirical research have usually relied on\nparticipant self-reported data (surveys, interviews, and contents of blogs),\nwhich can significantly bias the positive results usually reported on the use\nof blogs. Another source of bias and inaccuracy in the reported results is that\nmost of the studies lacked control group, i.e they do not follow an\nexperimental design. The purpose of this review is to examine the current state\nof the studies related to the evaluation of the blog effects in the education\nfield. The methods to select the studies and perform the corresponding analysis\nhave followed a qualitative systematic approach. The selection has been\nrestricted to empirical and peer-reviewed studies published between January\n2011 and June 2013. The findings have been integrated and compared using the\nGrounded Theory, giving rise to a set of categories that have structured the\nresults of the review.",
    "published_date": "2018-10-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.SI",
      "physics.ed-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.05421v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.05201v1",
    "title": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns",
    "authors": [
      "Kellie Webster",
      "Marta Recasens",
      "Vera Axelrod",
      "Jason Baldridge"
    ],
    "author_ids": [],
    "abstract": "Coreference resolution is an important task for natural language\nunderstanding, and the resolution of ambiguous pronouns a longstanding\nchallenge. Nonetheless, existing corpora do not capture ambiguous pronouns in\nsufficient volume or diversity to accurately indicate the practical utility of\nmodels. Furthermore, we find gender bias in existing corpora and systems\nfavoring masculine entities. To address this, we present and release GAP, a\ngender-balanced labeled corpus of 8,908 ambiguous pronoun-name pairs sampled to\nprovide diverse coverage of challenges posed by real-world text. We explore a\nrange of baselines which demonstrate the complexity of the challenge, the best\nachieving just 66.9% F1. We show that syntactic structure and continuous neural\nmodels provide promising, complementary cues for approaching the challenge.",
    "published_date": "2018-10-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.05201v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1811.12159v1",
    "title": "Systematic Biases in Link Prediction: comparing heuristic and graph embedding based methods",
    "authors": [
      "Aakash Sinha",
      "Rémy Cazabet",
      "Rémi Vaudaine"
    ],
    "author_ids": [],
    "abstract": "Link prediction is a popular research topic in network analysis. In the last\nfew years, new techniques based on graph embedding have emerged as a powerful\nalternative to heuristics. In this article, we study the problem of systematic\nbiases in the prediction, and show that some methods based on graph embedding\noffer less biased results than those based on heuristics, despite reaching\nlower scores according to usual quality scores. We discuss the relevance of\nthis finding in the context of the filter bubble problem and the algorithmic\nfairness of recommender systems.",
    "published_date": "2018-10-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.12159v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.04793v3",
    "title": "Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record",
    "authors": [
      "Jinghe Zhang",
      "Kamran Kowsari",
      "James H. Harrison",
      "Jennifer M. Lobo",
      "Laura E. Barnes"
    ],
    "author_ids": [],
    "abstract": "The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights.",
    "published_date": "2018-10-10T00:00:00",
    "year": 2018,
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.04793v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.05041v2",
    "title": "A General Framework for Fair Regression",
    "authors": [
      "Jack Fitzsimons",
      "AbdulRahman Al Ali",
      "Michael Osborne",
      "Stephen Roberts"
    ],
    "author_ids": [],
    "abstract": "Fairness, through its many forms and definitions, has become an important\nissue facing the machine learning community. In this work, we consider how to\nincorporate group fairness constraints in kernel regression methods, applicable\nto Gaussian processes, support vector machines, neural network regression and\ndecision tree regression. Further, we focus on examining the effect of\nincorporating these constraints in decision tree regression, with direct\napplications to random forests and boosted trees amongst other widespread\npopular inference techniques. We show that the order of complexity of memory\nand computation is preserved for such models and tightly bound the expected\nperturbations to the model in terms of the number of leaves of the trees.\nImportantly, the approach works on trained models and hence can be easily\napplied to models in current use and group labels are only required on training\ndata.",
    "published_date": "2018-10-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.05041v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.04531v1",
    "title": "Inferring User Gender from User Generated Visual Content on a Deep Semantic Space",
    "authors": [
      "David Semedo",
      "João Magalhães",
      "Flávio Martins"
    ],
    "author_ids": [],
    "abstract": "In this paper we address the task of gender classification on picture sharing\nsocial media networks such as Instagram and Flickr. We aim to infer the gender\nof an user given only a small set of the images shared in its profile. We make\nthe assumption that user's images contain a collection of visual elements that\nimplicitly encode discriminative patterns that allow inferring its gender, in a\nlanguage independent way. This information can then be used in personalisation\nand recommendation. Our main hypothesis is that semantic visual features are\nmore adequate for discriminating high-level classes.\n  The gender detection task is formalised as: given an user's profile,\nrepresented as a bag of images, we want to infer the gender of the user. Social\nmedia profiles can be noisy and contain confounding factors, therefore we\nclassify bags of user-profile's images to provide a more robust prediction.\nExperiments using a dataset from the picture sharing social network Instagram\nshow that the use of multiple images is key to improve detection performance.\nMoreover, we verify that deep semantic features are more suited for gender\ndetection than low-level image representations. The methods proposed can infer\nthe gender with precision scores higher than 0.825, and the best performing\nmethod achieving 0.911 precision.",
    "published_date": "2018-10-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MM",
      "I.5.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.04531v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.04528v1",
    "title": "Is there Gender bias and stereotype in Portuguese Word Embeddings?",
    "authors": [
      "Brenda Salenave Santana",
      "Vinicius Woloszyn",
      "Leandro Krug Wives"
    ],
    "author_ids": [],
    "abstract": "In this work, we propose an analysis of the presence of gender bias\nassociated with professions in Portuguese word embeddings. The objective of\nthis work is to study gender implications related to stereotyped professions\nfor women and men in the context of the Portuguese language.",
    "published_date": "2018-10-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.04528v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.04259v2",
    "title": "Fair Division Minimizing Inequality",
    "authors": [
      "Martin Aleksandrov",
      "Cunjing Ge",
      "Toby Walsh"
    ],
    "author_ids": [],
    "abstract": "Behavioural economists have shown that people are often averse to inequality\nand will make choices to avoid unequal outcomes. In this paper, we consider how\nto allocate indivisible goods fairly so as to minimize inequality. We consider\nhow this interacts with axiomatic properties such as envy-freeness, Pareto\nefficiency and strategy-proofness. We also consider the computational\ncomplexity of computing allocations minimizing inequality. Unfortunately, this\nis computationally intractable in general so we consider several tractable\ngreedy online mechanisms that minimize inequality. Finally, we run experiments\nto explore the performance of these methods.",
    "published_date": "2018-10-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.04259v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.03871v1",
    "title": "Conditional Generative Refinement Adversarial Networks for Unbalanced Medical Image Semantic Segmentation",
    "authors": [
      "Mina Rezaei",
      "Haojin Yang",
      "Christoph Meinel"
    ],
    "author_ids": [],
    "abstract": "We propose a new generative adversarial architecture to mitigate imbalance\ndata problem in medical image semantic segmentation where the majority of\npixels belongs to a healthy region and few belong to lesion or non-health\nregion. A model trained with imbalanced data tends to bias toward healthy data\nwhich is not desired in clinical applications and predicted outputs by these\nnetworks have high precision and low sensitivity. We propose a new conditional\ngenerative refinement network with three components: a generative, a\ndiscriminative, and a refinement network to mitigate unbalanced data problem\nthrough ensemble learning. The generative network learns to a segment at the\npixel level by getting feedback from the discriminative network according to\nthe true positive and true negative maps. On the other hand, the refinement\nnetwork learns to predict the false positive and the false negative masks\nproduced by the generative network that has significant value, especially in\nmedical application. The final semantic segmentation masks are then composed by\nthe output of the three networks. The proposed architecture shows\nstate-of-the-art results on LiTS-2017 for liver lesion segmentation, and two\nmicroscopic cell segmentation datasets MDA231, PhC-HeLa. We have achieved\ncompetitive results on BraTS-2017 for brain tumour segmentation.",
    "published_date": "2018-10-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03871v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03611v2",
    "title": "Understanding the Origins of Bias in Word Embeddings",
    "authors": [
      "Marc-Etienne Brunet",
      "Colleen Alkalay-Houlihan",
      "Ashton Anderson",
      "Richard Zemel"
    ],
    "author_ids": [],
    "abstract": "The power of machine learning systems not only promises great technical\nprogress, but risks societal harm. As a recent example, researchers have shown\nthat popular word embedding algorithms exhibit stereotypical biases, such as\ngender bias. The widespread use of these algorithms in machine learning\nsystems, from automated translation services to curriculum vitae scanners, can\namplify stereotypes in important contexts. Although methods have been developed\nto measure these biases and alter word embeddings to mitigate their biased\nrepresentations, there is a lack of understanding in how word embedding bias\ndepends on the training data. In this work, we develop a technique for\nunderstanding the origins of bias in word embeddings. Given a word embedding\ntrained on a corpus, our method identifies how perturbing the corpus will\naffect the bias of the resulting embedding. This can be used to trace the\norigins of word embedding bias back to the original training documents. Using\nour method, one can investigate trends in the bias of the underlying corpus and\nidentify subsets of documents whose removal would most reduce bias. We\ndemonstrate our techniques on both a New York Times and Wikipedia corpus and\nfind that our influence function-based approximations are very accurate.",
    "published_date": "2018-10-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03611v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03360v1",
    "title": "A Survey on Periocular Biometrics Research",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Josef Bigun"
    ],
    "author_ids": [],
    "abstract": "Periocular refers to the facial region in the vicinity of the eye, including\neyelids, lashes and eyebrows. While face and irises have been extensively\nstudied, the periocular region has emerged as a promising trait for\nunconstrained biometrics, following demands for increased robustness of face or\niris systems. With a surprisingly high discrimination ability, this region can\nbe easily obtained with existing setups for face and iris, and the requirement\nof user cooperation can be relaxed, thus facilitating the interaction with\nbiometric systems. It is also available over a wide range of distances even\nwhen the iris texture cannot be reliably obtained (low resolution) or under\npartial face occlusion (close distances). Here, we review the state of the art\nin periocular biometrics research. A number of aspects are described,\nincluding: i) existing databases, ii) algorithms for periocular detection\nand/or segmentation, iii) features employed for recognition, iv) identification\nof the most discriminative regions of the periocular area, v) comparison with\niris and face modalities, vi) soft-biometrics (gender/ethnicity\nclassification), and vii) impact of gender transformation and plastic surgery\non the recognition accuracy. This work is expected to provide an insight of the\nmost relevant issues in periocular biometrics, giving a comprehensive coverage\nof the existing literature and current state of the art.",
    "published_date": "2018-10-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03360v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03275v1",
    "title": "TV-regularized CT Reconstruction and Metal Artifact Reduction Using Inequality Constraints with Preconditioning",
    "authors": [
      "Clemens Schiffer"
    ],
    "author_ids": [],
    "abstract": "Total variation(TV) regularization is applied to X-Ray computed\ntomography(CT) in an effort to reduce metal artifacts. Tikhonov regularization\nwith $L^2$ data fidelity term and total variation regularization is augmented\nin this novel model by inequality constraints on sinogram data affected by\nmetal to model errors caused by metal. The formulated problem is discretized\nand solved using the Chambolle-Pock algorithm. Faster convergence is achieved\nusing preconditioning in a Douglas-Rachford spitting method as well as Advanced\nDirection Method of Multipliers(ADMM). The methods are applied to real and\nsynthetic data demonstrating feasibility of the model to reduce metal\nartifacts. Technical details of CT data used and its processing are given in\nthe appendix.",
    "published_date": "2018-10-08T00:00:00",
    "year": 2018,
    "categories": [
      "math.NA",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03275v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03130v4",
    "title": "Nonlinear Stochastic Attitude Filters on the Special Orthogonal Group 3: Ito and Stratonovich",
    "authors": [
      "Hashim A. Hashim",
      "Lyndon J. Brown",
      "Kenneth McIsaac"
    ],
    "author_ids": [],
    "abstract": "Two nonlinear stochastic complimentary filters are developed on SO(3). They\nguarantee that errors in the Rodriguez vector and estimates are semi-globally\nuniformly ultimately bounded in mean square, and they converge to a small\nneighborhood of the origin. Simulation results are presented to illustrate the\neffectiveness of the proposed filters considering high level of uncertainties\nin angular velocity as well as body-frame vector measurements. Keywords:\nAttitude estimate, Attitude estimator, Attitude observer, Attitude filter,\nNonlinear stochastic filter, stochastic differential equations, Brownian motion\nprocess, Ito, Stratonovich, Wong Zakai, Rodriguez vector, unit-quaternion,\nspecial orthogonal group 3, Euclidean, Euler angles, Angle-axis, Mapping,\nParameterization, Representation, Robust, Invariant, Kalman Filter, Extended\nKalman Filter, Multiplicative Extended Kalman Filter, Unscented Kalman Filter,\nParticle Filter, KF, EKF, MEKF, IEKF, first, second, Partial derivative,\noperator, probability, small, error, dynamics, kinematics, equilibrium,\nasymptotic, covariance, mean square, expected value, zero, unknown,\ntime-varying, global, semi-global, stable, stability, uncertain, white noise,\nGaussian noise, colored noise, bias, vectorial, vector measurement, angular\nvelocity, singular value decomposition, bounded, rotational matrix, identity,\ndeterministic, orientation, body frame, comparison, inertial frame, rigid body,\nthree dimensional, 3D, space, Attitude Control, Lie algebra, Lie group,\nprojection, Gyroscope, Inertial measurement units, micro electromechanical\nsystems, sensor, IMUs, MEMS, Roll, Pitch, Yaw, UAVs, QUAV, SVD, Fixed, Moving,\nVehicles, Robot, Robotic System, Spacecraft, submarine, Underwater vehicle,\nProblem, advantage, integral, integration, passive complementary filter,\nDisadvantage, autonomous, Review, Overview, Survey, comparative study, pose,\nSDEs, SE(3), SO(3).",
    "published_date": "2018-10-07T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03130v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.03032v1",
    "title": "Constructing Graph Node Embeddings via Discrimination of Similarity Distributions",
    "authors": [
      "Stanislav Tsepa",
      "Maxim Panov"
    ],
    "author_ids": [],
    "abstract": "The problem of unsupervised learning node embeddings in graphs is one of the\nimportant directions in modern network science. In this work we propose a novel\nframework, which is aimed to find embeddings by \\textit{discriminating\ndistributions of similarities (DDoS)} between nodes in the graph. The general\nidea is implemented by maximizing the \\textit{earth mover distance} between\ndistributions of decoded similarities of similar and dissimilar nodes. The\nresulting algorithm generates embeddings which give a state-of-the-art\nperformance in the problem of link prediction in real-world graphs.",
    "published_date": "2018-10-06T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03032v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03025v1",
    "title": "Discretizing Logged Interaction Data Biases Learning for Decision-Making",
    "authors": [
      "Peter Schulam",
      "Suchi Saria"
    ],
    "author_ids": [],
    "abstract": "Time series data that are not measured at regular intervals are commonly\ndiscretized as a preprocessing step. For example, data about customer arrival\ntimes might be simplified by summing the number of arrivals within hourly\nintervals, which produces a discrete-time time series that is easier to model.\nIn this abstract, we show that discretization introduces a bias that affects\nmodels trained for decision-making. We refer to this phenomenon as\ndiscretization bias, and show that we can avoid it by using continuous-time\nmodels instead.",
    "published_date": "2018-10-06T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03025v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.03005v1",
    "title": "Gendered behavior as a disadvantage in open source software development",
    "authors": [
      "Balazs Vedres",
      "Orsolya Vasarhelyi"
    ],
    "author_ids": [],
    "abstract": "Women are severely marginalized in software development, especially in open\nsource. In this article we argue that disadvantage is more due to gendered\nbehavior than to categorical discrimination: women are at a disadvantage\nbecause of what they do, rather than because of who they are. Using data on\nentire careers of users from GitHub.com, we develop a measure to capture the\ngendered pattern of behavior: We use a random forest prediction of being female\n(as opposed to being male) by behavioral choices in the level of activity,\nspecialization in programming languages, and choice of partners. We test\ndifferences in success and survival along both categorical gender and the\ngendered pattern of behavior. We find that 84.5% of women's disadvantage\n(compared to men) in success and 34.8% of their disadvantage in survival are\ndue to the female pattern of their behavior. Men are also disadvantaged along\ntheir interquartile range of the female pattern of their behavior, and users\nwho don't reveal their gender suffer an even more drastic disadvantage in\nsurvival probability. Moreover, we do not see evidence for any reduction of\nthese inequalities in time. Our findings are robust to noise in gender\nrecognition, and to taking into account particular programming languages, or\ndecision tree classes of gendered behavior. Our results suggest that fighting\ncategorical gender discrimination will have a limited impact on gender\ninequalities in open source software development, and that gender hiding is not\na viable strategy for women.",
    "published_date": "2018-10-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.03005v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.09841v1",
    "title": "Predicting and Explaining Behavioral Data with Structured Feature Space Decomposition",
    "authors": [
      "Peter G Fennell",
      "Zhiya Zuo",
      "Kristina Lerman"
    ],
    "author_ids": [],
    "abstract": "Modeling human behavioral data is challenging due to its scale, sparseness\n(few observations per individual), heterogeneity (differently behaving\nindividuals), and class imbalance (few observations of the outcome of\ninterest). An additional challenge is learning an interpretable model that not\nonly accurately predicts outcomes, but also identifies important factors\nassociated with a given behavior. To address these challenges, we describe a\nstatistical approach to modeling behavioral data called the structured\nsum-of-squares decomposition (S3D). The algorithm, which is inspired by\ndecision trees, selects important features that collectively explain the\nvariation of the outcome, quantifies correlations between the features, and\npartitions the subspace of important features into smaller, more homogeneous\nblocks that correspond to similarly-behaving subgroups within the population.\nThis partitioned subspace allows us to predict and analyze the behavior of the\noutcome variable both statistically and visually, giving a medium to examine\nthe effect of various features and to create explainable predictions. We apply\nS3D to learn models of online activity from large-scale data collected from\ndiverse sites, such as Stack Exchange, Khan Academy, Twitter, Duolingo, and\nDigg. We show that S3D creates parsimonious models that can predict outcomes in\nthe held-out data at levels comparable to state-of-the-art approaches, but in\naddition, produces interpretable models that provide insights into behaviors.\nThis is important for informing strategies aimed at changing behavior,\ndesigning social systems, but also for explaining predictions, a critical step\ntowards minimizing algorithmic bias.",
    "published_date": "2018-10-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "physics.data-an",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.09841v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.02702v1",
    "title": "Memetic Viability Evolution for Constrained Optimization",
    "authors": [
      "A. Maesani",
      "G. Iacca",
      "D. Floreano"
    ],
    "author_ids": [],
    "abstract": "The performance of evolutionary algorithms can be heavily undermined when\nconstraints limit the feasible areas of the search space. For instance, while\nCovariance Matrix Adaptation Evolution Strategy is one of the most efficient\nalgorithms for unconstrained optimization problems, it cannot be readily\napplied to constrained ones. Here, we used concepts from Memetic Computing,\ni.e. the harmonious combination of multiple units of algorithmic information,\nand Viability Evolution, an alternative abstraction of artificial evolution, to\ndevise a novel approach for solving optimization problems with inequality\nconstraints. Viability Evolution emphasizes elimination of solutions not\nsatisfying viability criteria, defined as boundaries on objectives and\nconstraints. These boundaries are adapted during the search to drive a\npopulation of local search units, based on Covariance Matrix Adaptation\nEvolution Strategy, towards feasible regions. These units can be recombined by\nmeans of Differential Evolution operators. Of crucial importance for the\nperformance of our method, an adaptive scheduler toggles between exploitation\nand exploration by selecting to advance one of the local search units and/or\nrecombine them. The proposed algorithm can outperform several state-of-the-art\nmethods on a diverse set of benchmark and engineering problems, both for\nquality of solutions and computational resources needed.",
    "published_date": "2018-10-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02702v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.02561v3",
    "title": "GPdoemd: a Python package for design of experiments for model discrimination",
    "authors": [
      "Simon Olofsson",
      "Lukas Hebing",
      "Sebastian Niedenführ",
      "Marc Peter Deisenroth",
      "Ruth Misener"
    ],
    "author_ids": [],
    "abstract": "Model discrimination identifies a mathematical model that usefully explains\nand predicts a given system's behaviour. Researchers will often have several\nmodels, i.e. hypotheses, about an underlying system mechanism, but insufficient\nexperimental data to discriminate between the models, i.e. discard inaccurate\nmodels. Given rival mathematical models and an initial experimental data set,\noptimal design of experiments suggests maximally informative experimental\nobservations that maximise a design criterion weighted by prediction\nuncertainty. The model uncertainty requires gradients, which may not be readily\navailable for black-box models. This paper (i) proposes a new design criterion\nusing the Jensen-R\\'enyi divergence, and (ii) develops a novel method replacing\nblack-box models with Gaussian process surrogates. Using the surrogates, we\nmarginalise out the model parameters with approximate inference. Results show\nthese contributions working well for both classical and new test instances. We\nalso (iii) introduce and discuss GPdoemd, the open-source implementation of the\nGaussian process surrogate method.",
    "published_date": "2018-10-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02561v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.02453v1",
    "title": "Correcting the bias in least squares regression with volume-rescaled sampling",
    "authors": [
      "Michał Dereziński",
      "Manfred K. Warmuth",
      "Daniel Hsu"
    ],
    "author_ids": [],
    "abstract": "Consider linear regression where the examples are generated by an unknown\ndistribution on $R^d\\times R$. Without any assumptions on the noise, the linear\nleast squares solution for any i.i.d. sample will typically be biased w.r.t.\nthe least squares optimum over the entire distribution. However, we show that\nif an i.i.d. sample of any size k is augmented by a certain small additional\nsample, then the solution of the combined sample becomes unbiased. We show this\nwhen the additional sample consists of d points drawn jointly according to the\ninput distribution that is rescaled by the squared volume spanned by the\npoints. Furthermore, we propose algorithms to sample from this volume-rescaled\ndistribution when the data distribution is only known through an i.i.d sample.",
    "published_date": "2018-10-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02453v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.02053v1",
    "title": "Proceedings 11th Interaction and Concurrency Experience",
    "authors": [
      "Massimo Bartoletti",
      "Sophia Knight"
    ],
    "author_ids": [],
    "abstract": "This volume contains the proceedings of ICE'18, the 11th Interaction and\nConcurrency Experience, which was held in Madrid, Spain on the 20th and 21st of\nJune 2018 as a satellite event of DisCoTec'18.\n  The ICE workshop series features a distinguishing review and selection\nprocedure, allowing PC members to interact anonymously with authors. As in the\npast ten editions, this interaction considerably improved the accuracy of the\nfeedback from the reviewers and the quality of accepted papers, and offered the\nbasis for lively discussion during the workshop. For the second time, the 2018\nedition of ICE included double blind reviewing of original research papers, in\norder to increase fairness and avoid bias in reviewing.\n  Each paper was reviewed by three PC members, and altogether six papers were\naccepted for publication (the workshop also featured four oral presentations\nwhich are not part of this volume). We were proud to host three invited talks,\nby Elvira Albert, Silvia Crafa, and Alexey Gotsman. The abstracts of these\ntalks are included in this volume together with the regular papers. Final\nversions of the contributions, taking into account the discussion at the\nworkshop, are included.",
    "published_date": "2018-10-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LO",
      "cs.DC",
      "cs.PL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02053v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.02003v2",
    "title": "From Soft Classifiers to Hard Decisions: How fair can we be?",
    "authors": [
      "Ran Canetti",
      "Aloni Cohen",
      "Nishanth Dikkala",
      "Govind Ramnarayan",
      "Sarah Scheffler",
      "Adam Smith"
    ],
    "author_ids": [],
    "abstract": "A popular methodology for building binary decision-making classifiers in the\npresence of imperfect information is to first construct a non-binary \"scoring\"\nclassifier that is calibrated over all protected groups, and then to\npost-process this score to obtain a binary decision. We study the feasibility\nof achieving various fairness properties by post-processing calibrated scores,\nand then show that deferring post-processors allow for more fairness conditions\nto hold on the final decision. Specifically, we show:\n  1. There does not exist a general way to post-process a calibrated classifier\nto equalize protected groups' positive or negative predictive value (PPV or\nNPV). For certain \"nice\" calibrated classifiers, either PPV or NPV can be\nequalized when the post-processor uses different thresholds across protected\ngroups, though there exist distributions of calibrated scores for which the two\nmeasures cannot be both equalized. When the post-processing consists of a\nsingle global threshold across all groups, natural fairness properties, such as\nequalizing PPV in a nontrivial way, do not hold even for \"nice\" classifiers.\n  2. When the post-processing is allowed to `defer' on some decisions (that is,\nto avoid making a decision by handing off some examples to a separate process),\nthen for the non-deferred decisions, the resulting classifier can be made to\nequalize PPV, NPV, false positive rate (FPR) and false negative rate (FNR)\nacross the protected groups. This suggests a way to partially evade the\nimpossibility results of Chouldechova and Kleinberg et al., which preclude\nequalizing all of these measures simultaneously. We also present different\ndeferring strategies and show how they affect the fairness properties of the\noverall system.\n  We evaluate our post-processing techniques using the COMPAS data set from\n2016.",
    "published_date": "2018-10-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02003v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.01943v1",
    "title": "AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias",
    "authors": [
      "Rachel K. E. Bellamy",
      "Kuntal Dey",
      "Michael Hind",
      "Samuel C. Hoffman",
      "Stephanie Houde",
      "Kalapriya Kannan",
      "Pranay Lohia",
      "Jacquelyn Martino",
      "Sameep Mehta",
      "Aleksandra Mojsilovic",
      "Seema Nagar",
      "Karthikeyan Natesan Ramamurthy",
      "John Richards",
      "Diptikalyan Saha",
      "Prasanna Sattigeri",
      "Moninder Singh",
      "Kush R. Varshney",
      "Yunfeng Zhang"
    ],
    "author_ids": [],
    "abstract": "Fairness is an increasingly important concern as machine learning models are\nused to support decision making in high-stakes applications such as mortgage\nlending, hiring, and prison sentencing. This paper introduces a new open source\nPython toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released\nunder an Apache v2.0 license {https://github.com/ibm/aif360). The main\nobjectives of this toolkit are to help facilitate the transition of fairness\nresearch algorithms to use in an industrial setting and to provide a common\nframework for fairness researchers to share and evaluate algorithms.\n  The package includes a comprehensive set of fairness metrics for datasets and\nmodels, explanations for these metrics, and algorithms to mitigate bias in\ndatasets and models. It also includes an interactive Web experience\n(https://aif360.mybluemix.net) that provides a gentle introduction to the\nconcepts and capabilities for line-of-business users, as well as extensive\ndocumentation, usage guidance, and industry-specific tutorials to enable data\nscientists and practitioners to incorporate the most appropriate tool for their\nproblem into their work products. The architecture of the package has been\nengineered to conform to a standard paradigm used in data science, thereby\nfurther improving usability for practitioners. Such architectural design and\nabstractions enable researchers and developers to extend the toolkit with their\nnew algorithms and improvements, and to use it for performance benchmarking. A\nbuilt-in testing infrastructure maintains code quality.",
    "published_date": "2018-10-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01943v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.01729v1",
    "title": "Can everyday AI be ethical. Fairness of Machine Learning Algorithms",
    "authors": [
      "Philippe Besse",
      "Celine Castets-Renard",
      "Aurelien Garivier",
      "Jean-Michel Loubes"
    ],
    "author_ids": [],
    "abstract": "Combining big data and machine learning algorithms, the power of automatic\ndecision tools induces as much hope as fear. Many recently enacted European\nlegislation (GDPR) and French laws attempt to regulate the use of these tools.\nLeaving aside the well-identified problems of data confidentiality and\nimpediments to competition, we focus on the risks of discrimination, the\nproblems of transparency and the quality of algorithmic decisions. The detailed\nperspective of the legal texts, faced with the complexity and opacity of the\nlearning algorithms, reveals the need for important technological disruptions\nfor the detection or reduction of the discrimination risk, and for addressing\nthe right to obtain an explanation of the auto- matic decision. Since trust of\nthe developers and above all of the users (citizens, litigants, customers) is\nessential, algorithms exploiting personal data must be deployed in a strict\nethical framework. In conclusion, to answer this need, we list some ways of\ncontrols to be developed: institutional control, ethical charter, external\naudit attached to the issue of a label.",
    "published_date": "2018-10-03T00:00:00",
    "year": 2018,
    "categories": [
      "stat.OT",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01729v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.01619v2",
    "title": "Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping",
    "authors": [
      "Johann Laconte",
      "Simon-Pierre Deschênes",
      "Mathieu Labussière",
      "François Pomerleau"
    ],
    "author_ids": [],
    "abstract": "In a context of 3D mapping, it is very important to get accurate measurements\nfrom sensors. In particular, Light Detection And Ranging (LIDAR) measurements\nare typically treated as a zero-mean Gaussian distribution. We show that this\nassumption leads to predictable localisation drifts, especially when a bias\nrelated to measuring obstacles with high incidence angles is not taken into\nconsideration. Moreover, we present a way to physically understand and model\nthis bias, which generalises to multiple sensors. Using an experimental setup,\nwe measured the bias of the Sick LMS151, Velodyne HDL-32E, and Robosense\nRS-LiDAR-16 as a function of depth and incidence angle, and showed that the\nbias can go up to 20 cm for high incidence angles. We then used our\nmodelisations to remove the bias from the measurements, leading to more\naccurate maps and a reduced localisation drift.",
    "published_date": "2018-10-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "68T40"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01619v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.01436v1",
    "title": "Efficient Estimation of Equilibria of Large Congestion Games with Heterogeneous Players",
    "authors": [
      "Cheng Wan",
      "Paulin Jacquot",
      "Olivier Beaude",
      "Nadia Oudjane"
    ],
    "author_ids": [],
    "abstract": "Computing an equilibrium in congestion games can be challenging when the\nnumber of players is large. Yet, it is a problem to be addressed in practice,\nfor instance to forecast the state of the system and be able to control it. In\nthis work, we analyze the case of generalized atomic congestion games, with\ncoupling constraints, and with players that are heterogeneous through their\naction sets and their utility functions. We obtain an approximation of the\nvariational Nash equilibria---a notion generalizing Nash equilibria in the\npresence of coupling constraints---of a large atomic congestion game by an\nequilibrium of an auxiliary population game, where each population corresponds\nto a group of atomic players of the initial game. Because the variational\ninequalities characterizing the equilibrium of the auxiliary game have smaller\ndimension than the original problem, this approach enables the fast computation\nof an estimation of equilibria in a large congestion game with thousands of\nheterogeneous players.",
    "published_date": "2018-10-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01436v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.01092v1",
    "title": "Relating Metric Distortion and Fairness of Social Choice Rules",
    "authors": [
      "Ashish Goel",
      "Reyna Hulett",
      "Anilesh K. Krishnaswamy"
    ],
    "author_ids": [],
    "abstract": "One way of evaluating social choice (voting) rules is through a utilitarian\ndistortion framework. In this model, we assume that agents submit full rankings\nover the alternatives, and these rankings are generated from underlying, but\nunknown, quantitative costs. The \\emph{distortion} of a social choice rule is\nthen the ratio of the total social cost of the chosen alternative to the\noptimal social cost of any alternative; since the true costs are unknown, we\nconsider the worst-case distortion over all possible underlying costs.\nAnalogously, we can consider the worst-case \\emph{fairness ratio} of a social\nchoice rule by comparing a useful notion of fairness (based on approximate\nmajorization) for the chosen alternative to that of the optimal alternative.\nWith an additional metric assumption -- that the costs equal the\nagent-alternative distances in some metric space -- it is known that the\nCopeland rule achieves both a distortion and fairness ratio of at most 5. For\nother rules, only bounds on the distortion are known, e.g., the popular Single\nTransferable Vote (STV) rule has distortion $O(\\log m)$, where $m$ is the\nnumber of alternatives. We prove that the distinct notions of distortion and\nfairness ratio are in fact closely linked -- within an additive factor of 2 for\nany voting rule -- and thus STV also achieves an $O(\\log m)$ fairness ratio. We\nfurther extend the notions of distortion and fairness ratio to social choice\nrules choosing a \\emph{set} of alternatives. By relating the distortion of\nsingle-winner rules to multiple-winner rules, we establish that Recursive\nCopeland achieves a distortion of 5 and a fairness ratio of at most 7 for\nchoosing a set of alternatives.",
    "published_date": "2018-10-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01092v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.01765v1",
    "title": "Predicting Factuality of Reporting and Bias of News Media Sources",
    "authors": [
      "Ramy Baly",
      "Georgi Karadzhov",
      "Dimitar Alexandrov",
      "James Glass",
      "Preslav Nakov"
    ],
    "author_ids": [],
    "abstract": "We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type.",
    "published_date": "2018-10-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01765v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.01488v1",
    "title": "Using Machine Learning to Discern Eruption in Noisy Environments: A Case Study using CO2-driven Cold-Water Geyser in Chimayo, New Mexico",
    "authors": [
      "B. Yuan",
      "Y. J. Tan",
      "M. K. Mudunuru",
      "O. E. Marcillo",
      "A. A. Delorey",
      "P. M. Roberts",
      "J. D. Webster",
      "C. N. L. Gammans",
      "S. Karra",
      "G. D. Guthrie",
      "P. A. Johnson"
    ],
    "author_ids": [],
    "abstract": "We present an approach based on machine learning (ML) to distinguish eruption\nand precursory signals of Chimay\\'{o} geyser (New Mexico, USA) under noisy\nenvironments. This geyser can be considered as a natural analog of\n$\\mathrm{CO}_2$ intrusion into shallow water aquifers. By studying this geyser,\nwe can understand upwelling of $\\mathrm{CO}_2$-rich fluids from depth, which\nhas relevance to leak monitoring in a $\\mathrm{CO}_2$ sequestration project. ML\nmethods such as Random Forests (RF) are known to be robust multi-class\nclassifiers and perform well under unfavorable noisy conditions. However, the\nextent of the RF method's accuracy is poorly understood for this\n$\\mathrm{CO}_2$-driven geysering application. The current study aims to\nquantify the performance of RF-classifiers to discern the geyser state. Towards\nthis goal, we first present the data collected from the seismometer that is\ninstalled near the Chimay\\'{o} geyser. The seismic signals collected at this\nsite contain different types of noises such as daily temperature variations,\nseasonal trends, animal movement near the geyser, and human activity. First, we\nfilter the signals from these noises by combining the Butterworth-Highpass\nfilter and an Autoregressive method in a multi-level fashion. We show that by\ncombining these filtering techniques, in a hierarchical fashion, leads to\nreduction in the noise in the seismic data without removing the precursors and\neruption event signals. We then use RF on the filtered data to classify the\nstate of geyser into three classes -- remnant noise, precursor, and eruption\nstates. We show that the classification accuracy using RF on the filtered data\nis greater than 90\\%.These aspects make the proposed ML framework attractive\nfor event discrimination and signal enhancement under noisy conditions, with\nstrong potential for application to monitoring leaks in $\\mathrm{CO}_2$\nsequestration.",
    "published_date": "2018-10-01T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SP",
      "cs.LG",
      "physics.data-an",
      "physics.geo-ph",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.01488v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.00562v1",
    "title": "The information-theoretic meaning of Gagliardo--Nirenberg type inequalities",
    "authors": [
      "Giuseppe Toscani"
    ],
    "author_ids": [],
    "abstract": "Gagliardo--Nirenberg inequalities are interpolation inequalities which were\nproved independently by Gagliardo and Nirenberg in the late fifties. In recent\nyears, their connections with theoretic aspects of information theory and\nnonlinear diffusion equations allowed to obtain some of them in optimal form,\nby recovering both the sharp constants and the explicit form of the optimizers.\nIn this note, at the light of these recent researches, we review the main\nconnections between Shannon-type entropies, diffusion equations and a class of\nthese inequalities.",
    "published_date": "2018-10-01T00:00:00",
    "year": 2018,
    "categories": [
      "math.FA",
      "cs.IT",
      "math-ph",
      "math.IT",
      "math.MP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.00562v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.00471v1",
    "title": "Identifying Bias in AI using Simulation",
    "authors": [
      "Daniel McDuff",
      "Roger Cheng",
      "Ashish Kapoor"
    ],
    "author_ids": [],
    "abstract": "Machine learned models exhibit bias, often because the datasets used to train\nthem are biased. This presents a serious problem for the deployment of such\ntechnology, as the resulting models might perform poorly on populations that\nare minorities within the training set and ultimately present higher risks to\nthem. We propose to use high-fidelity computer simulations to interrogate and\ndiagnose biases within ML classifiers. We present a framework that leverages\nBayesian parameter search to efficiently characterize the high dimensional\nfeature space and more quickly identify weakness in performance. We apply our\napproach to an example domain, face detection, and show that it can be used to\nhelp identify demographic biases in commercial face application programming\ninterfaces (APIs).",
    "published_date": "2018-09-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.00471v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1810.00257v2",
    "title": "Computational Convergence Analysis of Distributed Gradient Tracking for Smooth Convex Optimization Using Dissipativity Theory",
    "authors": [
      "Shuo Han"
    ],
    "author_ids": [],
    "abstract": "We present a computational analysis that establishes the $O(1/K)$ convergence\nof the distributed gradient tracking method when the objective function is\nsmooth and convex but not strongly convex. The analysis is inspired by recent\nwork on applying dissipativity theory to the analysis of centralized\noptimization algorithms, in which convergence is proved by searching for a\nnumerical certificate consisting of a storage function and a supply rate. We\nderive a base supply rate that can be used to analyze distributed optimization\nwith non-strongly convex objective functions. The base supply rate is then used\nto create a class of supply rates by combining with integral quadratic\nconstraints. Provided that the class of supply rates is rich enough, a\nnumerical certificate of convergence can be automatically generated following a\nstandard procedure that involves solving a linear matrix inequality. Our\ncomputational analysis is found capable of certifying convergence under a\nbroader range of step sizes than what is given by the original analytic result.",
    "published_date": "2018-09-29T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.00257v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.00031v2",
    "title": "Active Fairness in Algorithmic Decision Making",
    "authors": [
      "Alejandro Noriega-Campero",
      "Michiel A. Bakker",
      "Bernardo Garcia-Bulle",
      "Alex Pentland"
    ],
    "author_ids": [],
    "abstract": "Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness.",
    "published_date": "2018-09-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.00031v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.10858v2",
    "title": "Efficiently testing local optimality and escaping saddles for ReLU networks",
    "authors": [
      "Chulhee Yun",
      "Suvrit Sra",
      "Ali Jadbabaie"
    ],
    "author_ids": [],
    "abstract": "We provide a theoretical algorithm for checking local optimality and escaping\nsaddles at nondifferentiable points of empirical risks of two-layer ReLU\nnetworks. Our algorithm receives any parameter value and returns: local\nminimum, second-order stationary point, or a strict descent direction. The\npresence of $M$ data points on the nondifferentiability of the ReLU divides the\nparameter space into at most $2^M$ regions, which makes analysis difficult. By\nexploiting polyhedral geometry, we reduce the total computation down to one\nconvex quadratic program (QP) for each hidden node, $O(M)$ (in)equality tests,\nand one (or a few) nonconvex QP. For the last QP, we show that our specific\nproblem can be solved efficiently, in spite of nonconvexity. In the benign\ncase, we solve one equality constrained QP, and we prove that projected\ngradient descent solves it exponentially fast. In the bad case, we have to\nsolve a few more inequality constrained QPs, but we prove that the time\ncomplexity is exponential only in the number of inequality constraints. Our\nexperiments show that either benign case or bad case with very few inequality\nconstraints occurs, implying that our algorithm is efficient in most cases.",
    "published_date": "2018-09-28T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10858v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.10617v1",
    "title": "Enabling FAIR Research in Earth Science through Research Objects",
    "authors": [
      "Andres Garcia-Silva",
      "Jose Manuel Gomez-Perez",
      "Raul Palma",
      "Marcin Krystek",
      "Simone Mantovani",
      "Federica Foglini",
      "Valentina Grande",
      "Francesco De Leo",
      "Stefano Salvi",
      "Elisa Trasati",
      "Vito Romaniello",
      "Mirko Albani",
      "Cristiano Silvagni",
      "Rosemarie Leone",
      "Fulvio Marelli",
      "Sergio Albani",
      "Michele Lazzarini",
      "Hazel J. Napier",
      "Helen M. Glaves",
      "Timothy Aldridge",
      "Charles Meertens",
      "Fran Boler",
      "Henry W. Loescher",
      "Christine Laney",
      "Melissa A Genazzio",
      "Daniel Crawl",
      "Ilkay Altintas"
    ],
    "author_ids": [],
    "abstract": "Data-intensive science communities are progressively adopting FAIR practices\nthat enhance the visibility of scientific breakthroughs and enable reuse. At\nthe core of this movement, research objects contain and describe scientific\ninformation and resources in a way compliant with the FAIR principles and\nsustain the development of key infrastructure and tools. This paper provides an\naccount of the challenges, experiences and solutions involved in the adoption\nof FAIR around research objects over several Earth Science disciplines. During\nthis journey, our work has been comprehensive, with outcomes including: an\nextended research object model adapted to the needs of earth scientists; the\nprovisioning of digital object identifiers (DOI) to enable persistent\nidentification and to give due credit to authors; the generation of\ncontent-based, semantically rich, research object metadata through natural\nlanguage processing, enhancing visibility and reuse through recommendation\nsystems and third-party search engines; and various types of checklists that\nprovide a compact representation of research object quality as a key enabler of\nscientific reuse. All these results have been integrated in ROHub, a platform\nthat provides research object management functionality to a wealth of\napplications and interfaces across different scientific communities. To monitor\nand quantify the community uptake of research objects, we have defined\nindicators and obtained measures via ROHub that are also discussed herein.",
    "published_date": "2018-09-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10617v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.10610v2",
    "title": "Counterfactual Fairness in Text Classification through Robustness",
    "authors": [
      "Sahaj Garg",
      "Vincent Perot",
      "Nicole Limtiaco",
      "Ankur Taly",
      "Ed H. Chi",
      "Alex Beutel"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study counterfactual fairness in text classification, which\nasks the question: How would the prediction change if the sensitive attribute\nreferenced in the example were different? Toxicity classifiers demonstrate a\ncounterfactual fairness issue by predicting that \"Some people are gay\" is toxic\nwhile \"Some people are straight\" is nontoxic. We offer a metric, counterfactual\ntoken fairness (CTF), for measuring this particular form of fairness in text\nclassifiers, and describe its relationship with group fairness. Further, we\noffer three approaches, blindness, counterfactual augmentation, and\ncounterfactual logit pairing (CLP), for optimizing counterfactual token\nfairness during training, bridging the robustness and fairness literature.\nEmpirically, we find that blindness and CLP address counterfactual token\nfairness. The methods do not harm classifier performance, and have varying\ntradeoffs with group fairness. These approaches, both for measurement and\noptimization, provide a new path forward for addressing fairness concerns in\ntext classification.",
    "published_date": "2018-09-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10610v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.10421v2",
    "title": "Entropy versions of additive inequalities",
    "authors": [
      "Alberto Espuny Díaz",
      "Oriol Serra"
    ],
    "author_ids": [],
    "abstract": "The connection between inequalities in additive combinatorics and analogous\nversions in terms of the entropy of random variables has been extensively\nexplored over the past few years. This paper extends a device introduced by\nRuzsa in his seminal work introducing this correspondence. This extension\nprovides a toolbox for establishing the equivalence between sumset inequalities\nand their entropic versions. It supplies simpler proofs of known results and\nopens a path for obtaining new ones.",
    "published_date": "2018-09-27T00:00:00",
    "year": 2018,
    "categories": [
      "math.CO",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10421v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.10417v2",
    "title": "Deformable Object Tracking with Gated Fusion",
    "authors": [
      "Wenxi Liu",
      "Yibing Song",
      "Dengsheng Chen",
      "Shengfeng He",
      "Yuanlong Yu",
      "Tao Yan",
      "Gerhard P. Hancke",
      "Rynson W. H. Lau"
    ],
    "author_ids": [],
    "abstract": "The tracking-by-detection framework receives growing attentions through the\nintegration with the Convolutional Neural Networks (CNNs). Existing\ntracking-by-detection based methods, however, fail to track objects with severe\nappearance variations. This is because the traditional convolutional operation\nis performed on fixed grids, and thus may not be able to find the correct\nresponse while the object is changing pose or under varying environmental\nconditions. In this paper, we propose a deformable convolution layer to enrich\nthe target appearance representations in the tracking-by-detection framework.\nWe aim to capture the target appearance variations via deformable convolution,\nwhich adaptively enhances its original features. In addition, we also propose a\ngated fusion scheme to control how the variations captured by the deformable\nconvolution affect the original appearance. The enriched feature representation\nthrough deformable convolution facilitates the discrimination of the CNN\nclassifier on the target object and background. Extensive experiments on the\nstandard benchmarks show that the proposed tracker performs favorably against\nstate-of-the-art methods.",
    "published_date": "2018-09-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10417v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.10270v2",
    "title": "The QUIC Fix for Optimal Video Streaming",
    "authors": [
      "Mirko Palmer",
      "Thorben Krüger",
      "Balakrishnan Chandrasekaran",
      "Anja Feldmann"
    ],
    "author_ids": [],
    "abstract": "Within a few years of its introduction, QUIC has gained traction: a\nsignificant chunk of traffic is now delivered over QUIC. The networking\ncommunity is actively engaged in debating the fairness, performance, and\napplicability of QUIC for various use cases, but these debates are centered\naround a narrow, common theme: how does the new reliable transport built on top\nof UDP fare in different scenarios? Support for unreliable delivery in QUIC\nremains largely unexplored.\n  The option for delivering content unreliably, as in a best-effort model,\ndeserves the QUIC designers' and community's attention. We propose extending\nQUIC to support unreliable streams and present a simple approach for\nimplementation. We discuss a simple use case of video streaming---an\napplication that dominates the overall Internet traffic---that can leverage the\nunreliable streams and potentially bring immense benefits to network operators\nand content providers. To this end, we present a prototype implementation that,\nby using both the reliable and unreliable streams in QUIC, outperforms both TCP\nand QUIC in our evaluations.",
    "published_date": "2018-09-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10270v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.10032v3",
    "title": "Computational Courtship: Understanding the Evolution of Online Dating through Large-scale Data Analysis",
    "authors": [
      "Rachel Dinh",
      "Patrick Gildersleve",
      "Chris Blex",
      "Taha Yasseri"
    ],
    "author_ids": [],
    "abstract": "Have we become more tolerant of dating people of different social backgrounds\ncompared to ten years ago? Has the rise of online dating exacerbated or\nalleviated gender inequalities in modern courtship? Are the most attractive\npeople on these platforms necessarily the most successful? In this work, we\nexamine the mate preferences and communication patterns of male and female\nusers of the online dating site eHarmony over the past decade to identify how\nattitudes and behaviors have changed over this time period. While other studies\nhave investigated disparities in user behavior between male and female users,\nthis study is unique in its longitudinal approach. Specifically, we analyze how\nmen and women differ in their preferences for certain traits in potential\npartners and how those preferences have changed over time. The second line of\ninquiry investigates to what extent physical attractiveness determines the rate\nof messages a user receives, and how this relationship varies between men and\nwomen. Thirdly, we explore whether online dating practices between males and\nfemales have become more equal over time or if biases and inequalities have\nremained constant (or increased). Fourthly, we study the behavioural traits in\nsending and replying to messages based on one's own experience of receiving\nmessages and being replied to. Finally, we found that similarity between\nprofiles is not a predictor for success except for the number of children and\nsmoking habits. This work could have broader implications for shifting gender\nnorms and social attitudes, reflected in online courtship rituals. Apart from\nthe data-based research, we connect the results to existing theories that\nconcern the role of ICTs in societal change. As searching for love online\nbecomes increasingly common across generations and geographies, these findings\nmay shed light on how people can build relationships through the Internet.",
    "published_date": "2018-09-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10032v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1810.02685v1",
    "title": "Thinging Ethics for Software Engineers",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "author_ids": [],
    "abstract": "Ethical systems are usually described as principles for distinguishing right\nfrom wrong and forming beliefs about proper conduct. Ethical topics are\ncomplex, with excessively verbose accounts of mental models and intensely\ningrained philosophical assumptions. From practical experience, in teaching\nethics for software engineering students, an explanation of ethics alone often\ncannot provide insights of behavior and thought for students. Additionally, it\nseems that there has been no exploration into the development of a conceptual\npresentation of ethics that appeals to computer engineers. This is particularly\nclear in the area of software engineering, which focuses on software and\nassociated tools such as algorithms, diagramming, documentation, modeling and\ndesign as applied to various types of data and conceptual artifacts. It seems\nthat software engineers look at ethical materials as a collection of ideas and\nnotions that lack systemization and uniformity. Accordingly, this paper\nexplores a thinging schematization for ethical theories that can serve a role\nsimilar to that of modeling languages (e.g., UML). In this approach, thinging\nmeans actualization (existence, presence, being) of things and mechanisms that\ndefine a boundary around some region of ethically related reality, separating\nit from everything else. The resultant diagrammatic representation then\ndeveloped to model the process of making ethical decisions in that region.",
    "published_date": "2018-09-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1810.02685v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.09444v1",
    "title": "Defining the Collective Intelligence Supply Chain",
    "authors": [
      "Iain Barclay",
      "Alun Preece",
      "Ian Taylor"
    ],
    "author_ids": [],
    "abstract": "Organisations are increasingly open to scrutiny, and need to be able to prove\nthat they operate in a fair and ethical way. Accountability should extend to\nthe production and use of the data and knowledge assets used in AI systems, as\nit would for any raw material or process used in production of physical goods.\nThis paper considers collective intelligence, comprising data and knowledge\ngenerated by crowd-sourced workforces, which can be used as core components of\nAI systems. A proposal is made for the development of a supply chain model for\ntracking the creation and use of crowdsourced collective intelligence assets,\nwith a blockchain based decentralised architecture identified as an appropriate\nmeans of providing validation, accountability and fairness.",
    "published_date": "2018-09-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.09444v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.09245v1",
    "title": "Evaluating Fairness Metrics in the Presence of Dataset Bias",
    "authors": [
      "J. Henry Hinnefeld",
      "Peter Cooman",
      "Nat Mammo",
      "Rupert Deese"
    ],
    "author_ids": [],
    "abstract": "Data-driven algorithms play a large role in decision making across a variety\nof industries. Increasingly, these algorithms are being used to make decisions\nthat have significant ramifications for people's social and economic\nwell-being, e.g. in sentencing, loan approval, and policing. Amid the\nproliferation of such systems there is a growing concern about their potential\ndiscriminatory impact. In particular, machine learning systems which are\ntrained on biased data have the potential to learn and perpetuate those biases.\nA central challenge for practitioners is thus to determine whether their models\ndisplay discriminatory bias. Here we present a case study in which we frame the\nissue of bias detection as a causal inference problem with observational data.\nWe enumerate two main causes of bias, sampling bias and label bias, and we\ninvestigate the abilities of six different fairness metrics to detect each bias\ntype. Based on these investigations, we propose a set of best practice\nguidelines to select the fairness metric that is most likely to detect bias if\nit is present. Additionally, we aim to identify the conditions in which certain\nfairness metrics may fail to detect bias and instead give practitioners a false\nbelief that their biased model is making fair decisions.",
    "published_date": "2018-09-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.09245v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.08885v1",
    "title": "Robotics Rights and Ethics Rules",
    "authors": [
      "Tuncay Yigit",
      "Utku Kose",
      "Nilgun Sengoz"
    ],
    "author_ids": [],
    "abstract": "It is very important to adhere strictly to ethical and social influences when\ndelivering most of our life to artificial intelligence systems. With industry\n4.0, the internet of things, data analysis and automation have begun to be of\ngreat importance in our lives. With the Yapanese version of Industry 5.0, it\nhas come to our attention that machine-human interaction and human intelligence\nare working in harmony with the cognitive computer. In this context, robots\nworking on artificial intelligence algorithms co-ordinated with the development\nof technology have begun to enter our lives. But the consequences of the recent\ncomplaints of the Robots have been that important issues have arisen about how\nto be followed in terms of intellectual property and ethics. Although there are\nno laws regulating robots in our country at present, laws on robot ethics and\nrights abroad have entered into force. This means that it is important that we\norganize the necessary arrangements in the way that robots and artificial\nintelligence are so important in the new world order. In this study, it was\naimed to examine the existing rules of machine and robot ethics and to set an\nexample for the arrangements to be made in our country, and various discussions\nwere given in this context.",
    "published_date": "2018-09-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08885v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.08855v2",
    "title": "Measuring the effect of node aggregation on community detection",
    "authors": [
      "Yérali Gandica",
      "Adeline Decuyper",
      "Christophe Cloquet",
      "Isabelle Thomas",
      "Jean-Charles Delvenne"
    ],
    "author_ids": [],
    "abstract": "Many times the nodes of a complex network, whether deliberately or not, are\naggregated for technical, ethical, legal limitations or privacy reasons. A\ncommon example is the geographic position: one may uncover communities in a\nnetwork of places, or of individuals identified with their typical geographical\nposition, and then aggregate these places into larger entities, such as\nmunicipalities, thus obtaining another network. The communities found in the\nnetworks obtained at various levels of aggregation may exhibit various degrees\nof similarity, from full alignment to perfect independence. This is akin to the\nproblem of ecological and atomic fallacies in statistics, or to the Modified\nAreal Unit Problem in geography. We identify the class of community detection\nalgorithms most suitable to cope with node aggregation, and develop an index\nfor aggregability, capturing to which extent the aggregation preserves the\ncommunity structure. We illustrate its relevance on real-world examples (mobile\nphone and Twitter reply-to networks). Our main message is that any\nnode-partitioning analysis performed on aggregated networks should be\ninterpreted with caution, as the outcome may be strongly influenced by the\nlevel of the aggregation.",
    "published_date": "2018-09-24T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08855v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.10242v2",
    "title": "Addressing Training Bias via Automated Image Annotation",
    "authors": [
      "Zhujun Xiao",
      "Yanzi Zhu",
      "Yuxin Chen",
      "Ben Y. Zhao",
      "Junchen Jiang",
      "Haitao Zheng"
    ],
    "author_ids": [],
    "abstract": "Build accurate DNN models requires training on large labeled, context\nspecific datasets, especially those matching the target scenario. We believe\nadvances in wireless localization, working in unison with cameras, can produce\nautomated annotation of targets on images and videos captured in the wild.\nUsing pedestrian and vehicle detection as examples, we demonstrate the\nfeasibility, benefits, and challenges of an automatic image annotation system.\nOur work calls for new technical development on passive localization, mobile\ndata analytics, and error-resilient ML models, as well as design issues in user\nprivacy policies.",
    "published_date": "2018-09-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.10242v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.08453v1",
    "title": "Optimizing a Generalized Gini Index in Stable Marriage Problems: NP-Hardness, Approximation and a Polynomial Time Special Case",
    "authors": [
      "Hugo Gilbert",
      "Olivier Spanjaard"
    ],
    "author_ids": [],
    "abstract": "This paper deals with fairness in stable marriage problems. The idea studied\nhere is to achieve fairness thanks to a Generalized Gini Index (GGI), a\nwell-known criterion in inequality measurement, that includes both the\negalitarian and utilitarian criteria as special cases. We show that determining\na stable marriage optimizing a GGI criterion of agents' disutilities is an\nNP-hard problem. We then provide a polynomial time 2-approximation algorithm in\nthe general case, as well as an exact algorithm which is polynomial time in the\ncase of a constant number of non-zero weights parametrizing the GGI criterion.",
    "published_date": "2018-09-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08453v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.08343v1",
    "title": "Interpretable Multi-Objective Reinforcement Learning through Policy Orchestration",
    "authors": [
      "Ritesh Noothigattu",
      "Djallel Bouneffouf",
      "Nicholas Mattei",
      "Rachita Chandra",
      "Piyush Madan",
      "Kush Varshney",
      "Murray Campbell",
      "Moninder Singh",
      "Francesca Rossi"
    ],
    "author_ids": [],
    "abstract": "Autonomous cyber-physical agents and systems play an increasingly large role\nin our lives. To ensure that agents behave in ways aligned with the values of\nthe societies in which they operate, we must develop techniques that allow\nthese agents to not only maximize their reward in an environment, but also to\nlearn and follow the implicit constraints of society. These constraints and\nnorms can come from any number of sources including regulations, business\nprocess guidelines, laws, ethical principles, social norms, and moral values.\nWe detail a novel approach that uses inverse reinforcement learning to learn a\nset of unspecified constraints from demonstrations of the task, and\nreinforcement learning to learn to maximize the environment rewards. More\nprecisely, we assume that an agent can observe traces of behavior of members of\nthe society but has no access to the explicit set of constraints that give rise\nto the observed behavior. Inverse reinforcement learning is used to learn such\nconstraints, that are then combined with a possibly orthogonal value function\nthrough the use of a contextual bandit-based orchestrator that picks a\ncontextually-appropriate choice between the two policies (constraint-based and\nenvironment reward-based) when taking actions. The contextual bandit\norchestrator allows the agent to mix policies in novel ways, taking the best\nactions from either a reward maximizing or constrained policy. In addition, the\norchestrator is transparent on which policy is being employed at each time\nstep. We test our algorithms using a Pac-Man domain and show that the agent is\nable to learn to act optimally, act within the demonstrated constraints, and\nmix these two functions in complex ways.",
    "published_date": "2018-09-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08343v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.08328v1",
    "title": "On Quantifying and Understanding the Role of Ethics in AI Research: A Historical Account of Flagship Conferences and Journals",
    "authors": [
      "Marcelo Prates",
      "Pedro Avelar",
      "Luis C. Lamb"
    ],
    "author_ids": [],
    "abstract": "Recent developments in AI, Machine Learning and Robotics have raised concerns\nabout the ethical consequences of both academic and industrial AI research.\nLeading academics, businessmen and politicians have voiced an increasing number\nof questions about the consequences of AI not only over people, but also on the\nlarge-scale consequences on the the future of work and employment, its social\nconsequences and the sustainability of the planet. In this work, we analyse the\nuse and the occurrence of ethics-related research in leading AI, machine\nlearning and robotics venues. In order to do so we perform long term,\nhistorical corpus-based analyses on a large number of flagship conferences and\njournals. Our experiments identify the prominence of ethics-related terms in\npublished papers and presents several statistics on related topics. Finally,\nthis research provides quantitative evidence on the pressing ethical concerns\nof the AI community.",
    "published_date": "2018-09-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08328v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.08935v1",
    "title": "Lexical Bias In Essay Level Prediction",
    "authors": [
      "Georgios Balikas"
    ],
    "author_ids": [],
    "abstract": "Automatically predicting the level of non-native English speakers given their\nwritten essays is an interesting machine learning problem. In this work I\npresent the system \"balikasg\" that achieved the state-of-the-art performance in\nthe CAp 2018 data science challenge among 14 systems. I detail the feature\nextraction, feature engineering and model selection steps and I evaluate how\nthese decisions impact the system's performance. The paper concludes with\nremarks for future work.",
    "published_date": "2018-09-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.08935v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.07880v3",
    "title": "Teaching Social Behavior through Human Reinforcement for Ad hoc Teamwork -The STAR Framework",
    "authors": [
      "Shani Alkoby",
      "Avilash Rath",
      "Peter Stone"
    ],
    "author_ids": [],
    "abstract": "As AI technology continues to develop, more and more agents will become\ncapable of long term autonomy alongside people. Thus, a recent line of research\nhas studied the problem of teaching autonomous agents the concept of ethics and\nhuman social norms. Most existing work considers the case of an individual\nagent attempting to learn a predefined set of rules. In reality, however,\nsocial norms are not always pre-defined and are very difficult to represent\nalgorithmically. Moreover, the basic idea behind the social norms concept is\nensuring that one's actions do not negatively influence others' utilities,\nwhich is inherently a multiagent concept. Thus, here we investigate a way to\nteach agents, as a team, how to act according to human social norms. In this\nresearch, we introduce the STAR framework used to teach an ad hoc team of\nagents to act in accordance with human social norms. Using a hybrid team\n(agents and people), when taking an action considered to be socially\nunacceptable, the agents receive negative feedback from the human teammate(s)\nwho has(have) an awareness of the team's norms. We view STAR as an important\nstep towards teaching agents to act more consistently with respect to human\nmorality.",
    "published_date": "2018-09-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "68T"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.07880v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.07842v1",
    "title": "Bias Amplification in Artificial Intelligence Systems",
    "authors": [
      "Kirsten Lloyd"
    ],
    "author_ids": [],
    "abstract": "As Artificial Intelligence (AI) technologies proliferate, concern has\ncentered around the long-term dangers of job loss or threats of machines\ncausing harm to humans. All of this concern, however, detracts from the more\npertinent and already existing threats posed by AI today: its ability to\namplify bias found in training datasets, and swiftly impact marginalized\npopulations at scale. Government and public sector institutions have a\nresponsibility to citizens to establish a dialogue with technology developers\nand release thoughtful policy around data standards to ensure diverse\nrepresentation in datasets to prevent bias amplification and ensure that AI\nsystems are built with inclusion in mind.",
    "published_date": "2018-09-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.07842v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.07224v2",
    "title": "Non-Orthogonal Multiple Access: Common Myths and Critical Questions",
    "authors": [
      "Mojtaba Vaezi",
      "Robert Schober",
      "Zhiguo Ding",
      "H. Vincent Poor"
    ],
    "author_ids": [],
    "abstract": "Non-orthogonal multiple access (NOMA) has received tremendous attention for\nthe design of radio access techniques for fifth generation (5G) wireless\nnetworks and beyond. The basic concept behind NOMA is to serve more than one\nuser in the same resource block, e.g., a time slot, subcarrier, spreading code,\nor space. With this, NOMA promotes massive connectivity, lowers latency,\nimproves user fairness and spectral efficiency, and increases reliability\ncompared to orthogonal multiple access (OMA) techniques. While NOMA has gained\nsignificant attention from the communications community, it has also been\nsubject to several widespread misunderstandings, such as $``\\textit{NOMA is\nbased on allocating higher power to users with worse channel conditions. As\nsuch, cell-edge users receive more power in NOMA and due to this biased power\nallocation toward cell-edge users inter-cell interference is more severe in\nNOMA compared to OMA. NOMA also compromises security for spectral\nefficiency.}''$ The above statements are actually false, and this paper aims at\nidentifying such common myths about NOMA and clarifying why they are not true.\nWe also pose critical questions that are important for the effective adoption\nof NOMA in 5G and beyond and identify promising research directions for NOMA,\nwhich will require intense investigation in the future.",
    "published_date": "2018-09-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.07224v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.07027v1",
    "title": "The Key Concepts of Ethics of Artificial Intelligence - A Keyword based Systematic Mapping Study",
    "authors": [
      "Ville Vakkuri",
      "Pekka Abrahamsson"
    ],
    "author_ids": [],
    "abstract": "The growing influence and decision-making capacities of Autonomous systems\nand Artificial Intelligence in our lives force us to consider the values\nembedded in these systems. But how ethics should be implemented into these\nsystems? In this study, the solution is seen on philosophical conceptualization\nas a framework to form practical implementation model for ethics of AI. To take\nthe first steps on conceptualization main concepts used on the field needs to\nbe identified. A keyword based Systematic Mapping Study (SMS) on the keywords\nused in AI and ethics was conducted to help in identifying, defying and\ncomparing main concepts used in current AI ethics discourse. Out of 1062 papers\nretrieved SMS discovered 37 re-occurring keywords in 83 academic papers. We\nsuggest that the focus on finding keywords is the first step in guiding and\nproviding direction for future research in the AI ethics field.",
    "published_date": "2018-09-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.07027v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.09215v2",
    "title": "Learning to Address Health Inequality in the United States with a Bayesian Decision Network",
    "authors": [
      "Tavpritesh Sethi",
      "Anant Mittal",
      "Shubham Maheshwari",
      "Samarth Chugh"
    ],
    "author_ids": [],
    "abstract": "Life-expectancy is a complex outcome driven by genetic, socio-demographic,\nenvironmental and geographic factors. Increasing socio-economic and health\ndisparities in the United States are propagating the longevity-gap, making it a\ncause for concern. Earlier studies have probed individual factors but an\nintegrated picture to reveal quantifiable actions has been missing. There is a\ngrowing concern about a further widening of healthcare inequality caused by\nArtificial Intelligence (AI) due to differential access to AI-driven services.\nHence, it is imperative to explore and exploit the potential of AI for\nilluminating biases and enabling transparent policy decisions for positive\nsocial and health impact. In this work, we reveal actionable interventions for\ndecreasing the longevity-gap in the United States by analyzing a County-level\ndata resource containing healthcare, socio-economic, behavioral, education and\ndemographic features. We learn an ensemble-averaged structure, draw inferences\nusing the joint probability distribution and extend it to a Bayesian Decision\nNetwork for identifying policy actions. We draw quantitative estimates for the\nimpact of diversity, preventive-care quality and stable-families within the\nunified framework of our decision network. Finally, we make this analysis and\ndashboard available as an interactive web-application for enabling users and\npolicy-makers to validate our reported findings and to explore the impact of\nones beyond reported in this work.",
    "published_date": "2018-09-18T00:00:00",
    "year": 2018,
    "categories": [
      "stat.AP",
      "cs.LG",
      "stat.ML",
      "I.2.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.09215v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.06157v1",
    "title": "Periocular Recognition Using CNN Features Off-the-Shelf",
    "authors": [
      "Kevin Hernandez-Diaz",
      "Fernando Alonso-Fernandez",
      "Josef Bigun"
    ],
    "author_ids": [],
    "abstract": "Periocular refers to the region around the eye, including sclera, eyelids,\nlashes, brows and skin. With a surprisingly high discrimination ability, it is\nthe ocular modality requiring the least constrained acquisition. Here, we apply\nexisting pre-trained architectures, proposed in the context of the ImageNet\nLarge Scale Visual Recognition Challenge, to the task of periocular\nrecognition. These have proven to be very successful for many other computer\nvision tasks apart from the detection and classification tasks for which they\nwere designed. Experiments are done with a database of periocular images\ncaptured with a digital camera. We demonstrate that these off-the-shelf CNN\nfeatures can effectively recognize individuals based on periocular images,\ndespite being trained to classify generic objects. Compared against reference\nperiocular features, they show an EER reduction of up to ~40%, with the fusion\nof CNN and traditional features providing additional improvements.",
    "published_date": "2018-09-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.06157v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.06057v1",
    "title": "Cumulative effects of triadic closure and homophily in social networks",
    "authors": [
      "Aili Asikainen",
      "Gerardo Iñiguez",
      "Kimmo Kaski",
      "Mikko Kivelä"
    ],
    "author_ids": [],
    "abstract": "Much of the structure in social networks has been explained by two seemingly\nindependent network evolution mechanisms: triadic closure and homophily. While\nit is common to consider these mechanisms separately or in the frame of a\nstatic model, empirical studies suggest that their dynamic interplay is the\nvery process responsible for the homophilous patterns of association seen in\noff- and online social networks. By combining these two mechanisms in a minimal\nsolvable dynamic model, we confirm theoretically the long-held and empirically\nestablished hypothesis that homophily can be amplified by the triadic closure\nmechanism. This research approach allows us to estimate how much of the\nobserved homophily in various friendship and communication networks is due to\namplification for a given amount of triadic closure. We find that the\ncumulative advantage-like process leading to homophily amplification can, under\ncertain circumstances, also lead to the widely documented core-periphery\nstructure of social networks, as well as to the emergence of memory of previous\nhomophilic constraints (equivalent to hysteresis phenomena in physics). The\ntheoretical understanding provided by our results highlights the importance of\nearly intervention in managing at the societal level the most adverse effects\nof homophilic decision-making, such as inequality, segregation and online echo\nchambers.",
    "published_date": "2018-09-17T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.06057v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.05864v2",
    "title": "In Defense of the Classification Loss for Person Re-Identification",
    "authors": [
      "Yao Zhai",
      "Xun Guo",
      "Yan Lu",
      "Houqiang Li"
    ],
    "author_ids": [],
    "abstract": "The recent research for person re-identification has been focused on two\ntrends. One is learning the part-based local features to form more informative\nfeature descriptors. The other is designing effective metric learning loss\nfunctions such as the triplet loss family. We argue that learning global\nfeatures with classification loss could achieve the same goal, even with some\nsimple and cost-effective architecture design. In this paper, we first explain\nwhy the person re-id framework with standard classification loss usually has\ninferior performance compared to metric learning. Based on that, we further\npropose a person re-id framework featured by channel grouping and multi-branch\nstrategy, which divides global features into multiple channel groups and learns\nthe discriminative channel group features by multi-branch classification\nlayers. The extensive experiments show that our framework outperforms prior\nstate-of-the-arts in terms of both accuracy and inference speed.",
    "published_date": "2018-09-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.05864v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.06365v2",
    "title": "A class of non-linear fractional-order system stabilisation via fixed-order dynamic output feedback controller",
    "authors": [
      "Elyar Zavary",
      "Mahdi Sojoodi"
    ],
    "author_ids": [],
    "abstract": "This paper investigates the robust stabilisation of a class of\nfractional-order non-linear systems via fixed-order dynamic output feedback\ncontroller in terms of linear matrix inequalities (LMIs). The systematic\nstabilisation algorithm design for low-order controller based on direct\nLyapunov approach is proposed. In the presented algorithm the conditions\ncontaining the bilinear variables are decoupled into separate conditions\nwithout imposing equality constraints or considering an iterative search of the\ncontroller parameters. There is no any limiting constraint on the state space\nmatrices and also we assumed the most complete output feedback controller.\nSimulations results are given to approve the effectiveness and the\nstraightforwardness of the proposed design.",
    "published_date": "2018-09-15T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SP",
      "math.DS",
      "math.NA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.06365v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.07177v1",
    "title": "Parameter Synthesis Problems for one parametric clock Timed Automata",
    "authors": [
      "Liyun Dai",
      "Taolue Chen",
      "Zhiming Liu",
      "Bican Xia",
      "Naijun Zhan",
      "Kim G. Larsen"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study the parameter synthesis problem for a class of\nparametric timed automata. The problem asks to construct the set of valuations\nof the parameters in the parametric timed automa- ton, referred to as the\nfeasible region, under which the resulting timed automaton satisfies certain\nproperties. We show that the parameter syn- thesis problem of parametric timed\nautomata with only one parametric clock (unlimited concretely constrained\nclock) and arbitrarily many pa- rameters is solvable when all the expressions\nare linear expressions. And it is moreover the synthesis problem is solvable\nwhen the form of con- straints are parameter polynomial inequality not just\nsimple constraint and parameter domain is nonnegative real number.",
    "published_date": "2018-09-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.FL",
      "cs.LO",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.07177v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.05509v1",
    "title": "Feasibility and coordination of multiple mobile vehicles with mixed equality and inequality constraints",
    "authors": [
      "Zhiyong Sun",
      "Marcus Greiff",
      "Anders Robertsson",
      "Rolf Johansson"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of feasible coordination control for multiple\nhomogeneous or heterogeneous mobile vehicles subject to various constraints\n(nonholonomic motion constraints, holonomic coordination constraints,\nequality/inequality constraints etc). We develop a general framework involving\ndifferential-algebraic equations and viability theory to describe and determine\ncoordination feasibility for a coordinated motion control under heterogeneous\nvehicle dynamics and different types of coordination constraints. If a solution\nexists for the derived differential-algebraic equations and/or inequalities, a\nheuristic algorithm is proposed for generating feasible trajectories for each\nindividual vehicle. In case studies on coordinating two vehicles, we derive\nanalytical solutions to motion generation for two-vehicle groups consisting of\ncar-like vehicles, unicycle vehicles, or vehicles with constant speeds, which\nserve as benchmark coordination tasks for more complex vehicle groups. We show\nseveral simulation experiments on multi-vehicle coordination under various\nconstraints to validate the theory and the effectiveness of the proposed\nschemes.",
    "published_date": "2018-09-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.05509v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.04913v1",
    "title": "Query-Efficient Black-Box Attack by Active Learning",
    "authors": [
      "Pengcheng Li",
      "Jinfeng Yi",
      "Lijun Zhang"
    ],
    "author_ids": [],
    "abstract": "Deep neural network (DNN) as a popular machine learning model is found to be\nvulnerable to adversarial attack. This attack constructs adversarial examples\nby adding small perturbations to the raw input, while appearing unmodified to\nhuman eyes but will be misclassified by a well-trained classifier. In this\npaper, we focus on the black-box attack setting where attackers have almost no\naccess to the underlying models. To conduct black-box attack, a popular\napproach aims to train a substitute model based on the information queried from\nthe target DNN. The substitute model can then be attacked using existing\nwhite-box attack approaches, and the generated adversarial examples will be\nused to attack the target DNN. Despite its encouraging results, this approach\nsuffers from poor query efficiency, i.e., attackers usually needs to query a\nhuge amount of times to collect enough information for training an accurate\nsubstitute model. To this end, we first utilize state-of-the-art white-box\nattack methods to generate samples for querying, and then introduce an active\nlearning strategy to significantly reduce the number of queries needed.\nBesides, we also propose a diversity criterion to avoid the sampling bias. Our\nextensive experimental results on MNIST and CIFAR-10 show that the proposed\nmethod can reduce more than $90\\%$ of queries while preserve attacking success\nrates and obtain an accurate substitute model which is more than $85\\%$ similar\nwith the target oracle.",
    "published_date": "2018-09-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04913v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04737v1",
    "title": "Fairness-aware Classification: Criterion, Convexity, and Bounds",
    "authors": [
      "Yongkai Wu",
      "Lu Zhang",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Fairness-aware classification is receiving increasing attention in the\nmachine learning fields. Recently research proposes to formulate the\nfairness-aware classification as constrained optimization problems. However,\nseveral limitations exist in previous works due to the lack of a theoretical\nframework for guiding the formulation. In this paper, we propose a general\nframework for learning fair classifiers which addresses previous limitations.\nThe framework formulates various commonly-used fairness metrics as convex\nconstraints that can be directly incorporated into classic classification\nmodels. Within the framework, we propose a constraint-free criterion on the\ntraining data which ensures that any classifier learned from the data is fair.\nWe also derive the constraints which ensure that the real fairness metric is\nsatisfied when surrogate functions are used to achieve convexity. Our framework\ncan be used to for formulating fairness-aware classification with fairness\nguarantee and computational efficiency. The experiments using real-world\ndatasets demonstrate our theoretical results and show the effectiveness of\nproposed framework and methods.",
    "published_date": "2018-09-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04737v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.09030v1",
    "title": "A Fairness-aware Hybrid Recommender System",
    "authors": [
      "Golnoosh Farnadi",
      "Pigi Kouki",
      "Spencer K. Thompson",
      "Sriram Srinivasan",
      "Lise Getoor"
    ],
    "author_ids": [],
    "abstract": "Recommender systems are used in variety of domains affecting people's lives.\nThis has raised concerns about possible biases and discrimination that such\nsystems might exacerbate. There are two primary kinds of biases inherent in\nrecommender systems: observation bias and bias stemming from imbalanced data.\nObservation bias exists due to a feedback loop which causes the model to learn\nto only predict recommendations similar to previous ones. Imbalance in data\noccurs when systematic societal, historical, or other ambient bias is present\nin the data. In this paper, we address both biases by proposing a hybrid\nfairness-aware recommender system. Our model provides efficient and accurate\nrecommendations by incorporating multiple user-user and item-item similarity\nmeasures, content, and demographic information, while addressing recommendation\nbiases. We implement our model using a powerful and expressive probabilistic\nprogramming language called probabilistic soft logic. We experimentally\nevaluate our approach on a popular movie recommendation dataset, showing that\nour proposed model can provide more accurate and fairer recommendations,\ncompared to a state-of-the art fair recommender system.",
    "published_date": "2018-09-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.09030v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04684v1",
    "title": "Fair lending needs explainable models for responsible recommendation",
    "authors": [
      "Jiahao Chen"
    ],
    "author_ids": [],
    "abstract": "The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.AP",
      "stat.ML",
      "91G40, 68T01",
      "J.1; I.5.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04684v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04663v3",
    "title": "Creating Fair Models of Atherosclerotic Cardiovascular Disease Risk",
    "authors": [
      "Stephen Pfohl",
      "Ben Marafino",
      "Adrien Coulet",
      "Fatima Rodriguez",
      "Latha Palaniappan",
      "Nigam H. Shah"
    ],
    "author_ids": [],
    "abstract": "Guidelines for the management of atherosclerotic cardiovascular disease\n(ASCVD) recommend the use of risk stratification models to identify patients\nmost likely to benefit from cholesterol-lowering and other therapies. These\nmodels have differential performance across race and gender groups with\ninconsistent behavior across studies, potentially resulting in an inequitable\ndistribution of beneficial therapy. In this work, we leverage adversarial\nlearning and a large observational cohort extracted from electronic health\nrecords (EHRs) to develop a \"fair\" ASCVD risk prediction model with reduced\nvariability in error rates across groups. We empirically demonstrate that our\napproach is capable of aligning the distribution of risk predictions\nconditioned on the outcome across several groups simultaneously for models\nbuilt from high-dimensional EHR data. We also discuss the relevance of these\nresults in the context of the empirical trade-off between fairness and model\nperformance.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04663v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04578v2",
    "title": "Simplicity Creates Inequity: Implications for Fairness, Stereotypes, and Interpretability",
    "authors": [
      "Jon Kleinberg",
      "Sendhil Mullainathan"
    ],
    "author_ids": [],
    "abstract": "Algorithms are increasingly used to aid, or in some cases supplant, human\ndecision-making, particularly for decisions that hinge on predictions. As a\nresult, two additional features in addition to prediction quality have\ngenerated interest: (i) to facilitate human interaction and understanding with\nthese algorithms, we desire prediction functions that are in some fashion\nsimple or interpretable; and (ii) because they influence consequential\ndecisions, we also want them to produce equitable allocations. We develop a\nformal model to explore the relationship between the demands of simplicity and\nequity. Although the two concepts appear to be motivated by qualitatively\ndistinct goals, we show a fundamental inconsistency between them. Specifically,\nwe formalize a general framework for producing simple prediction functions, and\nin this framework we establish two basic results. First, every simple\nprediction function is strictly improvable: there exists a more complex\nprediction function that is both strictly more efficient and also strictly more\nequitable. Put another way, using a simple prediction function both reduces\nutility for disadvantaged groups and reduces overall welfare relative to other\noptions. Second, we show that simple prediction functions necessarily create\nincentives to use information about individuals' membership in a disadvantaged\ngroup --- incentives that weren't present before simplification, and that work\nagainst these individuals. Thus, simplicity transforms disadvantage into bias\nagainst the disadvantaged group. Our results are not only about algorithms but\nabout any process that produces simple models, and as such they connect to the\npsychology of stereotypes and to an earlier economics literature on statistical\ndiscrimination.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.DS",
      "cs.SI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04578v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04542v1",
    "title": "The Inductive Bias of Restricted f-GANs",
    "authors": [
      "Shuang Liu",
      "Kamalika Chaudhuri"
    ],
    "author_ids": [],
    "abstract": "Generative adversarial networks are a novel method for statistical inference\nthat have achieved much empirical success; however, the factors contributing to\nthis success remain ill-understood. In this work, we attempt to analyze\ngenerative adversarial learning -- that is, statistical inference as the result\nof a game between a generator and a discriminator -- with the view of\nunderstanding how it differs from classical statistical inference solutions\nsuch as maximum likelihood inference and the method of moments.\n  Specifically, we provide a theoretical characterization of the distribution\ninferred by a simple form of generative adversarial learning called restricted\nf-GANs -- where the discriminator is a function in a given function class, the\ndistribution induced by the generator is restricted to lie in a pre-specified\ndistribution class and the objective is similar to a variational form of the\nf-divergence. A consequence of our result is that for linear KL-GANs -- that\nis, when the discriminator is a linear function over some feature space and f\ncorresponds to the KL-divergence -- the distribution induced by the optimal\ngenerator is neither the maximum likelihood nor the method of moments solution,\nbut an interesting combination of both.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04542v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04262v1",
    "title": "Extracting Fairness Policies from Legal Documents",
    "authors": [
      "Rashmi Nagpal",
      "Chetna Wadhwa",
      "Mallika Gupta",
      "Samiulla Shaikh",
      "Sameep Mehta",
      "Vikram Goyal"
    ],
    "author_ids": [],
    "abstract": "Machine Learning community is recently exploring the implications of bias and\nfairness with respect to the AI applications. The definition of fairness for\nsuch applications varies based on their domain of application. The policies\ngoverning the use of such machine learning system in a given context are\ndefined by the constitutional laws of nations and regulatory policies enforced\nby the organizations that are involved in the usage. Fairness related laws and\npolicies are often spread across the large documents like constitution,\nagreements, and organizational regulations. These legal documents have long\ncomplex sentences in order to achieve rigorousness and robustness. Automatic\nextraction of fairness policies, or in general, any specific kind of policies\nfrom large legal corpus can be very useful for the study of bias and fairness\nin the context of AI applications.\n  We attempted to automatically extract fairness policies from publicly\navailable law documents using two approaches based on semantic relatedness. The\nexperiments reveal how classical Wordnet-based similarity and vector-based\nsimilarity differ in addressing this task. We have shown that similarity based\non word vectors beats the classical approach with a large margin, whereas other\nvector representations of senses and sentences fail to even match the classical\nbaseline. Further, we have presented thorough error analysis and reasoning to\nexplain the results with appropriate examples from the dataset for deeper\ninsights.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.IR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04262v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.04224v1",
    "title": "Access to Population-Level Signaling as a Source of Inequality",
    "authors": [
      "Nicole Immorlica",
      "Katrina Ligett",
      "Juba Ziani"
    ],
    "author_ids": [],
    "abstract": "We identify and explore differential access to population-level signaling\n(also known as information design) as a source of unequal access to\nopportunity. A population-level signaler has potentially noisy observations of\na binary type for each member of a population and, based on this, produces a\nsignal about each member. A decision-maker infers types from signals and\naccepts those individuals whose type is high in expectation. We assume the\nsignaler of the disadvantaged population reveals her observations to the\ndecision-maker, whereas the signaler of the advantaged population forms signals\nstrategically. We study the expected utility of the populations as measured by\nthe fraction of accepted members, as well as the false positive rates (FPR) and\nfalse negative rates (FNR).\n  We first show the intuitive results that for a fixed environment, the\nadvantaged population has higher expected utility, higher FPR, and lower FNR,\nthan the disadvantaged one (despite having identical population quality), and\nthat more accurate observations improve the expected utility of the advantaged\npopulation while harming that of the disadvantaged one. We next explore the\nintroduction of a publicly-observable signal, such as a test score, as a\npotential intervention. Our main finding is that this natural intervention,\nintended to reduce the inequality between the populations' utilities, may\nactually exacerbate it in settings where observations and test scores are\nnoisy.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04224v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.04199v1",
    "title": "Synthetic Attribute Data for Evaluating Consumer-side Fairness",
    "authors": [
      "Robin Burke",
      "Jackson Kontny",
      "Nasim Sonboli"
    ],
    "author_ids": [],
    "abstract": "When evaluating recommender systems for their fairness, it may be necessary\nto make use of demographic attributes, which are personally sensitive and\nusually excluded from publicly-available data sets. In addition, these\nattributes are fixed and therefore it is not possible to experiment with\ndifferent distributions using the same data. In this paper, we describe the\nFrequency-Linked Attribute Generation (FLAG) algorithm, and show its\napplicability for assigning synthetic demographic attributes to recommendation\ndata sets.",
    "published_date": "2018-09-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04199v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.04198v1",
    "title": "Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals",
    "authors": [
      "Andrew Cotter",
      "Heinrich Jiang",
      "Serena Wang",
      "Taman Narayan",
      "Maya Gupta",
      "Seungil You",
      "Karthik Sridharan"
    ],
    "author_ids": [],
    "abstract": "We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn.",
    "published_date": "2018-09-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.04198v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.05530v2",
    "title": "Fairness in Online Social Network Timelines: Measurements, Models and Mechanism Design",
    "authors": [
      "Eduardo Hargreaves",
      "Claudio Agosti",
      "Daniel Menasché",
      "Giovanni Neglia",
      "Alexandre Reiffers-Masson",
      "Eitan Altman"
    ],
    "author_ids": [],
    "abstract": "Facebook News Feed personalization algorithm has a significant impact, on a\ndaily basis, on the lifestyle, mood and opinion of millions of Internet users.\nNonetheless, the behavior of such algorithm lacks transparency, motivating\nmeasurements, modeling and analysis in order to understand and improve its\nproperties. In this paper, we propose a reproducible methodology encompassing\nmeasurements, an analytical model and a fairness-based News Feed design. The\nmodel leverages the versatility and analytical tractability of time-to-live\n(TTL) counters to capture the visibility and occupancy of publishers over a\nNews Feed. Measurements are used to parameterize and to validate the expressive\npower of the proposed model. Then, we conduct a what-if analysis to assess the\nvisibility and occupancy bias incurred by users against a baseline derived from\nthe model. Our results indicate that a significant bias exists and it is more\nprominent at the top position of the News Feed. In addition, we find that the\nbias is non-negligible even for users that are deliberately set as neutral with\nrespect to their political views, motivating the proposal of a novel and more\ntransparent fairness-based News Feed design.",
    "published_date": "2018-09-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.05530v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03901v1",
    "title": "Mitigating Confirmation Bias on Twitter by Recommending Opposing Views",
    "authors": [
      "Elisabeth Lex",
      "Mario Wagner",
      "Dominik Kowald"
    ],
    "author_ids": [],
    "abstract": "In this work, we propose a content-based recommendation approach to increase\nexposure to opposing beliefs and opinions. Our aim is to help provide users\nwith more diverse viewpoints on issues, which are discussed in partisan groups\nfrom different perspectives. Since due to the backfire effect, people's\noriginal beliefs tend to strengthen when challenged with counter evidence, we\nneed to expose them to opposing viewpoints at the right time. The preliminary\nwork presented here describes our first step into this direction. As\nillustrative showcase, we take the political debate on Twitter around the\npresidency of Donald Trump.",
    "published_date": "2018-09-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03901v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03733v3",
    "title": "Consensus of a class of nonlinear fractional-order multi-agent systems via dynamic output feedback controller",
    "authors": [
      "Elyar Zavary",
      "Pouya Badri",
      "Mahdi Sojoodi"
    ],
    "author_ids": [],
    "abstract": "This paper addresses the consensus of a class of uncertain nonlinear\nfractional-order multi-agent systems (FOMAS). First a fractional non-fragile\ndynamic output feedback controller is put forward via the output measurements\nof neighboring agents, then appropriate state transformation reduced the\nconsensus problem to a stability one. A sufficient condition based on direct\nLyapunov approach, for the robust asymptotic stability of the transformed\nsystem and subsequently for the consensus of the main system is presented.\nAdditionally, utilizing S-procedure and Schur complement, the systematic\nstabilization design algorithm is proposed for fractional-order system with and\nwithout nonlinear term. The results are formulated as an optimization problem\nwith linear matrix inequality constraints. Simulation results are given to\nverify the effectiveness of the theoretical results.",
    "published_date": "2018-09-11T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.NA",
      "eess.SP",
      "math.NA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03733v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03676v1",
    "title": "Unbiasing Semantic Segmentation For Robot Perception using Synthetic Data Feature Transfer",
    "authors": [
      "Jonathan C Balloch",
      "Varun Agrawal",
      "Irfan Essa",
      "Sonia Chernova"
    ],
    "author_ids": [],
    "abstract": "Robot perception systems need to perform reliable image segmentation in\nreal-time on noisy, raw perception data. State-of-the-art segmentation\napproaches use large CNN models and carefully constructed datasets; however,\nthese models focus on accuracy at the cost of real-time inference. Furthermore,\nthe standard semantic segmentation datasets are not large enough for training\nCNNs without augmentation and are not representative of noisy, uncurated robot\nperception data. We propose improving the performance of real-time segmentation\nframeworks on robot perception data by transferring features learned from\nsynthetic segmentation data. We show that pretraining real-time segmentation\narchitectures with synthetic segmentation data instead of ImageNet improves\nfine-tuning performance by reducing the bias learned in pretraining and closing\nthe \\textit{transfer gap} as a result. Our experiments show that our real-time\nrobot perception models pretrained on synthetic data outperform those\npretrained on ImageNet for every scale of fine-tuning data examined. Moreover,\nthe degree to which synthetic pretraining outperforms ImageNet pretraining\nincreases as the availability of robot data decreases, making our approach\nattractive for robotics domains where dataset collection is hard and/or\nexpensive.",
    "published_date": "2018-09-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03676v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.03577v1",
    "title": "Using Image Fairness Representations in Diversity-Based Re-ranking for Recommendations",
    "authors": [
      "Chen Karako",
      "Putra Manggala"
    ],
    "author_ids": [],
    "abstract": "The trade-off between relevance and fairness in personalized recommendations\nhas been explored in recent works, with the goal of minimizing learned\ndiscrimination towards certain demographics while still producing relevant\nresults.\n  We present a fairness-aware variation of the Maximal Marginal Relevance (MMR)\nre-ranking method which uses representations of demographic groups computed\nusing a labeled dataset. This method is intended to incorporate fairness with\nrespect to these demographic groups.\n  We perform an experiment on a stock photo dataset and examine the trade-off\nbetween relevance and fairness against a well known baseline, MMR, by using\nhuman judgment to examine the results of the re-ranking when using different\nfractions of a labeled dataset, and by performing a quantitative analysis on\nthe ranked results of a set of query images. We show that our proposed method\ncan incorporate fairness in the ranked results while obtaining higher precision\nthan the baseline, while our case study shows that even a limited amount of\nlabeled data can be used to compute the representations to obtain fairness.\nThis method can be used as a post-processing step for recommender systems and\nsearch.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03577v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03539v1",
    "title": "Annotating shadows, highlights and faces: the contribution of a 'human in the loop' for digital art history",
    "authors": [
      "Maarten W. A. Wijntjes"
    ],
    "author_ids": [],
    "abstract": "While automatic computational techniques appear to reveal novel insights in\ndigital art history, a complementary approach seems to get less attention: that\nof human annotation. We argue and exemplify that a 'human in the loop' can\nreveal insights that may be difficult to detect automatically. Specifically, we\nfocussed on perceptual aspects within pictorial art. Using rather simple\nannotation tasks (e.g. delineate human lengths, indicate highlights and\nclassify gaze direction) we could both replicate earlier findings and reveal\nnovel insights into pictorial conventions. We found that Canaletto depicted\nhuman figures in rather accurate perspective, varied viewpoint elevation\nbetween approximately 3 and 9 meters and highly preferred light directions\nparallel to the projection plane. Furthermore, we found that taking the\naveraged images of leftward looking faces reveals a woman, and for rightward\nlooking faces showed a male, confirming earlier accounts on lateral gender bias\nin pictorial art. Lastly, we confirmed and refined the well-known\nlight-from-the-left bias. Together, the annotations, analyses and results\nexemplify how human annotation can contribute and complement to technical and\ndigital art history.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03539v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.03400v2",
    "title": "A Moral Framework for Understanding of Fair ML through Economic Models of Equality of Opportunity",
    "authors": [
      "Hoda Heidari",
      "Michele Loi",
      "Krishna P. Gummadi",
      "Andreas Krause"
    ],
    "author_ids": [],
    "abstract": "We map the recently proposed notions of algorithmic fairness to economic\nmodels of Equality of opportunity (EOP)---an extensively studied ideal of\nfairness in political philosophy. We formally show that through our conceptual\nmapping, many existing definition of algorithmic fairness, such as predictive\nvalue parity and equality of odds, can be interpreted as special cases of EOP.\nIn this respect, our work serves as a unifying moral framework for\nunderstanding existing notions of algorithmic fairness. Most importantly, this\nframework allows us to explicitly spell out the moral assumptions underlying\neach notion of fairness, and interpret recent fairness impossibility results in\na new light. Last but not least and inspired by luck egalitarian models of EOP,\nwe propose a new family of measures for algorithmic fairness. We illustrate our\nproposal empirically and show that employing a measure of algorithmic\n(un)fairness when its underlying moral assumptions are not satisfied, can have\ndevastating consequences for the disadvantaged group's welfare.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "econ.TH",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03400v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.03332v1",
    "title": "Assessing and Addressing Algorithmic Bias - But Before We Get There",
    "authors": [
      "Jean Garcia-Gathright",
      "Aaron Springer",
      "Henriette Cramer"
    ],
    "author_ids": [],
    "abstract": "Algorithmic and data bias are gaining attention as a pressing issue in\npopular press - and rightly so. However, beyond these calls to action, standard\nprocesses and tools for practitioners do not readily exist to assess and\naddress unfair algorithmic and data biases. The literature is relatively\nscattered and the needed interdisciplinary approach means that very different\ncommunities are working on the topic. We here provide a number of challenges\nencountered in assessing and addressing algorithmic and data bias in practice.\nWe describe an early approach that attempts to translate the literature into\nprocesses for (production) teams wanting to assess both intended data and\nalgorithm characteristics and unintended, unfair biases.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03332v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03260v1",
    "title": "Automated Test Generation to Detect Individual Discrimination in AI Models",
    "authors": [
      "Aniya Agarwal",
      "Pranay Lohia",
      "Seema Nagar",
      "Kuntal Dey",
      "Diptikalyan Saha"
    ],
    "author_ids": [],
    "abstract": "Dependability on AI models is of utmost importance to ensure full acceptance\nof the AI systems. One of the key aspects of the dependable AI system is to\nensure that all its decisions are fair and not biased towards any individual.\nIn this paper, we address the problem of detecting whether a model has an\nindividual discrimination. Such a discrimination exists when two individuals\nwho differ only in the values of their protected attributes (such as,\ngender/race) while the values of their non-protected ones are exactly the same,\nget different decisions. Measuring individual discrimination requires an\nexhaustive testing, which is infeasible for a non-trivial system. In this\npaper, we present an automated technique to generate test inputs, which is\ngeared towards finding individual discrimination. Our technique combines the\nwell-known technique called symbolic execution along with the local\nexplainability for generation of effective test cases. Our experimental results\nclearly demonstrate that our technique produces 3.72 times more successful test\ncases than the existing state-of-the-art across all our chosen benchmarks.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03260v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.03203v1",
    "title": "Studying Confirmation Bias in Hashtag Usage on Twitter",
    "authors": [
      "Dominik Kowald",
      "Elisabeth Lex"
    ],
    "author_ids": [],
    "abstract": "The micro-blogging platform Twitter allows its nearly 320 million monthly\nactive users to build a network of follower connections to other Twitter users\n(i.e., followees) in order to subscribe to content posted by these users. With\nthis feature, Twitter has become one of the most popular social networks on the\nWeb and was also the first platform that offered the concept of hashtags.\nHashtags are freely-chosen keywords, which start with the hash character, to\nannotate, categorize and contextualize Twitter posts (i.e., tweets).\n  Although hashtags are widely accepted and used by the Twitter community, the\nheavy reuse of hashtags that are popular in the personal Twitter networks\n(i.e., own hashtags and hashtags used by followees) can lead to filter bubble\neffects and thus, to situations, in which only content associated with these\nhashtags are presented to the user. These filter bubble effects are also highly\nassociated with the concept of confirmation bias, which is the tendency to\nfavor and reuse information that confirms personal preferences. One example\nwould be a Twitter user who is interested in political tweets of US president\nDonald Trump. Depending on the hashtags used, the user could either be stuck in\na pro-Trump (e.g., #MAGA) or contra-Trump (e.g., #fakepresident) filter bubble.\nTherefore, the goal of this paper is to study confirmation bias and filter\nbubble effects in hashtag usage on Twitter by treating the reuse of hashtags as\na phenomenon that fosters confirmation bias.",
    "published_date": "2018-09-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03203v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.03040v2",
    "title": "Fairness-Aware Recommendation of Information Curators",
    "authors": [
      "Ziwei Zhu",
      "Jianling Wang",
      "Yin Zhang",
      "James Caverlee"
    ],
    "author_ids": [],
    "abstract": "This paper highlights our ongoing efforts to create effective information\ncurator recommendation models that can be personalized for individual users,\nwhile maintaining important fairness properties. Concretely, we introduce the\nproblem of information curator recommendation, provide a high-level overview of\na fairness-aware recommender, and introduce some preliminary experimental\nevidence over a real-world Twitter dataset. We conclude with some thoughts on\nfuture directions.",
    "published_date": "2018-09-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03040v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.02925v2",
    "title": "Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning",
    "authors": [
      "Ilya Kostrikov",
      "Kumar Krishna Agrawal",
      "Debidatta Dwibedi",
      "Sergey Levine",
      "Jonathan Tompson"
    ],
    "author_ids": [],
    "abstract": "We identify two issues with the family of algorithms based on the Adversarial\nImitation Learning framework. The first problem is implicit bias present in the\nreward functions used in these algorithms. While these biases might work well\nfor some environments, they can also lead to sub-optimal behavior in others.\nSecondly, even though these algorithms can learn from few expert\ndemonstrations, they require a prohibitively large number of interactions with\nthe environment in order to imitate the expert for many real-world\napplications. In order to address these issues, we propose a new algorithm\ncalled Discriminator-Actor-Critic that uses off-policy Reinforcement Learning\nto reduce policy-environment interaction sample complexity by an average factor\nof 10. Furthermore, since our reward function is designed to be unbiased, we\ncan apply our algorithm to many problems without making any task-specific\nadjustments.",
    "published_date": "2018-09-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02925v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.02921v2",
    "title": "Personalizing Fairness-aware Re-ranking",
    "authors": [
      "Weiwen Liu",
      "Robin Burke"
    ],
    "author_ids": [],
    "abstract": "Personalized recommendation brings about novel challenges in ensuring\nfairness, especially in scenarios in which users are not the only stakeholders\ninvolved in the recommender system. For example, the system may want to ensure\nthat items from different providers have a fair chance of being recommended. To\nsolve this problem, we propose a Fairness-Aware Re-ranking algorithm (FAR) to\nbalance the ranking quality and provider-side fairness. We iteratively generate\nthe ranking list by trading off between accuracy and the coverage of the\nproviders. Although fair treatment of providers is desirable, users may differ\nin their receptivity to the addition of this type of diversity. Therefore,\npersonalized user tolerance towards provider diversification is incorporated.\nExperiments are conducted on both synthetic and real-world data. The results\nshow that our proposed re-ranking algorithm can significantly promote fairness\nwith a slight sacrifice in accuracy and can do so while being attentive to\nindividual user differences.",
    "published_date": "2018-09-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02921v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.02519v3",
    "title": "Fairness Through Causal Awareness: Learning Latent-Variable Models for Biased Data",
    "authors": [
      "David Madras",
      "Elliot Creager",
      "Toniann Pitassi",
      "Richard Zemel"
    ],
    "author_ids": [],
    "abstract": "How do we learn from biased data? Historical datasets often reflect\nhistorical prejudices; sensitive or protected attributes may affect the\nobserved treatments and outcomes. Classification algorithms tasked with\npredicting outcomes accurately from these datasets tend to replicate these\nbiases. We advocate a causal modeling approach to learning from biased data,\nexploring the relationship between fair classification and intervention. We\npropose a causal model in which the sensitive attribute confounds both the\ntreatment and the outcome. Building on prior work in deep learning and\ngenerative modeling, we describe how to learn the parameters of this causal\nmodel from observational data alone, even in the presence of unobserved\nconfounders. We show experimentally that fairness-aware causal modeling\nprovides better estimates of the causal effects between the sensitive\nattribute, the treatment, and the outcome. We further present evidence that\nestimating these causal effects can help learn policies that are both more\naccurate and fair, when presented with a historically biased dataset.",
    "published_date": "2018-09-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02519v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.02244v3",
    "title": "Learning Optimal Fair Policies",
    "authors": [
      "Razieh Nabi",
      "Daniel Malinsky",
      "Ilya Shpitser"
    ],
    "author_ids": [],
    "abstract": "Systematic discriminatory biases present in our society influence the way\ndata is collected and stored, the way variables are defined, and the way\nscientific findings are put into practice as policy. Automated decision\nprocedures and learning algorithms applied to such data may serve to perpetuate\nexisting injustice or unfairness in our society. In this paper, we consider how\nto make optimal but fair decisions, which \"break the cycle of injustice\" by\ncorrecting for the unfair dependence of both decisions and outcomes on\nsensitive features (e.g., variables that correspond to gender, race,\ndisability, or other protected attributes). We use methods from causal\ninference and constrained optimization to learn optimal policies in a way that\naddresses multiple potential biases which afflict data analysis in sensitive\ncontexts, extending the approach of (Nabi and Shpitser 2018). Our proposal\ncomes equipped with the theoretical guarantee that the chosen fair policy will\ninduce a joint distribution for new instances that satisfies given fairness\nconstraints. We illustrate our approach with both synthetic data and real\ncriminal justice data.",
    "published_date": "2018-09-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02244v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.02208v4",
    "title": "Assessing Gender Bias in Machine Translation -- A Case Study with Google Translate",
    "authors": [
      "Marcelo O. R. Prates",
      "Pedro H. C. Avelar",
      "Luis Lamb"
    ],
    "author_ids": [],
    "abstract": "Recently there has been a growing concern about machine bias, where trained\nstatistical models grow to reflect controversial societal asymmetries, such as\ngender or racial bias. A significant number of AI tools have recently been\nsuggested to be harmfully biased towards some minority, with reports of racist\ncriminal behavior predictors, Iphone X failing to differentiate between two\nAsian people and Google photos' mistakenly classifying black people as\ngorillas. Although a systematic study of such biases can be difficult, we\nbelieve that automated translation tools can be exploited through gender\nneutral languages to yield a window into the phenomenon of gender bias in AI.\n  In this paper, we start with a comprehensive list of job positions from the\nU.S. Bureau of Labor Statistics (BLS) and used it to build sentences in\nconstructions like \"He/She is an Engineer\" in 12 different gender neutral\nlanguages such as Hungarian, Chinese, Yoruba, and several others. We translate\nthese sentences into English using the Google Translate API, and collect\nstatistics about the frequency of female, male and gender-neutral pronouns in\nthe translated output. We show that GT exhibits a strong tendency towards male\ndefaults, in particular for fields linked to unbalanced gender distribution\nsuch as STEM jobs. We ran these statistics against BLS' data for the frequency\nof female participation in each job position, showing that GT fails to\nreproduce a real-world distribution of female workers. We provide experimental\nevidence that even if one does not expect in principle a 50:50 pronominal\ngender distribution, GT yields male defaults much more frequently than what\nwould be expected from demographic data alone.\n  We are hopeful that this work will ignite a debate about the need to augment\ncurrent statistical translation tools with debiasing techniques which can\nalready be found in the scientific literature.",
    "published_date": "2018-09-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02208v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.02070v2",
    "title": "ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience Replay",
    "authors": [
      "Sameera Lanka",
      "Tianfu Wu"
    ],
    "author_ids": [],
    "abstract": "Experience replay is an important technique for addressing\nsample-inefficiency in deep reinforcement learning (RL), but faces difficulty\nin learning from binary and sparse rewards due to disproportionately few\nsuccessful experiences in the replay buffer. Hindsight experience replay (HER)\nwas recently proposed to tackle this difficulty by manipulating unsuccessful\ntransitions, but in doing so, HER introduces a significant bias in the replay\nbuffer experiences and therefore achieves a suboptimal improvement in\nsample-efficiency. In this paper, we present an analysis on the source of bias\nin HER, and propose a simple and effective method to counter the bias, to most\neffectively harness the sample-efficiency provided by HER. Our method,\nmotivated by counter-factual reasoning and called ARCHER, extends HER with a\ntrade-off to make rewards calculated for hindsight experiences numerically\ngreater than real rewards. We validate our algorithm on two continuous control\nenvironments from DeepMind Control Suite - Reacher and Finger, which simulate\nmanipulation tasks with a robotic arm - in combination with various reward\nfunctions, task complexities and goal sampling strategies. Our experiments\nconsistently demonstrate that countering bias using more aggressive hindsight\nrewards increases sample efficiency, thus establishing the greater benefit of\nARCHER in RL applications with limited computing budget.",
    "published_date": "2018-09-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.02070v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.01952v1",
    "title": "Sparsity Analysis of a Sonomyographic Muscle-Computer Interface",
    "authors": [
      "Nima Akhlaghi",
      "Ananya Dhawan",
      "Amir A. Khan",
      "Biswarup Mukherjee",
      "Cecile Truong",
      "Siddhartha Sikdar"
    ],
    "author_ids": [],
    "abstract": "Objective: The objectives of this paper are to determine the optimal location\nfor ultrasound transducer placement on the anterior forearm for imaging maximum\nmuscle deformations during different hand motions and to investigate the effect\nof using a sparse set of ultrasound scanlines for motion classification for\nultrasound-based muscle computer interfaces (MCIs). Methods: The optimal\nplacement of the ultrasound transducer along the forearm is identified using\nfreehand 3D reconstructions of the muscle thickness during rest and motion\ncompletion. From the ultrasound images acquired from the optimally placed\ntransducer, we determine classification accuracy with equally spaced scanlines\nacross the cross-sectional field-of-view (FOV). Furthermore, we investigated\nthe unique contribution of each scanline to class discrimination using Fisher\ncriteria (FC) and mutual information (MI) with respect to motion\ndiscriminability. Results: Experiments with 5 able-bodied subjects show that\nthe maximum muscle deformation occurred between 30-50% of the forearm length\nfor multiple degrees-of-freedom. The average classification accuracy was 94.6%\nwith the entire 128 scanline image and 94.5% with 4 equally-spaced scanlines.\nHowever, no significant improvement in classification accuracy was observed\nwith optimal scanline selection using FC and MI. Conclusion: For an optimally\nplaced transducer, a small subset of ultrasound scanlines can be used instead\nof a full imaging array without sacrificing performance in terms of\nclassification accuracy for multiple degrees-of-freedom. Significance: The\nselection of a small subset of transducer elements can enable the reduction of\ncomputation, and simplification of the instrumentation and power consumption of\nwearable sonomyographic MCIs particularly for rehabilitation and gesture\nrecognition applications.",
    "published_date": "2018-09-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01952v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.01808v3",
    "title": "Security Metrics of Networked Control Systems under Sensor Attacks (extended preprint)",
    "authors": [
      "Carlos Murguia",
      "Iman Shames",
      "Justin Ruths",
      "Dragan Nesic"
    ],
    "author_ids": [],
    "abstract": "As more attention is paid to security in the context of control systems and\nas attacks occur to real control systems throughout the world, it has become\nclear that some of the most nefarious attacks are those that evade detection.\nThe term stealthy has come to encompass a variety of techniques that attackers\ncan employ to avoid being detected. In this manuscript, for a class of\nperturbed linear time-invariant systems, we propose two security metrics to\nquantify the potential impact that stealthy attacks could have on the system\ndynamics by tampering with sensor measurements. We provide analysis\nmathematical tools (in terms of linear matrix inequalities) to quantify these\nmetrics for given system dynamics, control structure, system monitor, and set\nof sensors being attacked. Then, we provide synthesis tools (in terms of\nsemidefinite programs) to redesign controllers and monitors such that the\nimpact of stealthy attacks is minimized and the required attack-free system\nperformance is guaranteed.",
    "published_date": "2018-09-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01808v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.01563v2",
    "title": "Debiasing Desire: Addressing Bias & Discrimination on Intimate Platforms",
    "authors": [
      "Jevan Hutson",
      "Jessie G. Taft",
      "Solon Barocas",
      "Karen Levy"
    ],
    "author_ids": [],
    "abstract": "Designing technical systems to be resistant to bias and discrimination\nrepresents vital new terrain for researchers, policymakers, and the\nanti-discrimination project more broadly. We consider bias and discrimination\nin the context of popular online dating and hookup platforms in the United\nStates, which we call intimate platforms. Drawing on work in\nsocial-justice-oriented and Queer HCI, we review design features of popular\nintimate platforms and their potential role in exacerbating or mitigating\ninterpersonal bias. We argue that focusing on platform design can reveal\nopportunities to reshape troubling patterns of intimate contact without\noverriding users' decisional autonomy. We identify and address the difficult\nethical questions that nevertheless come along with such intervention, while\nurging the social computing community to engage more deeply with issues of\nbias, discrimination, and exclusion in the study and design of intimate\nplatforms.",
    "published_date": "2018-09-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01563v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.01436v1",
    "title": "Modified Diversity of Class Probability Estimation Co-training for Hyperspectral Image Classification",
    "authors": [
      "Yan Ju",
      "Lingling Li",
      "Licheng Jiao",
      "Zhongle Ren",
      "Biao Hou",
      "Shuyuan Yang"
    ],
    "author_ids": [],
    "abstract": "Due to the limited amount and imbalanced classes of labeled training data,\nthe conventional supervised learning can not ensure the discrimination of the\nlearned feature for hyperspectral image (HSI) classification. In this paper, we\npropose a modified diversity of class probability estimation (MDCPE) with two\ndeep neural networks to learn spectral-spatial feature for HSI classification.\nIn co-training phase, recurrent neural network (RNN) and convolutional neural\nnetwork (CNN) are utilized as two learners to extract features from labeled and\nunlabeled data. Based on the extracted features, MDCPE selects most credible\nsamples to update initial labeled data by combining k-means clustering with the\ntraditional diversity of class probability estimation (DCPE) co-training. In\nthis way, MDCPE can keep new labeled data class-balanced and extract\ndiscriminative features for both the minority and majority classes. During\ntesting process, classification results are acquired by co-decision of the two\nlearners. Experimental results demonstrate that the proposed semi-supervised\nco-training method can make full use of unlabeled information to enhance\ngenerality of the learners and achieve favorable accuracies on all three widely\nused data sets: Salinas, Pavia University and Pavia Center.",
    "published_date": "2018-09-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01436v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.01255v2",
    "title": "Gender differences in research areas and topics: An analysis of publications in 285 fields",
    "authors": [
      "Mike Thelwall",
      "Carol Bailey",
      "Catherine Tobin",
      "Noel-Ann Bradshaw"
    ],
    "author_ids": [],
    "abstract": "Although the gender gap in academia has narrowed, females are\nunderrepresented within some fields in the USA. Prior research suggests that\nthe imbalances between science, technology, engineering and mathematics fields\nmay be partly due to greater male interest in things and greater female\ninterest in people, or to off-putting masculine cultures in some disciplines.\nTo seek more detailed insights across all subjects, this article compares\npractising US male and female researchers between and within 285 narrow Scopus\nfields inside 26 broad fields from their first-authored articles published in\n2017. The comparison is based on publishing fields and the words used in\narticle titles, abstracts, and keywords. The results cannot be fully explained\nby the people/thing dimensions. Exceptions include greater female interest in\nveterinary science and cell biology and greater male interest in abstraction,\npatients, and power/control fields, such as politics and law. These may be due\nto other factors, such as the ability of a career to provide status or social\nimpact or the availability of alternative careers. As a possible side effect of\nthe partial people/thing relationship, females are more likely to use\nexploratory and qualitative methods and males are more likely to use\nquantitative methods. The results suggest that the necessary steps of\neliminating explicit and implicit gender bias in academia are insufficient and\nmight be complemented by measures to make fields more attractive to minority\ngenders.",
    "published_date": "2018-09-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01255v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.01017v1",
    "title": "Aesthetic Discrimination of Graph Layouts",
    "authors": [
      "Moritz Klammler",
      "Tamara Mchedlidze",
      "Alexey Pak"
    ],
    "author_ids": [],
    "abstract": "This paper addresses the following basic question: given two layouts of the\nsame graph, which one is more aesthetically pleasing? We propose a neural\nnetwork-based discriminator model trained on a labeled dataset that decides\nwhich of two layouts has a higher aesthetic quality. The feature vectors used\nas inputs to the model are based on known graph drawing quality metrics,\nclassical statistics, information-theoretical quantities, and two-point\nstatistics inspired by methods of condensed matter physics. The large corpus of\nlayout pairs used for training and testing is constructed using force-directed\ndrawing algorithms and the layouts that naturally stem from the process of\ngraph generation. It is further extended using data augmentation techniques.\nThe mean prediction accuracy of our model is 95.70%, outperforming\ndiscriminators based on stress and on the linear combination of popular quality\nmetrics by a statistically significant margin.",
    "published_date": "2018-09-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS",
      "cs.HC",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01017v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.03313v1",
    "title": "A Global Alignment Kernel based Approach for Group-level Happiness Intensity Estimation",
    "authors": [
      "Xiaohua Huang",
      "Abhinav Dhall",
      "Roland Goecke",
      "Matti Pietikainen",
      "Guoying Zhao"
    ],
    "author_ids": [],
    "abstract": "With the progress in automatic human behavior understanding, analysing the\nperceived affect of multiple people has been recieved interest in affective\ncomputing community. Unlike conventional facial expression analysis, this paper\nprimarily focuses on analysing the behaviour of multiple people in an image.\nThe proposed method is based on support vector regression with the combined\nglobal alignment kernels (GAKs) to estimate the happiness intensity of a group\nof people. We first exploit Riesz-based volume local binary pattern (RVLBP) and\ndeep convolutional neural network (CNN) based features for characterizing\nfacial images. Furthermore, we propose to use the GAK for RVLBP and deep CNN\nfeatures, respectively for explicitly measuring the similarity of two\ngroup-level images. Specifically, we exploit the global weight sort scheme to\nsort the face images from group-level image according to their spatial weights,\nmaking an efficient data structure to GAK. Lastly, we propose Multiple kernel\nlearning based on three combination strategies for combining two respective\nGAKs based on RVLBP and deep CNN features, such that enhancing the\ndiscriminative ability of each GAK. Intensive experiments are performed on the\nchallenging group-level happiness intensity database, namely HAPPEI. Our\nexperimental results demonstrate that the proposed approach achieves promising\nperformance for group happiness intensity analysis, when compared with the\nrecent state-of-the-art methods.",
    "published_date": "2018-09-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.03313v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.00421v2",
    "title": "Hierarchically Learned View-Invariant Representations for Cross-View Action Recognition",
    "authors": [
      "Yang Liu",
      "Zhaoyang Lu",
      "Jing Li",
      "Tao Yang"
    ],
    "author_ids": [],
    "abstract": "Recognizing human actions from varied views is challenging due to huge\nappearance variations in different views. The key to this problem is to learn\ndiscriminant view-invariant representations generalizing well across views. In\nthis paper, we address this problem by learning view-invariant representations\nhierarchically using a novel method, referred to as Joint Sparse Representation\nand Distribution Adaptation (JSRDA). To obtain robust and informative feature\nrepresentations, we first incorporate a sample-affinity matrix into the\nmarginalized stacked denoising Autoencoder (mSDA) to obtain shared features,\nwhich are then combined with the private features. In order to make the feature\nrepresentations of videos across views transferable, we then learn a\ntransferable dictionary pair simultaneously from pairs of videos taken at\ndifferent views to encourage each action video across views to have the same\nsparse representation. However, the distribution difference across views still\nexists because a unified subspace where the sparse representations of one\naction across views are the same may not exist when the view difference is\nlarge. Therefore, we propose a novel unsupervised distribution adaptation\nmethod that learns a set of projections that project the source and target\nviews data into respective low-dimensional subspaces where the marginal and\nconditional distribution differences are reduced simultaneously. Therefore, the\nfinally learned feature representation is view-invariant and robust for\nsubstantial distribution difference across views even the view difference is\nlarge. Experimental results on four multiview datasets show that our approach\noutperforms the state-ofthe-art approaches.",
    "published_date": "2018-09-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00421v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.00304v1",
    "title": "Congestion Control for RTP Media: a Comparison on Simulated Environment",
    "authors": [
      "Songyang Zhang"
    ],
    "author_ids": [],
    "abstract": "To develop low latency congestion control algorithm for real time taffic has\nbeen gained attention recently. RTP Media Congestion Avoidance Techniques\n(RMCAT) working group was initiated for standard defination. There are three\nalgorithms under this group, Network Assisted Dynamic Adaptation (NADA)\nproposed by Cisco, Google Congestion Control (GCC) proposed by Google and\nSelf-Clocked Rate Adaptation for Multimedia(SCReAM) proposed by Ericsson. This\npaper compares and analyses the performance of these algorithms on simulation\nenvironment. Results show GCC has well fairness property and performs well in\nlossy link but slow convergence in dynamic link, NADA stabilizes its rate\nquickly but suffers \"late-comer\" effect, SCReAM has the lowest queue occupation\nbut also lower link capacity utilization.",
    "published_date": "2018-09-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00304v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.00109v1",
    "title": "Multi-UAV Continuum Deformation Flight Optimization in Cluttered Urban Environments",
    "authors": [
      "Hossein Rastgoftar",
      "Ella Atkins"
    ],
    "author_ids": [],
    "abstract": "This paper studies collective motion optimization of a fleet of UAVs flying\nover a populated and geometrically constrained area. The paper treats UAVs as\nparticles of a deformable body, thus, UAV coordination is defined by a\nhomeomorphic continuum deformation function. Under continuum deformation, the\ndistance between individual UAVs can significantly change while assuring the\nUAVs dont collide, enabling a swarm to travel through the potentially cluttered\nenvironment. To ensure inter-agent and obstacle collision avoidance, the paper\nformulates safety requirements as inequality constraints of the coordination\noptimization problem. The main objective of the paper is then to optimize\ncontinuum deformation of the UAV team satisfying all continuum deformation\ninequality constraints. Given initial and target configurations, the cost is\ndefined as a weighted sum of the travel distance and distributed cost\nproportional to the likelihood of the human presence",
    "published_date": "2018-09-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00109v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.00103v1",
    "title": "Privacy, ethics, and data access: A case study of the Fragile Families Challenge",
    "authors": [
      "Ian Lundberg",
      "Arvind Narayanan",
      "Karen Levy",
      "Matthew J. Salganik"
    ],
    "author_ids": [],
    "abstract": "Stewards of social science data face a fundamental tension. On one hand, they\nwant to make their data accessible to as many researchers as possible to\nfacilitate new discoveries. At the same time, they want to restrict access to\ntheir data as much as possible in order to protect the people represented in\nthe data. In this paper, we provide a case study addressing this common tension\nin an uncommon setting: the Fragile Families Challenge, a scientific mass\ncollaboration designed to yield insights that could improve the lives of\ndisadvantaged children in the United States. We describe our process of threat\nmodeling, threat mitigation, and third-party guidance. We also describe the\nethical principles that formed the basis of our process. We are open about our\nprocess and the trade-offs that we made in the hopes that others can improve on\nwhat we have done.",
    "published_date": "2018-09-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00103v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.01499v2",
    "title": "Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts",
    "authors": [
      "Samuel Carton",
      "Qiaozhu Mei",
      "Paul Resnick"
    ],
    "author_ids": [],
    "abstract": "We introduce an adversarial method for producing high-recall explanations of\nneural text classifier decisions. Building on an existing architecture for\nextractive explanations via hard attention, we add an adversarial layer which\nscans the residual of the attention for remaining predictive signal. Motivated\nby the important domain of detecting personal attacks in social media comments,\nwe additionally demonstrate the importance of manually setting a semantically\nappropriate `default' behavior for the model by explicitly manipulating its\nbias term. We develop a validation set of human-annotated personal attacks to\nevaluate the impact of these changes.",
    "published_date": "2018-09-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.01499v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1809.00080v1",
    "title": "Location and Capacity Planning of Facilities with General Service-Time Distributions Using Conic Optimization",
    "authors": [
      "Amir Ahmadi-Javid",
      "Oded Berman",
      "Pooya Hoseinpour"
    ],
    "author_ids": [],
    "abstract": "This paper studies a stochastic congested location problem in the network of\na service system that consists of facilities to be established in a finite\nnumber of candidate locations. Population zones allocated to each open service\nfacility together creates a stream of demand that follows a Poisson process and\nmay cause congestion at the facility. The service time at each facility is\nstochastic and depends on the service capacity and follows a general\ndistribution that can differ for each facility. The service capacity is\nselected from a given (bounded or unbounded) interval. The objective of our\nproblem is to optimize a balanced performance measure that compromises between\nfacility-induced and customer-related costs. Service times are represented by a\nflexible location-scale stochastic model. The problem is formulated using\nquadratic conic optimization. Valid inequalities and a cut-generation procedure\nare developed to increase computational efficiency. A comprehensive numerical\nstudy is carried out to show the efficiency and effectiveness of the solution\nprocedure. Moreover, our numerical experiments using real data of a preventive\nhealthcare system in Toronto show that the optimal service network\nconfiguration is highly sensitive to the service-time distribution. Our method\nfor convexifying the waiting-time formulas of M/G/1 queues is general and\nextends the existing convexity results in queueing theory such that they can be\nused in optimization problems where the service rates are continuous.",
    "published_date": "2018-08-31T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.DM",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00080v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.10685v3",
    "title": "Extracting Keywords from Open-Ended Business Survey Questions",
    "authors": [
      "Barbara McGillivray",
      "Gard Jenset",
      "Dominik Heil"
    ],
    "author_ids": [],
    "abstract": "Open-ended survey data constitute an important basis in research as well as\nfor making business decisions. Collecting and manually analysing free-text\nsurvey data is generally more costly than collecting and analysing survey data\nconsisting of answers to multiple-choice questions. Yet free-text data allow\nfor new content to be expressed beyond predefined categories and are a very\nvaluable source of new insights into people's opinions. At the same time,\nsurveys always make ontological assumptions about the nature of the entities\nthat are researched, and this has vital ethical consequences. Human\ninterpretations and opinions can only be properly ascertained in their richness\nusing textual data sources; if these sources are analyzed appropriately, the\nessential linguistic nature of humans and social entities is safeguarded.\nNatural Language Processing (NLP) offers possibilities for meeting this ethical\nbusiness challenge by automating the analysis of natural language and thus\nallowing for insightful investigations of human judgements. We present a\ncomputational pipeline for analysing large amounts of responses to open-ended\nquestions in surveys and extract keywords that appropriately represent people's\nopinions. This pipeline addresses the need to perform such tasks outside the\nscope of both commercial software and bespoke analysis, exceeds the performance\nto state-of-the-art systems, and performs this task in a transparent way that\nallows for scrutinising and exposing potential biases in the analysis.\nFollowing the principle of Open Data Science, our code is open-source and\ngeneralizable to other datasets.",
    "published_date": "2018-08-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10685v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.10593v2",
    "title": "Asymptotic Seed Bias in Respondent-driven Sampling",
    "authors": [
      "Yuling Yan",
      "Bret Hanlon",
      "Sebastien Roch",
      "Karl Rohe"
    ],
    "author_ids": [],
    "abstract": "Respondent-driven sampling (RDS) collects a sample of individuals in a\nnetworked population by incentivizing the sampled individuals to refer their\ncontacts into the sample. This iterative process is initialized from some seed\nnode(s). Sometimes, this selection creates a large amount of seed bias. Other\ntimes, the seed bias is small. This paper gains a deeper understanding of this\nbias by characterizing its effect on the limiting distribution of various RDS\nestimators. Using classical tools and results from multi-type branching\nprocesses (Kesten and Stigum, 1966), we show that the seed bias is negligible\nfor the Generalized Least Squares (GLS) estimator and non-negligible for both\nthe inverse probability weighted and Volz-Heckathorn (VH) estimators. In\nparticular, we show that (i) above a critical threshold, VH converge to a\nnon-trivial mixture distribution, where the mixture component depends on the\nseed node, and the mixture distribution is possibly multi-modal. Moreover, (ii)\nGLS converges to a Gaussian distribution independent of the seed node, under a\ncertain condition on the Markov process. Numerical experiments with both\nsimulated data and empirical social networks suggest that these results appear\nto hold beyond the Markov conditions of the theorems.",
    "published_date": "2018-08-31T00:00:00",
    "year": 2018,
    "categories": [
      "math.ST",
      "cs.SI",
      "math.PR",
      "stat.ME",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10593v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.10549v2",
    "title": "Fair Algorithms for Learning in Allocation Problems",
    "authors": [
      "Hadi Elzayn",
      "Shahin Jabbari",
      "Christopher Jung",
      "Michael Kearns",
      "Seth Neel",
      "Aaron Roth",
      "Zachary Schutzman"
    ],
    "author_ids": [],
    "abstract": "Settings such as lending and policing can be modeled by a centralized agent\nallocating a resource (loans or police officers) amongst several groups, in\norder to maximize some objective (loans given that are repaid or criminals that\nare apprehended). Often in such problems fairness is also a concern. A natural\nnotion of fairness, based on general principles of equality of opportunity,\nasks that conditional on an individual being a candidate for the resource, the\nprobability of actually receiving it is approximately independent of the\nindividual's group. In lending this means that equally creditworthy individuals\nin different racial groups have roughly equal chances of receiving a loan. In\npolicing it means that two individuals committing the same crime in different\ndistricts would have roughly equal chances of being arrested.\n  We formalize this fairness notion for allocation problems and investigate its\nalgorithmic consequences. Our main technical results include an efficient\nlearning algorithm that converges to an optimal fair allocation even when the\nfrequency of candidates (creditworthy individuals or criminals) in each group\nis unknown. The algorithm operates in a censored feedback model in which only\nthe number of candidates who received the resource in a given allocation can be\nobserved, rather than the true number of candidates. This models the fact that\nwe do not learn the creditworthiness of individuals we do not give loans to nor\nlearn about crimes committed if the police presence in a district is low.\n  As an application of our framework, we consider the predictive policing\nproblem. The learning algorithm is trained on arrest data gathered from its own\ndeployments on previous days, resulting in a potential feedback loop that our\nalgorithm provably overcomes. We empirically investigate the performance of our\nalgorithm on the Philadelphia Crime Incidents dataset.",
    "published_date": "2018-08-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10549v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.10078v2",
    "title": "Discriminative Learning of Similarity and Group Equivariant Representations",
    "authors": [
      "Shubhendu Trivedi"
    ],
    "author_ids": [],
    "abstract": "One of the most fundamental problems in machine learning is to compare\nexamples: Given a pair of objects we want to return a value which indicates\ndegree of (dis)similarity. Similarity is often task specific, and pre-defined\ndistances can perform poorly, leading to work in metric learning. However,\nbeing able to learn a similarity-sensitive distance function also presupposes\naccess to a rich, discriminative representation for the objects at hand. In\nthis dissertation we present contributions towards both ends. In the first part\nof the thesis, assuming good representations for the data, we present a\nformulation for metric learning that makes a more direct attempt to optimize\nfor the k-NN accuracy as compared to prior work. We also present extensions of\nthis formulation to metric learning for kNN regression, asymmetric similarity\nlearning and discriminative learning of Hamming distance. In the second part,\nwe consider a situation where we are on a limited computational budget i.e.\noptimizing over a space of possible metrics would be infeasible, but access to\na label aware distance metric is still desirable. We present a simple, and\ncomputationally inexpensive approach for estimating a well motivated metric\nthat relies only on gradient estimates, discussing theoretical and experimental\nresults. In the final part, we address representational issues, considering\ngroup equivariant convolutional neural networks (GCNNs). Equivariance to\nsymmetry transformations is explicitly encoded in GCNNs; a classical CNN being\nthe simplest example. In particular, we present a SO(3)-equivariant neural\nnetwork architecture for spherical data, that operates entirely in Fourier\nspace, while also providing a formalism for the design of fully Fourier neural\nnetworks that are equivariant to the action of any continuous compact group.",
    "published_date": "2018-08-30T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10078v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.10075v2",
    "title": "Towards Effective Deep Embedding for Zero-Shot Learning",
    "authors": [
      "Lei Zhang",
      "Peng Wang",
      "Lingqiao Liu",
      "Chunhua Shen",
      "Wei Wei",
      "Yannning Zhang",
      "Anton Van Den Hengel"
    ],
    "author_ids": [],
    "abstract": "Zero-shot learning (ZSL) can be formulated as a cross-domain matching\nproblem: after being projected into a joint embedding space, a visual sample\nwill match against all candidate class-level semantic descriptions and be\nassigned to the nearest class. In this process, the embedding space underpins\nthe success of such matching and is crucial for ZSL. In this paper, we conduct\nan in-depth study on the construction of embedding space for ZSL and posit that\nan ideal embedding space should satisfy two criteria: intra-class compactness\nand inter-class separability. While the former encourages the embeddings of\nvisual samples of one class to distribute tightly close to the semantic\ndescription embedding of this class, the latter requires embeddings from\ndifferent classes to be well separated from each other. Towards this goal, we\npresent a simple but effective two-branch network to simultaneously map\nsemantic descriptions and visual samples into a joint space, on which visual\nembeddings are forced to regress to their class-level semantic embeddings and\nthe embeddings crossing classes are required to be distinguishable by a\ntrainable classifier. Furthermore, we extend our method to a transductive\nsetting to better handle the model bias problem in ZSL (i.e., samples from\nunseen classes tend to be categorized into seen classes) with minimal extra\nsupervision. Specifically, we propose a pseudo labeling strategy to\nprogressively incorporate the testing samples into the training process and\nthus balance the model between seen and unseen classes. Experimental results on\nfive standard ZSL datasets show the superior performance of the proposed method\nand its transductive extension.",
    "published_date": "2018-08-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10075v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.10068v2",
    "title": "A polynomial-time algorithm for median-closed semilinear constraints",
    "authors": [
      "Manuel Bodirsky",
      "Marcello Mamino"
    ],
    "author_ids": [],
    "abstract": "A subset of Q^n is called semilinear (or piecewise linear) if it is Boolean\ncombination of linear half-spaces. We study the computational complexity of the\nconstraint satisfaction problem (CSP) over the rationals when all the\nconstraints are semilinear. When the sets are convex the CSP is polynomial-time\nequivalent to linear programming. A semilinear relation is convex if and only\nif it is preserved by taking averages. Our main result is a polynomial-time\nalgorithm for the CSP of semilinear constraints that are preserved by applying\nmedians. We also prove that this class is maximally tractable in the sense that\nany larger class of semilinear relations has an NP-hard CSP. To illustrate, our\nclass contains all relations that can be expressed by linear inequalities with\nat most two variables (so-called TVPI constraints), but it also contains many\nnon-convex relations, for example constraints of the form x in S for arbitrary\nfinite subset S of Q, or more generally disjunctive constraints of the form x <\nc or y < d for constants c and d.",
    "published_date": "2018-08-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10068v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.10006v2",
    "title": "Correcting Length Bias in Neural Machine Translation",
    "authors": [
      "Kenton Murray",
      "David Chiang"
    ],
    "author_ids": [],
    "abstract": "We study two problems in neural machine translation (NMT). First, in beam\nsearch, whereas a wider beam should in principle help translation, it often\nhurts NMT. Second, NMT has a tendency to produce translations that are too\nshort. Here, we argue that these problems are closely related and both rooted\nin label bias. We show that correcting the brevity problem almost eliminates\nthe beam problem; we compare some commonly-used methods for doing this, finding\nthat a simple per-word reward works well; and we introduce a simple and quick\nway to tune this reward using the perceptron algorithm.",
    "published_date": "2018-08-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.10006v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.09479v1",
    "title": "Residualized Factor Adaptation for Community Social Media Prediction Tasks",
    "authors": [
      "Mohammadzaman Zamani",
      "H. Andrew Schwartz",
      "Veronica E. Lynn",
      "Salvatore Giorgi",
      "Niranjan Balasubramanian"
    ],
    "author_ids": [],
    "abstract": "Predictive models over social media language have shown promise in capturing\ncommunity outcomes, but approaches thus far largely neglect the\nsocio-demographic context (e.g. age, education rates, race) of the community\nfrom which the language originates. For example, it may be inaccurate to assume\npeople in Mobile, Alabama, where the population is relatively older, will use\nwords the same way as those from San Francisco, where the median age is younger\nwith a higher rate of college education. In this paper, we present residualized\nfactor adaptation, a novel approach to community prediction tasks which both\n(a) effectively integrates community attributes, as well as (b) adapts\nlinguistic features to community attributes (factors). We use eleven\ndemographic and socioeconomic attributes, and evaluate our approach over five\ndifferent community-level predictive tasks, spanning health (heart disease\nmortality, percent fair/poor health), psychology (life satisfaction), and\neconomics (percent housing price increase, foreclosure rate). Our evaluation\nshows that residualized factor adaptation significantly improves 4 out of 5\ncommunity-level outcome predictions over prior state-of-the-art for\nincorporating socio-demographic contexts.",
    "published_date": "2018-08-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09479v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.09347v2",
    "title": "Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation",
    "authors": [
      "Chao Chen",
      "Zhihong Chen",
      "Boyuan Jiang",
      "Xinyu Jin"
    ],
    "author_ids": [],
    "abstract": "Recently, considerable effort has been devoted to deep domain adaptation in\ncomputer vision and machine learning communities. However, most of existing\nwork only concentrates on learning shared feature representation by minimizing\nthe distribution discrepancy across different domains. Due to the fact that all\nthe domain alignment approaches can only reduce, but not remove the domain\nshift. Target domain samples distributed near the edge of the clusters, or far\nfrom their corresponding class centers are easily to be misclassified by the\nhyperplane learned from the source domain. To alleviate this issue, we propose\nto joint domain alignment and discriminative feature learning, which could\nbenefit both domain alignment and final classification. Specifically, an\ninstance-based discriminative feature learning method and a center-based\ndiscriminative feature learning method are proposed, both of which guarantee\nthe domain invariant features with better intra-class compactness and\ninter-class separability. Extensive experiments show that learning the\ndiscriminative features in the shared feature space can significantly boost the\nperformance of deep domain adaptation methods.",
    "published_date": "2018-08-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09347v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.09273v1",
    "title": "Motorcycle Classification in Urban Scenarios using Convolutional Neural Networks for Feature Extraction",
    "authors": [
      "Jorge E. Espinosa",
      "Sergio A. Velastin",
      "John W. Branch"
    ],
    "author_ids": [],
    "abstract": "This paper presents a motorcycle classification system for urban scenarios\nusing Convolutional Neural Network (CNN). Significant results on image\nclassification has been achieved using CNNs at the expense of a high\ncomputational cost for training with thousands or even millions of examples.\nNevertheless, features can be extracted from CNNs already trained. In this work\nAlexNet, included in the framework CaffeNet, is used to extract features from\nframes taken on a real urban scenario. The extracted features from the CNN are\nused to train a support vector machine (SVM) classifier to discriminate\nmotorcycles from other road users. The obtained results show a mean accuracy of\n99.40% and 99.29% on a classification task of three and five classes\nrespectively. Further experiments are performed on a validation set of images\nshowing a satisfactory classification.",
    "published_date": "2018-08-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09273v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.09211v1",
    "title": "DeepGUM: Learning Deep Robust Regression with a Gaussian-Uniform Mixture Model",
    "authors": [
      "Stéphane Lathuilière",
      "Pablo Mesejo",
      "Xavier Alameda-Pineda",
      "Radu Horaud"
    ],
    "author_ids": [],
    "abstract": "In this paper, we address the problem of how to robustly train a ConvNet for\nregression, or deep robust regression. Traditionally, deep regression employs\nthe L2 loss function, known to be sensitive to outliers, i.e. samples that\neither lie at an abnormal distance away from the majority of the training\nsamples, or that correspond to wrongly annotated targets. This means that,\nduring back-propagation, outliers may bias the training process due to the high\nmagnitude of their gradient. In this paper, we propose DeepGUM: a deep\nregression model that is robust to outliers thanks to the use of a\nGaussian-uniform mixture model. We derive an optimization algorithm that\nalternates between the unsupervised detection of outliers using\nexpectation-maximization, and the supervised training with cleaned samples\nusing stochastic gradient descent. DeepGUM is able to adapt to a continuously\nevolving outlier distribution, avoiding to manually impose any threshold on the\nproportion of outliers in the training set. Extensive experimental evaluations\non four different tasks (facial and fashion landmark detection, age and head\npose estimation) lead us to conclude that our novel robust technique provides\nreliability in the presence of various types of noise and protection against a\nhigh percentage of outliers.",
    "published_date": "2018-08-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09211v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.09004v1",
    "title": "Downstream Effects of Affirmative Action",
    "authors": [
      "Sampath Kannan",
      "Aaron Roth",
      "Juba Ziani"
    ],
    "author_ids": [],
    "abstract": "We study a two-stage model, in which students are 1) admitted to college on\nthe basis of an entrance exam which is a noisy signal about their\nqualifications (type), and then 2) those students who were admitted to college\ncan be hired by an employer as a function of their college grades, which are an\nindependently drawn noisy signal of their type. Students are drawn from one of\ntwo populations, which might have different type distributions. We assume that\nthe employer at the end of the pipeline is rational, in the sense that it\ncomputes a posterior distribution on student type conditional on all\ninformation that it has available (college admissions, grades, and group\nmembership), and makes a decision based on posterior expectation. We then study\nwhat kinds of fairness goals can be achieved by the college by setting its\nadmissions rule and grading policy. For example, the college might have the\ngoal of guaranteeing equal opportunity across populations: that the probability\nof passing through the pipeline and being hired by the employer should be\nindependent of group membership, conditioned on type. Alternately, the college\nmight have the goal of incentivizing the employer to have a group blind hiring\nrule. We show that both goals can be achieved when the college does not report\ngrades. On the other hand, we show that under reasonable conditions, these\ngoals are impossible to achieve even in isolation when the college uses an\n(even minimally) informative grading policy.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.LG",
      "econ.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09004v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08905v1",
    "title": "Fair redistricting is hard",
    "authors": [
      "Richard Kueng",
      "Dustin G. Mixon",
      "Soledad Villar"
    ],
    "author_ids": [],
    "abstract": "Gerrymandering is a long-standing issue within the U.S. political system, and\nit has received scrutiny recently by the U.S. Supreme Court. In this note, we\nprove that deciding whether there exists a fair redistricting among legal maps\nis NP-hard. To make this precise, we use simplified notions of \"legal\" and\n\"fair\" that account for desirable traits such as geographic compactness of\ndistricts and sufficient representation of voters. The proof of our result is\ninspired by the work of Mahanjan, Minbhorkar and Varadarajan that proves that\nplanar k-means is NP-hard.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08905v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.08811v3",
    "title": "Exponential inequalities for nonstationary Markov Chains",
    "authors": [
      "Pierre Alquier",
      "Paul Doukhan",
      "Xiequan Fan"
    ],
    "author_ids": [],
    "abstract": "Exponential inequalities are main tools in machine learning theory. To prove\nexponential inequalities for non i.i.d random variables allows to extend many\nlearning techniques to these variables. Indeed, much work has been done both on\ninequalities and learning theory for time series, in the past 15 years.\nHowever, for the non independent case, almost all the results concern\nstationary time series. This excludes many important applications: for example\nany series with a periodic behavior is non-stationary. In this paper, we extend\nthe basic tools of Dedecker and Fan (2015) to nonstationary Markov chains. As\nan application, we provide a Bernstein-type inequality, and we deduce risk\nbounds for the prediction of periodic autoregressive processes with an unknown\nperiod.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08811v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08709v1",
    "title": "Kinetostatic analysis and solution classification of a class of planar tensegrity mechanisms",
    "authors": [
      "Philippe Wenger",
      "D. Chablat"
    ],
    "author_ids": [],
    "abstract": "Tensegrity mechanisms are composed of rigid and tensile parts that are in\nequilibrium. They are interesting alternative designs for some applications,\nsuch as modelling musculo-skeleton systems. Tensegrity mechanisms are more\ndifficult to analyze than classical mechanisms as the static equilibrium\nconditions that must be satisfied generally result in complex equations. A\nclass of planar one-degree-of-freedom tensegrity mechanisms with three linear\nsprings is analyzed in detail for the sake of systematic solution\nclassifications. The kinetostatic equations are derived and solved under\nseveral loading and geometric conditions. It is shown that these mechanisms\nexhibit up to six equilibrium configurations, of which one or two are stable,\ndepending on the geometric and loading conditions. Discriminant varieties and\ncylindrical algebraic decomposition combined with Groebner base elimination are\nused to classify solutions as a function of the geometric, loading and actuator\ninput parameters.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08709v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.08683v2",
    "title": "Regression adjustments for estimating the global treatment effect in experiments with interference",
    "authors": [
      "Alex Chin"
    ],
    "author_ids": [],
    "abstract": "Standard estimators of the global average treatment effect can be biased in\nthe presence of interference. This paper proposes regression adjustment\nestimators for removing bias due to interference in Bernoulli randomized\nexperiments. We use a fitted model to predict the counterfactual outcomes of\nglobal control and global treatment. Our work differs from standard regression\nadjustments in that the adjustment variables are constructed from functions of\nthe treatment assignment vector, and that we allow the researcher to use a\ncollection of any functions correlated with the response, turning the problem\nof detecting interference into a feature engineering problem. We characterize\nthe distribution of the proposed estimator in a linear model setting and\nconnect the results to the standard theory of regression adjustments under\nSUTVA. We then propose an estimator that allows for flexible machine learning\nestimators to be used for fitting a nonlinear interference functional form. We\npropose conducting statistical inference via bootstrap and resampling methods,\nwhich allow us to sidestep the complicated dependences implied by interference\nand instead rely on empirical covariance structures. Such variance estimation\nrelies on an exogeneity assumption akin to the standard unconfoundedness\nassumption invoked in observational studies. In simulation experiments, our\nmethods are better at debiasing estimates than existing inverse propensity\nweighted estimators based on neighborhood exposure modeling. We use our method\nto reanalyze an experiment concerning weather insurance adoption conducted on a\ncollection of villages in rural China.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ME",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08683v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08646v4",
    "title": "The Disparate Effects of Strategic Manipulation",
    "authors": [
      "Lily Hu",
      "Nicole Immorlica",
      "Jennifer Wortman Vaughan"
    ],
    "author_ids": [],
    "abstract": "When consequential decisions are informed by algorithmic input, individuals\nmay feel compelled to alter their behavior in order to gain a system's\napproval. Models of agent responsiveness, termed \"strategic manipulation,\"\nanalyze the interaction between a learner and agents in a world where all\nagents are equally able to manipulate their features in an attempt to \"trick\" a\npublished classifier. In cases of real world classification, however, an\nagent's ability to adapt to an algorithm is not simply a function of her\npersonal interest in receiving a positive classification, but is bound up in a\ncomplex web of social factors that affect her ability to pursue certain action\nresponses. In this paper, we adapt models of strategic manipulation to capture\ndynamics that may arise in a setting of social inequality wherein candidate\ngroups face different costs to manipulation. We find that whenever one group's\ncosts are higher than the other's, the learner's equilibrium strategy exhibits\nan inequality-reinforcing phenomenon wherein the learner erroneously admits\nsome members of the advantaged group, while erroneously excluding some members\nof the disadvantaged group. We also consider the effects of interventions in\nwhich a learner subsidizes members of the disadvantaged group, lowering their\ncosts in order to improve her own classification performance. Here we encounter\na paradoxical result: there exist cases in which providing a subsidy improves\nonly the learner's utility while actually making both candidate groups\nworse-off--even the group receiving the subsidy. Our results reveal the\npotentially adverse social ramifications of deploying tools that attempt to\nevaluate an individual's \"quality\" when agents' capacities to adaptively\nrespond differ.",
    "published_date": "2018-08-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08646v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08619v7",
    "title": "Avoiding Disparity Amplification under Different Worldviews",
    "authors": [
      "Samuel Yeom",
      "Michael Carl Tschantz"
    ],
    "author_ids": [],
    "abstract": "We mathematically compare four competing definitions of group-level\nnondiscrimination: demographic parity, equalized odds, predictive parity, and\ncalibration. Using the theoretical framework of Friedler et al., we study the\nproperties of each definition under various worldviews, which are assumptions\nabout how, if at all, the observed data is biased. We argue that different\nworldviews call for different definitions of fairness, and we specify the\nworldviews that, when combined with the desire to avoid a criterion for\ndiscrimination that we call disparity amplification, motivate demographic\nparity and equalized odds. We also argue that predictive parity and calibration\nare insufficient for avoiding disparity amplification because predictive parity\nallows an arbitrarily large inter-group disparity and calibration is not robust\nto post-processing. Finally, we define a worldview that is more realistic than\nthe previously considered ones, and we introduce a new notion of fairness that\ncorresponds to this worldview.",
    "published_date": "2018-08-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08619v7",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08558v2",
    "title": "Spectral Pruning: Compressing Deep Neural Networks via Spectral Analysis and its Generalization Error",
    "authors": [
      "Taiji Suzuki",
      "Hiroshi Abe",
      "Tomoya Murata",
      "Shingo Horiuchi",
      "Kotaro Ito",
      "Tokuma Wachi",
      "So Hirai",
      "Masatoshi Yukishima",
      "Tomoaki Nishimura"
    ],
    "author_ids": [],
    "abstract": "Compression techniques for deep neural network models are becoming very\nimportant for the efficient execution of high-performance deep learning systems\non edge-computing devices. The concept of model compression is also important\nfor analyzing the generalization error of deep learning, known as the\ncompression-based error bound. However, there is still huge gap between a\npractically effective compression method and its rigorous background of\nstatistical learning theory. To resolve this issue, we develop a new\ntheoretical framework for model compression and propose a new pruning method\ncalled {\\it spectral pruning} based on this framework. We define the ``degrees\nof freedom'' to quantify the intrinsic dimensionality of a model by using the\neigenvalue distribution of the covariance matrix across the internal nodes and\nshow that the compression ability is essentially controlled by this quantity.\nMoreover, we present a sharp generalization error bound of the compressed model\nand characterize the bias--variance tradeoff induced by the compression\nprocedure. We apply our method to several datasets to justify our theoretical\nanalyses and show the superiority of the the proposed method.",
    "published_date": "2018-08-26T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08558v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08524v2",
    "title": "When facts fail: Bias, polarisation and truth in social networks",
    "authors": [
      "Orowa Sikder",
      "Robert E. Smith",
      "Pierpaolo Vivo",
      "Giacomo Livan"
    ],
    "author_ids": [],
    "abstract": "Online social networks provide users with unprecedented opportunities to\nengage with diverse opinions. At the same time, they enable confirmation bias\non large scales by empowering individuals to self-select narratives they want\nto be exposed to. A precise understanding of such tradeoffs is still largely\nmissing. We introduce a social learning model where most participants in a\nnetwork update their beliefs unbiasedly based on new information, while a\nminority of participants reject information that is incongruent with their\npreexisting beliefs. This simple mechanism generates permanent opinion\npolarization and cascade dynamics, and accounts for the aforementioned tradeoff\nbetween confirmation bias and social connectivity through analytic results. We\ninvestigate the model's predictions empirically using US county-level data on\nthe impact of Internet access on the formation of beliefs about global warming.\nWe conclude by discussing policy implications of our model, highlighting the\ndownsides of debunking and suggesting alternative strategies to contrast\nmisinformation.",
    "published_date": "2018-08-26T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08524v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.08460v2",
    "title": "The Social Cost of Strategic Classification",
    "authors": [
      "Smitha Milli",
      "John Miller",
      "Anca D. Dragan",
      "Moritz Hardt"
    ],
    "author_ids": [],
    "abstract": "Consequential decision-making typically incentivizes individuals to behave\nstrategically, tailoring their behavior to the specifics of the decision rule.\nA long line of work has therefore sought to counteract strategic behavior by\ndesigning more conservative decision boundaries in an effort to increase\nrobustness to the effects of strategic covariate shift. We show that these\nefforts benefit the institutional decision maker at the expense of the\nindividuals being classified. Introducing a notion of social burden, we prove\nthat any increase in institutional utility necessarily leads to a corresponding\nincrease in social burden. Moreover, we show that the negative externalities of\nstrategic classification can disproportionately harm disadvantaged groups in\nthe population. Our results highlight that strategy-robustness must be weighed\nagainst considerations of social welfare and fairness.",
    "published_date": "2018-08-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08460v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08231v2",
    "title": "The Entropy Power Inequality with quantum conditioning",
    "authors": [
      "Giacomo De Palma"
    ],
    "author_ids": [],
    "abstract": "The conditional entropy power inequality is a fundamental inequality in\ninformation theory, stating that the conditional entropy of the sum of two\nconditionally independent vector-valued random variables each with an assigned\nconditional entropy is minimum when the random variables are Gaussian. We prove\nthe conditional entropy power inequality in the scenario where the conditioning\nsystem is quantum. The proof is based on the heat semigroup and on a\ngeneralization of the Stam inequality in the presence of quantum conditioning.\nThe entropy power inequality with quantum conditioning will be a key tool of\nquantum information, with applications in distributed source coding protocols\nwith the assistance of quantum entanglement.",
    "published_date": "2018-08-24T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math-ph",
      "math.IT",
      "math.MP",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08231v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.08166v1",
    "title": "An Empirical Study of Rich Subgroup Fairness for Machine Learning",
    "authors": [
      "Michael Kearns",
      "Seth Neel",
      "Aaron Roth",
      "Zhiwei Steven Wu"
    ],
    "author_ids": [],
    "abstract": "Kearns et al. [2018] recently proposed a notion of rich subgroup fairness\nintended to bridge the gap between statistical and individual notions of\nfairness. Rich subgroup fairness picks a statistical fairness constraint (say,\nequalizing false positive rates across protected groups), but then asks that\nthis constraint hold over an exponentially or infinitely large collection of\nsubgroups defined by a class of functions with bounded VC dimension. They give\nan algorithm guaranteed to learn subject to this constraint, under the\ncondition that it has access to oracles for perfectly learning absent a\nfairness constraint. In this paper, we undertake an extensive empirical\nevaluation of the algorithm of Kearns et al. On four real datasets for which\nfairness is a concern, we investigate the basic convergence of the algorithm\nwhen instantiated with fast heuristics in place of learning oracles, measure\nthe tradeoffs between fairness and accuracy, and compare this approach with the\nrecent algorithm of Agarwal et al. [2018], which implements weaker and more\ntraditional marginal fairness constraints defined by individual protected\nattributes. We find that in general, the Kearns et al. algorithm converges\nquickly, large gains in fairness can be obtained with mild costs to accuracy,\nand that optimizing accuracy subject only to marginal fairness leads to\nclassifiers with substantial subgroup unfairness. We also provide a number of\nanalyses and visualizations of the dynamics and behavior of the Kearns et al.\nalgorithm. Overall we find this algorithm to be effective on real data, and\nrich subgroup fairness to be a viable notion in practice.",
    "published_date": "2018-08-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08166v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.08145v1",
    "title": "Overcoming unambiguous state discrimination attack with the help of Schrödinger Cat decoy states",
    "authors": [
      "Andrei Gaidash",
      "Anton Kozubov",
      "George Miroshnichenko"
    ],
    "author_ids": [],
    "abstract": "In this work we propose the technique for phase-coded weak coherent states\nprotocols utilizing two signal states and one decoy state which is found as\nlinear combination of signal states (Schr\\\"odinger Cat states); the latter\nallows to overcome the USD attack. For instance, Schr\\\"odinger Cat states can\nbe considered as even coherent states. Moreover we consider decoy states\nimplementation based on squeezed vacuum states which might not disables USD\ncompletely yet produces discrimination probabilities low enough to distribute\nkeys in channel with particular losses. Thus we can detect Eve simply by\nmonitoring the detection rate of decoy states. It should be noted that this\napproach can be scaled to more complex schemes.",
    "published_date": "2018-08-24T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08145v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.07586v2",
    "title": "Exploring Author Gender in Book Rating and Recommendation",
    "authors": [
      "Michael D. Ekstrand",
      "Daniel Kluver"
    ],
    "author_ids": [],
    "abstract": "Collaborative filtering algorithms find useful patterns in rating and\nconsumption data and exploit these patterns to guide users to good items. Many\nof the patterns in rating datasets reflect important real-world differences\nbetween the various users and items in the data; other patterns may be\nirrelevant or possibly undesirable for social or ethical reasons, particularly\nif they reflect undesired discrimination, such as discrimination in publishing\nor purchasing against authors who are women or ethnic minorities. In this work,\nwe examine the response of collaborative filtering recommender algorithms to\nthe distribution of their input data with respect to a dimension of social\nconcern, namely content creator gender. Using publicly-available book ratings\ndata, we measure the distribution of the genders of the authors of books in\nuser rating profiles and recommendation lists produced from this data. We find\nthat common collaborative filtering algorithms differ in the gender\ndistribution of their recommendation lists, and in the relationship of that\noutput distribution to user profile distribution.",
    "published_date": "2018-08-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.07586v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.07235v1",
    "title": "Finding Good Representations of Emotions for Text Classification",
    "authors": [
      "Ji Ho Park"
    ],
    "author_ids": [],
    "abstract": "It is important for machines to interpret human emotions properly for better\nhuman-machine communications, as emotion is an essential part of human-to-human\ncommunications. One aspect of emotion is reflected in the language we use. How\nto represent emotions in texts is a challenge in natural language processing\n(NLP). Although continuous vector representations like word2vec have become the\nnew norm for NLP problems, their limitations are that they do not take emotions\ninto consideration and can unintentionally contain bias toward certain\nidentities like different genders.\n  This thesis focuses on improving existing representations in both word and\nsentence levels by explicitly taking emotions inside text and model bias into\naccount in their training process. Our improved representations can help to\nbuild more robust machine learning models for affect-related text\nclassification like sentiment/emotion analysis and abusive language detection.\n  We first propose representations called emotional word vectors (EVEC), which\nis learned from a convolutional neural network model with an emotion-labeled\ncorpus, which is constructed using hashtags. Secondly, we extend to learning\nsentence-level representations with a huge corpus of texts with the pseudo task\nof recognizing emojis. Our results show that, with the representations trained\nfrom millions of tweets with weakly supervised labels such as hashtags and\nemojis, we can solve sentiment/emotion analysis tasks more effectively.\n  Lastly, as examples of model bias in representations of existing approaches,\nwe explore a specific problem of automatic detection of abusive language. We\naddress the issue of gender bias in various neural network models by conducting\nexperiments to measure and reduce those biases in the representations in order\nto build more robust classification models.",
    "published_date": "2018-08-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.07235v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.07231v1",
    "title": "Reducing Gender Bias in Abusive Language Detection",
    "authors": [
      "Ji Ho Park",
      "Jamin Shin",
      "Pascale Fung"
    ],
    "author_ids": [],
    "abstract": "Abusive language detection models tend to have a problem of being biased\ntoward identity words of a certain group of people because of imbalanced\ntraining datasets. For example, \"You are a good woman\" was considered \"sexist\"\nwhen trained on an existing dataset. Such model bias is an obstacle for models\nto be robust enough for practical use. In this work, we measure gender biases\non models trained with different abusive language datasets, while analyzing the\neffect of different pre-trained word embeddings and model architectures. We\nalso experiment with three bias mitigation methods: (1) debiased word\nembeddings, (2) gender swap data augmentation, and (3) fine-tuning with a\nlarger corpus. These methods can effectively reduce gender bias by 90-98% and\ncan be extended to correct model bias in other scenarios.",
    "published_date": "2018-08-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.07231v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.07151v3",
    "title": "MobilityMirror: Bias-Adjusted Transportation Datasets",
    "authors": [
      "Luke Rodriguez",
      "Babak Salimi",
      "Haoyue Ping",
      "Julia Stoyanovich",
      "Bill Howe"
    ],
    "author_ids": [],
    "abstract": "We describe customized synthetic datasets for publishing mobility data.\nPrivate companies are providing new transportation modalities, and their data\nis of high value for integrative transportation research, policy enforcement,\nand public accountability. However, these companies are disincentivized from\nsharing data not only to protect the privacy of individuals (drivers and/or\npassengers), but also to protect their own competitive advantage. Moreover,\ndemographic biases arising from how the services are delivered may be amplified\nif released data is used in other contexts.\n  We describe a model and algorithm for releasing origin-destination histograms\nthat removes selected biases in the data using causality-based methods. We\ncompute the origin-destination histogram of the original dataset then adjust\nthe counts to remove undesirable causal relationships that can lead to\ndiscrimination or violate contractual obligations with data owners. We evaluate\nthe utility of the algorithm on real data from a dockless bike share program in\nSeattle and taxi data in New York, and show that these adjusted transportation\ndatasets can retain utility while removing bias in the underlying data.",
    "published_date": "2018-08-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.07151v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.08206v1",
    "title": "Throughput Optimization of Coexistent LTE-U and WiFi in Next Generation Networks",
    "authors": [
      "Suganya S",
      "Ramesh C",
      "Sumit Maheshwari"
    ],
    "author_ids": [],
    "abstract": "Next generation networks are envisioned to have ubiquitous availability and\nseamless access as main goals. In general, coexistence of multiple access\ntechnologies is one of the most promising way to achieve these goals,\nparticularly using WiFi and LTE (Long Term Evolution) simultaneously which are\ntwo major players in future Internet. LTE is primarily used in a licensed\nspectrum but an unlicensed version is also in use by research communities. In\nthis work we study LTE-U (LTE-Unlicensed) and WiFi Coexistence in a handheld\ndevice by analyzing existing scheduling mechanisms and proposing a novel scheme\nof cooperation. Throughput and fairness of these multi-homed technologies are\nstudied in detailed. Also, we propose to use a deferral based proactive scheme\nfor improved system utilization.",
    "published_date": "2018-08-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.08206v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.06152v1",
    "title": "On Design of Problem Token Questions in Quality of Experience Surveys",
    "authors": [
      "Jayant Gupchup",
      "Ebrahim Beyrami",
      "Martin Ellis",
      "Yasaman Hosseinkashi",
      "Sam Johnson",
      "Ross Cutler"
    ],
    "author_ids": [],
    "abstract": "User surveys for Quality of Experience (QoE) are a critical source of\ninformation. In addition to the common \"star rating\" used to estimate Mean\nOpinion Score (MOS), more detailed survey questions (problem tokens) about\nspecific areas provide valuable insight into the factors impacting QoE. This\npaper explores two aspects of the problem token questionnaire design. First, we\nstudy the bias introduced by fixed question order, and second, we study the\nchallenge of selecting a subset of questions to keep the token set small. Based\non 900,000 calls gathered using a randomized controlled experiment from a live\nsystem, we find that the order bias can be significantly reduced by randomizing\nthe display order of tokens. The difference in response rate varies based on\ntoken position and display design. It is worth noting that the users respond to\nthe randomized-order variant at levels that are comparable to the fixed-order\nvariant. The effective selection of a subset of token questions is achieved by\nextracting tokens that provide the highest information gain over user ratings.\nThis selection is known to be in the class of NP-hard problems. We apply a\nwell-known greedy submodular maximization method on our dataset to capture 94%\nof the information using just 30% of the questions.",
    "published_date": "2018-08-19T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.06152v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.06148v5",
    "title": "Generalized Bregman and Jensen divergences which include some f-divergences",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "author_ids": [],
    "abstract": "In this paper, we introduce new classes of divergences by extending the\ndefinitions of the Bregman divergence and the skew Jensen divergence. These new\ndivergence classes (g-Bregman divergence and skew g-Jensen divergence) satisfy\nsome properties similar to the Bregman or skew Jensen divergence. We show these\ng-divergences include divergences which belong to a class of f-divergence (the\nHellinger distance, the chi-square divergence and the alpha-divergence in\naddition to the Kullback-Leibler divergence). Moreover, we derive an inequality\nbetween the g-Bregman divergence and the skew g-Jensen divergence and show this\ninequality is a generalization of Lin's inequality.",
    "published_date": "2018-08-19T00:00:00",
    "year": 2018,
    "categories": [
      "math.ST",
      "cs.IT",
      "math.IT",
      "stat.ML",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.06148v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1809.00939v1",
    "title": "Decentralized Search on Decentralized Web",
    "authors": [
      "Ziliang Lai",
      "Chris Liu",
      "Eric Lo",
      "Ben Kao",
      "Siu-Ming Yiu"
    ],
    "author_ids": [],
    "abstract": "Decentralized Web, or DWeb, is envisioned as a promising future of the Web.\nBeing decentralized, there are no dedicated web servers in DWeb; Devices that\nretrieve web contents also serve their cached data to peer devices with\nstraight privacy-preserving mechanisms. The fact that contents in DWeb are\ndistributed, replicated, and decentralized lead to a number of key advantages\nover the conventional web. These include better resiliency against network\npartitioning and distributed-denial-of-service attacks (DDoS), and better\nbrowsing experiences in terms of shorter latency and higher throughput.\nMoreover, DWeb provides tamper-proof contents because each content piece is\nuniquely identified by a cryptographic hash. DWeb also clicks well with future\nInternet architectures, such as Named Data Networking (NDN).Search engines have\nbeen an inseparable element of the Web. Contemporary (\"Web 2.0\") search\nengines, however, provide centralized services. They are thus subject to DDoS\nattacks, insider threat, and ethical issues like search bias and censorship. As\nthe web moves from being centralized to being decentralized, search engines\nought to follow. We propose QueenBee, a decentralized search engine for DWeb.\nQueenBee is so named because worker bees and honeycomb are a common metaphor\nfor distributed architectures, with the queen being the one that holds the\ncolony together. QueenBee aims to revolutionize the search engine business\nmodel by offering incentives to both content providers and peers that\nparticipate in QueenBee's page indexing and ranking operations.",
    "published_date": "2018-08-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CR",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1809.00939v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.05744v1",
    "title": "Dynamic Routing on Deep Neural Network for Thoracic Disease Classification and Sensitive Area Localization",
    "authors": [
      "Yan Shen",
      "Mingchen Gao"
    ],
    "author_ids": [],
    "abstract": "We present and evaluate a new deep neural network architecture for automatic\nthoracic disease detection on chest X-rays. Deep neural networks have shown\ngreat success in a plethora of visual recognition tasks such as image\nclassification and object detection by stacking multiple layers of\nconvolutional neural networks (CNN) in a feed-forward manner. However, the\nperformance gain by going deeper has reached bottlenecks as a result of the\ntrade-off between model complexity and discrimination power. We address this\nproblem by utilizing the recently developed routing-by agreement mechanism in\nour architecture. A novel characteristic of our network structure is that it\nextends routing to two types of layer connections (1) connection between\nfeature maps in dense layers, (2) connection between primary capsules and\nprediction capsules in final classification layer. We show that our networks\nachieve comparable results with much fewer layers in the measurement of AUC\nscore. We further show the combined benefits of model interpretability by\ngenerating Gradient-weighted Class Activation Mapping (Grad-CAM) for\nlocalization. We demonstrate our results on the NIH chestX-ray14 dataset that\nconsists of 112,120 images on 30,805 unique patients including 14 kinds of lung\ndiseases.",
    "published_date": "2018-08-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.05744v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.05686v1",
    "title": "Embedded EthiCS: Integrating Ethics Broadly Across Computer Science Education",
    "authors": [
      "Barbara J. Grosz",
      "David Gray Grant",
      "Kate Vredenburgh",
      "Jeff Behrends",
      "Lily Hu",
      "Alison Simmons",
      "Jim Waldo"
    ],
    "author_ids": [],
    "abstract": "Computing technologies have become pervasive in daily life, sometimes\nbringing unintended but harmful consequences. For students to learn to think\nnot only about what technology they could create, but also about what\ntechnology they should create, computer science curricula must expand to\ninclude ethical reasoning about the societal value and impact of these\ntechnologies. This paper presents Embedded EthiCS, a novel approach to\nintegrating ethics into computer science education that incorporates ethical\nreasoning throughout courses in the standard computer science curriculum. It\nthus changes existing courses rather than requiring wholly new courses. The\npaper describes a pilot Embedded EthiCS program that embeds philosophers\nteaching ethical reasoning directly into computer science courses. It discusses\nlessons learned and challenges to implementing such a program across different\ntypes of academic institutions.",
    "published_date": "2018-08-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.05686v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.05864v3",
    "title": "Context-Aware Visual Policy Network for Sequence-Level Image Captioning",
    "authors": [
      "Daqing Liu",
      "Zheng-Jun Zha",
      "Hanwang Zhang",
      "Yongdong Zhang",
      "Feng Wu"
    ],
    "author_ids": [],
    "abstract": "Many vision-language tasks can be reduced to the problem of sequence\nprediction for natural language output. In particular, recent advances in image\ncaptioning use deep reinforcement learning (RL) to alleviate the \"exposure\nbias\" during training: ground-truth subsequence is exposed in every step\nprediction, which introduces bias in test when only predicted subsequence is\nseen. However, existing RL-based image captioning methods only focus on the\nlanguage policy while not the visual policy (e.g., visual attention), and thus\nfail to capture the visual context that are crucial for compositional reasoning\nsuch as visual relationships (e.g., \"man riding horse\") and comparisons (e.g.,\n\"smaller cat\"). To fill the gap, we propose a Context-Aware Visual Policy\nnetwork (CAVP) for sequence-level image captioning. At every time step, CAVP\nexplicitly accounts for the previous visual attentions as the context, and then\ndecides whether the context is helpful for the current word generation given\nthe current visual attention. Compared against traditional visual attention\nthat only fixes a single image region at every step, CAVP can attend to complex\nvisual compositions over time. The whole image captioning model --- CAVP and\nits subsequent language policy network --- can be efficiently optimized\nend-to-end by using an actor-critic policy gradient method with respect to any\ncaption evaluation metric. We demonstrate the effectiveness of CAVP by\nstate-of-the-art performances on MS-COCO offline split and online server, using\nvarious metrics and sensible visualizations of qualitative visual context. The\ncode is available at https://github.com/daqingliu/CAVP",
    "published_date": "2018-08-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.05864v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.05385v3",
    "title": "On the Decision Boundary of Deep Neural Networks",
    "authors": [
      "Yu Li",
      "Lizhong Ding",
      "Xin Gao"
    ],
    "author_ids": [],
    "abstract": "While deep learning models and techniques have achieved great empirical\nsuccess, our understanding of the source of success in many aspects remains\nvery limited. In an attempt to bridge the gap, we investigate the decision\nboundary of a production deep learning architecture with weak assumptions on\nboth the training data and the model. We demonstrate, both theoretically and\nempirically, that the last weight layer of a neural network converges to a\nlinear SVM trained on the output of the last hidden layer, for both the binary\ncase and the multi-class case with the commonly used cross-entropy loss.\nFurthermore, we show empirically that training a neural network as a whole,\ninstead of only fine-tuning the last weight layer, may result in better bias\nconstant for the last weight layer, which is important for generalization. In\naddition to facilitating the understanding of deep learning, our result can be\nhelpful for solving a broad range of practical problems of deep learning, such\nas catastrophic forgetting and adversarial attacking. The experiment codes are\navailable at https://github.com/lykaust15/NN_decision_boundary",
    "published_date": "2018-08-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.05385v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.04747v2",
    "title": "A penalty scheme for monotone systems with interconnected obstacles: convergence and error estimates",
    "authors": [
      "Christoph Reisinger",
      "Yufei Zhang"
    ],
    "author_ids": [],
    "abstract": "We present a novel penalty approach for a class of quasi-variational\ninequalities (QVIs) involving monotone systems and interconnected obstacles. We\nshow that for any given positive switching cost, the solutions of the penalized\nequations converge monotonically to those of the QVIs. We estimate the\npenalization errors and are able to deduce that the optimal switching regions\nare constructed exactly. We further demonstrate that as the switching cost\ntends to zero, the QVI degenerates into an equation of HJB type, which is\napproximated by the penalized equation at the same order (up to a log factor)\nas that for positive switching cost. Numerical experiments on optimal switching\nproblems are presented to illustrate the theoretical results and to demonstrate\nthe effectiveness of the method.",
    "published_date": "2018-08-14T00:00:00",
    "year": 2018,
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC",
      "34A38, 65M12, 65K15"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04747v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.04571v1",
    "title": "Learning A Shared Transform Model for Skull to Digital Face Image Matching",
    "authors": [
      "Maneet Singh",
      "Shruti Nagpal",
      "Richa Singh",
      "Mayank Vatsa",
      "Afzel Noore"
    ],
    "author_ids": [],
    "abstract": "Human skull identification is an arduous task, traditionally requiring the\nexpertise of forensic artists and anthropologists. This paper is an effort to\nautomate the process of matching skull images to digital face images, thereby\nestablishing an identity of the skeletal remains. In order to achieve this, a\nnovel Shared Transform Model is proposed for learning discriminative\nrepresentations. The model learns robust features while reducing the\nintra-class variations between skulls and digital face images. Such a model can\nassist law enforcement agencies by speeding up the process of skull\nidentification, and reducing the manual load. Experimental evaluation performed\non two pre-defined protocols of the publicly available IdentifyMe dataset\ndemonstrates the efficacy of the proposed model.",
    "published_date": "2018-08-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04571v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.04551v1",
    "title": "Moving Object Segmentation in Jittery Videos by Stabilizing Trajectories Modeled in Kendall's Shape Space",
    "authors": [
      "Geethu Miriam Jacob",
      "Sukhendu Das"
    ],
    "author_ids": [],
    "abstract": "Moving Object Segmentation is a challenging task for jittery/wobbly videos.\nFor jittery videos, the non-smooth camera motion makes discrimination between\nforeground objects and background layers hard to solve. While most recent works\nfor moving video object segmentation fail in this scenario, our method\ngenerates an accurate segmentation of a single moving object. The proposed\nmethod performs a sparse segmentation, where frame-wise labels are assigned\nonly to trajectory coordinates, followed by the pixel-wise labeling of frames.\nThe sparse segmentation involving stabilization and clustering of trajectories\nin a 3-stage iterative process. At the 1st stage, the trajectories are\nclustered using pairwise Procrustes distance as a cue for creating an affinity\nmatrix. The 2nd stage performs a block-wise Procrustes analysis of the\ntrajectories and estimates Frechet means (in Kendall's shape space) of the\nclusters. The Frechet means represent the average trajectories of the motion\nclusters. An optimization function has been formulated to stabilize the Frechet\nmeans, yielding stabilized trajectories at the 3rd stage. The accuracy of the\nmotion clusters are iteratively refined, producing distinct groups of\nstabilized trajectories. Next, the labels obtained from the sparse segmentation\nare propagated for pixel-wise labeling of the frames, using a GraphCut based\nenergy formulation. Use of Procrustes analysis and energy minimization in\nKendall's shape space for moving object segmentation in jittery videos, is the\nnovelty of this work. Second contribution comes from experiments performed on a\ndataset formed of 20 real-world natural jittery videos, with manually annotated\nground truth. Experiments are done with controlled levels of artificial jitter\non videos of SegTrack2 dataset. Qualitative and quantitative results indicate\nthe superiority of the proposed method.",
    "published_date": "2018-08-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04551v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.04422v1",
    "title": "Social media and mobility landscape: uncovering spatial patterns of urban human mobility with multi source data",
    "authors": [
      "Yilan Cui",
      "Xing Xie",
      "Yi Liu"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a three-step methodological framework, including\nlocation identification, bias modification, and out-of-sample validation, so as\nto promote human mobility analysis with social media data. More specifically,\nwe propose ways of identifying personal activity-specific places and commuting\npatterns in Beijing, China, based on Weibo (China's Twitter) check-in records,\nas well as modifying sample bias of check-in data with population synthesis\ntechnique. An independent citywide travel logistic survey is used as the\nbenchmark for validating the results. Obvious differences are discerned from\nWeibo users' and survey respondents' activity-mobility patterns, while there is\na large variation of population representativeness between data from the two\nsources. After bias modification, the similarity coefficient between commuting\ndistance distributions of Weibo data and survey observations increases\nsubstantially from 23% to 63%. Synthetic data proves to be a satisfactory\ncost-effective alternative source of mobility information. The proposed\nframework can inform many applications related to human mobility, ranging from\ntransportation, through urban planning to transport emission modelling.",
    "published_date": "2018-08-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04422v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.04039v1",
    "title": "Dynamic Pricing for Revenue Maximization in Mobile Social Data Market with Network Effects",
    "authors": [
      "Zehui Xiong",
      "Dusit Niyato",
      "Ping Wang",
      "Zhu Han",
      "Yang Zhang"
    ],
    "author_ids": [],
    "abstract": "Mobile data demand is increasing tremendously in wireless social networks,\nand thus an efficient pricing scheme for social-enabled services is urgently\nneeded. Though static pricing is dominant in the actual data market, price\nintuitively ought to be dynamically changed to yield greater revenue. The\ncritical question is how to design the optimal dynamic pricing scheme, with\nprospects for maximizing the expected long-term revenue. In this paper, we\nstudy the sequential dynamic pricing scheme of a monopoly mobile network\noperator in the social data market. In the market, the operator, i.e., the\nseller, individually offers each mobile user, i.e., the buyer, a certain price\nin multiple time periods dynamically and repeatedly. The proposed scheme\nexploits the network effects in the mobile users' behaviors that boost the\nsocial data demand. Furthermore, due to limited radio resource, the impact of\nwireless network congestion is taken into account in the pricing scheme.\nThereafter, we propose a modified sequential pricing policy in order to ensure\nsocial fairness among mobile users in terms of their individual utilities. We\nanalytically demonstrate that the proposed sequential dynamic pricing scheme\ncan help the operator gain greater revenue and mobile users achieve higher\ntotal utilities than those of the baseline static pricing scheme. To gain more\ninsights, we further study a simultaneous dynamic pricing scheme in which the\noperator determines the pricing strategy at the beginning of each time period.\nMobile users decide on their individual data demand in each time period\nsimultaneously, considering the network effects in the social domain and the\ncongestion effects in the network domain. We construct the social graph using\nErd\\H{o}s-R\\'enyi (ER) model and the real dataset based social network for\nperformance evaluation.",
    "published_date": "2018-08-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04039v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.03364v1",
    "title": "A Panel Quantile Approach to Attrition Bias in Big Data: Evidence from a Randomized Experiment",
    "authors": [
      "Matthew Harding",
      "Carlos Lamarche"
    ],
    "author_ids": [],
    "abstract": "This paper introduces a quantile regression estimator for panel data models\nwith individual heterogeneity and attrition. The method is motivated by the\nfact that attrition bias is often encountered in Big Data applications. For\nexample, many users sign-up for the latest program but few remain active users\nseveral months later, making the evaluation of such interventions inherently\nvery challenging. Building on earlier work by Hausman and Wise (1979), we\nprovide a simple identification strategy that leads to a two-step estimation\nprocedure. In the first step, the coefficients of interest in the selection\nequation are consistently estimated using parametric or nonparametric methods.\nIn the second step, standard panel quantile methods are employed on a subset of\nweighted observations. The estimator is computationally easy to implement in\nBig Data applications with a large number of subjects. We investigate the\nconditions under which the parameter estimator is asymptotically Gaussian and\nwe carry out a series of Monte Carlo simulations to investigate the finite\nsample properties of the estimator. Lastly, using a simulation exercise, we\napply the method to the evaluation of a recent Time-of-Day electricity pricing\nexperiment inspired by the work of Aigner and Hausman (1980).",
    "published_date": "2018-08-09T00:00:00",
    "year": 2018,
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.AP",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.03364v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.02784v1",
    "title": "Schools are segregated by educational outcomes in the digital space",
    "authors": [
      "Ivan Smirnov"
    ],
    "author_ids": [],
    "abstract": "The Internet provides students with a unique opportunity to connect and\nmaintain social ties with peers from other schools, irrespective of how far\nthey are from each other. However, little is known about the real structure of\nsuch online relationships. In this paper, we investigate the structure of\ninterschool friendship on a popular social networking site. We use data from\n36,951 students from 590 schools of a large European city. We find that the\nprobability of a friendship tie between students from neighboring schools is\nhigh and that it decreases with the distance between schools following the\npower law. We also find that students are more likely to be connected if the\neducational outcomes of their schools are similar. We show that this fact is\nnot a consequence of residential segregation. While high- and low-performing\nschools are evenly distributed across the city, this is not the case for the\ndigital space, where schools turn out to be segregated by educational outcomes.\nThere is no significant correlation between the educational outcomes of a\nschool and its geographical neighbors; however, there is a strong correlation\nbetween the educational outcomes of a school and its digital neighbors. These\nresults challenge the common assumption that the Internet is a borderless\nspace, and may have important implications for the understanding of educational\ninequality in the digital age.",
    "published_date": "2018-08-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02784v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.02780v1",
    "title": "Cache Aided Communications with Multiple Antennas at Finite SNR",
    "authors": [
      "Itsik Bergel",
      "Soheil Mohajer"
    ],
    "author_ids": [],
    "abstract": "We study the problem of cache-aided communication for cellular networks with\nmulti-user and multiple antennas at finite signal-to-noise ratio. Users are\nassumed to have non-symmetric links, modeled by wideband fading channels. We\nshow that the problem can be formulated as a linear program, whose solution\nprovides a joint cache allocation along with pre-fetching and fetching schemes\nthat minimize the duration of the communication in the delivery phase. The\nsuggested scheme uses zero-forcing and cached interference subtraction and\nhence allow each user to be served at the rate of its own channel. Thus, this\nscheme is better than the previously published schemes that are compromised by\nthe poorest user in the communication group. We also consider a special case of\nthe parameters for which we can derive a closed form solution and formulate the\noptimal power, rate and cache optimization. This special case shows that the\ngain of MIMO coded caching goes beyond the throughput. In particular, it is\nshown that in this case, the cache is used to balance the users such that\nfairness and throughput are no longer contradicting. More specifically, in this\ncase, strict fairness is achieved jointly with maximizing the network\nthroughput.",
    "published_date": "2018-08-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02780v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.02585v2",
    "title": "Reachability Analysis Using Dissipation Inequalities For Uncertain Nonlinear Systems",
    "authors": [
      "He Yin",
      "Andrew Packard",
      "Murat Arcak",
      "Peter Seiler"
    ],
    "author_ids": [],
    "abstract": "We propose a method to outer bound forward reachable sets on finite horizons\nfor uncertain nonlinear systems with polynomial dynamics. This method makes use\nof time-dependent polynomial storage functions that satisfy appropriate\ndissipation inequalities that account for time-varying uncertain parameters, L2\ndisturbances, and perturbations characterized by integral quadratic constraints\n(IQCs) with both hard and soft factorizations. In fact, to our knowledge, this\nis the first result introducing IQCs to reachability analysis, thus allowing\nfor various types of uncertainty, including unmodeled dynamics. The generalized\nS-procedure and Sum-of-Squares techniques are used to derive algorithms with\nthe goal of finding the tightest outer bound with a desired shape. Both\npedagogical and practically motivated examples are presented, including a\n7-state F-18 aircraft model.",
    "published_date": "2018-08-07T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02585v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.02517v3",
    "title": "Fair Packing and Covering on a Relative Scale",
    "authors": [
      "Jelena Diakonikolas",
      "Maryam Fazel",
      "Lorenzo Orecchia"
    ],
    "author_ids": [],
    "abstract": "Fair resource allocation is a fundamental optimization problem with\napplications in operations research, networking, and economic and game theory.\nResearch in these areas has led to the general acceptance of a class of\n$\\alpha$-fair utility functions parameterized by $\\alpha \\in [0, \\infty]$. We\nconsider $\\alpha$-fair packing -- the problem of maximizing $\\alpha$-fair\nutilities under positive linear constraints -- and provide a simple first-order\nmethod for solving it with relative-error guarantees. The method has a\nsignificantly lower convergence time than the state of the art, and to analyze\nit, we leverage the Approximate Duality Gap Technique, which provides an\nintuitive interpretation of the convergence argument. Finally, we introduce a\nnatural counterpart of $\\alpha$-fairness for minimization problems and motivate\nits usage in the context of fair task allocation. This generalization yields\n$\\alpha$-fair covering problems, for which we provide the first\nnear-linear-time solvers with relative-error guarantees.",
    "published_date": "2018-08-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS",
      "cs.NI",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02517v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.02212v1",
    "title": "Contemplating Visual Emotions: Understanding and Overcoming Dataset Bias",
    "authors": [
      "Rameswar Panda",
      "Jianming Zhang",
      "Haoxiang Li",
      "Joon-Young Lee",
      "Xin Lu",
      "Amit K. Roy-Chowdhury"
    ],
    "author_ids": [],
    "abstract": "While machine learning approaches to visual emotion recognition offer great\npromise, current methods consider training and testing models on small scale\ndatasets covering limited visual emotion concepts. Our analysis identifies an\nimportant but long overlooked issue of existing visual emotion benchmarks in\nthe form of dataset biases. We design a series of tests to show and measure how\nsuch dataset biases obstruct learning a generalizable emotion recognition\nmodel. Based on our analysis, we propose a webly supervised approach by\nleveraging a large quantity of stock image data. Our approach uses a simple yet\neffective curriculum guided training strategy for learning discriminative\nemotion features. We discover that the models learned using our large scale\nstock image dataset exhibit significantly better generalization ability than\nthe existing datasets without the manual collection of even a single label.\nMoreover, visual representation learned using our approach holds a lot of\npromise across a variety of tasks on different image and video datasets.",
    "published_date": "2018-08-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02212v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.02004v2",
    "title": "Robust Secrecy Energy Efficient Beamforming in MISOME-SWIPT Systems With Proportional Fairness",
    "authors": [
      "Yanjie Dong",
      "Md. Jahangir Hossain",
      "Julian Cheng",
      "Victor C. M. Leung"
    ],
    "author_ids": [],
    "abstract": "The joint design of beamforming vector and artificial noise covariance matrix\nis investigated for multiple-input-single-output-multiple-eavesdropper\nsimultaneous wireless information and power transferring (MISOME-SWIPT)\nsystems. A secrecy energy efficiency (SEE) maximization problem is formulated\nin the MISOME-SWIPT system with imperfect channel state information and\nproportional secrecy rate constraints. Since the formulated SEE maximization\nproblem is non-convex, it is first recast into a series of convex problems in\norder to obtain the optimal solution with a reasonable computational\ncomplexity. Numerical results are used to verify the performance of the\nproposed algorithm and to reveal practical insights.",
    "published_date": "2018-08-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.02004v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.01664v3",
    "title": "Structured Adversarial Attack: Towards General Implementation and Better Interpretability",
    "authors": [
      "Kaidi Xu",
      "Sijia Liu",
      "Pu Zhao",
      "Pin-Yu Chen",
      "Huan Zhang",
      "Quanfu Fan",
      "Deniz Erdogmus",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "author_ids": [],
    "abstract": "When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016).",
    "published_date": "2018-08-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.01664v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.01624v1",
    "title": "On the Fairness of Quality-based Data Markets",
    "authors": [
      "Dan Zhang",
      "Hongzhi Wang",
      "Xiaoou Ding",
      "Yice Zhang",
      "Jianzhong Li",
      "Hong Gao"
    ],
    "author_ids": [],
    "abstract": "For data pricing, data quality is a factor that must be considered. To keep\nthe fairness of data market from the aspect of data quality, we proposed a fair\ndata market that considers data quality while pricing. To ensure fairness, we\nfirst design a quality-driven data pricing strategy. Then based on the\nstrategy, a fairness assurance mechanism for quality-driven data marketplace is\nproposed. In this mechanism, we ensure that savvy consumers cannot cheat the\nsystem and users can verify each consumption with Trusted Third Party (TTP)\nthat they are charged properly. Based on this mechanism, we develop a fair\nquality-driven data market system. Extensive experiments are performed to\nverify the effectiveness of proposed techniques. Experimental results show that\nour quality-driven data pricing strategy could assign a reasonable price to the\ndata according to data quality and the fairness assurance mechanism could\neffectively protect quality-driven data pricing from potential cheating.",
    "published_date": "2018-08-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.01624v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.01531v3",
    "title": "Global Convergence to the Equilibrium of GANs using Variational Inequalities",
    "authors": [
      "Ian Gemp",
      "Sridhar Mahadevan"
    ],
    "author_ids": [],
    "abstract": "In optimization, the negative gradient of a function denotes the direction of\nsteepest descent. Furthermore, traveling in any direction orthogonal to the\ngradient maintains the value of the function. In this work, we show that these\northogonal directions that are ignored by gradient descent can be critical in\nequilibrium problems. Equilibrium problems have drawn heightened attention in\nmachine learning due to the emergence of the Generative Adversarial Network\n(GAN). We use the framework of Variational Inequalities to analyze popular\ntraining algorithms for a fundamental GAN variant: the Wasserstein\nLinear-Quadratic GAN. We show that the steepest descent direction causes\ndivergence from the equilibrium, and convergence to the equilibrium is achieved\nthrough following a particular orthogonal direction. We call this successful\ntechnique Crossing-the-Curl, named for its mathematical derivation as well as\nits intuition: identify the game's axis of rotation and move \"across\" space in\nthe direction towards smaller \"curling\".",
    "published_date": "2018-08-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.01531v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.01498v2",
    "title": "Amortized Channel Divergence for Asymptotic Quantum Channel Discrimination",
    "authors": [
      "Mark M. Wilde",
      "Mario Berta",
      "Christoph Hirche",
      "Eneet Kaur"
    ],
    "author_ids": [],
    "abstract": "It is well known that for the discrimination of classical and quantum\nchannels in the finite, non-asymptotic regime, adaptive strategies can give an\nadvantage over non-adaptive strategies. However, Hayashi [IEEE Trans. Inf.\nTheory 55(8), 3807 (2009)] showed that in the asymptotic regime, the\nexponential error rate for the discrimination of classical channels is not\nimproved in the adaptive setting. We extend this result in several ways. First,\nwe establish the strong Stein's lemma for classical-quantum channels by showing\nthat asymptotically the exponential error rate for classical-quantum channel\ndiscrimination is not improved by adaptive strategies. Second, we recover many\nother classes of channels for which adaptive strategies do not lead to an\nasymptotic advantage. Third, we give various converse bounds on the power of\nadaptive protocols for general asymptotic quantum channel discrimination.\nIntriguingly, it remains open whether adaptive protocols can improve the\nexponential error rate for quantum channel discrimination in the asymmetric\nStein setting. Our proofs are based on the concept of amortized\ndistinguishability of quantum channels, which we analyse using data-processing\ninequalities.",
    "published_date": "2018-08-04T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.01498v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1808.01486v3",
    "title": "Spatial Deep Learning for Wireless Scheduling",
    "authors": [
      "Wei Cui",
      "Kaiming Shen",
      "Wei Yu"
    ],
    "author_ids": [],
    "abstract": "The optimal scheduling of interfering links in a dense wireless network with\nfull frequency reuse is a challenging task. The traditional method involves\nfirst estimating all the interfering channel strengths then optimizing the\nscheduling based on the model. This model-based method is however resource\nintensive and computationally hard because channel estimation is expensive in\ndense networks; furthermore, finding even a locally optimal solution of the\nresulting optimization problem may be computationally complex. This paper shows\nthat by using a deep learning approach, it is possible to bypass the channel\nestimation and to schedule links efficiently based solely on the geographic\nlocations of the transmitters and the receivers, due to the fact that in many\npropagation environments, the wireless channel strength is largely a function\nof the distance dependent path-loss. This is accomplished by unsupervised\ntraining over randomly deployed networks, and by using a novel neural network\narchitecture that computes the geographic spatial convolutions of the\ninterfering or interfered neighboring nodes along with subsequent multiple\nfeedback stages to learn the optimum solution. The resulting neural network\ngives near-optimal performance for sum-rate maximization and is capable of\ngeneralizing to larger deployment areas and to deployments of different link\ndensities. Moreover, to provide fairness, this paper proposes a novel\nscheduling approach that utilizes the sum-rate optimal scheduling algorithm\nover judiciously chosen subsets of links for maximizing a proportional fairness\nobjective over the network. The proposed approach shows highly competitive and\ngeneralizable network utility maximization results.",
    "published_date": "2018-08-04T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SP",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.01486v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.00588v1",
    "title": "Weather Classification: A new multi-class dataset, data augmentation approach and comprehensive evaluations of Convolutional Neural Networks",
    "authors": [
      "Jose Carlos Villarreal Guerra",
      "Zeba Khanam",
      "Shoaib Ehsan",
      "Rustam Stolkin",
      "Klaus McDonald-Maier"
    ],
    "author_ids": [],
    "abstract": "Weather conditions often disrupt the proper functioning of transportation\nsystems. Present systems either deploy an array of sensors or use an in-vehicle\ncamera to predict weather conditions. These solutions have resulted in\nincremental cost and limited scope. To ensure smooth operation of all\ntransportation services in all-weather conditions, a reliable detection system\nis necessary to classify weather in wild. The challenges involved in solving\nthis problem is that weather conditions are diverse in nature and there is an\nabsence of discriminate features among various weather conditions. The existing\nworks to solve this problem have been scene specific and have targeted\nclassification of two categories of weather. In this paper, we have created a\nnew open source dataset consisting of images depicting three classes of weather\ni.e rain, snow and fog called RFS Dataset. A novel algorithm has also been\nproposed which has used super pixel delimiting masks as a form of data\naugmentation, leading to reasonable results with respect to ten Convolutional\nNeural Network architectures.",
    "published_date": "2018-08-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.00588v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.00313v1",
    "title": "A Network Structure to Explicitly Reduce Confusion Errors in Semantic Segmentation",
    "authors": [
      "Qichuan Geng",
      "Xinyu Huang",
      "Zhong Zhou",
      "Ruigang Yang"
    ],
    "author_ids": [],
    "abstract": "Confusing classes that are ubiquitous in real world often degrade performance\nfor many vision related applications like object detection, classification, and\nsegmentation. The confusion errors are not only caused by similar visual\npatterns but also amplified by various factors during the training of our\ndesigned models, such as reduced feature resolution in the encoding process or\nimbalanced data distributions. A large amount of deep learning based network\nstructures has been proposed in recent years to deal with these individual\nfactors and improve network performance. However, to our knowledge, no existing\nwork in semantic image segmentation is designed to tackle confusion errors\nexplicitly. In this paper, we present a novel and general network structure\nthat reduces confusion errors in more direct manner and apply the network for\nsemantic segmentation. There are two major contributions in our network\nstructure: 1) We ensemble subnets with heterogeneous output spaces based on the\ndiscriminative confusing groups. The training for each subnet can distinguish\nconfusing classes within the group without affecting unrelated classes outside\nthe group. 2) We propose an improved cross-entropy loss function that maximizes\nthe probability assigned to the correct class and penalizes the probabilities\nassigned to the confusing classes at the same time. Our network structure is a\ngeneral structure and can be easily adapted to any other networks to further\nreduce confusion errors. Without any changes in the feature encoder and\npost-processing steps, our experiments demonstrate consistent and significant\nimprovements on different baseline models on Cityscapes and PASCAL VOC datasets\n(e.g., 3.05% over ResNet-101 and 1.30% over ResNet-38).",
    "published_date": "2018-08-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.00313v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.00171v1",
    "title": "Shuffle-Then-Assemble: Learning Object-Agnostic Visual Relationship Features",
    "authors": [
      "Xu Yang",
      "Hanwang Zhang",
      "Jianfei Cai"
    ],
    "author_ids": [],
    "abstract": "Due to the fact that it is prohibitively expensive to completely annotate\nvisual relationships, i.e., the (obj1, rel, obj2) triplets, relationship models\nare inevitably biased to object classes of limited pairwise patterns, leading\nto poor generalization to rare or unseen object combinations. Therefore, we are\ninterested in learning object-agnostic visual features for more generalizable\nrelationship models. By \"agnostic\", we mean that the feature is less likely\nbiased to the classes of paired objects. To alleviate the bias, we propose a\nnovel \\texttt{Shuffle-Then-Assemble} pre-training strategy. First, we discard\nall the triplet relationship annotations in an image, leaving two unpaired\nobject domains without obj1-obj2 alignment. Then, our feature learning is to\nrecover possible obj1-obj2 pairs. In particular, we design a cycle of residual\ntransformations between the two domains, to capture shared but not\nobject-specific visual patterns. Extensive experiments on two visual\nrelationship benchmarks show that by using our pre-trained features, naive\nrelationship models can be consistently improved and even outperform other\nstate-of-the-art relationship models. Code has been made available at:\n\\url{https://github.com/yangxuntu/vrd}.",
    "published_date": "2018-08-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.00171v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.00089v2",
    "title": "Towards Composable Bias Rating of AI Services",
    "authors": [
      "Biplav Srivastava",
      "Francesca Rossi"
    ],
    "author_ids": [],
    "abstract": "A new wave of decision-support systems are being built today using AI\nservices that draw insights from data (like text and video) and incorporate\nthem in human-in-the-loop assistance. However, just as we expect humans to be\nethical, the same expectation needs to be met by automated systems that\nincreasingly get delegated to act on their behalf. A very important aspect of\nan ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias\noccurs when the data distribution is not representative enough of the natural\nphenomenon one wants to model and reason about. The possibly biased behavior of\na service is hard to detect and handle if the AI service is merely being used\nand not developed from scratch, since the training data set is not available.\nIn this situation, we envisage a 3rd party rating agency that is independent of\nthe API producer or consumer and has its own set of biased and unbiased data,\nwith customizable distributions. We propose a 2-step rating approach that\ngenerates bias ratings signifying whether the AI service is unbiased\ncompensating, data-sensitive biased, or biased. The approach also works on\ncomposite services. We implement it in the context of text translation and\nreport interesting results.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.00089v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.00023v3",
    "title": "The Measure and Mismeasure of Fairness",
    "authors": [
      "Sam Corbett-Davies",
      "Johann D. Gaebler",
      "Hamed Nilforoshan",
      "Ravi Shroff",
      "Sharad Goel"
    ],
    "author_ids": [],
    "abstract": "The field of fair machine learning aims to ensure that decisions guided by\nalgorithms are equitable. Over the last decade, several formal, mathematical\ndefinitions of fairness have gained prominence. Here we first assemble and\ncategorize these definitions into two broad families: (1) those that constrain\nthe effects of decisions on disparities; and (2) those that constrain the\neffects of legally protected characteristics, like race and gender, on\ndecisions. We then show, analytically and empirically, that both families of\ndefinitions typically result in strongly Pareto dominated decision policies.\nFor example, in the case of college admissions, adhering to popular formal\nconceptions of fairness would simultaneously result in lower student-body\ndiversity and a less academically prepared class, relative to what one could\nachieve by explicitly tailoring admissions policies to achieve desired\noutcomes. In this sense, requiring that these fairness definitions hold can,\nperversely, harm the very groups they were designed to protect. In contrast to\naxiomatic notions of fairness, we argue that the equitable design of algorithms\nrequires grappling with their context-specific consequences, akin to the\nequitable design of policy. We conclude by listing several open challenges in\nfair machine learning and offering strategies to ensure algorithms are better\naligned with policy goals.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.00023v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.11720v2",
    "title": "Regional Multi-scale Approach for Visually Pleasing Explanations of Deep Neural Networks",
    "authors": [
      "Dasom Seo",
      "Kanghan Oh",
      "Il-Seok Oh"
    ],
    "author_ids": [],
    "abstract": "Recently, many methods to interpret and visualize deep neural network\npredictions have been proposed and significant progress has been made. However,\na more class-discriminative and visually pleasing explanation is required.\nThus, this paper proposes a region-based approach that estimates feature\nimportance in terms of appropriately segmented regions. By fusing the saliency\nmaps generated from multi-scale segmentations, a more class-discriminative and\nvisually pleasing map is obtained. We incorporate this regional multi-scale\nconcept into a prediction difference method that is model-agnostic. An input\nimage is segmented in several scales using the super-pixel method, and\nexclusion of a region is simulated by sampling a normal distribution\nconstructed using the boundary prior. The experimental results demonstrate that\nthe regional multi-scale method produces much more class-discriminative and\nvisually pleasing saliency maps.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11720v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.11714v2",
    "title": "Gender Bias in Neural Natural Language Processing",
    "authors": [
      "Kaiji Lu",
      "Piotr Mardziel",
      "Fangjing Wu",
      "Preetam Amancharla",
      "Anupam Datta"
    ],
    "author_ids": [],
    "abstract": "We examine whether neural natural language processing (NLP) systems reflect\nhistorical biases in training data. We define a general benchmark to quantify\ngender bias in a variety of neural NLP tasks. Our empirical evaluation with\nstate-of-the-art neural coreference resolution and textbook RNN-based language\nmodels trained on benchmark datasets finds significant gender bias in how\nmodels view occupations. We then mitigate bias with CDA: a generic methodology\nfor corpus augmentation via causal interventions that breaks associations\nbetween gendered and gender-neutral words. We empirically show that CDA\neffectively decreases gender bias while preserving accuracy. We also explore\nthe space of mitigation strategies with CDA, a prior approach to word embedding\ndebiasing (WED), and their compositions. We show that CDA outperforms WED,\ndrastically so when word embeddings are trained. For pre-trained embeddings,\nthe two methods can be effectively composed. We also find that as training\nproceeds on the original data set with gradient descent the gender bias grows\nas the loss reduces, indicating that the optimization encourages bias; CDA\nmitigates this behavior.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11714v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.11657v7",
    "title": "Removing Bias and Incentivizing Precision in Peer-grading",
    "authors": [
      "Anujit Chakraborty",
      "Jatin Jindal",
      "Swaprava Nath"
    ],
    "author_ids": [],
    "abstract": "We study peer-grading with competitive graders who enjoy a higher utility\nwhen their peers get lower scores. We propose a new mechanism, PEQA, that\nincentivizes such graders through a score-assignment rule which aggregates the\nfinal score from multiple peer-evaluations, and a grading performance score\nthat rewards performance in the peer-grading exercise. PEQA makes grader-bias\nirrelevant. Additionally, under PEQA, a peer-grader's utility increases\nmonotonically with the reliability of her grading, irrespective of her\ncompetitiveness and how her co-graders act. In a reasonably general class of\nscore assignment rules, PEQA uniquely satisfies this utility- reliability\nmonotonicity. When grading is costly and costs are private information, a\nmodified version of PEQA implements the socially optimal effort choices in an\nequilibrium of the peer-evaluation game. Data from our classroom experiments\nconfirm our theoretical assumptions and show that PEQA outperforms the popular\nmedian mechanism.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11657v7",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.11632v2",
    "title": "Scaling and bias codes for modeling speaker-adaptive DNN-based speech synthesis systems",
    "authors": [
      "Hieu-Thi Luong",
      "Junichi Yamagishi"
    ],
    "author_ids": [],
    "abstract": "Most neural-network based speaker-adaptive acoustic models for speech\nsynthesis can be categorized into either layer-based or input-code approaches.\nAlthough both approaches have their own pros and cons, most existing works on\nspeaker adaptation focus on improving one or the other. In this paper, after we\nfirst systematically overview the common principles of neural-network based\nspeaker-adaptive models, we show that these approaches can be represented in a\nunified framework and can be generalized further. More specifically, we\nintroduce the use of scaling and bias codes as generalized means for\nspeaker-adaptive transformation. By utilizing these codes, we can create a more\nefficient factorized speaker-adaptive model and capture advantages of both\napproaches while reducing their disadvantages. The experiments show that the\nproposed method can improve the performance of speaker adaptation compared with\nspeaker adaptation based on the conventional input code.",
    "published_date": "2018-07-31T00:00:00",
    "year": 2018,
    "categories": [
      "eess.AS",
      "cs.SD",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11632v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.11245v2",
    "title": "Recurrently Exploring Class-wise Attention in A Hybrid Convolutional and Bidirectional LSTM Network for Multi-label Aerial Image Classification",
    "authors": [
      "Yuansheng Hua",
      "Lichao Mou",
      "Xiao Xiang Zhu"
    ],
    "author_ids": [],
    "abstract": "Aerial image classification is of great significance in remote sensing\ncommunity, and many researches have been conducted over the past few years.\nAmong these studies, most of them focus on categorizing an image into one\nsemantic label, while in the real world, an aerial image is often associated\nwith multiple labels, e.g., multiple object-level labels in our case. Besides,\na comprehensive picture of present objects in a given high resolution aerial\nimage can provide more in-depth understanding of the studied region. For these\nreasons, aerial image multi-label classification has been attracting increasing\nattention. However, one common limitation shared by existing methods in the\ncommunity is that the co-occurrence relationship of various classes, so called\nclass dependency, is underexplored and leads to an inconsiderate decision. In\nthis paper, we propose a novel end-to-end network, namely class-wise\nattention-based convolutional and bidirectional LSTM network (CA-Conv-BiLSTM),\nfor this task. The proposed network consists of three indispensable components:\n1) a feature extraction module, 2) a class attention learning layer, and 3) a\nbidirectional LSTM-based sub-network. Particularly, the feature extraction\nmodule is designed for extracting fine-grained semantic feature maps, while the\nclass attention learning layer aims at capturing discriminative class-specific\nfeatures. As the most important part, the bidirectional LSTM-based sub-network\nmodels the underlying class dependency in both directions and produce\nstructured multiple object labels. Experimental results on UCM multi-label\ndataset and DFC15 multi-label dataset validate the effectiveness of our model\nquantitatively and qualitatively.",
    "published_date": "2018-07-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11245v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.11130v4",
    "title": "Geo-Supervised Visual Depth Prediction",
    "authors": [
      "Xiaohan Fei",
      "Alex Wong",
      "Stefano Soatto"
    ],
    "author_ids": [],
    "abstract": "We propose using global orientation from inertial measurements, and the bias\nit induces on the shape of objects populating the scene, to inform visual 3D\nreconstruction. We test the effect of using the resulting prior in depth\nprediction from a single image, where the normal vectors to surfaces of objects\nof certain classes tend to align with gravity or be orthogonal to it. Adding\nsuch a prior to baseline methods for monocular depth prediction yields\nimprovements beyond the state-of-the-art and illustrates the power of gravity\nas a supervisory signal.",
    "published_date": "2018-07-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11130v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.10978v4",
    "title": "Energy Contract Settlements through Automated Negotiation in Residential Cooperatives",
    "authors": [
      "Shantanu Chakraborty",
      "Tim Baarslag",
      "Michael Kaisers"
    ],
    "author_ids": [],
    "abstract": "This paper presents an automated peer-to-peer (P2P) negotiation strategy for\nsettling energy contracts among prosumers in a Residential Energy Cooperative\n(REC) considering heterogeneous prosumer preferences. The heterogeneity arises\nfrom prosumers' evaluation of energy contracts through multiple societal and\nenvironmental criteria and the prosumers' private preferences over those\ncriteria. The prosumers engage in bilateral negotiations with peers to mutually\nagree on periodical energy contracts/loans that consist of an energy volume to\nbe exchanged at that period and the return time of the exchanged energy. The\nprosumers keep an ordered preference profile of possible energy contracts by\nevaluating the contracts from their own valuations on the entailed criteria,\nand iteratively offer the peers contracts until an agreement is formed. A\nprosumer embeds the valuations into a utility function that further considers\nuncertainties imposed by demand and generation profiles. Empirical evaluation\non real demand, generation and storage profiles illustrates that the proposed\nnegotiation based strategy is able to increase the system efficiency (measured\nby utilitarian social welfare) and fairness (measured by Nash social welfare)\nover a baseline strategy and an individual flexibility control strategy. We\nthus elicit system benefits from P2P flexibility exchange already with few\nagents and without central coordination, providing a simple yet flexible and\neffective paradigm that may complement existing markets.",
    "published_date": "2018-07-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10978v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.11919v1",
    "title": "Efficiency, Sequenceability and Deal-Optimality in Fair Division of Indivisible Goods",
    "authors": [
      "Aurélie Beynier",
      "Sylvain Bouveret",
      "Michel Lemaître",
      "Nicolas Maudet",
      "Simon Rey"
    ],
    "author_ids": [],
    "abstract": "In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is as\nfollows: at each stage, a designated agent picks one object among those that\nremain. Another intuitive way to obtain an allocation is to give objects to\nagents in the first place, and to let agents exchange them as long as such\n\"deals\" are beneficial. This paper investigates these notions, when agents have\nadditive preferences over objects, and unveils surprising connections between\nthem, and with other efficiency and fairness notions. In particular, we show\nthat an allocation is sequenceable iff it is optimal for a certain type of\ndeals, namely cycle deals involving a single object. Furthermore, any\nPareto-optimal allocation is sequenceable, but not the converse. Regarding\nfairness, we show that an allocation can be envy-free and non-sequenceable, but\nthat every competitive equilibrium with equal incomes is sequenceable. To\ncomplete the picture, we show how some domain restrictions may affect the\nrelations between these notions. Finally, we experimentally explore the links\nbetween the scales of efficiency and fairness.",
    "published_date": "2018-07-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11919v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.10684v4",
    "title": "Fair allocation of combinations of indivisible goods and chores",
    "authors": [
      "Haris Aziz",
      "Ioannis Caragiannis",
      "Ayumi Igarashi",
      "Toby Walsh"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of fairly dividing a set of items. Much of the fair\ndivision literature assumes that the items are `goods' i.e., they yield\npositive utility for the agents. There is also some work where the items are\n`chores' that yield negative utility for the agents. In this paper, we consider\na more general scenario where an agent may have negative or positive utility\nfor each item. This framework captures, e.g., fair task assignment, where\nagents can have both positive and negative utilities for each task. We show\nthat whereas some of the positive axiomatic and computational results extend to\nthis more general setting, others do not. We present several new and efficient\nalgorithms for finding fair allocations in this general setting. We also point\nout several gaps in the literature regarding the existence of allocations\nsatisfying certain fairness and efficiency properties and further study the\ncomplexity of computing such allocations.",
    "published_date": "2018-07-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10684v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.11386v1",
    "title": "On the Inability of Markov Models to Capture Criticality in Human Mobility",
    "authors": [
      "Vaibhav Kulkarni",
      "Abhijit Mahalunkar",
      "Benoit Garbinato",
      "John D. Kelleher"
    ],
    "author_ids": [],
    "abstract": "We examine the non-Markovian nature of human mobility by exposing the\ninability of Markov models to capture criticality in human mobility. In\nparticular, the assumed Markovian nature of mobility was used to establish a\ntheoretical upper bound on the predictability of human mobility (expressed as a\nminimum error probability limit), based on temporally correlated entropy. Since\nits inception, this bound has been widely used and empirically validated using\nMarkov chains. We show that recurrent-neural architectures can achieve\nsignificantly higher predictability, surpassing this widely used upper bound.\nIn order to explain this anomaly, we shed light on several underlying\nassumptions in previous research works that has resulted in this bias. By\nevaluating the mobility predictability on real-world datasets, we show that\nhuman mobility exhibits scale-invariant long-range correlations, bearing\nsimilarity to a power-law decay. This is in contrast to the initial assumption\nthat human mobility follows an exponential decay. This assumption of\nexponential decay coupled with Lempel-Ziv compression in computing Fano's\ninequality has led to an inaccurate estimation of the predictability upper\nbound. We show that this approach inflates the entropy, consequently lowering\nthe upper bound on human mobility predictability. We finally highlight that\nthis approach tends to overlook long-range correlations in human mobility. This\nexplains why recurrent-neural architectures that are designed to handle\nlong-range structural correlations surpass the previously computed upper bound\non mobility predictability.",
    "published_date": "2018-07-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.11386v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.10552v1",
    "title": "Improving High Resolution Histology Image Classification with Deep Spatial Fusion Network",
    "authors": [
      "Yongxiang Huang",
      "Albert Chi-shing Chung"
    ],
    "author_ids": [],
    "abstract": "Histology imaging is an essential diagnosis method to finalize the grade and\nstage of cancer of different tissues, especially for breast cancer diagnosis.\nSpecialists often disagree on the final diagnosis on biopsy tissue due to the\ncomplex morphological variety. Although convolutional neural networks (CNN)\nhave advantages in extracting discriminative features in image classification,\ndirectly training a CNN on high resolution histology images is computationally\ninfeasible currently. Besides, inconsistent discriminative features often\ndistribute over the whole histology image, which incurs challenges in\npatch-based CNN classification method. In this paper, we propose a novel\narchitecture for automatic classification of high resolution histology images.\nFirst, an adapted residual network is employed to explore hierarchical features\nwithout attenuation. Second, we develop a robust deep fusion network to utilize\nthe spatial relationship between patches and learn to correct the prediction\nbias generated from inconsistent discriminative feature distribution. The\nproposed method is evaluated using 10-fold cross-validation on 400 high\nresolution breast histology images with balanced labels and reports 95%\naccuracy on 4-class classification and 98.5% accuracy, 99.6% AUC on 2-class\nclassification (carcinoma and non-carcinoma), which substantially outperforms\nprevious methods and close to pathologist performance.",
    "published_date": "2018-07-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10552v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1808.04437v1",
    "title": "Discriminative multi-view Privileged Information learning for image re-ranking",
    "authors": [
      "Jun Li",
      "Chang Xu",
      "Wankou Yang",
      "Changyin Sun",
      "Dacheng Tao",
      "Hong Zhang"
    ],
    "author_ids": [],
    "abstract": "Conventional multi-view re-ranking methods usually perform asymmetrical\nmatching between the region of interest (ROI) in the query image and the whole\ntarget image for similarity computation. Due to the inconsistency in the visual\nappearance, this practice tends to degrade the retrieval accuracy particularly\nwhen the image ROI, which is usually interpreted as the image objectness,\naccounts for a smaller region in the image. Since Privileged Information (PI),\nwhich can be viewed as the image prior, enables well characterizing the image\nobjectness, we are aiming at leveraging PI for further improving the\nperformance of the multi-view re-ranking accuracy in this paper. Towards this\nend, we propose a discriminative multi-view re-ranking approach in which both\nthe original global image visual contents and the local auxiliary PI features\nare simultaneously integrated into a unified training framework for generating\nthe latent subspaces with sufficient discriminating power. For the on-the-fly\nre-ranking, since the multi-view PI features are unavailable, we only project\nthe original multi-view image representations onto the latent subspace, and\nthus the re-ranking can be achieved by computing and sorting the distances from\nthe multi-view embeddings to the separating hyperplane. Extensive experimental\nevaluations on the two public benchmarks Oxford5k and Paris6k reveal our\napproach provides further performance boost for accurate image re-ranking,\nwhilst the comparative study demonstrates the advantage of our method against\nother multi-view re-ranking methods.",
    "published_date": "2018-07-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.04437v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.10166v1",
    "title": "Rademacher Generalization Bounds for Classifier Chains",
    "authors": [
      "Moura Simon",
      "Amini Massih-Reza",
      "Louhichi Sana",
      "Clausel Marianne"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a new framework to study the generalization\nproperty of classifier chains trained over observations associated with\nmultiple and interdependent class labels. The results are based on large\ndeviation inequalities for Lipschitz functions of weakly dependent sequences\nproposed by Rio in 2000. We believe that the resulting generalization error\nbound brings many advantages and could be adapted to other frameworks that\nconsider interdependent outputs. First, it explicitly exhibits the dependencies\nbetween class labels. Secondly, it provides insights of the effect of the order\nof the chain on the algorithm generalization performances. Finally, the two\ndependency coefficients that appear in the bound could also be used to design\nnew strategies to decide the order of the chain.",
    "published_date": "2018-07-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10166v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.09993v1",
    "title": "Divide and Grow: Capturing Huge Diversity in Crowd Images with Incrementally Growing CNN",
    "authors": [
      "Deepak Babu Sam",
      "Neeraj N Sajjan",
      "R. Venkatesh Babu"
    ],
    "author_ids": [],
    "abstract": "Automated counting of people in crowd images is a challenging task. The major\ndifficulty stems from the large diversity in the way people appear in crowds.\nIn fact, features available for crowd discrimination largely depend on the\ncrowd density to the extent that people are only seen as blobs in a highly\ndense scene. We tackle this problem with a growing CNN which can progressively\nincrease its capacity to account for the wide variability seen in crowd scenes.\nOur model starts from a base CNN density regressor, which is trained in\nequivalence on all types of crowd images. In order to adapt with the huge\ndiversity, we create two child regressors which are exact copies of the base\nCNN. A differential training procedure divides the dataset into two clusters\nand fine-tunes the child networks on their respective specialties.\nConsequently, without any hand-crafted criteria for forming specialties, the\nchild regressors become experts on certain types of crowds. The child networks\nare again split recursively, creating two experts at every division. This\nhierarchical training leads to a CNN tree, where the child regressors are more\nfine experts than any of their parents. The leaf nodes are taken as the final\nexperts and a classifier network is then trained to predict the correct\nspecialty for a given test image patch. The proposed model achieves higher\ncount accuracy on major crowd datasets. Further, we analyse the characteristics\nof specialties mined automatically by our method.",
    "published_date": "2018-07-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.09993v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.09546v1",
    "title": "Patch-based Evaluation of Dense Image Matching Quality",
    "authors": [
      "Zhenchao Zhang",
      "Markus Gerke",
      "George Vosselman",
      "Michael Ying Yang"
    ],
    "author_ids": [],
    "abstract": "Airborne laser scanning and photogrammetry are two main techniques to obtain\n3D data representing the object surface. Due to the high cost of laser\nscanning, we want to explore the potential of using point clouds derived by\ndense image matching (DIM), as effective alternatives to laser scanning data.\nWe present a framework to evaluate point clouds from dense image matching and\nderived Digital Surface Models (DSM) based on automatically extracted sample\npatches. Dense matching error and noise level are evaluated quantitatively at\nboth the local level and whole block level. Experiments show that the optimal\nvertical accuracy achieved by dense matching is as follows: the mean offset to\nthe reference data is 0.1 Ground Sampling Distance (GSD); the maximum offset\ngoes up to 1.0 GSD. When additional oblique images are used in dense matching,\nthe mean deviation, the variation of mean deviation and the level of random\nnoise all get improved. We also detect a bias between the point cloud and DSM\nfrom a single photogrammetric workflow. This framework also allows to reveal\ninhomogeneity in the distribution of the dense matching errors due to\nover-fitted BBA network. Meanwhile, suggestions are given on the\nphotogrammetric quality control.",
    "published_date": "2018-07-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.09546v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.10615v1",
    "title": "Judging a Book by its Description : Analyzing Gender Stereotypes in the Man Bookers Prize Winning Fiction",
    "authors": [
      "Nishtha Madaan",
      "Sameep Mehta",
      "Shravika Mittal",
      "Ashima Suvarna"
    ],
    "author_ids": [],
    "abstract": "The presence of gender stereotypes in many aspects of society is a well-known\nphenomenon. In this paper, we focus on studying and quantifying such\nstereotypes and bias in the Man Bookers Prize winning fiction. We consider 275\nbooks shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias\nis analyzed by semantic modeling of book descriptions on Goodreads. This\nreveals the pervasiveness of gender bias and stereotype in the books on\ndifferent features like occupation, introductions and actions associated to the\ncharacters in the book.",
    "published_date": "2018-07-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10615v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.09406v1",
    "title": "Estimating group properties in online social networks with a classifier",
    "authors": [
      "George Berry",
      "Antonio Sirianni",
      "Nathan High",
      "Agrippa Kellum",
      "Ingmar Weber",
      "Michael Macy"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of obtaining unbiased estimates of group properties\nin social networks when using a classifier for node labels. Inference for this\nproblem is complicated by two factors: the network is not known and must be\ncrawled, and even high-performance classifiers provide biased estimates of\ngroup proportions. We propose and evaluate AdjustedWalk for addressing this\nproblem. This is a three step procedure which entails: 1) walking the graph\nstarting from an arbitrary node; 2) learning a classifier on the nodes in the\nwalk; and 3) applying a post-hoc adjustment to classification labels. The walk\nstep provides the information necessary to make inferences over the nodes and\nedges, while the adjustment step corrects for classifier bias in estimating\ngroup proportions. This process provides de-biased estimates at the cost of\nadditional variance. We evaluate AdjustedWalk on four tasks: the proportion of\nnodes belonging to a minority group, the proportion of the minority group among\nhigh degree nodes, the proportion of within-group edges, and Coleman's\nhomophily index. Simulated and empirical graphs show that this procedure\nperforms well compared to optimal baselines in a variety of circumstances,\nwhile indicating that variance increases can be large for low-recall\nclassifiers.",
    "published_date": "2018-07-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.09406v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.09123v1",
    "title": "Learning Class Prototypes via Structure Alignment for Zero-Shot Recognition",
    "authors": [
      "Huajie Jiang",
      "Ruiping Wang",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "author_ids": [],
    "abstract": "Zero-shot learning (ZSL) aims to recognize objects of novel classes without\nany training samples of specific classes, which is achieved by exploiting the\nsemantic information and auxiliary datasets. Recently most ZSL approaches focus\non learning visual-semantic embeddings to transfer knowledge from the auxiliary\ndatasets to the novel classes. However, few works study whether the semantic\ninformation is discriminative or not for the recognition task. To tackle such\nproblem, we propose a coupled dictionary learning approach to align the\nvisual-semantic structures using the class prototypes, where the discriminative\ninformation lying in the visual space is utilized to improve the less\ndiscriminative semantic space. Then, zero-shot recognition can be performed in\ndifferent spaces by the simple nearest neighbor approach using the learned\nclass prototypes. Extensive experiments on four benchmark datasets show the\neffectiveness of the proposed approach.",
    "published_date": "2018-07-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.09123v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.08673v2",
    "title": "Variational inequalities and mean-field approximations for partially observed systems of queueing networks",
    "authors": [
      "Iker Perez",
      "Giuliano Casale"
    ],
    "author_ids": [],
    "abstract": "Queueing networks are systems of theoretical interest that find widespread\nuse in the performance evaluation of interconnected resources. In comparison to\ncounterpart models in genetics or mathematical biology, the stochastic (jump)\nprocesses induced by queueing networks have distinctive coupling and\nsynchronization properties. This has prevented the derivation of variational\napproximations for conditional representations of transient dynamics, which\nrely on simplifying independence assumptions. Here, we present a model\naugmentation to a multivariate counting process for interactions across service\nstations, and we enable the variational evaluation of mean-field measures for\npartially-observed multi-class networks. We also show that our framework offers\nan efficient and improved alternative for inference tasks, where existing\nvariational or numerically intensive solutions do not work.",
    "published_date": "2018-07-23T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ME",
      "cs.PF",
      "stat.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.08673v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.08479v1",
    "title": "Domain Generalization via Conditional Invariant Representation",
    "authors": [
      "Ya Li",
      "Mingming Gong",
      "Xinmei Tian",
      "Tongliang Liu",
      "Dacheng Tao"
    ],
    "author_ids": [],
    "abstract": "Domain generalization aims to apply knowledge gained from multiple labeled\nsource domains to unseen target domains. The main difficulty comes from the\ndataset bias: training data and test data have different distributions, and the\ntraining set contains heterogeneous samples from different distributions. Let\n$X$ denote the features, and $Y$ be the class labels. Existing domain\ngeneralization methods address the dataset bias problem by learning a\ndomain-invariant representation $h(X)$ that has the same marginal distribution\n$\\mathbb{P}(h(X))$ across multiple source domains. The functional relationship\nencoded in $\\mathbb{P}(Y|X)$ is usually assumed to be stable across domains\nsuch that $\\mathbb{P}(Y|h(X))$ is also invariant. However, it is unclear\nwhether this assumption holds in practical problems. In this paper, we consider\nthe general situation where both $\\mathbb{P}(X)$ and $\\mathbb{P}(Y|X)$ can\nchange across all domains. We propose to learn a feature representation which\nhas domain-invariant class conditional distributions $\\mathbb{P}(h(X)|Y)$. With\nthe conditional invariant representation, the invariance of the joint\ndistribution $\\mathbb{P}(h(X),Y)$ can be guaranteed if the class prior\n$\\mathbb{P}(Y)$ does not change across training and test domains. Extensive\nexperiments on both synthetic and real data demonstrate the effectiveness of\nthe proposed method.",
    "published_date": "2018-07-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.08479v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.08362v3",
    "title": "An Intersectional Definition of Fairness",
    "authors": [
      "James Foulds",
      "Rashidul Islam",
      "Kamrun Naher Keya",
      "Shimei Pan"
    ],
    "author_ids": [],
    "abstract": "We propose definitions of fairness in machine learning and artificial\nintelligence systems that are informed by the framework of intersectionality, a\ncritical lens arising from the Humanities literature which analyzes how\ninterlocking systems of power and oppression affect individuals along\noverlapping dimensions including gender, race, sexual orientation, class, and\ndisability. We show that our criteria behave sensibly for any subset of the set\nof protected attributes, and we prove economic, privacy, and generalization\nguarantees. We provide a learning algorithm which respects our intersectional\nfairness criteria. Case studies on census data and the COMPAS criminal\nrecidivism dataset demonstrate the utility of our methods.",
    "published_date": "2018-07-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.08362v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.08346v2",
    "title": "Biases in the Facebook News Feed: a Case Study on the Italian Elections",
    "authors": [
      "Eduardo Hargreaves",
      "Claudio Agosti",
      "Daniel Menasché",
      "Giovanni Neglia",
      "Alexandre Reiffers-Masson",
      "Eitan Altman"
    ],
    "author_ids": [],
    "abstract": "Facebook News Feed personalization algorithm has a significant impact, on a\ndaily basis, on the lifestyle, mood and opinion of millions of Internet users.\nNonetheless, the behavior of such algorithms usually lacks transparency,\nmotivating measurements, modeling and analysis in order to understand and\nimprove its properties. In this paper, we propose a reproducible methodology\nencompassing measurements and an analytical model to capture the visibility of\npublishers over a News Feed. First, measurements are used to parameterize and\nto validate the expressive power of the proposed model. Then, we conduct a\nwhat-if analysis to assess the visibility bias incurred by the users against a\nbaseline derived from the model. Our results indicate that a significant bias\nexists and it is more prominent at the top position of the News Feed. In\naddition, we found that the bias is non-negligible even for users that are\ndeliberately set as neutral with respect to their political views.",
    "published_date": "2018-07-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.08346v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.08142v1",
    "title": "{\\em Crypto-Battleships} or How to play Battleships game over the Blockchain?",
    "authors": [
      "Guy Barshap"
    ],
    "author_ids": [],
    "abstract": "Battleships is a well known traditional board game for two players which\ndates from World War I. Though, the game has several digital version\nimplementations, they are affected by similar major drawbacks such as fairness\nand a trust model that relies on third party. In this paper, we demonstrate how\nto implement a fair, resistant to denial-of-service, where the honest winner\nearns the deposit money {\\em immediately}. The game is built on a\npermissionless Blockchain that supports Turing complete smart-contract\ncomputation.",
    "published_date": "2018-07-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.08142v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.07838v4",
    "title": "TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time",
    "authors": [
      "Feargus Pendlebury",
      "Fabio Pierazzi",
      "Roberto Jordaney",
      "Johannes Kinder",
      "Lorenzo Cavallaro"
    ],
    "author_ids": [],
    "abstract": "Is Android malware classification a solved problem? Published F1 scores of up\nto 0.99 appear to leave very little room for improvement. In this paper, we\nargue that results are commonly inflated due to two pervasive sources of\nexperimental bias: \"spatial bias\" caused by distributions of training and\ntesting data that are not representative of a real-world deployment; and\n\"temporal bias\" caused by incorrect time splits of training and testing sets,\nleading to impossible configurations. We propose a set of space and time\nconstraints for experiment design that eliminates both sources of bias. We\nintroduce a new metric that summarizes the expected robustness of a classifier\nin a real-world setting, and we present an algorithm to tune its performance.\nFinally, we demonstrate how this allows us to evaluate mitigation strategies\nfor time decay such as active learning. We have implemented our solutions in\nTESSERACT, an open source evaluation framework for comparing malware\nclassifiers in a realistic setting. We used TESSERACT to evaluate three Android\nmalware classifiers from the literature on a dataset of 129K applications\nspanning over three years. Our evaluation confirms that earlier published\nresults are biased, while also revealing counter-intuitive performance and\nshowing that appropriate tuning can lead to significant improvements.",
    "published_date": "2018-07-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07838v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.07761v1",
    "title": "Controllability of Social Networks and the Strategic Use of Random Information",
    "authors": [
      "Marco Cremonini",
      "Francesca Casamassima"
    ],
    "author_ids": [],
    "abstract": "This work is aimed at studying realistic social control strategies for social\nnetworks based on the introduction of random information into the state of\nselected driver agents. Deliberately exposing selected agents to random\ninformation is a technique already experimented in recommender systems or\nsearch engines, and represents one of the few options for influencing the\nbehavior of a social context that could be accepted as ethical, could be fully\ndisclosed to members, and does not involve the use of force or of deception.\nOur research is based on a model of knowledge diffusion applied to a\ntime-varying adaptive network, and considers two well-known strategies for\ninfluencing social contexts. One is the selection of few influencers for\nmanipulating their actions in order to drive the whole network to a certain\nbehavior; the other, instead, drives the network behavior acting on the state\nof a large subset of ordinary, scarcely influencing users. The two approaches\nhave been studied in terms of network and diffusion effects. The network effect\nis analyzed through the changes induced on network average degree and\nclustering coefficient, while the diffusion effect is based on two ad-hoc\nmetrics defined to measure the degree of knowledge diffusion and skill level,\nas well as the polarization of agent interests. The results, obtained through\nsimulations on synthetic networks, show a rich dynamics and strong effects on\nthe communication structure and on the distribution of knowledge and skills,\nsupporting our hypothesis that the strategic use of random information could\nrepresent a realistic approach to social network controllability, and that with\nboth strategies, in principle, the control effect could be remarkable.",
    "published_date": "2018-07-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07761v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.07658v2",
    "title": "Deriving star cluster parameters with convolutional neural networks. I. Age, mass, and size",
    "authors": [
      "J. Bialopetravičius",
      "D. Narbutis",
      "V. Vansevičius"
    ],
    "author_ids": [],
    "abstract": "Context. Convolutional neural networks (CNNs) have been proven to perform\nfast classification and detection on natural images and have potential to infer\nastrophysical parameters on the exponentially increasing amount of sky survey\nimaging data. The inference pipeline can be trained either from real\nhuman-annotated data or simulated mock observations. Until now star cluster\nanalysis was based on integral or individual resolved stellar photometry. This\nlimits the amount of information that can be extracted from cluster images.\n  Aims. Develop a CNN-based algorithm aimed to simultaneously derive ages,\nmasses, and sizes of star clusters directly from multi-band images. Demonstrate\nCNN capabilities on low mass semi-resolved star clusters in a low\nsignal-to-noise ratio regime.\n  Methods. A CNN was constructed based on the deep residual network (ResNet)\narchitecture and trained on simulated images of star clusters with various\nages, masses, and sizes. To provide realistic backgrounds, M31 star fields\ntaken from the PHAT survey were added to the mock cluster images.\n  Results. The proposed CNN was verified on mock images of artificial clusters\nand has demonstrated high precision and no significant bias for clusters of\nages $\\lesssim$3Gyr and masses between 250 and 4,000 ${\\rm M_\\odot}$. The\npipeline is end-to-end, starting from input images all the way to the inferred\nparameters; no hand-coded steps have to be performed: estimates of parameters\nare provided by the neural network in one inferential step from raw images.",
    "published_date": "2018-07-19T00:00:00",
    "year": 2018,
    "categories": [
      "astro-ph.GA",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07658v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.07483v2",
    "title": "Prophet Secretary Through Blind Strategies",
    "authors": [
      "Jose Correa",
      "Raimundo Saona",
      "Bruno Ziliotto"
    ],
    "author_ids": [],
    "abstract": "In the classic prophet inequality, samples from independent random variables\narrive online. A gambler that knows the distributions must decide at each point\nin time whether to stop and pick the current sample or to continue and lose\nthat sample forever. The goal of the gambler is to maximize the expected value\nof what she picks and the performance measure is the worst case ratio between\nthe expected value the gambler gets and what a prophet, that sees all the\nrealizations in advance, gets. In the late seventies, Krengel and Sucheston,\nand Gairing (1977) established that this worst case ratio is a universal\nconstant equal to 1/2. In the last decade prophet inequalities has resurged as\nan important problem due to its connections to posted price mechanisms,\nfrequently used in online sales. A very interesting variant is the Prophet\nSecretary problem, in which the only difference is that the samples arrive in a\nuniformly random order. For this variant several algorithms achieve a constant\nof 1-1/e and very recently this barrier was slightly improved. This paper\nanalyzes strategies that set a nonincreasing sequence of thresholds to be\napplied at different times. The gambler stops the first time a sample surpasses\nthe corresponding threshold. Specifically we consider a class of strategies\ncalled blind quantile strategies. They consist in fixing a function which is\nused to define a sequence of thresholds once the instance is revealed. Our main\nresult shows that they can achieve a constant of 0.665, improving upon the best\nknown result of Azar et al. (2018), and on Beyhaghi et al. (2018) (order\nselection). Our proof analyzes precisely the underlying stopping time\ndistribution, relying on Schur-convexity theory. We further prove that blind\nstrategies cannot achieve better than 0.675. Finally we prove that no algorithm\nfor the gambler can achieve better than 0.732.",
    "published_date": "2018-07-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07483v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.10583v1",
    "title": "EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand Ultrasound Imaging without External Trackers",
    "authors": [
      "Bishesh Khanal",
      "Alberto Gomez",
      "Nicolas Toussaint",
      "Steven McDonagh",
      "Veronika Zimmer",
      "Emily Skelton",
      "Jacqueline Matthew",
      "Daniel Grzech",
      "Robert Wright",
      "Chandni Gupta",
      "Benjamin Hou",
      "Daniel Rueckert",
      "Julia A. Schnabel",
      "Bernhard Kainz"
    ],
    "author_ids": [],
    "abstract": "Ultrasound (US) is the most widely used fetal imaging technique. However, US\nimages have limited capture range, and suffer from view dependent artefacts\nsuch as acoustic shadows. Compounding of overlapping 3D US acquisitions into a\nhigh-resolution volume can extend the field of view and remove image artefacts,\nwhich is useful for retrospective analysis including population based studies.\nHowever, such volume reconstructions require information about relative\ntransformations between probe positions from which the individual volumes were\nacquired. In prenatal US scans, the fetus can move independently from the\nmother, making external trackers such as electromagnetic or optical tracking\nunable to track the motion between probe position and the moving fetus. We\nprovide a novel methodology for image-based tracking and volume reconstruction\nby combining recent advances in deep learning and simultaneous localisation and\nmapping (SLAM). Tracking semantics are established through the use of a\nResidual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of\nconcept, experiments are conducted on US volumes taken from a whole body fetal\nphantom, and from the heads of real fetuses. For the fetal head segmentation,\nwe also introduce a novel weak annotation approach to minimise the required\nmanual effort for ground truth annotation. We evaluate our method\nqualitatively, and quantitatively with respect to tissue discrimination\naccuracy and tracking robustness.",
    "published_date": "2018-07-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10583v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.07351v1",
    "title": "Can We Assess Mental Health through Social Media and Smart Devices? Addressing Bias in Methodology and Evaluation",
    "authors": [
      "Adam Tsakalidis",
      "Maria Liakata",
      "Theo Damoulas",
      "Alexandra I. Cristea"
    ],
    "author_ids": [],
    "abstract": "Predicting mental health from smartphone and social media data on a\nlongitudinal basis has recently attracted great interest, with very promising\nresults being reported across many studies. Such approaches have the potential\nto revolutionise mental health assessment, if their development and evaluation\nfollows a real world deployment setting. In this work we take a closer look at\nstate-of-the-art approaches, using different mental health datasets and\nindicators, different feature sources and multiple simulations, in order to\nassess their ability to generalise. We demonstrate that under a pragmatic\nevaluation framework, none of the approaches deliver or even approach the\nreported performances. In fact, we show that current state-of-the-art\napproaches can barely outperform the most na\\\"ive baselines in the real-world\nsetting, posing serious questions not only about their deployment ability, but\nalso about the contribution of the derived features for the mental health\nassessment task and how to make better use of such data in the future.",
    "published_date": "2018-07-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07351v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.07217v4",
    "title": "Deconfounding age effects with fair representation learning when assessing dementia",
    "authors": [
      "Zining Zhu",
      "Jekaterina Novikova",
      "Frank Rudzicz"
    ],
    "author_ids": [],
    "abstract": "One of the most prevalent symptoms among the elderly population, dementia,\ncan be detected by classifiers trained on linguistic features extracted from\nnarrative transcripts. However, these linguistic features are impacted in a\nsimilar but different fashion by the normal aging process. Aging is therefore a\nconfounding factor, whose effects have been hard for machine learning\nclassifiers (especially deep neural network based models) to ignore. We show\nDNN models are capable of estimating ages based on linguistic features.\nPredicting dementia based on this aging bias could lead to potentially\nnon-generalizable accuracies on clinical datasets, if not properly\ndeconfounded.\n  In this paper, we propose to address this deconfounding problem with fair\nrepresentation learning. We build neural network classifiers that learn\nlow-dimensional representations reflecting the impacts of dementia yet\ndiscarding the effects of age. To evaluate these classifiers, we specify a\nmodel-agnostic score $\\Delta_{eo}^{(N)}$ measuring how classifier results are\ndeconfounded from age. Our best models compromise accuracy by only 2.56\\% and\n1.54\\% on two clinical datasets compared to DNNs, and their $\\Delta_{eo}^{(2)}$\nscores are better than statistical (residulization and inverse probability\nweight) adjustments.",
    "published_date": "2018-07-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07217v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.07049v1",
    "title": "Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias",
    "authors": [
      "Abhinav Gupta",
      "Adithyavairavan Murali",
      "Dhiraj Gandhi",
      "Lerrel Pinto"
    ],
    "author_ids": [],
    "abstract": "Data-driven approaches to solving robotic tasks have gained a lot of traction\nin recent years. However, most existing policies are trained on large-scale\ndatasets collected in curated lab settings. If we aim to deploy these models in\nunstructured visual environments like people's homes, they will be unable to\ncope with the mismatch in data distribution. In such light, we present the\nfirst systematic effort in collecting a large dataset for robotic grasping in\nhomes. First, to scale and parallelize data collection, we built a low cost\nmobile manipulator assembled for under 3K USD. Second, data collected using low\ncost robots suffer from noisy labels due to imperfect execution and calibration\nerrors. To handle this, we develop a framework which factors out the noise as a\nlatent variable. Our model is trained on 28K grasps collected in several houses\nunder an array of different environmental conditions. We evaluate our models by\nphysically executing grasps on a collection of novel objects in multiple unseen\nhomes. The models trained with our home dataset showed a marked improvement of\n43.7% over a baseline model trained with data collected in lab. Our\narchitecture which explicitly models the latent noise in the dataset also\nperformed 10% better than one that did not factor out the noise. We hope this\neffort inspires the robotics community to look outside the lab and embrace\nlearning based approaches to handle inaccurate cheap robots.",
    "published_date": "2018-07-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.07049v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.06958v1",
    "title": "Quantifying Biases in Online Information Exposure",
    "authors": [
      "Dimitar Nikolov",
      "Mounia Lalmas",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "author_ids": [],
    "abstract": "Our consumption of online information is mediated by filtering, ranking, and\nrecommendation algorithms that introduce unintentional biases as they attempt\nto deliver relevant and engaging content. It has been suggested that our\nreliance on online technologies such as search engines and social media may\nlimit exposure to diverse points of view and make us vulnerable to manipulation\nby disinformation. In this paper, we mine a massive dataset of Web traffic to\nquantify two kinds of bias: (i) homogeneity bias, which is the tendency to\nconsume content from a narrow set of information sources, and (ii) popularity\nbias, which is the selective exposure to content from top sites. Our analysis\nreveals different bias levels across several widely used Web platforms. Search\nexposes users to a diverse set of sources, while social media traffic tends to\nexhibit high popularity and homogeneity bias. When we focus our analysis on\ntraffic to news sites, we find higher levels of popularity bias, with smaller\ndifferences across applications. Overall, our results quantify the extent to\nwhich our choices of online systems confine us inside \"social bubbles.\"",
    "published_date": "2018-07-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06958v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.06713v2",
    "title": "On the Interaction Effects Between Prediction and Clustering",
    "authors": [
      "Matt Barnes",
      "Artur Dubrawski"
    ],
    "author_ids": [],
    "abstract": "Machine learning systems increasingly depend on pipelines of multiple\nalgorithms to provide high quality and well structured predictions. This paper\nargues interaction effects between clustering and prediction (e.g.\nclassification, regression) algorithms can cause subtle adverse behaviors\nduring cross-validation that may not be initially apparent. In particular, we\nfocus on the problem of estimating the out-of-cluster (OOC) prediction loss\ngiven an approximate clustering with probabilistic error rate $p_0$.\nTraditional cross-validation techniques exhibit significant empirical bias in\nthis setting, and the few attempts to estimate and correct for these effects\nare intractable on larger datasets. Further, no previous work has been able to\ncharacterize the conditions under which these empirical effects occur, and if\nthey do, what properties they have. We precisely answer these questions by\nproviding theoretical properties which hold in various settings, and prove that\nexpected out-of-cluster loss behavior rapidly decays with even minor clustering\nerrors. Fortunately, we are able to leverage these same properties to construct\nhypothesis tests and scalable estimators necessary for correcting the problem.\nEmpirical results on benchmark datasets validate our theoretical results and\ndemonstrate how scaling techniques provide solutions to new classes of\nproblems.",
    "published_date": "2018-07-18T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06713v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.06456v3",
    "title": "Quantum Chebyshev's Inequality and Applications",
    "authors": [
      "Yassine Hamoudi",
      "Frédéric Magniez"
    ],
    "author_ids": [],
    "abstract": "In this paper we provide new quantum algorithms with polynomial speed-up for\na range of problems for which no such results were known, or we improve\nprevious algorithms. First, we consider the approximation of the frequency\nmoments $F_k$ of order $k \\geq 3$ in the multi-pass streaming model with\nupdates (turnstile model). We design a $P$-pass quantum streaming algorithm\nwith memory $M$ satisfying a tradeoff of $P^2 M = \\tilde{O}(n^{1-2/k})$,\nwhereas the best classical algorithm requires $P M = \\Theta(n^{1-2/k})$. Then,\nwe study the problem of estimating the number $m$ of edges and the number $t$\nof triangles given query access to an $n$-vertex graph. We describe optimal\nquantum algorithms that perform $\\tilde{O}(\\sqrt{n}/m^{1/4})$ and\n$\\tilde{O}(\\sqrt{n}/t^{1/6} + m^{3/4}/\\sqrt{t})$ queries respectively. This is\na quadratic speed-up compared to the classical complexity of these problems.\n  For this purpose we develop a new quantum paradigm that we call Quantum\nChebyshev's inequality. Namely we demonstrate that, in a certain model of\nquantum sampling, one can approximate with relative error the mean of any\nrandom variable with a number of quantum samples that is linear in the ratio of\nthe square root of the variance to the mean. Classically the dependency is\nquadratic. Our algorithm subsumes a previous result of Montanaro [Mon15]. This\nnew paradigm is based on a refinement of the Amplitude Estimation algorithm of\nBrassard et al. [BHMT02] and of previous quantum algorithms for the mean\nestimation problem. We show that this speed-up is optimal, and we identify\nanother common model of quantum sampling where it cannot be obtained. For our\napplications, we also adapt the variable-time amplitude amplification technique\nof Ambainis [Amb10] into a variable-time amplitude estimation algorithm.",
    "published_date": "2018-07-17T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS",
      "stat.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06456v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.06349v1",
    "title": "User Fairness in Recommender Systems",
    "authors": [
      "Jurek Leonhardt",
      "Avishek Anand",
      "Megha Khosla"
    ],
    "author_ids": [],
    "abstract": "Recent works in recommendation systems have focused on diversity in\nrecommendations as an important aspect of recommendation quality. In this work\nwe argue that the post-processing algorithms aimed at only improving diversity\namong recommendations lead to discrimination among the users. We introduce the\nnotion of user fairness which has been overlooked in literature so far and\npropose measures to quantify it. Our experiments on two diversification\nalgorithms show that an increase in aggregate diversity results in increased\ndisparity among the users.",
    "published_date": "2018-07-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06349v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.06071v2",
    "title": "Verification of Immediate Observation Population Protocols",
    "authors": [
      "Javier Esparza",
      "Pierre Ganty",
      "Rupak Majumdar",
      "Chana Weil-Kennedy"
    ],
    "author_ids": [],
    "abstract": "Population protocols (Angluin et al., PODC, 2004) are a formal model of\nsensor networks consisting of identical mobile devices. Two devices can\ninteract and thereby change their states. Computations are infinite sequences\nof interactions satisfying a strong fairness constraint.\n  A population protocol is well-specified if for every initial configuration\n$C$ of devices, and every computation starting at $C$, all devices eventually\nagree on a consensus value depending only on $C$. If a protocol is\nwell-specified, then it is said to compute the predicate that assigns to each\ninitial configuration its consensus value.\n  In a previous paper we have shown that the problem whether a given protocol\nis well-specified and the problem whether it computes a given predicate are\ndecidable. However, in the same paper we prove that both problems are at least\nas hard as the reachability problem for Petri nets. Since all known algorithms\nfor Petri net reachability have non-primitive recursive complexity, in this\npaper we restrict attention to immediate observation (IO) population protocols,\na class introduced and studied in (Angluin et al., PODC, 2006). We show that\nboth problems are solvable in exponential space for IO protocols. This is the\nfirst syntactically defined, interesting class of protocols for which an\nalgorithm not requiring Petri net reachability is found.",
    "published_date": "2018-07-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06071v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.06068v3",
    "title": "Automated Data Slicing for Model Validation:A Big data - AI Integration Approach",
    "authors": [
      "Yeounoh Chung",
      "Tim Kraska",
      "Neoklis Polyzotis",
      "Ki Hyun Tae",
      "Steven Euijong Whang"
    ],
    "author_ids": [],
    "abstract": "As machine learning systems become democratized, it becomes increasingly\nimportant to help users easily debug their models. However, current data tools\nare still primitive when it comes to helping users trace model performance\nproblems all the way to the data. We focus on the particular problem of slicing\ndata to identify subsets of the validation data where the model performs\npoorly. This is an important problem in model validation because the overall\nmodel performance can fail to reflect that of the smaller subsets, and slicing\nallows users to analyze the model performance on a more granular-level. Unlike\ngeneral techniques (e.g., clustering) that can find arbitrary slices, our goal\nis to find interpretable slices (which are easier to take action compared to\narbitrary subsets) that are problematic and large. We propose Slice Finder,\nwhich is an interactive framework for identifying such slices using statistical\ntechniques. Applications include diagnosing model fairness and fraud detection,\nwhere identifying slices that are interpretable to humans is crucial. This\nresearch is part of a larger trend of Big data and Artificial Intelligence (AI)\nintegration and opens many opportunities for new research.",
    "published_date": "2018-07-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.06068v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.05592v4",
    "title": "Pseudo-linear regression identification based on generalized orthonormal transfer functions: Convergence conditions and bias distribution",
    "authors": [
      "Bernard Vau",
      "Henri Bourlès"
    ],
    "author_ids": [],
    "abstract": "In this paper we generalize three identification recursive algorithms\nbelonging to the pseudo-linear class, by introducing a predictor established on\na generalized orthonormal function basis. Contrary to the existing\nidentification schemes that use such functions, no constraint on the model\npoles is imposed. Not only this predictor parameterization offers the\nopportunity to relax the convergence conditions of the associated recursive\nschemes, but it entails a modification of the bias distribution linked to the\nbasis poles. This result is specific to pseudo-linear regression properties,\nand cannot be transposed to most of prediction error method algorithms. A\ndetailed bias distribution is provided, using the concept of equivalent\nprediction error, which reveals strong analogies between the three proposed\nschemes, corresponding to ARMAX, Output Error and a generalization of ARX\nmodels. That leads to introduce an indicator of the basis poles location effect\non the bias distribution in the frequency domain. As shown by the simulations,\nthe said basis poles play the role of tuning parameters, allowing to manage the\nmodel fit in the frequency domain, and allowing efficient identification of\nfast sampled or stiff discrete-time systems.",
    "published_date": "2018-07-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.05592v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.05477v2",
    "title": "Linear Programming Based Near-Optimal Pricing for Laminar Bayesian Online Selection",
    "authors": [
      "Nima Anari",
      "Rad Niazadeh",
      "Amin Saberi",
      "Ali Shameli"
    ],
    "author_ids": [],
    "abstract": "The Bayesian online selection problem aims to design a pricing scheme for a\nsequence of arriving buyers that maximizes the expected social welfare (or\nrevenue) subject to different structural constraints. Inspired by applications\nwith a hierarchy of service, this paper focuses on the cases where a laminar\nmatroid characterizes the set of served buyers. We give the first\nPolynomial-Time Approximation Scheme (PTAS) for the problem when the laminar\nmatroid has constant depth. Our approach is based on rounding the solution of a\nhierarchy of linear programming relaxations that approximate the optimum online\nsolution with any degree of accuracy, plus a concentration argument showing\nthat rounding incurs a small loss. We also study another variation, which we\ncall the production-constrained problem. The allowable set of served buyers is\ncharacterized by a collection of production and shipping constraints that form\na particular example of a laminar matroid. Using a similar LP-based approach,\nwe design a PTAS for this problem, although in this special case the depth of\nthe underlying laminar matroid is not necessarily a constant. The analysis\nexploits the negative dependency of the optimum selection rule in the lower\nlevels of the laminar family. Finally, to demonstrate the generality of our\ntechnique, we employ the linear programming-based approach employed in the\npaper to re-derive some of the classic prophet inequalities known in the\nliterature -- as a side result.",
    "published_date": "2018-07-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.DS",
      "econ.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.05477v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.05419v1",
    "title": "Stochastic Stability in Schelling's Segregation Model with Markovian Asynchronous Update",
    "authors": [
      "Gabriel Istrate"
    ],
    "author_ids": [],
    "abstract": "We investigate the dependence of steady-state properties of Schelling's\nsegregation model on the agents' activation order. Our basic formalism is the\nPollicott-Weiss version of Schelling's segregation model. Our main result\nmodifies this baseline scenario by incorporating contagion in the decision to\nmove: (pairs of) agents are connected by a second, agent influence network.\nPair activation is specified by a random walk on this network.\n  The considered schedulers choose the next pair nonadaptively. We can\ncomplement this result by an example of adaptive scheduler (even one that is\nquite fair) that is able to preclude maximal segregation. Thus scheduler\nnonadaptiveness seems to be required for the validity of the original result\nunder arbitrary asynchronous scheduling. The analysis (and our result) are part\nof an adversarial scheduling approach we are advocating to evolutionary games\nand social simulations.",
    "published_date": "2018-07-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "math.CO",
      "math.PR",
      "nlin.CG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.05419v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.05327v1",
    "title": "How Humans versus Bots React to Deceptive and Trusted News Sources: A Case Study of Active Users",
    "authors": [
      "Maria Glenski",
      "Tim Weninger",
      "Svitlana Volkova"
    ],
    "author_ids": [],
    "abstract": "Society's reliance on social media as a primary source of news has spawned a\nrenewed focus on the spread of misinformation. In this work, we identify the\ndifferences in how social media accounts identified as bots react to news\nsources of varying credibility, regardless of the veracity of the content those\nsources have shared. We analyze bot and human responses annotated using a\nfine-grained model that labels responses as being an answer, appreciation,\nagreement, disagreement, an elaboration, humor, or a negative reaction. We\npresent key findings of our analysis into the prevalence of bots, the variety\nand speed of bot and human reactions, and the disparity in authorship of\nreaction tweets between these two sub-populations. We observe that bots are\nresponsible for 9-15% of the reactions to sources of any given type but\ncomprise only 7-10% of accounts responsible for reaction-tweets; trusted news\nsources have the highest proportion of humans who reacted; bots respond with\nsignificantly shorter delays than humans when posting answer-reactions in\nresponse to sources identified as propaganda. Finally, we report significantly\ndifferent inequality levels in reaction rates for accounts identified as bots\nvs not.",
    "published_date": "2018-07-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.05327v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.04975v2",
    "title": "Recognition in Terra Incognita",
    "authors": [
      "Sara Beery",
      "Grant van Horn",
      "Pietro Perona"
    ],
    "author_ids": [],
    "abstract": "It is desirable for detection and classification algorithms to generalize to\nunfamiliar environments, but suitable benchmarks for quantitatively studying\nthis phenomenon are not yet available. We present a dataset designed to measure\nrecognition generalization to novel environments. The images in our dataset are\nharvested from twenty camera traps deployed to monitor animal populations.\nCamera traps are fixed at one location, hence the background changes little\nacross images; capture is triggered automatically, hence there is no human\nbias. The challenge is learning recognition in a handful of locations, and\ngeneralizing animal detection and classification to new locations where no\ntraining data is available. In our experiments state-of-the-art algorithms show\nexcellent performance when tested at the same location where they were trained.\nHowever, we find that generalization to new locations is poor, especially for\nclassification systems.",
    "published_date": "2018-07-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "q-bio.PE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04975v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.04899v2",
    "title": "Analysis Dictionary Learning based Classification: Structure for Robustness",
    "authors": [
      "Wen Tang",
      "Ashkan Panahi",
      "Hamid Krim",
      "Liyi Dai"
    ],
    "author_ids": [],
    "abstract": "A discriminative structured analysis dictionary is proposed for the\nclassification task. A structure of the union of subspaces (UoS) is integrated\ninto the conventional analysis dictionary learning to enhance the capability of\ndiscrimination. A simple classifier is also simultaneously included into the\nformulated functional to ensure a more complete consistent classification. The\nsolution of the algorithm is efficiently obtained by the linearized alternating\ndirection method of multipliers. Moreover, a distributed structured analysis\ndictionary learning is also presented to address large scale datasets. It can\ngroup-(class-) independently train the structured analysis dictionaries by\ndifferent machines/cores/threads, and therefore avoid a high computational\ncost. A consensus structured analysis dictionary and a global classifier are\njointly learned in the distributed approach to safeguard the discriminative\npower and the efficiency of classification. Experiments demonstrate that our\nmethod achieves a comparable or better performance than the state-of-the-art\nalgorithms in a variety of visual classification tasks. In addition, the\ntraining and testing computational complexity are also greatly reduced.",
    "published_date": "2018-07-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04899v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.04723v1",
    "title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning Approach",
    "authors": [
      "Iulian Vlad Serban",
      "Chinnadhurai Sankar",
      "Michael Pieper",
      "Joelle Pineau",
      "Yoshua Bengio"
    ],
    "author_ids": [],
    "abstract": "Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches.",
    "published_date": "2018-07-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE",
      "stat.ML",
      "I.5.1; I.2.7"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04723v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.04384v1",
    "title": "Verification and Calibration of Antenna Cross-Polarization Discrimination and Penetration Loss for Millimeter Wave Communications",
    "authors": [
      "Yunchou Xing",
      "Ojas Kanhere",
      "Shihao Ju",
      "Theodore S. Rappaport",
      "George R. MacCartney Jr"
    ],
    "author_ids": [],
    "abstract": "This article presents measurement guidelines and verification procedures for\nantenna cross-polarization discrimination (XPD) and penetration loss\nmeasurements for millimeter wave (mmWave) channel sounder systems. These\ntechniques are needed to ensure accurate and consistent measurements by\ndifferent researchers at different frequencies and bandwidths. Measurements at\n73 GHz are used to demonstrate and verify the guidelines, and show the\nconsistency of the antenna XPD factor and the penetration loss at different\ntransmitter-receiver (T-R) separation distances, thus providing a systematic\nmethod that may be used at any frequency for reliable field measurements.",
    "published_date": "2018-07-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04384v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.04152v1",
    "title": "Integrality Gap of the Configuration LP for the Restricted Max-Min Fair Allocation",
    "authors": [
      "Siu-Wing Cheng",
      "Yuchen Mao"
    ],
    "author_ids": [],
    "abstract": "The max-min fair allocation problem seeks an allocation of resources to\nplayers that maximizes the minimum total value obtained by any player. Each\nplayer $p$ has a non-negative value $v_{pr}$ on resource $r$. In the restricted\ncase, we have $v_{pr}\\in \\{v_r, 0\\}$. That is, a resource $r$ is worth value\n$v_r$ for the players who desire it and value 0 for the other players. In this\npaper, we consider the configuration LP, a linear programming relaxation for\nthe restricted problem. The integrality gap of the configuration LP is at least\n$2$. Asadpour, Feige, and Saberi proved an upper bound of $4$. We improve the\nupper bound to $23/6$ using the dual of the configuration LP. Since the\nconfiguration LP can be solved to any desired accuracy $\\delta$ in polynomial\ntime, our result leads to a polynomial-time algorithm which estimates the\noptimal value within a factor of $23/6+\\delta$.",
    "published_date": "2018-07-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04152v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.04058v2",
    "title": "Presentation Attack Detection for Cadaver Iris",
    "authors": [
      "Mateusz Trokielewicz",
      "Adam Czajka",
      "Piotr Maciejewicz"
    ],
    "author_ids": [],
    "abstract": "This paper presents a deep-learning-based method for iris presentation attack\ndetection (PAD) when iris images are obtained from deceased people. Our\napproach is based on the VGG-16 architecture fine-tuned with a database of 574\npost-mortem, near-infrared iris images from the\nWarsaw-BioBase-PostMortem-Iris-v1 database, complemented by a dataset of 256\nimages of live irises, collected within the scope of this study. Experiments\ndescribed in this paper show that our approach is able to correctly classify\niris images as either representing a live or a dead eye in almost 99% of the\ntrials, averaged over 20 subject-disjoint, train/test splits. We also show that\nthe post-mortem iris detection accuracy increases as time since death elapses,\nand that we are able to construct a classification system with\nAPCER=0%@BPCER=1% (Attack Presentation and Bona Fide Presentation\nClassification Error Rates, respectively) when only post-mortem samples\ncollected at least 16 hours post-mortem are considered. Since acquisitions of\nante- and post-mortem samples differ significantly, we applied countermeasures\nto minimize bias in our classification methodology caused by image properties\nthat are not related to the PAD. This included using the same iris sensor in\ncollection of ante- and post-mortem samples, and analysis of class activation\nmaps to ensure that discriminant iris regions utilized by our classifier are\nrelated to properties of the eye, and not to those of the acquisition protocol.\nThis paper offers the first known to us PAD method in a post-mortem setting,\ntogether with an explanation of the decisions made by the convolutional neural\nnetwork. Along with the paper we offer source codes, weights of the trained\nnetwork, and a dataset of live iris images to facilitate reproducibility and\nfurther research.",
    "published_date": "2018-07-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.04058v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.10572v1",
    "title": "Two-Layer Mixture Network Ensemble for Apparel Attributes Classification",
    "authors": [
      "Tianqi Han",
      "Zhihui Fu",
      "Hongyu Li"
    ],
    "author_ids": [],
    "abstract": "Recognizing apparel attributes has recently drawn great interest in the\ncomputer vision community. Methods based on various deep neural networks have\nbeen proposed for image classification, which could be applied to apparel\nattributes recognition. An interesting problem raised is how to ensemble these\nmethods to further improve the accuracy. In this paper, we propose a two-layer\nmixture framework for ensemble different networks. In the first layer of this\nframework, two types of ensemble learning methods, bagging and boosting, are\nseparately applied. Different from traditional methods, our bagging process\nmakes use of the whole training set, not random subsets, to train each model in\nthe ensemble, where several differentiated deep networks are used to promote\nmodel variance. To avoid the bias of small-scale samples, the second layer only\nadopts bagging to mix the results obtained with bagging and boosting in the\nfirst layer. Experimental results demonstrate that the proposed mixture\nframework outperforms any individual network model or either independent\nensemble method in apparel attributes classification.",
    "published_date": "2018-07-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.10572v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.03521v3",
    "title": "Privacy and Fairness in Recommender Systems via Adversarial Training of User Representations",
    "authors": [
      "Yehezkel S. Resheff",
      "Yanai Elazar",
      "Moni Shahar",
      "Oren Sar Shalom"
    ],
    "author_ids": [],
    "abstract": "Latent factor models for recommender systems represent users and items as low\ndimensional vectors. Privacy risks of such systems have previously been studied\nmostly in the context of recovery of personal information in the form of usage\nrecords from the training data. However, the user representations themselves\nmay be used together with external data to recover private user information\nsuch as gender and age. In this paper we show that user vectors calculated by a\ncommon recommender system can be exploited in this way. We propose the\nprivacy-adversarial framework to eliminate such leakage of private information,\nand study the trade-off between recommender performance and leakage both\ntheoretically and empirically using a benchmark dataset. An advantage of the\nproposed method is that it also helps guarantee fairness of results, since all\nimplicit knowledge of a set of attributes is scrubbed from the representations\nused by the model, and thus can't enter into the decision making. We discuss\nfurther applications of this method towards the generation of deeper and more\ninsightful recommendations.",
    "published_date": "2018-07-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.03521v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.03495v3",
    "title": "Significance-based Estimation-of-Distribution Algorithms",
    "authors": [
      "Benjamin Doerr",
      "Martin Krejca"
    ],
    "author_ids": [],
    "abstract": "Estimation-of-distribution algorithms (EDAs) are randomized search heuristics\nthat create a probabilistic model of the solution space, which is updated\niteratively, based on the quality of the solutions sampled according to the\nmodel. As previous works show, this iteration-based perspective can lead to\nerratic updates of the model, in particular, to bit-frequencies approaching a\nrandom boundary value.\n  In order to overcome this problem, we propose a new EDA based on the classic\ncompact genetic algorithm (cGA) that takes into account a longer history of\nsamples and updates its model only with respect to information which it\nclassifies as statistically significant. We prove that this significance-based\ncompact genetic algorithm (sig-cGA) optimizes the commonly regarded benchmark\nfunctions OneMax, LeadingOnes, and BinVal all in quasilinear time, a result\nshown for no other EDA or evolutionary algorithm so far.\n  For the recently proposed scGA -- an EDA that tries to prevent erratic model\nupdates by imposing a bias to the uniformly distributed model -- we prove that\nit optimizes OneMax only in a time exponential in its hypothetical population\nsize. Similarly, we show that the convex search algorithm cannot optimize\nOneMax in polynomial time.",
    "published_date": "2018-07-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.03495v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.03293v1",
    "title": "Beamforming Techniques for Non-Orthogonal Multiple Access in 5G Cellular Networks",
    "authors": [
      "Faezeh Alavi",
      "Kanapathippillai Cumanan",
      "Zhiguo Ding",
      "Alister G. Burr"
    ],
    "author_ids": [],
    "abstract": "In this paper, we develop various beamforming techniques for downlink\ntransmission for multiple-input single-output (MISO) non-orthogonal multiple\naccess (NOMA) systems. First, a beamforming approach with perfect channel state\ninformation (CSI) is investigated to provide the required quality of service\n(QoS) for all users. Taylor series approximation and semidefinite relaxation\n(SDR) techniques are employed to reformulate the original non-convex power\nminimization problem to a tractable one. Further, a fairness-based beamforming\napproach is proposed through a max-min formulation to maintain fairness between\nusers. Next, we consider a robust scheme by incorporating channel\nuncertainties, where the transmit power is minimized while satisfying the\noutage probability requirement at each user. Through exploiting the SDR\napproach, the original non-convex problem is reformulated in a linear matrix\ninequality (LMI) form to obtain the optimal solution. Numerical results\ndemonstrate that the robust scheme can achieve better performance compared to\nthe non-robust scheme in terms of the rate satisfaction ratio. Further,\nsimulation results confirm that NOMA consumes a little over half transmit power\nneeded by OMA for the same data rate requirements. Hence, NOMA has the\npotential to significantly improve the system performance in terms of transmit\npower consumption in future 5G networks and beyond.",
    "published_date": "2018-07-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.03293v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.02987v1",
    "title": "Fair Task Allocation in Crowdsourced Delivery",
    "authors": [
      "Fuat Basik",
      "Bugra Gedik",
      "Hakan Ferhatosmanoglu",
      "Kun-Lung Wu"
    ],
    "author_ids": [],
    "abstract": "Faster and more cost-efficient, crowdsourced delivery is needed to meet the\ngrowing customer demands of many industries, including online shopping,\non-demand local delivery, and on-demand transportation. The power of\ncrowdsourced delivery stems from the large number of workers potentially\navailable to provide services and reduce costs. It has been shown in social\npsychology literature that fairness is key to ensuring high worker\nparticipation. However, existing assignment solutions fall short on modeling\nthe dynamic fairness metric. In this work, we introduce a new assignment\nstrategy for crowdsourced delivery tasks. This strategy takes fairness towards\nworkers into consideration, while maximizing the task allocation ratio. Since\nredundant assignments are not possible in delivery tasks, we first introduce a\n2-phase allocation model that increases the reliability of a worker to complete\na given task. To realize the effectiveness of our model in practice, we present\nboth offline and online versions of our proposed algorithm called F-Aware.\nGiven a task-to-worker bipartite graph, F-Aware assigns each task to a worker\nthat minimizes unfairness, while allocating tasks to use worker capacities as\nmuch as possible. We present an evaluation of our algorithms with respect to\nrunning time, task allocation ratio (TAR), as well as unfairness and assignment\nratio. Experiments show that F-Aware runs around 10^7 x faster than the\nTAR-optimal solution and allocates 96.9% of the tasks that can be allocated by\nit. Moreover, it is shown that, F-Aware is able to provide a much fair\ndistribution of tasks to workers than the best competitor algorithm.",
    "published_date": "2018-07-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02987v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.02682v1",
    "title": "A Supervised Geometry-Aware Mapping Approach for Classification of Hyperspectral Images",
    "authors": [
      "Ramanarayan Mohanty",
      "S L Happy",
      "Aurobinda Routray"
    ],
    "author_ids": [],
    "abstract": "The lack of proper class discrimination among the Hyperspectral (HS) data\npoints poses a potential challenge in HS classification. To address this issue,\nthis paper proposes an optimal geometry-aware transformation for enhancing the\nclassification accuracy. The underlying idea of this method is to obtain a\nlinear projection matrix by solving a nonlinear objective function based on the\nintrinsic geometrical structure of the data. The objective function is\nconstructed to quantify the discrimination between the points from dissimilar\nclasses on the projected data space. Then the obtained projection matrix is\nused to linearly map the data to more discriminative space. The effectiveness\nof the proposed transformation is illustrated with three benchmark real-world\nHS data sets. The experiments reveal that the classification and dimensionality\nreduction methods on the projected discriminative space outperform their\ncounterpart in the original space.",
    "published_date": "2018-07-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02682v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.02629v2",
    "title": "Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile",
    "authors": [
      "Panayotis Mertikopoulos",
      "Bruno Lecouat",
      "Houssam Zenati",
      "Chuan-Sheng Foo",
      "Vijay Chandrasekhar",
      "Georgios Piliouras"
    ],
    "author_ids": [],
    "abstract": "Owing to their connection with generative adversarial networks (GANs),\nsaddle-point problems have recently attracted considerable interest in machine\nlearning and beyond. By necessity, most theoretical guarantees revolve around\nconvex-concave (or even linear) problems; however, making theoretical inroads\ntowards efficient GAN training depends crucially on moving beyond this classic\nframework. To make piecemeal progress along these lines, we analyze the\nbehavior of mirror descent (MD) in a class of non-monotone problems whose\nsolutions coincide with those of a naturally associated variational inequality\n- a property which we call coherence. We first show that ordinary, \"vanilla\" MD\nconverges under a strict version of this condition, but not otherwise; in\nparticular, it may fail to converge even in bilinear models with a unique\nsolution. We then show that this deficiency is mitigated by optimism: by taking\nan \"extra-gradient\" step, optimistic mirror descent (OMD) converges in all\ncoherent problems. Our analysis generalizes and extends the results of\nDaskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear\nproblems, and makes concrete headway for establishing convergence beyond\nconvex-concave games. We also provide stochastic analogues of these results,\nand we validate our analysis by numerical experiments in a wide array of GAN\nmodels (including Gaussian mixture models, as well as the CelebA and CIFAR-10\ndatasets).",
    "published_date": "2018-07-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.GT",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02629v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.02622v2",
    "title": "Rényi Entropy Power Inequalities via Normal Transport and Rotation",
    "authors": [
      "Olivier Rioul"
    ],
    "author_ids": [],
    "abstract": "Following a recent proof of Shannon's entropy power inequality (EPI), a\ncomprehensive framework for deriving various EPIs for the R\\'enyi entropy is\npresented that uses transport arguments from normal densities and a change of\nvariable by rotation. Simple arguments are given to recover the previously\nknown R\\'enyi EPIs and derive new ones, by unifying a multiplicative form with\nconstant c and a modification with exponent {\\alpha} of previous works. In\nparticular, for log-concave densities, we obtain a simple transportation proof\nof a sharp varentropy bound.",
    "published_date": "2018-07-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02622v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.02490v1",
    "title": "Deep Multiple Instance Feature Learning via Variational Autoencoder",
    "authors": [
      "Shabnam Ghaffarzadegan"
    ],
    "author_ids": [],
    "abstract": "We describe a novel weakly supervised deep learning framework that combines\nboth the discriminative and generative models to learn meaningful\nrepresentation in the multiple instance learning (MIL) setting. MIL is a weakly\nsupervised learning problem where labels are associated with groups of\ninstances (referred as bags) instead of individual instances. To address the\nessential challenge in MIL problems raised from the uncertainty of positive\ninstances label, we use a discriminative model regularized by variational\nautoencoders (VAEs) to maximize the differences between latent representations\nof all instances and negative instances. As a result, the hidden layer of the\nvariational autoencoder learns meaningful representation. This representation\ncan effectively be used for MIL problems as illustrated by better performance\non the standard benchmark datasets comparing to the state-of-the-art\napproaches. More importantly, unlike most related studies, the proposed\nframework can be easily scaled to large dataset problems, as illustrated by the\naudio event detection and segmentation task. Visualization also confirms the\neffectiveness of the latent representation in discriminating positive and\nnegative classes.",
    "published_date": "2018-07-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02490v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.02110v1",
    "title": "TextTopicNet - Self-Supervised Learning of Visual Features Through Embedding Images on Semantic Text Spaces",
    "authors": [
      "Yash Patel",
      "Lluis Gomez",
      "Raul Gomez",
      "Marçal Rusiñol",
      "Dimosthenis Karatzas",
      "C. V. Jawahar"
    ],
    "author_ids": [],
    "abstract": "The immense success of deep learning based methods in computer vision heavily\nrelies on large scale training datasets. These richly annotated datasets help\nthe network learn discriminative visual features. Collecting and annotating\nsuch datasets requires a tremendous amount of human effort and annotations are\nlimited to popular set of classes. As an alternative, learning visual features\nby designing auxiliary tasks which make use of freely available\nself-supervision has become increasingly popular in the computer vision\ncommunity.\n  In this paper, we put forward an idea to take advantage of multi-modal\ncontext to provide self-supervision for the training of computer vision\nalgorithms. We show that adequate visual features can be learned efficiently by\ntraining a CNN to predict the semantic textual context in which a particular\nimage is more probable to appear as an illustration. More specifically we use\npopular text embedding techniques to provide the self-supervision for the\ntraining of deep CNN.\n  Our experiments demonstrate state-of-the-art performance in image\nclassification, object detection, and multi-modal retrieval compared to recent\nself-supervised or naturally-supervised approaches.",
    "published_date": "2018-07-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.02110v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.01653v2",
    "title": "Latent Space Autoregression for Novelty Detection",
    "authors": [
      "Davide Abati",
      "Angelo Porrello",
      "Simone Calderara",
      "Rita Cucchiara"
    ],
    "author_ids": [],
    "abstract": "Novelty detection is commonly referred to as the discrimination of\nobservations that do not conform to a learned model of regularity. Despite its\nimportance in different application settings, designing a novelty detector is\nutterly complex due to the unpredictable nature of novelties and its\ninaccessibility during the training procedure, factors which expose the\nunsupervised nature of the problem. In our proposal, we design a general\nframework where we equip a deep autoencoder with a parametric density estimator\nthat learns the probability distribution underlying its latent representations\nthrough an autoregressive procedure. We show that a maximum likelihood\nobjective, optimized in conjunction with the reconstruction of normal samples,\neffectively acts as a regularizer for the task at hand, by minimizing the\ndifferential entropy of the distribution spanned by latent vectors. In addition\nto providing a very general formulation, extensive experiments of our model on\npublicly available datasets deliver on-par or superior performances if compared\nto state-of-the-art methods in one-class and video anomaly detection settings.\nDifferently from prior works, our proposal does not make any assumption about\nthe nature of the novelties, making our work readily applicable to diverse\ncontexts.",
    "published_date": "2018-07-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.01653v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.01496v1",
    "title": "Centrality-Friendship Paradoxes: When Our Friends Are More Important Than Us",
    "authors": [
      "Desmond J. Higham"
    ],
    "author_ids": [],
    "abstract": "The friendship paradox states that, on average, our friends have more friends\nthan we do. In network terms, the average degree over the nodes can never\nexceed the average degree over the neighbours of nodes. This effect, which is a\nclassic example of sampling bias, has attracted much attention in the social\nscience and network science literature, with variations and extensions of the\nparadox being defined, tested and interpreted. Here, we show that a version of\nthe paradox holds rigorously for eigenvector centrality: on average, our\nfriends are more important than us. We then consider general matrix-function\ncentrality, including Katz centrality, and give sufficient conditions for the\nparadox to hold. We also discuss which results can be generalized to the cases\nof directed and weighted edges. In this way, we add theoretical support for a\nfield that has largely been evolving through empirical testing.",
    "published_date": "2018-07-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DM",
      "cs.SI",
      "68R10, 94C15",
      "G.2.2; F.2.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.01496v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.01408v3",
    "title": "Case for the double-blind peer review",
    "authors": [
      "Lucie Tvrznikova"
    ],
    "author_ids": [],
    "abstract": "Peer review is a process designed to produce a fair assessment of research\nquality before the publication of scholarly work in a journal. Demographics,\nnepotism, and seniority have been all shown to affect reviewer behavior\nsuggesting the most common, single-blind review method (or the less common open\nreview method) might be biased. A survey of current research indicates that\ndouble-blind review offers a solution to many biases stemming from author's\ngender, seniority, or location without imposing any significant downsides.",
    "published_date": "2018-07-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.01408v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.01134v1",
    "title": "Welfare and Distributional Impacts of Fair Classification",
    "authors": [
      "Lily Hu",
      "Yiling Chen"
    ],
    "author_ids": [],
    "abstract": "Current methodologies in machine learning analyze the effects of various\nstatistical parity notions of fairness primarily in light of their impacts on\npredictive accuracy and vendor utility loss. In this paper, we propose a new\nframework for interpreting the effects of fairness criteria by converting the\nconstrained loss minimization problem into a social welfare maximization\nproblem. This translation moves a classifier and its output into utility space\nwhere individuals, groups, and society at-large experience different welfare\nchanges due to classification assignments. Under this characterization,\npredictions and fairness constraints are seen as shaping societal welfare and\ndistribution and revealing individuals' implied welfare weights in\nsociety--weights that may then be interpreted through a fairness lens. The\nsocial welfare formulation of the fairness problem brings to the fore concerns\nof distributive justice that have always had a central albeit more implicit\nrole in standard algorithmic fairness approaches.",
    "published_date": "2018-07-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.01134v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00948v1",
    "title": "Does Removing Stereotype Priming Remove Bias? A Pilot Human-Robot Interaction Study",
    "authors": [
      "Tobi Ogunyale",
      "De'Aira Bryant",
      "Ayanna Howard"
    ],
    "author_ids": [],
    "abstract": "Robots capable of participating in complex social interactions have shown\ngreat potential in a variety of applications. As these robots grow more\npopular, it is essential to continuously evaluate the dynamics of the\nhuman-robot relationship. One factor shown to have potential impacts on this\ncritical relationship is the human projection of stereotypes onto social\nrobots, a practice that is implicitly known to effect both developers and users\nof this technology. As such, in this research, we wished to investigate the\ndifference in participants' perceptions of the robot interaction if we removed\nstereotype priming. This has not yet been a common practice in similar studies.\nGiven the stereotypes of emotions among ethnic groups, especially in the U.S.,\nthis study specifically sought to investigate the impact that robot \"skin\ncolor\" could potentially have on the human perception of a robot's emotional\nexpressive behavior. A between-subject experiment with 198 individuals was\nconducted. The results showed no significant differences in the overall emotion\nclassification or intensity ratings for the different robot skin colors. These\nresults lend credence to our hypothesis that when individuals are not primed\nwith information related to human stereotypes, robots are evaluated based on\nfunctional attributes versus stereotypical attributes. This provides some\nconfidence that robots, if designed correctly, can potentially be used as a\ntool to override stereotype-based biases associated with human behavior.",
    "published_date": "2018-07-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00948v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.00905v2",
    "title": "Learning under selective labels in the presence of expert consistency",
    "authors": [
      "Maria De-Arteaga",
      "Artur Dubrawski",
      "Alexandra Chouldechova"
    ],
    "author_ids": [],
    "abstract": "We explore the problem of learning under selective labels in the context of\nalgorithm-assisted decision making. Selective labels is a pervasive selection\nbias problem that arises when historical decision making blinds us to the true\noutcome for certain instances. Examples of this are common in many\napplications, ranging from predicting recidivism using pre-trial release data\nto diagnosing patients. In this paper we discuss why selective labels often\ncannot be effectively tackled by standard methods for adjusting for sample\nselection bias, even if there are no unobservables. We propose a data\naugmentation approach that can be used to either leverage expert consistency to\nmitigate the partial blindness that results from selective labels, or to\nempirically validate whether learning under such framework may lead to\nunreliable models prone to systemic discrimination.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00905v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00787v1",
    "title": "A Unified Approach to Quantifying Algorithmic Unfairness: Measuring Individual & Group Unfairness via Inequality Indices",
    "authors": [
      "Till Speicher",
      "Hoda Heidari",
      "Nina Grgic-Hlaca",
      "Krishna P. Gummadi",
      "Adish Singla",
      "Adrian Weller",
      "Muhammad Bilal Zafar"
    ],
    "author_ids": [],
    "abstract": "Discrimination via algorithmic decision making has received considerable\nattention. Prior work largely focuses on defining conditions for fairness, but\ndoes not define satisfactory measures of algorithmic unfairness. In this paper,\nwe focus on the following question: Given two unfair algorithms, how should we\ndetermine which of the two is more unfair? Our core idea is to use existing\ninequality indices from economics to measure how unequally the outcomes of an\nalgorithm benefit different individuals or groups in a population. Our work\noffers a justified and general framework to compare and contrast the\n(un)fairness of algorithmic predictors. This unifying approach enables us to\nquantify unfairness both at the individual and the group level. Further, our\nwork reveals overlooked tradeoffs between different fairness notions: using our\nproposed measures, the overall individual-level unfairness of an algorithm can\nbe decomposed into a between-group and a within-group component. Earlier\nmethods are typically designed to tackle only between-group unfairness, which\nmay be justified for legal or other reasons. However, we demonstrate that\nminimizing exclusively the between-group component may, in fact, increase the\nwithin-group, and hence the overall unfairness. We characterize and illustrate\nthe tradeoffs between our measures of (un)fairness and the prediction accuracy.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00787v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00553v2",
    "title": "A Broader View on Bias in Automated Decision-Making: Reflecting on Epistemology and Dynamics",
    "authors": [
      "Roel Dobbe",
      "Sarah Dean",
      "Thomas Gilbert",
      "Nitin Kohli"
    ],
    "author_ids": [],
    "abstract": "Machine learning (ML) is increasingly deployed in real world contexts,\nsupplying actionable insights and forming the basis of automated\ndecision-making systems. While issues resulting from biases pre-existing in\ntraining data have been at the center of the fairness debate, these systems are\nalso affected by technical and emergent biases, which often arise as\ncontext-specific artifacts of implementation. This position paper interprets\ntechnical bias as an epistemological problem and emergent bias as a dynamical\nfeedback phenomenon. In order to stimulate debate on how to change machine\nlearning practice to effectively address these issues, we explore this broader\nview on bias, stress the need to reflect on epistemology, and point to\nvalue-sensitive design methodologies to revisit the design and implementation\nprocess of automated decision-making systems.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "math.DS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00553v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00517v1",
    "title": "Women also Snowboard: Overcoming Bias in Captioning Models (Extended Abstract)",
    "authors": [
      "Lisa Anne Hendricks",
      "Kaylee Burns",
      "Kate Saenko",
      "Trevor Darrell",
      "Anna Rohrbach"
    ],
    "author_ids": [],
    "abstract": "Most machine learning methods are known to capture and exploit biases of the\ntraining data. While some biases are beneficial for learning, others are\nharmful. Specifically, image captioning models tend to exaggerate biases\npresent in training data. This can lead to incorrect captions in domains where\nunbiased captions are desired, or required, due to over reliance on the learned\nprior and image context. We investigate generation of gender specific caption\nwords (e.g. man, woman) based on the person's appearance or the image context.\nWe introduce a new Equalizer model that ensures equal gender probability when\ngender evidence is occluded in a scene and confident predictions when gender\nevidence is present. The resulting model is forced to look at a person rather\nthan use contextual cues to make a gender specific prediction. The losses that\ncomprise our model, the Appearance Confusion Loss and the Confident Loss, are\ngeneral, and can be added to any description model in order to mitigate impacts\nof unwanted bias in a description dataset. Our proposed model has lower error\nthan prior work when describing images with people and mentioning their gender\nand more closely matches the ground truth ratio of sentences including women to\nsentences including men.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00517v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00504v1",
    "title": "Deep Reasoning with Knowledge Graph for Social Relationship Understanding",
    "authors": [
      "Zhouxia Wang",
      "Tianshui Chen",
      "Jimmy Ren",
      "Weihao Yu",
      "Hui Cheng",
      "Liang Lin"
    ],
    "author_ids": [],
    "abstract": "Social relationships (e.g., friends, couple etc.) form the basis of the\nsocial network in our daily life. Automatically interpreting such relationships\nbears a great potential for the intelligent systems to understand human\nbehavior in depth and to better interact with people at a social level. Human\nbeings interpret the social relationships within a group not only based on the\npeople alone, and the interplay between such social relationships and the\ncontextual information around the people also plays a significant role.\nHowever, these additional cues are largely overlooked by the previous studies.\nWe found that the interplay between these two factors can be effectively\nmodeled by a novel structured knowledge graph with proper message propagation\nand attention. And this structured knowledge can be efficiently integrated into\nthe deep neural network architecture to promote social relationship\nunderstanding by an end-to-end trainable Graph Reasoning Model (GRM), in which\na propagation mechanism is learned to propagate node message through the graph\nto explore the interaction between persons of interest and the contextual\nobjects. Meanwhile, a graph attentional mechanism is introduced to explicitly\nreason about the discriminative objects to promote recognition. Extensive\nexperiments on the public benchmarks demonstrate the superiority of our method\nover the existing leading competitors.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00504v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00468v2",
    "title": "Automated Directed Fairness Testing",
    "authors": [
      "Sakshi Udeshi",
      "Pryanshu Arora",
      "Sudipta Chattopadhyay"
    ],
    "author_ids": [],
    "abstract": "Fairness is a critical trait in decision making. As machine-learning models\nare increasingly being used in sensitive application domains (e.g. education\nand employment) for decision making, it is crucial that the decisions computed\nby such models are free of unintended bias. But how can we automatically\nvalidate the fairness of arbitrary machine-learning models? For a given\nmachine-learning model and a set of sensitive input parameters, our AEQUITAS\napproach automatically discovers discriminatory inputs that highlight fairness\nviolation. At the core of AEQUITAS are three novel strategies to employ\nprobabilistic search over the input space with the objective of uncovering\nfairness violation. Our AEQUITAS approach leverages inherent robustness\nproperty in common machine-learning models to design and implement scalable\ntest generation methodologies. An appealing feature of our generated test\ninputs is that they can be systematically added to the training set of the\nunderlying model and improve its fairness. To this end, we design a fully\nautomated module that guarantees to improve the fairness of the underlying\nmodel.\n  We implemented AEQUITAS and we have evaluated it on six state-of-the-art\nclassifiers, including a classifier that was designed with fairness\nconstraints. We show that AEQUITAS effectively generates inputs to uncover\nfairness violation in all the subject classifiers and systematically improves\nthe fairness of the respective models using the generated test inputs. In our\nevaluation, AEQUITAS generates up to 70% discriminatory inputs (w.r.t. the\ntotal number of inputs generated) and leverages these inputs to improve the\nfairness up to 94%.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00468v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00461v1",
    "title": "Debiasing representations by removing unwanted variation due to protected attributes",
    "authors": [
      "Amanda Bower",
      "Laura Niss",
      "Yuekai Sun",
      "Alexander Vargo"
    ],
    "author_ids": [],
    "abstract": "We propose a regression-based approach to removing implicit biases in\nrepresentations. On tasks where the protected attribute is observed, the method\nis statistically more efficient than known approaches. Further, we show that\nthis approach leads to debiased representations that satisfy a first order\napproximation of conditional parity. Finally, we demonstrate the efficacy of\nthe proposed approach by reducing racial bias in recidivism risk scores.",
    "published_date": "2018-07-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00461v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1807.00392v1",
    "title": "Gradient Reversal Against Discrimination",
    "authors": [
      "Edward Raff",
      "Jared Sylvester"
    ],
    "author_ids": [],
    "abstract": "No methods currently exist for making arbitrary neural networks fair. In this\nwork we introduce GRAD, a new and simplified method to producing fair neural\nnetworks that can be used for auto-encoding fair representations or directly\nwith predictive networks. It is easy to implement and add to existing\narchitectures, has only one (insensitive) hyper-parameter, and provides\nimproved individual and group fairness. We use the flexibility of GRAD to\ndemonstrate multi-attribute protection.",
    "published_date": "2018-07-01T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00392v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00199v1",
    "title": "Achieving Fairness through Adversarial Learning: an Application to Recidivism Prediction",
    "authors": [
      "Christina Wadsworth",
      "Francesca Vera",
      "Chris Piech"
    ],
    "author_ids": [],
    "abstract": "Recidivism prediction scores are used across the USA to determine sentencing\nand supervision for hundreds of thousands of inmates. One such generator of\nrecidivism prediction scores is Northpointe's Correctional Offender Management\nProfiling for Alternative Sanctions (COMPAS) score, used in states like\nCalifornia and Florida, which past research has shown to be biased against\nblack inmates according to certain measures of fairness. To counteract this\nracial bias, we present an adversarially-trained neural network that predicts\nrecidivism and is trained to remove racial bias. When comparing the results of\nour model to COMPAS, we gain predictive accuracy and get closer to achieving\ntwo out of three measures of fairness: parity and equality of odds. Our model\ncan be generalized to any prediction and demographic. This piece of research\ncontributes an example of scientific replication and simplification in a\nhigh-stakes real-world application like recidivism prediction.",
    "published_date": "2018-06-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00199v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1807.00028v2",
    "title": "Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints",
    "authors": [
      "Andrew Cotter",
      "Maya Gupta",
      "Heinrich Jiang",
      "Nathan Srebro",
      "Karthik Sridharan",
      "Serena Wang",
      "Blake Woodworth",
      "Seungil You"
    ],
    "author_ids": [],
    "abstract": "Classifiers can be trained with data-dependent constraints to satisfy\nfairness goals, reduce churn, achieve a targeted false positive rate, or other\npolicy goals. We study the generalization performance for such constrained\noptimization problems, in terms of how well the constraints are satisfied at\nevaluation time, given that they are satisfied at training time. To improve\ngeneralization performance, we frame the problem as a two-player game where one\nplayer optimizes the model parameters on a training dataset, and the other\nplayer enforces the constraints on an independent validation dataset. We build\non recent work in two-player constrained optimization to show that if one uses\nthis two-dataset approach, then constraint generalization can be significantly\nimproved. As we illustrate experimentally, this approach works not only in\ntheory, but also in practice.",
    "published_date": "2018-06-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1807.00028v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.11386v1",
    "title": "Ethical Aspects of Internet of Things from Islamic Perspective",
    "authors": [
      "Wazir Zada Khan",
      "Mohammed Zahid",
      "Mohammed Y Aalsalem",
      "Hussein Mohammed Zangoti",
      "Quratulain Arshad"
    ],
    "author_ids": [],
    "abstract": "The Internet of Things (IoTs) is an evolving new face of technology that\nprovides state of the art services using ubiquitously connected smart objects.\nThese smart objects are capable of sensing, processing, collaborating,\ncommunicating the events and provide services. The IoT is a collection of\nheterogeneous technologies like Sensor, RFID, Communication and nanotechnology.\nThese technologies enable smart objects to identify objects, collect\ninformation about their status,communicating the collected information for\ntaking some desired actions. Widespread adaptations of IoT based devices and\nservices raised the ethical challenges for their users. In this paper we\nhighlight ethical challenges raised by IoT and discuss the solutions and\nmethods for encouraging people to properly use these technologies according to\nIslamic teachings.",
    "published_date": "2018-06-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.11386v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.11322v1",
    "title": "Bias in Semantic and Discourse Interpretation",
    "authors": [
      "Nicholas Asher",
      "Soumya Paul"
    ],
    "author_ids": [],
    "abstract": "In this paper, we show how game-theoretic work on conversation combined with\na theory of discourse structure provides a framework for studying interpretive\nbias. Interpretive bias is an essential feature of learning and understanding\nbut also something that can be used to pervert or subvert the truth. The\nframework we develop here provides tools for understanding and analyzing the\nrange of interpretive biases and the factors that contribute to them.",
    "published_date": "2018-06-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.11322v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.11212v1",
    "title": "Proxy Fairness",
    "authors": [
      "Maya Gupta",
      "Andrew Cotter",
      "Mahdi Milani Fard",
      "Serena Wang"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of improving fairness when one lacks access to a\ndataset labeled with protected groups, making it difficult to take advantage of\nstrategies that can improve fairness but require protected group labels, either\nat training or runtime. To address this, we investigate improving fairness\nmetrics for proxy groups, and test whether doing so results in improved\nfairness for the true sensitive groups. Results on benchmark and real-world\ndatasets demonstrate that such a proxy fairness strategy can work well in\npractice. However, we caution that the effectiveness likely depends on the\nchoice of fairness metric, as well as how aligned the proxy groups are with the\ntrue protected groups in terms of the constrained model parameters.",
    "published_date": "2018-06-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.11212v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.10419v1",
    "title": "MTBI Identification From Diffusion MR Images Using Bag of Adversarial Visual Features",
    "authors": [
      "Shervin Minaee",
      "Yao Wang",
      "Alp Aygar",
      "Sohae Chung",
      "Xiuyuan Wang",
      "Yvonne W. Lui",
      "Els Fieremans",
      "Steven Flanagan",
      "Joseph Rath"
    ],
    "author_ids": [],
    "abstract": "In this work, we propose bag of adversarial features (BAF) for identifying\nmild traumatic brain injury (MTBI) patients from their diffusion magnetic\nresonance images (MRI) (obtained within one month of injury) by incorporating\nunsupervised feature learning techniques. MTBI is a growing public health\nproblem with an estimated incidence of over 1.7 million people annually in US.\nDiagnosis is based on clinical history and symptoms, and accurate, concrete\nmeasures of injury are lacking. Unlike most of previous works, which use\nhand-crafted features extracted from different parts of brain for MTBI\nclassification, we employ feature learning algorithms to learn more\ndiscriminative representation for this task. A major challenge in this field\nthus far is the relatively small number of subjects available for training.\nThis makes it difficult to use an end-to-end convolutional neural network to\ndirectly classify a subject from MR images. To overcome this challenge, we\nfirst apply an adversarial auto-encoder (with convolutional structure) to learn\npatch-level features, from overlapping image patches extracted from different\nbrain regions. We then aggregate these features through a bag-of-word approach.\nWe perform an extensive experimental study on a dataset of 227 subjects\n(including 109 MTBI patients, and 118 age and sex matched healthy controls),\nand compare the bag-of-deep-features with several previous approaches. Our\nexperimental results show that the BAF significantly outperforms earlier works\nrelying on the mean values of MR metrics in selected brain regions.",
    "published_date": "2018-06-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.10419v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.10322v1",
    "title": "The Virtuous Machine - Old Ethics for New Technology?",
    "authors": [
      "Nicolas Berberich",
      "Klaus Diepold"
    ],
    "author_ids": [],
    "abstract": "Modern AI and robotic systems are characterized by a high and ever-increasing\nlevel of autonomy. At the same time, their applications in fields such as\nautonomous driving, service robotics and digital personal assistants move\ncloser to humans. From the combination of both developments emerges the field\nof AI ethics which recognizes that the actions of autonomous machines entail\nmoral dimensions and tries to answer the question of how we can build moral\nmachines. In this paper we argue for taking inspiration from Aristotelian\nvirtue ethics by showing that it forms a suitable combination with modern AI\ndue to its focus on learning from experience. We furthermore propose that\nimitation learning from moral exemplars, a central concept in virtue ethics,\ncan solve the value alignment problem. Finally, we show that an intelligent\nsystem endowed with the virtues of temperance and friendship to humans would\nnot pose a control problem as it would not have the desire for limitless\nself-improvement.",
    "published_date": "2018-06-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.10322v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09918v2",
    "title": "Hierarchical VampPrior Variational Fair Auto-Encoder",
    "authors": [
      "Philip Botros",
      "Jakub M. Tomczak"
    ],
    "author_ids": [],
    "abstract": "Decision making is a process that is extremely prone to different biases. In\nthis paper we consider learning fair representations that aim at removing\nnuisance (sensitive) information from the decision process. For this purpose,\nwe propose to use deep generative modeling and adapt a hierarchical Variational\nAuto-Encoder to learn these fair representations. Moreover, we utilize the\nmutual information as a useful regularizer for enforcing fairness of a\nrepresentation. In experiments on two benchmark datasets and two scenarios\nwhere the sensitive variables are fully and partially observable, we show that\nthe proposed approach either outperforms or performs on par with the current\nbest model.",
    "published_date": "2018-06-26T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09918v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09777v1",
    "title": "On the Implicit Bias of Dropout",
    "authors": [
      "Poorya Mianjy",
      "Raman Arora",
      "Rene Vidal"
    ],
    "author_ids": [],
    "abstract": "Algorithmic approaches endow deep learning systems with implicit bias that\nhelps them generalize even in over-parametrized settings. In this paper, we\nfocus on understanding such a bias induced in learning through dropout, a\npopular technique to avoid overfitting in deep learning. For single\nhidden-layer linear neural networks, we show that dropout tends to make the\nnorm of incoming/outgoing weight vectors of all the hidden nodes equal. In\naddition, we provide a complete characterization of the optimization landscape\ninduced by dropout.",
    "published_date": "2018-06-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09777v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09251v1",
    "title": "Optimal Online Contention Resolution Schemes via Ex-Ante Prophet Inequalities",
    "authors": [
      "Euiwoong Lee",
      "Sahil Singla"
    ],
    "author_ids": [],
    "abstract": "Online contention resolution schemes (OCRSs) were proposed by Feldman,\nSvensson, and Zenklusen as a generic technique to round a fractional solution\nin the matroid polytope in an online fashion. It has found applications in\nseveral stochastic combinatorial problems where there is a commitment\nconstraint: on seeing the value of a stochastic element, the algorithm has to\nimmediately and irrevocably decide whether to select it while always\nmaintaining an independent set in the matroid. Although OCRSs immediately lead\nto prophet inequalities, these prophet inequalities are not optimal. Can we\ninstead use prophet inequalities to design optimal OCRSs?\n  We design the first optimal $1/2$-OCRS for matroids by reducing the problem\nto designing a matroid prophet inequality where we compare to the stronger\nbenchmark of an ex-ante relaxation. We also introduce and design optimal\n$(1-1/e)$-random order CRSs for matroids, which are similar to OCRSs but the\narrival is chosen uniformly at random.",
    "published_date": "2018-06-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09251v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.09211v1",
    "title": "Equalizing Financial Impact in Supervised Learning",
    "authors": [
      "Govind Ramnarayan"
    ],
    "author_ids": [],
    "abstract": "Notions of \"fair classification\" that have arisen in computer science\ngenerally revolve around equalizing certain statistics across protected groups.\nThis approach has been criticized as ignoring societal issues, including how\nerrors can hurt certain groups disproportionately. We pose a modification of\none of the fairness criteria from Hardt, Price, and Srebro [NIPS, 2016] that\nmakes a small step towards addressing this issue in the case of financial\ndecisions like giving loans. We call this new notion \"equalized financial\nimpact.\"",
    "published_date": "2018-06-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09211v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09090v1",
    "title": "Segmentation of Overlapped Steatosis in Whole-Slide Liver Histopathology Microscopy Images",
    "authors": [
      "Mousumi Roy",
      "Fusheng Wang",
      "George Teodoro",
      "Miriam B Vos",
      "Alton Brad Farris",
      "Jun Kong"
    ],
    "author_ids": [],
    "abstract": "An accurate steatosis quantification with pathology tissue samples is of high\nclinical importance. However, such pathology measurement is manually made in\nmost clinical practices, subject to severe reader variability due to large\nsampling bias and poor reproducibility. Although some computerized automated\nmethods are developed to quantify the steatosis regions, they present limited\nanalysis capacity for high resolution whole-slide microscopy images and\naccurate overlapped steatosis division. In this paper, we propose a method that\nextracts an individual whole tissue piece at high resolution with minimum\nbackground area by estimating tissue bounding box and rotation angle. This is\nfollowed by the segmentation and segregation of steatosis regions with high\ncurvature point detection and an ellipse fitting quality assessment method. We\nvalidate our method with isolated and overlapped steatosis regions in liver\ntissue images of 11 patients. The experimental results suggest that our method\nis promising for enhanced support of steatosis quantization during the\npathology review for liver disease treatment.",
    "published_date": "2018-06-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09090v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09081v1",
    "title": "Ethical Implications of Social Internet of Vehicles Systems",
    "authors": [
      "Ricardo Silva",
      "Razi Iqbal"
    ],
    "author_ids": [],
    "abstract": "The core concept of IoT is to equip real world objects with computing,\nprocessing and communicating capabilities to enable socializing between them.\nInternet of Vehicles (IoV) is an adherent of IoT that has realized significant\nadvancements using communication technologies. Vehicles connected through\nInternet are capable of sharing information that can substantially enhance the\nquality of traffic on roads. Social Internet of Things (SIoT) is an instance of\nIoT that deals specifically in socialization of connected objects. SIoT enables\nthe notion of Social Internet of Vehicles (SIoV) where vehicles are the key\nentities for sharing information between themselves and the infrastructure\n(commonly known as Road Side Units (RSUs)). Vehicles in SIoV socialize by\nexchanging data such as traffic congestions, weather conditions, infotainment,\nvacant parking slots, alternate routes and discount coupons for restaurants\netc. In SIoV, vehicles can communicate with other vehicles and infrastructure\nthrough traditional communication technologies like Wi-Fi, Cellular networks or\nthrough Dedicated Short Range Communication (DSRC) etc. SIoV will be confronted\nwith ethical dilemmas and expected to function in an ethically responsible\nmanner. This paper highlights the ethical implications of SIoV systems. Vehicle\nto Vehicle (V2V) and Vehicle to Infrastructure (V2I) involves autonomous\ndecision making that requires setting ethical and moral rules before taking\nverdict. The article discusses the lack of ethical guidelines in designing and\ndeploying of SIoV systems that are of utmost importance. Finally, an addition\nto SIoV architecture is proposed to incorporate the ethical and moral\nprinciples for scheming the SIoV systems.",
    "published_date": "2018-06-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09081v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.08734v3",
    "title": "On the Spectral Bias of Neural Networks",
    "authors": [
      "Nasim Rahaman",
      "Aristide Baratin",
      "Devansh Arpit",
      "Felix Draxler",
      "Min Lin",
      "Fred A. Hamprecht",
      "Yoshua Bengio",
      "Aaron Courville"
    ],
    "author_ids": [],
    "abstract": "Neural networks are known to be a class of highly expressive functions able\nto fit even random input-output mappings with $100\\%$ accuracy. In this work,\nwe present properties of neural networks that complement this aspect of\nexpressivity. By using tools from Fourier analysis, we show that deep ReLU\nnetworks are biased towards low frequency functions, meaning that they cannot\nhave local fluctuations without affecting their global behavior. Intuitively,\nthis property is in line with the observation that over-parameterized networks\nfind simple patterns that generalize across data samples. We also investigate\nhow the shape of the data manifold affects expressivity by showing evidence\nthat learning high frequencies gets \\emph{easier} with increasing manifold\ncomplexity, and present a theoretical understanding of this behavior. Finally,\nwe study the robustness of the frequency components with respect to parameter\nperturbation, to develop the intuition that the parameters must be finely tuned\nto express high frequency functions.",
    "published_date": "2018-06-22T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.08734v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.08010v2",
    "title": "Fairness Without Demographics in Repeated Loss Minimization",
    "authors": [
      "Tatsunori B. Hashimoto",
      "Megha Srivastava",
      "Hongseok Namkoong",
      "Percy Liang"
    ],
    "author_ids": [],
    "abstract": "Machine learning models (e.g., speech recognizers) are usually trained to\nminimize average loss, which results in representation disparity---minority\ngroups (e.g., non-native speakers) contribute less to the training objective\nand thus tend to suffer higher loss. Worse, as model accuracy affects user\nretention, a minority group can shrink over time. In this paper, we first show\nthat the status quo of empirical risk minimization (ERM) amplifies\nrepresentation disparity over time, which can even make initially fair models\nunfair. To mitigate this, we develop an approach based on distributionally\nrobust optimization (DRO), which minimizes the worst case risk over all\ndistributions close to the empirical distribution. We prove that this approach\ncontrols the risk of the minority group at each time step, in the spirit of\nRawlsian distributive justice, while remaining oblivious to the identity of the\ngroups. We demonstrate that DRO prevents disparity amplification on examples\nwhere ERM fails, and show improvements in minority group user satisfaction in a\nreal-world text autocomplete task.",
    "published_date": "2018-06-20T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.08010v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.07926v1",
    "title": "Resource Allocation in SWIPT Networks under a Non-Linear Energy Harvesting Model: Power Efficiency, User Fairness, and Channel Non-Reciprocity",
    "authors": [
      "Ha-Vu Tran",
      "Georges Kaddoum",
      "Kien T. Truong"
    ],
    "author_ids": [],
    "abstract": "This paper considers a multi-user simultaneous wireless information and power\ntransfer (SWIPT) system with a non-linear energy harvesting model, in which a\nmulti-antenna base station (BS) estimates the downlink channel state\ninformation (CSI) via uplink pilots. Each single-antenna user is equipped with\na power splitter. Three crucial issues on resource management for this system\ninclude: (i) power-efficient improvement, (ii) user-fairness guarantee, and\n(iii) non-ideal channel reciprocity effect mitigation. Potentially, a resource\nallocation scheme to address jointly such issues can be devised by using the\nframework of multi-objective optimization. However, the resulting problem might\nbe complex to solve since the three issues hold different characteristics.\nTherefore, we propose a novel method to design the resource allocation scheme.\nIn particular, the principle of our method relies on structuralizing\nmathematically the issues into a cross-layer multi-level optimization problem.\nOn this basis, we then devise solving algorithms and closed-form solutions.\nMoreover, to instantly adapt the CSI changes in practice while reducing\ncomputational burdens, we propose a closed-form suboptimal solution to tackle\nthe problem. Finally, we provide numerical results to show the achievable\nperformance gains using the optimal and suboptimal solutions, and then validate\nthe proposed resource allocation scheme.",
    "published_date": "2018-06-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.07926v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.07473v1",
    "title": "An Input-Output Approach to Structured Stochastic Uncertainty",
    "authors": [
      "Bassam Bamieh",
      "Maurice Filo"
    ],
    "author_ids": [],
    "abstract": "We consider linear time invariant systems with exogenous stochastic\ndisturbances, and in feedback with structured stochastic uncertainties. This\nsetting encompasses linear systems with both additive and multiplicative noise.\nOur concern is to characterize second-order properties such as mean-square\nstability and performance. A purely input-output treatment of these systems is\ngiven without recourse to state space models, and thus the results are\napplicable to certain classes of distributed systems. We derive necessary and\nsufficient conditions for mean-square stability in terms of the spectral radius\nof a linear matrix operator whose dimension is that of the number of\nuncertainties, rather than the dimension of any underlying state space models.\nOur condition is applicable to the case of correlated uncertainties, and\nreproduces earlier results for uncorrelated uncertainties. For cases where\nstate space realizations are given, Linear Matrix Inequality (LMI) equivalents\nof the input-output conditions are given.",
    "published_date": "2018-06-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY",
      "math.OC",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.07473v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.07751v1",
    "title": "Versatile Auxiliary Classifier with Generative Adversarial Network (VAC+GAN), Multi Class Scenarios",
    "authors": [
      "Shabab Bazrafkan",
      "Peter Corcoran"
    ],
    "author_ids": [],
    "abstract": "Conditional generators learn the data distribution for each class in a\nmulti-class scenario and generate samples for a specific class given the right\ninput from the latent space. In this work, a method known as \"Versatile\nAuxiliary Classifier with Generative Adversarial Network\" for multi-class\nscenarios is presented. In this technique, the Generative Adversarial Networks\n(GAN)'s generator is turned into a conditional generator by placing a\nmulti-class classifier in parallel with the discriminator network and\nbackpropagate the classification error through the generator. This technique is\nversatile enough to be applied to any GAN implementation. The results on two\ndatabases and comparisons with other method are provided as well.",
    "published_date": "2018-06-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "eess.IV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.07751v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06973v1",
    "title": "On the Bias of Reed-Muller Codes over Odd Prime Fields",
    "authors": [
      "Paul Beame",
      "Shayan Oveis Gharan",
      "Xin Yang"
    ],
    "author_ids": [],
    "abstract": "We study the bias of random bounded-degree polynomials over odd prime fields\nand show that, with probability exponentially close to 1, such polynomials have\nexponentially small bias. This also yields an exponential tail bound on the\nweight distribution of Reed-Muller codes over odd prime fields. These results\ngeneralize bounds of Ben-Eliezer, Hod, and Lovett who proved similar results\nover $\\mathbb{F}_2$. A key to our bounds is the proof of a new precise extremal\nproperty for the rank of sub-matrices of the generator matrices of Reed-Muller\ncodes over odd prime fields. This extremal property is a substantial extension\nof an extremal property shown by Keevash and Sudakov for the case of\n$\\mathbb{F}_2$.\n  Our exponential tail bounds on the bias can be used to derive exponential\nlower bounds on the time for space-bounded learning of bounded-degree\npolynomials from their evaluations over odd prime fields.",
    "published_date": "2018-06-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DM",
      "cs.CC",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06973v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.06895v1",
    "title": "Some remarks on the bias distribution analysis of discrete-time identification algorithms based on pseudo-linear regressions",
    "authors": [
      "Bernard Vau",
      "Henri Bourlès"
    ],
    "author_ids": [],
    "abstract": "In 1998, A. Karimi and I.D. Landau published in the journal \"Systems and\nControl letters\" an article entitled \"Comparison of the closed-loop\nidentification methods in terms of bias distribution\". One of its main purposes\nwas to provide a bias distribution analysis in the frequency domain of\nclosed-loop output error identification algorithms that had been recently\ndeveloped. The expressions provided in that paper are only valid for prediction\nerror identification methods (PEM), not for pseudo-linear regression (PLR)\nones, for which we give the correct frequency domain bias analysis, both in\nopen- and closed-loop. Although PLR was initially (and is still) considered as\nan approximation of PEM, we show that it gives better results at high\nfrequencies.",
    "published_date": "2018-06-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06895v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.06876v3",
    "title": "Diving Deep onto Discriminative Ensemble of Histological Hashing & Class-Specific Manifold Learning for Multi-class Breast Carcinoma Taxonomy",
    "authors": [
      "Sawon Pratiher",
      "Subhankar Chattoraj"
    ],
    "author_ids": [],
    "abstract": "Histopathological images (HI) encrypt resolution dependent heterogeneous\ntextures & diverse color distribution variability, manifesting in\nmicro-structural surface tissue convolutions. Also, inherently high coherency\nof cancerous cells poses significant challenges to breast cancer (BC)\nmulti-classification. As such, multi-class stratification is sparsely explored\n& prior work mainly focus on benign & malignant tissue characterization only,\nwhich forestalls further quantitative analysis of subordinate classes like\nadenosis, mucinous carcinoma & fibroadenoma etc, for diagnostic competence. In\nthis work, a fully-automated, near-real-time & computationally inexpensive\nrobust multi-classification deep framework from HI is presented.\n  The proposed scheme employs deep neural network (DNN) aided discriminative\nensemble of holistic class-specific manifold learning (CSML) for underlying HI\nsub-space embedding & HI hashing based local shallow signatures. The model\nachieves 95.8% accuracy pertinent to multi-classification & 2.8% overall\nperformance improvement & 38.2% enhancement for Lobular carcinoma (LC)\nsub-class recognition rate as compared to the existing state-of-the-art on well\nknown BreakHis dataset is achieved. Also, 99.3% recognition rate at 200X & a\nsensitivity of 100% for binary grading at all magnification validates its\nsuitability for clinical deployment in hand-held smart devices.",
    "published_date": "2018-06-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06876v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06626v1",
    "title": "On Enhancing Speech Emotion Recognition using Generative Adversarial Networks",
    "authors": [
      "Saurabh Sahu",
      "Rahul Gupta",
      "Carol Espy-Wilson"
    ],
    "author_ids": [],
    "abstract": "Generative Adversarial Networks (GANs) have gained a lot of attention from\nmachine learning community due to their ability to learn and mimic an input\ndata distribution. GANs consist of a discriminator and a generator working in\ntandem playing a min-max game to learn a target underlying data distribution;\nwhen fed with data-points sampled from a simpler distribution (like uniform or\nGaussian distribution). Once trained, they allow synthetic generation of\nexamples sampled from the target distribution. We investigate the application\nof GANs to generate synthetic feature vectors used for speech emotion\nrecognition. Specifically, we investigate two set ups: (i) a vanilla GAN that\nlearns the distribution of a lower dimensional representation of the actual\nhigher dimensional feature vector and, (ii) a conditional GAN that learns the\ndistribution of the higher dimensional feature vectors conditioned on the\nlabels or the emotional class to which it belongs. As a potential practical\napplication of these synthetically generated samples, we measure any\nimprovement in a classifier's performance when the synthetic data is used along\nwith real data for training. We perform cross-validation analyses followed by a\ncross-corpus study.",
    "published_date": "2018-06-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06626v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06301v1",
    "title": "Biased Embeddings from Wild Data: Measuring, Understanding and Removing",
    "authors": [
      "Adam Sutton",
      "Thomas Lansdall-Welfare",
      "Nello Cristianini"
    ],
    "author_ids": [],
    "abstract": "Many modern Artificial Intelligence (AI) systems make use of data embeddings,\nparticularly in the domain of Natural Language Processing (NLP). These\nembeddings are learnt from data that has been gathered \"from the wild\" and have\nbeen found to contain unwanted biases. In this paper we make three\ncontributions towards measuring, understanding and removing this problem. We\npresent a rigorous way to measure some of these biases, based on the use of\nword lists created for social psychology applications; we observe how gender\nbias in occupations reflects actual gender bias in the same occupations in the\nreal world; and finally we demonstrate how a simple projection can\nsignificantly reduce the effects of embedding bias. All this is part of an\nongoing effort to understand how trust can be built into AI systems.",
    "published_date": "2018-06-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06301v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06237v2",
    "title": "PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review",
    "authors": [
      "Ivan Stelmakh",
      "Nihar B. Shah",
      "Aarti Singh"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of automated assignment of papers to reviewers in\nconference peer review, with a focus on fairness and statistical accuracy. Our\nfairness objective is to maximize the review quality of the most disadvantaged\npaper, in contrast to the commonly used objective of maximizing the total\nquality over all papers. We design an assignment algorithm based on an\nincremental max-flow procedure that we prove is near-optimally fair. Our\nstatistical accuracy objective is to ensure correct recovery of the papers that\nshould be accepted. We provide a sharp minimax analysis of the accuracy of the\npeer-review process for a popular objective-score model as well as for a novel\nsubjective-score model that we propose in the paper. Our analysis proves that\nour proposed assignment algorithm also leads to a near-optimal statistical\naccuracy. Finally, we design a novel experiment that allows for an objective\ncomparison of various assignment algorithms, and overcomes the inherent\ndifficulty posed by the absence of a ground truth in experiments on\npeer-review. The results of this experiment as well as of other experiments on\nsynthetic and real data corroborate the theoretical guarantees of our\nalgorithm.",
    "published_date": "2018-06-16T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.DS",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06237v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06230v1",
    "title": "Nonsmooth Aggregative Games with Coupling Constraints and Infinitely Many Classes of Players",
    "authors": [
      "Paulin Jacquot",
      "Cheng Wan"
    ],
    "author_ids": [],
    "abstract": "After defining a pure-action profile in a nonatomic aggregative game, where\nplayers have specific compact convex pure-action sets and nonsmooth convex cost\nfunctions, as a square-integrable function, we characterize a Wardrop\nequilibrium as a solution to an infinite-dimensional generalized variational\ninequality. We show the existence of Wardrop equilibrium and variational\nWardrop equilibrium, a concept of equilibrium adapted to the presence of\ncoupling constraints, in monotone nonatomic aggregative games. The uniqueness\nof (variational) Wardrop equilibrium is proved for strictly or aggregatively\nstrictly monotone nonatomic aggregative games. We then show that, for a\nsequence of finite-player aggregative games with aggregative constraints, if\nthe players' pure-action sets converge to those of a strongly (resp.\naggregatively strongly) monotone nonatomic aggregative game, and the\naggregative constraints in the finite-player games converge to the aggregative\nconstraint of the nonatomic game, then a sequence of so-called variational Nash\nequilibria in these finite-player games converge to the variational Wardrop\nequilibrium in pure-action profile (resp. aggregate-action profile). In\nparticular, it allows the construction of an auxiliary sequence of games with\nfinite-dimensional equilibria to approximate the infinite-dimensional\nequilibrium in such a nonatomic game. Finally, we show how to construct\nauxiliary finite-player games for two general classes of nonatomic games.",
    "published_date": "2018-06-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "math.OC",
      "90B20, 91A13"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06230v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.06122v2",
    "title": "Fairness Under Composition",
    "authors": [
      "Cynthia Dwork",
      "Christina Ilvento"
    ],
    "author_ids": [],
    "abstract": "Algorithmic fairness, and in particular the fairness of scoring and\nclassification algorithms, has become a topic of increasing social concern and\nhas recently witnessed an explosion of research in theoretical computer\nscience, machine learning, statistics, the social sciences, and law. Much of\nthe literature considers the case of a single classifier (or scoring function)\nused once, in isolation. In this work, we initiate the study of the fairness\nproperties of systems composed of algorithms that are fair in isolation; that\nis, we study fairness under composition. We identify pitfalls of naive\ncomposition and give general constructions for fair composition, demonstrating\nboth that classifiers that are fair in isolation do not necessarily compose\ninto fair systems and also that seemingly unfair components may be carefully\ncombined to construct fair systems. We focus primarily on the individual\nfairness setting proposed in [Dwork, Hardt, Pitassi, Reingold, Zemel, 2011],\nbut also extend our results to a large class of group fairness definitions\npopular in the recent literature, exhibiting several cases in which group\nfairness definitions give misleading signals under composition.",
    "published_date": "2018-06-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06122v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.06055v3",
    "title": "Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees",
    "authors": [
      "L. Elisa Celis",
      "Lingxiao Huang",
      "Vijay Keswani",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Developing classification algorithms that are fair with respect to sensitive\nattributes of the data has become an important problem due to the growing\ndeployment of classification algorithms in various social contexts. Several\nrecent works have focused on fairness with respect to a specific metric,\nmodeled the corresponding fair classification problem as a constrained\noptimization problem, and developed tailored algorithms to solve them. Despite\nthis, there still remain important metrics for which we do not have fair\nclassifiers and many of the aforementioned algorithms do not come with\ntheoretical guarantees; perhaps because the resulting optimization problem is\nnon-convex. The main contribution of this paper is a new meta-algorithm for\nclassification that takes as input a large class of fairness constraints, with\nrespect to multiple non-disjoint sensitive attributes, and which comes with\nprovable guarantees. This is achieved by first developing a meta-algorithm for\na large family of classification problems with convex constraints, and then\nshowing that classification problems with general types of fairness constraints\ncan be reduced to those in this family. We present empirical results that show\nthat our algorithm can achieve near-perfect fairness with respect to various\nfairness metrics, and that the loss in accuracy due to the imposed fairness\nconstraints is often small. Overall, this work unifies several prior works on\nfair classification, presents a practical algorithm with theoretical\nguarantees, and can handle fairness metrics that were previously not possible.",
    "published_date": "2018-06-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.06055v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05797v1",
    "title": "Polyhedra Circuits and Their Applications",
    "authors": [
      "Bin Fu",
      "Pengfei Gu",
      "Yuming Zhao"
    ],
    "author_ids": [],
    "abstract": "We introduce polyhedra circuits. Each polyhedra circuit characterizes a\ngeometric region in $\\mathbb{R}^d$. They can be applied to represent a rich\nclass of geometric objects, which include all polyhedra and the union of a\nfinite number of polyhedra. They can be used to approximate a large class of\n$d$-dimensional manifolds in $\\mathbb{R}^d$. Barvinok developed polynomial time\nalgorithms to compute the volume of a rational polyhedra, and to count the\nnumber of lattice points in a rational polyhedra in a fixed dimensional space\n$\\mathbb{R}^d$ with a fix $d$. Define $T_V(d,\\, n)$ be the polynomial time in\n$n$ to compute the volume of one rational polyhedra, $T_L(d,\\, n)$ be the\npolynomial time in $n$ to count the number of lattice points in one rational\npolyhedra with $d$ be a fixed dimensional number, $T_I(d,\\, n)$ be the\npolynomial time in $n$ to solve integer linear programming time with $d$ be the\nfixed dimensional number, where $n$ is the total number of linear inequalities\nfrom input polyhedra. We develop algorithms to count the number of lattice\npoints in the geometric region determined by a polyhedra circuit in\n$O\\left(nd\\cdot r_d(n)\\cdot T_V(d,\\, n)\\right)$ time and to compute the volume\nof the geometric region determined by a polyhedra circuit in $O\\left(n\\cdot\nr_d(n)\\cdot T_I(d,\\, n)+r_d(n)T_L(d,\\, n)\\right)$ time, where $n$ is the number\nof input linear inequalities, $d$ is number of variables and $r_d(n)$ be the\nmaximal number of regions that $n$ linear inequalities with $d$ variables\npartition $\\mathbb{R}^d$.",
    "published_date": "2018-06-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CG",
      "cs.DM",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05797v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.05542v1",
    "title": "Status maximization as a source of fairness in a networked dictator game",
    "authors": [
      "Jan E. Snellman",
      "Gerardo Iñiguez",
      "János Kertész",
      "R. A. Barrio",
      "Kimmo K. Kaski"
    ],
    "author_ids": [],
    "abstract": "Human behavioural patterns exhibit selfish or competitive, as well as\nselfless or altruistic tendencies, both of which have demonstrable effects on\nhuman social and economic activity. In behavioural economics, such effects have\ntraditionally been illustrated experimentally via simple games like the\ndictator and ultimatum games. Experiments with these games suggest that, beyond\nrational economic thinking, human decision-making processes are influenced by\nsocial preferences, such as an inclination to fairness. In this study we\nsuggest that the apparent gap between competitive and altruistic human\ntendencies can be bridged by assuming that people are primarily maximising\ntheir status, i.e., a utility function different from simple profit\nmaximisation. To this end we analyse a simple agent-based model, where\nindividuals play the repeated dictator game in a social network they can\nmodify. As model parameters we consider the living costs and the rate at which\nagents forget infractions by others. We find that individual strategies used in\nthe game vary greatly, from selfish to selfless, and that both of the above\nparameters determine when individuals form complex and cohesive social\nnetworks.",
    "published_date": "2018-06-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.GT",
      "cs.SI",
      "q-fin.GN",
      "I.2.11"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05542v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.05250v1",
    "title": "What About Applied Fairness?",
    "authors": [
      "Jared Sylvester",
      "Edward Raff"
    ],
    "author_ids": [],
    "abstract": "Machine learning practitioners are often ambivalent about the ethical aspects\nof their products. We believe anything that gets us from that current state to\none in which our systems are achieving some degree of fairness is an\nimprovement that should be welcomed. This is true even when that progress does\nnot get us 100% of the way to the goal of \"complete\" fairness or perfectly\nalign with our personal belief on which measure of fairness is used. Some\nmeasure of fairness being built would still put us in a better position than\nthe status quo. Impediments to getting fairness and ethical concerns applied in\nreal applications, whether they are abstruse philosophical debates or technical\noverhead such as the introduction of ever more hyper-parameters, should be\navoided. In this paper we further elaborate on our argument for this viewpoint\nand its importance.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05250v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05147v2",
    "title": "Cross-modal Hallucination for Few-shot Fine-grained Recognition",
    "authors": [
      "Frederik Pahde",
      "Patrick Jähnichen",
      "Tassilo Klein",
      "Moin Nabi"
    ],
    "author_ids": [],
    "abstract": "State-of-the-art deep learning algorithms generally require large amounts of\ndata for model training. Lack thereof can severely deteriorate the performance,\nparticularly in scenarios with fine-grained boundaries between categories. To\nthis end, we propose a multimodal approach that facilitates bridging the\ninformation gap by means of meaningful joint embeddings. Specifically, we\npresent a benchmark that is multimodal during training (i.e. images and texts)\nand single-modal in testing time (i.e. images), with the associated task to\nutilize multimodal data in base classes (with many samples), to learn explicit\nvisual classifiers for novel classes (with few samples). Next, we propose a\nframework built upon the idea of cross-modal data hallucination. In this\nregard, we introduce a discriminative text-conditional GAN for sample\ngeneration with a simple self-paced strategy for sample selection. We show the\nresults of our proposed discriminative hallucinated method for 1-, 2-, and 5-\nshot learning on the CUB dataset, where the accuracy is improved by employing\nmultimodal data.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05147v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05180v1",
    "title": "A Retrospective Analysis of the Fake News Challenge Stance Detection Task",
    "authors": [
      "Andreas Hanselowski",
      "Avinesh PVS",
      "Benjamin Schiller",
      "Felix Caspelherr",
      "Debanjan Chaudhuri",
      "Christian M. Meyer",
      "Iryna Gurevych"
    ],
    "author_ids": [],
    "abstract": "The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05180v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05112v1",
    "title": "Comparing Fairness Criteria Based on Social Outcome",
    "authors": [
      "Junpei Komiyama",
      "Hajime Shimao"
    ],
    "author_ids": [],
    "abstract": "Fairness in algorithmic decision-making processes is attracting increasing\nconcern. When an algorithm is applied to human-related decision-making an\nestimator solely optimizing its predictive power can learn biases on the\nexisting data, which motivates us the notion of fairness in machine learning.\nwhile several different notions are studied in the literature, little studies\nare done on how these notions affect the individuals. We demonstrate such a\ncomparison between several policies induced by well-known fairness criteria,\nincluding the color-blind (CB), the demographic parity (DP), and the equalized\nodds (EO). We show that the EO is the only criterion among them that removes\ngroup-level disparity. Empirical studies on the social welfare and disparity of\nthese policies are conducted.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05112v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05085v2",
    "title": "Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratings",
    "authors": [
      "Jingyan Wang",
      "Nihar B. Shah"
    ],
    "author_ids": [],
    "abstract": "Cardinal scores (numeric ratings) collected from people are well known to\nsuffer from miscalibrations. A popular approach to address this issue is to\nassume simplistic models of miscalibration (such as linear biases) to de-bias\nthe scores. This approach, however, often fares poorly because people's\nmiscalibrations are typically far more complex and not well understood. In the\nabsence of simplifying assumptions on the miscalibration, it is widely believed\nby the crowdsourcing community that the only useful information in the cardinal\nscores is the induced ranking. In this paper, inspired by the framework of\nStein's shrinkage, empirical Bayes, and the classic two-envelope problem, we\ncontest this widespread belief. Specifically, we consider cardinal scores with\narbitrary (or even adversarially chosen) miscalibrations which are only\nrequired to be consistent with the induced ranking. We design estimators which\ndespite making no assumptions on the miscalibration, strictly and uniformly\noutperform all possible estimators that rely on only the ranking. Our\nestimators are flexible in that they can be used as a plug-in for a variety of\napplications, and we provide a proof-of-concept for A/B testing and ranking.\nOur results thus provide novel insights in the eternal debate between cardinal\nand ordinal data.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05085v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.05009v3",
    "title": "Tree Edit Distance Learning via Adaptive Symbol Embeddings",
    "authors": [
      "Benjamin Paaßen",
      "Claudio Gallicchio",
      "Alessio Micheli",
      "Barbara Hammer"
    ],
    "author_ids": [],
    "abstract": "Metric learning has the aim to improve classification accuracy by learning a\ndistance measure which brings data points from the same class closer together\nand pushes data points from different classes further apart. Recent research\nhas demonstrated that metric learning approaches can also be applied to trees,\nsuch as molecular structures, abstract syntax trees of computer programs, or\nsyntax trees of natural language, by learning the cost function of an edit\ndistance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.\nHowever, learning such costs directly may yield an edit distance which violates\nmetric axioms, is challenging to interpret, and may not generalize well. In\nthis contribution, we propose a novel metric learning approach for trees which\nwe call embedding edit distance learning (BEDL) and which learns an edit\ndistance indirectly by embedding the tree nodes as vectors, such that the\nEuclidean distance between those vectors supports class discrimination. We\nlearn such embeddings by reducing the distance to prototypical trees from the\nsame class and increasing the distance to prototypical trees from different\nclasses. In our experiments, we show that BEDL improves upon the\nstate-of-the-art in metric learning for trees on six benchmark data sets,\nranging from computer science over biomedical data to a natural-language\nprocessing data set containing over 300,000 nodes.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.05009v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.04959v4",
    "title": "Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making",
    "authors": [
      "Hoda Heidari",
      "Claudio Ferrari",
      "Krishna P. Gummadi",
      "Andreas Krause"
    ],
    "author_ids": [],
    "abstract": "We draw attention to an important, yet largely overlooked aspect of\nevaluating fairness for automated decision making systems---namely risk and\nwelfare considerations. Our proposed family of measures corresponds to the\nlong-established formulations of cardinal social welfare in economics, and is\njustified by the Rawlsian conception of fairness behind a veil of ignorance.\nThe convex formulation of our welfare-based measures of fairness allows us to\nintegrate them as a constraint into any convex loss minimization pipeline. Our\nempirical analysis reveals interesting trade-offs between our proposal and (a)\nprediction accuracy, (b) group discrimination, and (c) Dwork et al.'s notion of\nindividual fairness. Furthermore and perhaps most importantly, our work\nprovides both heuristic justification and empirical evidence suggesting that a\nlower-bound on our measures often leads to bounded inequality in algorithmic\noutcomes; hence presenting the first computationally feasible mechanism for\nbounding individual-level inequality.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.04959v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.04819v5",
    "title": "Integral Privacy for Sampling",
    "authors": [
      "Hisham Husain",
      "Zac Cranko",
      "Richard Nock"
    ],
    "author_ids": [],
    "abstract": "Differential privacy is a leading protection setting, focused by design on\nindividual privacy. Many applications, in medical / pharmaceutical domains or\nsocial networks, rather posit privacy at a group level, a setting we call\nintegral privacy. We aim for the strongest form of privacy: the group size is\nin particular not known in advance. We study a problem with related\napplications in domains cited above that have recently met with substantial\nrecent press: sampling.\n  Keeping correct utility levels in such a strong model of statistical\nindistinguishability looks difficult to be achieved with the usual differential\nprivacy toolbox because it would typically scale in the worst case the\nsensitivity by the sample size and so the noise variance by up to its square.\nWe introduce a trick specific to sampling that bypasses the sensitivity\nanalysis. Privacy enforces an information theoretic barrier on approximation,\nand we show how to reach this barrier with guarantees on the approximation of\nthe target non private density. We do so using a recent approach to non private\ndensity estimation relying on the original boosting theory, learning the\nsufficient statistics of an exponential family with classifiers. Approximation\nguarantees cover the mode capture problem. In the context of learning, the\nsampling problem is particularly important: because integral privacy enjoys the\nsame closure under post-processing as differential privacy does, any algorithm\nusing integrally privacy sampled data would result in an output equally\nintegrally private. We also show that this brings fairness guarantees on\npost-processing that would eventually elude classical differential privacy: any\ndecision process has bounded data-dependent bias when the data is integrally\nprivately sampled. Experimental results against private kernel density\nestimation and private GANs displays the quality of our results.",
    "published_date": "2018-06-13T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.04819v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.04234v1",
    "title": "Lecture Notes on Fair Division",
    "authors": [
      "Ulle Endriss"
    ],
    "author_ids": [],
    "abstract": "Fair division is the problem of dividing one or several goods amongst two or\nmore agents in a way that satisfies a suitable fairness criterion. These Notes\nprovide a succinct introduction to the field. We cover three main topics.\nFirst, we need to define what is to be understood by a \"fair\" allocation of\ngoods to individuals. We present an overview of the most important fairness\ncriteria (as well as the closely related criteria for economic efficiency)\ndeveloped in the literature, together with a short discussion of their\naxiomatic foundations. Second, we give an introduction to cake-cutting\nprocedures as an example of methods for fairly dividing a single divisible\nresource amongst a group of individuals. Third, we discuss the combinatorial\noptimisation problem of fairly allocating a set of indivisible goods to a group\nof agents, covering both centralised algorithms (similar to auctions) and a\ndistributed approach based on negotiation.\n  While the classical literature on fair division has largely developed within\nEconomics, these Notes are specifically written for readers with a background\nin Computer Science or similar, and who may be (or may wish to be) engaged in\nresearch in Artificial Intelligence, Multiagent Systems, or Computational\nSocial Choice. References for further reading, as well as a small number of\nexercises, are included.\n  Notes prepared for a tutorial at the 11th European Agent Systems Summer\nSchool (EASSS-2009), Torino, Italy, 31 August and 1 September 2009. Updated for\na tutorial at the COST-ADT Doctoral School on Computational Social Choice,\nEstoril, Portugal, 9--14 April 2010.",
    "published_date": "2018-06-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.04234v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.04224v1",
    "title": "NeuroNet: Fast and Robust Reproduction of Multiple Brain Image Segmentation Pipelines",
    "authors": [
      "Martin Rajchl",
      "Nick Pawlowski",
      "Daniel Rueckert",
      "Paul M. Matthews",
      "Ben Glocker"
    ],
    "author_ids": [],
    "abstract": "NeuroNet is a deep convolutional neural network mimicking multiple popular\nand state-of-the-art brain segmentation tools including FSL, SPM, and MALPEM.\nThe network is trained on 5,000 T1-weighted brain MRI scans from the UK Biobank\nImaging Study that have been automatically segmented into brain tissue and\ncortical and sub-cortical structures using the standard neuroimaging pipelines.\nTraining a single model from these complementary and partially overlapping\nlabel maps yields a new powerful \"all-in-one\", multi-output segmentation tool.\nThe processing time for a single subject is reduced by an order of magnitude\ncompared to running each individual software package. We demonstrate very good\nreproducibility of the original outputs while increasing robustness to\nvariations in the input data. We believe NeuroNet could be an important tool in\nlarge-scale population imaging studies and serve as a new standard in\nneuroscience by reducing the risk of introducing bias when choosing a specific\nsoftware package.",
    "published_date": "2018-06-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.04224v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.04167v1",
    "title": "Learning an Approximate Model Predictive Controller with Guarantees",
    "authors": [
      "Michael Hertneck",
      "Johannes Köhler",
      "Sebastian Trimpe",
      "Frank Allgöwer"
    ],
    "author_ids": [],
    "abstract": "A supervised learning framework is proposed to approximate a model predictive\ncontroller (MPC) with reduced computational complexity and guarantees on\nstability and constraint satisfaction. The framework can be used for a wide\nclass of nonlinear systems. Any standard supervised learning technique (e.g.\nneural networks) can be employed to approximate the MPC from samples. In order\nto obtain closed-loop guarantees for the learned MPC, a robust MPC design is\ncombined with statistical learning bounds. The MPC design ensures robustness to\ninaccurate inputs within given bounds, and Hoeffding's Inequality is used to\nvalidate that the learned MPC satisfies these bounds with high confidence. The\nresult is a closed-loop statistical guarantee on stability and constraint\nsatisfaction for the learned MPC. The proposed learning-based MPC framework is\nillustrated on a nonlinear benchmark problem, for which we learn a neural\nnetwork controller with guarantees.",
    "published_date": "2018-06-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.04167v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.03967v2",
    "title": "Latent Space Representation for Shape Analysis and Learning",
    "authors": [
      "Ruqi Huang",
      "Panos Achlioptas",
      "Leonidas Guibas",
      "Maks Ovsjanikov"
    ],
    "author_ids": [],
    "abstract": "We propose a novel shape representation useful for analyzing and processing\nshape collections, as well for a variety of learning and inference tasks.\nUnlike most approaches that capture variability in a collection by using a\ntemplate model or a base shape, we show that it is possible to construct a full\nshape representation by using the latent space induced by a functional map net-\nwork, allowing us to represent shapes in the context of a collection without\nthe bias induced by selecting a template shape. Key to our construction is a\nnovel analysis of latent functional spaces, which shows that after proper\nregularization they can be endowed with a natural geometric structure, giving\nrise to a well-defined, stable and fully informative shape representation. We\ndemonstrate the utility of our representation in shape analysis tasks, such as\nhighlighting the most distorted shape parts in a collection or separating\nvariability modes between shape classes. We further exploit our representation\nin learning applications by showing how it can naturally be used within deep\nlearning and convolutional neural networks for shape classi cation or\nreconstruction, signi cantly outperforming existing point-based techniques.",
    "published_date": "2018-06-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.03967v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.03619v1",
    "title": "VoxelAtlasGAN: 3D Left Ventricle Segmentation on Echocardiography with Atlas Guided Generation and Voxel-to-voxel Discrimination",
    "authors": [
      "Suyu Dong",
      "Gongning Luo",
      "Kuanquan Wang",
      "Shaodong Cao",
      "Ashley Mercado",
      "Olga Shmuilovich",
      "Henggui Zhang",
      "Shuo Li"
    ],
    "author_ids": [],
    "abstract": "3D left ventricle (LV) segmentation on echocardiography is very important for\ndiagnosis and treatment of cardiac disease. It is not only because of that\nechocardiography is a real-time imaging technology and widespread in clinical\napplication, but also because of that LV segmentation on 3D echocardiography\ncan provide more full volume information of heart than LV segmentation on 2D\nechocardiography. However, 3D LV segmentation on echocardiography is still an\nopen and challenging task owing to the lower contrast, higher noise and data\ndimensionality, limited annotation of 3D echocardiography. In this paper, we\nproposed a novel real-time framework, i.e., VoxelAtlasGAN, for 3D LV\nsegmentation on 3D echocardiography. This framework has three contributions: 1)\nIt is based on voxel-to-voxel conditional generative adversarial nets (cGAN).\nFor the first time, cGAN is used for 3D LV segmentation on echocardiography.\nAnd cGAN advantageously fuses substantial 3D spatial context information from\n3D echocardiography by self-learning structured loss; 2) For the first time, it\nembeds the atlas into an end-to-end optimization framework, which uses 3D LV\natlas as a powerful prior knowledge to improve the inference speed, address the\nlower contrast and the limited annotation problems of 3D echocardiography; 3)\nIt combines traditional discrimination loss and the new proposed consistent\nconstraint, which further improves the generalization of the proposed\nframework. VoxelAtlasGAN was validated on 60 subjects on 3D echocardiography\nand it achieved satisfactory segmentation results and high inference speed. The\nmean surface distance is 1.85 mm, the mean hausdorff surface distance is 7.26\nmm, mean dice is 0.953, the correlation of EF is 0.918, and the mean inference\nspeed is 0.1s. These results have demonstrated that our proposed method has\ngreat potential for clinical application",
    "published_date": "2018-06-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.03619v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.03555v1",
    "title": "Consistent Position Bias Estimation without Online Interventions for Learning-to-Rank",
    "authors": [
      "Aman Agarwal",
      "Ivan Zaitsev",
      "Thorsten Joachims"
    ],
    "author_ids": [],
    "abstract": "Presentation bias is one of the key challenges when learning from implicit\nfeedback in search engines, as it confounds the relevance signal with\nuninformative signals due to position in the ranking, saliency, and other\npresentation factors. While it was recently shown how counterfactual\nlearning-to-rank (LTR) approaches \\cite{Joachims/etal/17a} can provably\novercome presentation bias if observation propensities are known, it remains to\nshow how to accurately estimate these propensities. In this paper, we propose\nthe first method for producing consistent propensity estimates without manual\nrelevance judgments, disruptive interventions, or restrictive relevance\nmodeling assumptions. We merely require that we have implicit feedback data\nfrom multiple different ranking functions. Furthermore, we argue that our\nestimation technique applies to an extended class of Contextual Position-Based\nPropensity Models, where propensities not only depend on position but also on\nobservable features of the query and document. Initial simulation studies\nconfirm that the approach is scalable, accurate, and robust.",
    "published_date": "2018-06-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.IR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.03555v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.10095v3",
    "title": "Research on Artificial Intelligence Ethics Based on the Evolution of Population Knowledge Base",
    "authors": [
      "Feng Liu",
      "Yong Shi"
    ],
    "author_ids": [],
    "abstract": "The unclear development direction of human society is a deep reason for that\nit is difficult to form a uniform ethical standard for human society and\nartificial intelligence. Since the 21st century, the latest advances in the\nInternet, brain science and artificial intelligence have brought new\ninspiration to the research on the development direction of human society.\nThrough the study of the Internet brain model, AI IQ evaluation, and the\nevolution of the brain, this paper proposes that the evolution of population\nknowledge base is the key for judging the development direction of human\nsociety, thereby discussing the standards and norms for the construction of\nartificial intelligence ethics.",
    "published_date": "2018-06-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.OH",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.10095v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.03281v1",
    "title": "Blind Justice: Fairness with Encrypted Sensitive Attributes",
    "authors": [
      "Niki Kilbertus",
      "Adrià Gascón",
      "Matt J. Kusner",
      "Michael Veale",
      "Krishna P. Gummadi",
      "Adrian Weller"
    ],
    "author_ids": [],
    "abstract": "Recent work has explored how to train machine learning models which do not\ndiscriminate against any subgroup of the population as determined by sensitive\nattributes such as gender or race. To avoid disparate treatment, sensitive\nattributes should not be considered. On the other hand, in order to avoid\ndisparate impact, sensitive attributes must be examined, e.g., in order to\nlearn a fair model, or to check if a given model is fair. We introduce methods\nfrom secure multi-party computation which allow us to avoid both. By encrypting\nsensitive attributes, we show how an outcome-based fair model may be learned,\nchecked, or have its outputs verified and held to account, without users\nrevealing their sensitive attributes.",
    "published_date": "2018-06-08T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.03281v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.03086v1",
    "title": "Mobile Phone Metadata for Development",
    "authors": [
      "Damien C. Jacques"
    ],
    "author_ids": [],
    "abstract": "Mobile phones are now widely adopted by most of the world population. Each\ntime a call is made (or an SMS sent), a Call Detail Record (CDR) is generated\nby the telecom companies for billing purpose. These metadata provide\ninformation on when, how, from where and with whom we communicate.\nConceptually, they can be described as a geospatial, dynamic, weighted and\ndirected network. Applications of CDRs for development are numerous. They have\nbeen used to model the spread of infectious diseases, study road traffic,\nsupport electrification planning strategies or map socio-economic level of\npopulation. While massive, CDRs are not statistically representative of the\nwhole population due to several sources of bias (market, usage, spatial and\ntemporal resolution). Furthermore, mobile phone metadata are held by telecom\ncompanies. Consequently, their access is not necessarily straightforward and\ncan seriously hamper any operational application. Finally, a trade-off exists\nbetween privacy and utility when using sensitive data like CDRs. New\ninitiatives such as Open Algorithm might help to deal with these fundamental\nquestions by allowing researchers to run algorithms on the data that remain\nsafely stored behind the firewall of the providers.",
    "published_date": "2018-06-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "97P70"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.03086v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.02984v2",
    "title": "DeepFirearm: Learning Discriminative Feature Representation for Fine-grained Firearm Retrieval",
    "authors": [
      "Jiedong Hao",
      "Jing Dong",
      "Wei Wang",
      "Tieniu Tan"
    ],
    "author_ids": [],
    "abstract": "There are great demands for automatically regulating inappropriate appearance\nof shocking firearm images in social media or identifying firearm types in\nforensics. Image retrieval techniques have great potential to solve these\nproblems. To facilitate research in this area, we introduce Firearm 14k, a\nlarge dataset consisting of over 14,000 images in 167 categories. It can be\nused for both fine-grained recognition and retrieval of firearm images. Recent\nadvances in image retrieval are mainly driven by fine-tuning state-of-the-art\nconvolutional neural networks for retrieval task. The conventional single\nmargin contrastive loss, known for its simplicity and good performance, has\nbeen widely used. We find that it performs poorly on the Firearm 14k dataset\ndue to: (1) Loss contributed by positive and negative image pairs is unbalanced\nduring training process. (2) A huge domain gap exists between this dataset and\nImageNet. We propose to deal with the unbalanced loss by employing a double\nmargin contrastive loss. We tackle the domain gap issue with a two-stage\ntraining strategy, where we first fine-tune the network for classification, and\nthen fine-tune it for retrieval. Experimental results show that our approach\noutperforms the conventional single margin approach by a large margin (up to\n88.5% relative improvement) and even surpasses the strong triplet-loss-based\napproach.",
    "published_date": "2018-06-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02984v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02887v1",
    "title": "Residual Unfairness in Fair Machine Learning from Prejudiced Data",
    "authors": [
      "Nathan Kallus",
      "Angela Zhou"
    ],
    "author_ids": [],
    "abstract": "Recent work in fairness in machine learning has proposed adjusting for\nfairness by equalizing accuracy metrics across groups and has also studied how\ndatasets affected by historical prejudices may lead to unfair decision\npolicies. We connect these lines of work and study the residual unfairness that\narises when a fairness-adjusted predictor is not actually fair on the target\npopulation due to systematic censoring of training data by existing biased\npolicies. This scenario is particularly common in the same applications where\nfairness is a concern. We characterize theoretically the impact of such\ncensoring on standard fairness metrics for binary classifiers and provide\ncriteria for when residual unfairness may or may not appear. We prove that,\nunder certain conditions, fairness-adjusted classifiers will in fact induce\nresidual unfairness that perpetuates the same injustices, against the same\ngroups, that biased the data to begin with, thus showing that even\nstate-of-the-art fair machine learning can have a \"bias in, bias out\" property.\nWhen certain benchmark data is available, we show how sample reweighting can\nestimate and adjust fairness metrics while accounting for censoring. We use\nthis to study the case of Stop, Question, and Frisk (SQF) and demonstrate that\nattempting to adjust for fairness perpetuates the same injustices that the\npolicy is infamous for.",
    "published_date": "2018-06-07T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02887v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02720v1",
    "title": "Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy, Confidence, and Decisions in Visual Analytics",
    "authors": [
      "Ryan Wesslen",
      "Sashank Santhanam",
      "Alireza Karduni",
      "Isaac Cho",
      "Samira Shaikh",
      "Wenwen Dou"
    ],
    "author_ids": [],
    "abstract": "Cognitive biases have been shown to lead to faulty decision-making. Recent\nresearch has demonstrated that the effect of cognitive biases, anchoring bias\nin particular, transfers to information visualization and visual analytics.\nHowever, it is still unclear how users of visual interfaces can be anchored and\nthe impact of anchoring on user performance and decision-making process. To\ninvestigate, we performed two rounds of between-subjects, in-laboratory\nexperiments with 94 participants to analyze the effect of visual anchors and\nstrategy cues in decision-making with a visual analytic system that employs\ncoordinated multiple view design. The decision-making task is identifying\nmisinformation from Twitter news accounts. Participants were randomly assigned\none of three treatment groups (including control) in which participant training\nprocesses were modified. Our findings reveal that strategy cues and visual\nanchors (scenario videos) can significantly affect user activity, speed,\nconfidence, and, under certain circumstances, accuracy. We discuss the\nimplications of our experiment results on training users how to use a newly\ndeveloped visual interface. We call for more careful consideration into how\nvisualization designers and researchers train users to avoid unintentionally\nanchoring users and thus affecting the end result.",
    "published_date": "2018-06-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02720v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.02711v6",
    "title": "POTs: Protective Optimization Technologies",
    "authors": [
      "Bogdan Kulynych",
      "Rebekah Overdorf",
      "Carmela Troncoso",
      "Seda Gürses"
    ],
    "author_ids": [],
    "abstract": "Algorithmic fairness aims to address the economic, moral, social, and\npolitical impact that digital systems have on populations through solutions\nthat can be applied by service providers. Fairness frameworks do so, in part,\nby mapping these problems to a narrow definition and assuming the service\nproviders can be trusted to deploy countermeasures. Not surprisingly, these\ndecisions limit fairness frameworks' ability to capture a variety of harms\ncaused by systems.\n  We characterize fairness limitations using concepts from requirements\nengineering and from social sciences. We show that the focus on algorithms'\ninputs and outputs misses harms that arise from systems interacting with the\nworld; that the focus on bias and discrimination omits broader harms on\npopulations and their environments; and that relying on service providers\nexcludes scenarios where they are not cooperative or intentionally adversarial.\n  We propose Protective Optimization Technologies (POTs). POTs provide means\nfor affected parties to address the negative impacts of systems in the\nenvironment, expanding avenues for political contestation. POTs intervene from\noutside the system, do not require service providers to cooperate, and can\nserve to correct, shift, or expose harms that systems impose on populations and\ntheir environments. We illustrate the potential and limitations of POTs in two\ncase studies: countering road congestion caused by traffic-beating\napplications, and recalibrating credit scoring for loan applicants.",
    "published_date": "2018-06-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02711v6",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02510v1",
    "title": "Removing Algorithmic Discrimination (With Minimal Individual Error)",
    "authors": [
      "El Mahdi El Mhamdi",
      "Rachid Guerraoui",
      "Lê Nguyên Hoang",
      "Alexandre Maurer"
    ],
    "author_ids": [],
    "abstract": "We address the problem of correcting group discriminations within a score\nfunction, while minimizing the individual error. Each group is described by a\nprobability density function on the set of profiles. We first solve the problem\nanalytically in the case of two populations, with a uniform bonus-malus on the\nzones where each population is a majority. We then address the general case of\nn populations, where the entanglement of populations does not allow a similar\nanalytical solution. We show that an approximate solution with an arbitrarily\nhigh level of precision can be computed with linear programming. Finally, we\naddress the inverse problem where the error should not go beyond a certain\nvalue and we seek to minimize the discrimination.",
    "published_date": "2018-06-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02510v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02380v1",
    "title": "Causal Interventions for Fairness",
    "authors": [
      "Matt J. Kusner",
      "Chris Russell",
      "Joshua R. Loftus",
      "Ricardo Silva"
    ],
    "author_ids": [],
    "abstract": "Most approaches in algorithmic fairness constrain machine learning methods so\nthe resulting predictions satisfy one of several intuitive notions of fairness.\nWhile this may help private companies comply with non-discrimination laws or\navoid negative publicity, we believe it is often too little, too late. By the\ntime the training data is collected, individuals in disadvantaged groups have\nalready suffered from discrimination and lost opportunities due to factors out\nof their control. In the present work we focus instead on interventions such as\na new public policy, and in particular, how to maximize their positive effects\nwhile improving the fairness of the overall system. We use causal methods to\nmodel the effects of interventions, allowing for potential interference--each\nindividual's outcome may depend on who else receives the intervention. We\ndemonstrate this with an example of allocating a budget of teaching resources\nusing a dataset of schools in New York City.",
    "published_date": "2018-06-06T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02380v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02329v1",
    "title": "Mitigating Bias in Adaptive Data Gathering via Differential Privacy",
    "authors": [
      "Seth Neel",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "Data that is gathered adaptively --- via bandit algorithms, for example ---\nexhibits bias. This is true both when gathering simple numeric valued data ---\nthe empirical means kept track of by stochastic bandit algorithms are biased\ndownwards --- and when gathering more complicated data --- running hypothesis\ntests on complex data gathered via contextual bandit algorithms leads to false\ndiscovery. In this paper, we show that this problem is mitigated if the data\ncollection procedure is differentially private. This lets us both bound the\nbias of simple numeric valued quantities (like the empirical means of\nstochastic bandit algorithms), and correct the p-values of hypothesis tests run\non the adaptively gathered data. Moreover, there exist differentially private\nbandit algorithms with near optimal regret bounds: we apply existing theorems\nin the simple stochastic case, and give a new analysis for linear contextual\nbandits. We complement our theoretical results with experiments validating our\ntheory.",
    "published_date": "2018-06-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02329v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.02155v1",
    "title": "Understanding News Outlets' Audience-Targeting Patterns",
    "authors": [
      "Erick Elejalde",
      "Leo Ferres",
      "Rossano Schifanella"
    ],
    "author_ids": [],
    "abstract": "The power of the press to shape the informational landscape of a population\nis unparalleled, even now in the era of democratic access to all information\noutlets. However, it is known that news outlets (particularly more traditional\nones) tend to discriminate who they want to reach, and who to leave aside. In\nthis work, we attempt to shed some light on the audience targeting patterns of\nnewspapers, using the Chilean media ecosystem. First, we use the gravity model\nto analyze geography as a factor in explaining audience reachability. This\nshows that some newspapers are indeed driven by geographical factors (mostly\nlocal news outlets) but some others are not (national-distribution outlets).\nFor those which are not, we use a regression model to study the influence of\nsocioeconomic and political characteristics in news outlets adoption. We\nconclude that indeed larger, national-distribution news outlets target\npopulations based on these factors, rather than on geography or immediacy.",
    "published_date": "2018-06-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02155v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.02146v1",
    "title": "Adversarial Auto-encoders for Speech Based Emotion Recognition",
    "authors": [
      "Saurabh Sahu",
      "Rahul Gupta",
      "Ganesh Sivaraman",
      "Wael AbdAlmageed",
      "Carol Espy-Wilson"
    ],
    "author_ids": [],
    "abstract": "Recently, generative adversarial networks and adversarial autoencoders have\ngained a lot of attention in machine learning community due to their\nexceptional performance in tasks such as digit classification and face\nrecognition. They map the autoencoder's bottleneck layer output (termed as code\nvectors) to different noise Probability Distribution Functions (PDFs), that can\nbe further regularized to cluster based on class information. In addition, they\nalso allow a generation of synthetic samples by sampling the code vectors from\nthe mapped PDFs. Inspired by these properties, we investigate the application\nof adversarial autoencoders to the domain of emotion recognition. Specifically,\nwe conduct experiments on the following two aspects: (i) their ability to\nencode high dimensional feature vector representations for emotional utterances\ninto a compressed space (with a minimal loss of emotion class discriminability\nin the compressed space), and (ii) their ability to regenerate synthetic\nsamples in the original feature space, to be later used for purposes such as\ntraining emotion recognition classifiers. We demonstrate the promise of\nadversarial autoencoders with regards to these aspects on the Interactive\nEmotional Dyadic Motion Capture (IEMOCAP) corpus and present our analysis.",
    "published_date": "2018-06-06T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.02146v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.09541v1",
    "title": "Technology, Propaganda, and the Limits of Human Intellect",
    "authors": [
      "Panagiotis Metaxas"
    ],
    "author_ids": [],
    "abstract": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.",
    "published_date": "2018-06-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09541v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.01710v1",
    "title": "Level-Based Analysis of the Population-Based Incremental Learning Algorithm",
    "authors": [
      "Per Kristian Lehre",
      "Phan Trung Hai Nguyen"
    ],
    "author_ids": [],
    "abstract": "The Population-Based Incremental Learning (PBIL) algorithm uses a convex\ncombination of the current model and the empirical model to construct the next\nmodel, which is then sampled to generate offspring. The Univariate Marginal\nDistribution Algorithm (UMDA) is a special case of the PBIL, where the current\nmodel is ignored. Dang and Lehre (GECCO 2015) showed that UMDA can optimise\nLeadingOnes efficiently. The question still remained open if the PBIL performs\nequally well. Here, by applying the level-based theorem in addition to\nDvoretzky--Kiefer--Wolfowitz inequality, we show that the PBIL optimises\nfunction LeadingOnes in expected time $\\mathcal{O}(n\\lambda \\log \\lambda +\nn^2)$ for a population size $\\lambda = \\Omega(\\log n)$, which matches the bound\nof the UMDA. Finally, we show that the result carries over to BinVal, giving\nthe fist runtime result for the PBIL on the BinVal problem.",
    "published_date": "2018-06-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01710v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.01261v3",
    "title": "Relational inductive biases, deep learning, and graph networks",
    "authors": [
      "Peter W. Battaglia",
      "Jessica B. Hamrick",
      "Victor Bapst",
      "Alvaro Sanchez-Gonzalez",
      "Vinicius Zambaldi",
      "Mateusz Malinowski",
      "Andrea Tacchetti",
      "David Raposo",
      "Adam Santoro",
      "Ryan Faulkner",
      "Caglar Gulcehre",
      "Francis Song",
      "Andrew Ballard",
      "Justin Gilmer",
      "George Dahl",
      "Ashish Vaswani",
      "Kelsey Allen",
      "Charles Nash",
      "Victoria Langston",
      "Chris Dyer",
      "Nicolas Heess",
      "Daan Wierstra",
      "Pushmeet Kohli",
      "Matt Botvinick",
      "Oriol Vinyals",
      "Yujia Li",
      "Razvan Pascanu"
    ],
    "author_ids": [],
    "abstract": "Artificial intelligence (AI) has undergone a renaissance recently, making\nmajor progress in key domains such as vision, language, control, and\ndecision-making. This has been due, in part, to cheap data and cheap compute\nresources, which have fit the natural strengths of deep learning. However, many\ndefining characteristics of human intelligence, which developed under much\ndifferent pressures, remain out of reach for current approaches. In particular,\ngeneralizing beyond one's experiences--a hallmark of human intelligence from\ninfancy--remains a formidable challenge for modern AI.\n  The following is part position paper, part review, and part unification. We\nargue that combinatorial generalization must be a top priority for AI to\nachieve human-like abilities, and that structured representations and\ncomputations are key to realizing this objective. Just as biology uses nature\nand nurture cooperatively, we reject the false choice between\n\"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an\napproach which benefits from their complementary strengths. We explore how\nusing relational inductive biases within deep learning architectures can\nfacilitate learning about entities, relations, and rules for composing them. We\npresent a new building block for the AI toolkit with a strong relational\ninductive bias--the graph network--which generalizes and extends various\napproaches for neural networks that operate on graphs, and provides a\nstraightforward interface for manipulating structured knowledge and producing\nstructured behaviors. We discuss how graph networks can support relational\nreasoning and combinatorial generalization, laying the foundation for more\nsophisticated, interpretable, and flexible patterns of reasoning. As a\ncompanion to this paper, we have released an open-source software library for\nbuilding graph networks, with demonstrations of how to use them in practice.",
    "published_date": "2018-06-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01261v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.01242v1",
    "title": "Graph networks as learnable physics engines for inference and control",
    "authors": [
      "Alvaro Sanchez-Gonzalez",
      "Nicolas Heess",
      "Jost Tobias Springenberg",
      "Josh Merel",
      "Martin Riedmiller",
      "Raia Hadsell",
      "Peter Battaglia"
    ],
    "author_ids": [],
    "abstract": "Understanding and interacting with everyday physical scenes requires rich\nknowledge about the structure of the world, represented either implicitly in a\nvalue or policy function, or explicitly in a transition model. Here we\nintroduce a new class of learnable models--based on graph networks--which\nimplement an inductive bias for object- and relation-centric representations of\ncomplex, dynamical systems. Our results show that as a forward model, our\napproach supports accurate predictions from real and simulated data, and\nsurprisingly strong and efficient generalization, across eight distinct\nphysical systems which we varied parametrically and structurally. We also found\nthat our inference model can perform system identification. Our models are also\ndifferentiable, and support online planning via gradient-based trajectory\noptimization, as well as offline policy optimization. Our framework offers new\nopportunities for harnessing and exploiting rich knowledge about the world, and\ntakes a key step toward building machines with more human-like representations\nof the world.",
    "published_date": "2018-06-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01242v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.01203v1",
    "title": "Relational inductive bias for physical construction in humans and machines",
    "authors": [
      "Jessica B. Hamrick",
      "Kelsey R. Allen",
      "Victor Bapst",
      "Tina Zhu",
      "Kevin R. McKee",
      "Joshua B. Tenenbaum",
      "Peter W. Battaglia"
    ],
    "author_ids": [],
    "abstract": "While current deep learning systems excel at tasks such as object\nclassification, language processing, and gameplay, few can construct or modify\na complex system such as a tower of blocks. We hypothesize that what these\nsystems lack is a \"relational inductive bias\": a capacity for reasoning about\ninter-object relations and making choices over a structured description of a\nscene. To test this hypothesis, we focus on a task that involves gluing pairs\nof blocks together to stabilize a tower, and quantify how well humans perform.\nWe then introduce a deep reinforcement learning agent which uses object- and\nrelation-centric scene and policy representations and apply it to the task. Our\nresults show that these structured representations allow the agent to\noutperform both humans and more naive approaches, suggesting that relational\ninductive bias is an important component in solving structured reasoning\nproblems and for building more intelligent, flexible machines.",
    "published_date": "2018-06-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01203v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.01059v2",
    "title": "iFair: Learning Individually Fair Data Representations for Algorithmic Decision Making",
    "authors": [
      "Preethi Lahoti",
      "Krishna P. Gummadi",
      "Gerhard Weikum"
    ],
    "author_ids": [],
    "abstract": "People are rated and ranked, towards algorithmic decision making in an\nincreasing number of applications, typically based on machine learning.\nResearch on how to incorporate fairness into such tasks has prevalently pursued\nthe paradigm of group fairness: giving adequate success rates to specifically\nprotected groups. In contrast, the alternative paradigm of individual fairness\nhas received relatively little attention, and this paper advances this less\nexplored direction. The paper introduces a method for probabilistically mapping\nuser records into a low-rank representation that reconciles individual fairness\nand the utility of classifiers and rankings in downstream applications. Our\nnotion of individual fairness requires that users who are similar in all\ntask-relevant attributes such as job qualification, and disregarding all\npotentially discriminating attributes such as gender, should have similar\noutcomes. We demonstrate the versatility of our method by applying it to\nclassification and learning-to-rank tasks on a variety of real-world datasets.\nOur experiments show substantial improvements over the best prior work for this\nsetting.",
    "published_date": "2018-06-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.IR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01059v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.00830v1",
    "title": "Studying Politically Vulnerable Communities Online: Ethical Dilemmas, Questions, and Solutions",
    "authors": [
      "Robert Gorwa",
      "Philip N. Howard"
    ],
    "author_ids": [],
    "abstract": "This short article introduces the concept of political vulnerability for\nsocial media researchers. How are traditional notions of harm challenged by\nresearch subjects in politically vulnerable communities? Through a selection of\ncase studies, we explore some of the trade-offs, challenges, and questions\nraised by research that seeks be robust and transparent while also preserving\nanonymity and privacy, especially in high-stakes, politically fraught contexts.",
    "published_date": "2018-06-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00830v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.00468v2",
    "title": "Implicit Bias of Gradient Descent on Linear Convolutional Networks",
    "authors": [
      "Suriya Gunasekar",
      "Jason Lee",
      "Daniel Soudry",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "We show that gradient descent on full-width linear convolutional networks of\ndepth $L$ converges to a linear predictor related to the $\\ell_{2/L}$ bridge\npenalty in the frequency domain. This is in contrast to linearly fully\nconnected networks, where gradient descent converges to the hard margin linear\nsupport vector machine solution, regardless of depth.",
    "published_date": "2018-06-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00468v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.00241v2",
    "title": "Proportional Fairness in ALOHA Networks with RF Energy Harvesting",
    "authors": [
      "Zoran Hadzi-Velkov",
      "Slavche Pejoski",
      "Nikola Zlatanov",
      "Robert Schober"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study wireless powered communication networks that employ\nthe slotted ALOHA protocol, which is the preferred protocol for simple and\nuncoordinated networks. In the energy harvesting (EH) phase, the base station\nbroadcasts radio frequency energy to the EH users (EHUs). The EHUs harvest the\nbroadcasted energy and use it to transmit information back to the base station\nby contending for access to the uplink channel in the random access (RA) phase.\nIn order to ensure fairness among the users, we propose a proportionally fair\nresource allocation scheme that exploits the RA nature of slotted ALOHA.\nSpecifically, assuming statistical channel state information, we determine the\noptimal transmit power at the base station, the optimal durations of the EH and\nRA phases, the channel access probability, and the rate of each EHU.",
    "published_date": "2018-06-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00241v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.00194v2",
    "title": "Deep Imbalanced Learning for Face Recognition and Attribute Prediction",
    "authors": [
      "Chen Huang",
      "Yining Li",
      "Chen Change Loy",
      "Xiaoou Tang"
    ],
    "author_ids": [],
    "abstract": "Data for face analysis often exhibit highly-skewed class distribution, i.e.,\nmost data belong to a few majority classes, while the minority classes only\ncontain a scarce amount of instances. To mitigate this issue, contemporary deep\nlearning methods typically follow classic strategies such as class re-sampling\nor cost-sensitive training. In this paper, we conduct extensive and systematic\nexperiments to validate the effectiveness of these classic schemes for\nrepresentation learning on class-imbalanced data. We further demonstrate that\nmore discriminative deep representation can be learned by enforcing a deep\nnetwork to maintain inter-cluster margins both within and between classes. This\ntight constraint effectively reduces the class imbalance inherent in the local\ndata neighborhood, thus carving much more balanced class boundaries locally. We\nshow that it is easy to deploy angular margins between the cluster\ndistributions on a hypersphere manifold. Such learned Cluster-based Large\nMargin Local Embedding (CLMLE), when combined with a simple k-nearest cluster\nalgorithm, shows significant improvements in accuracy over existing methods on\nboth face recognition and face attribute prediction tasks that exhibit\nimbalanced class distribution.",
    "published_date": "2018-06-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00194v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.00081v2",
    "title": "Resisting Adversarial Attacks using Gaussian Mixture Variational Autoencoders",
    "authors": [
      "Partha Ghosh",
      "Arpan Losalka",
      "Michael J Black"
    ],
    "author_ids": [],
    "abstract": "Susceptibility of deep neural networks to adversarial attacks poses a major\ntheoretical and practical challenge. All efforts to harden classifiers against\nsuch attacks have seen limited success. Two distinct categories of samples to\nwhich deep networks are vulnerable, \"adversarial samples\" and \"fooling\nsamples\", have been tackled separately so far due to the difficulty posed when\nconsidered together. In this work, we show how one can address them both under\none unified framework. We tie a discriminative model with a generative model,\nrendering the adversarial objective to entail a conflict. Our model has the\nform of a variational autoencoder, with a Gaussian mixture prior on the latent\nvector. Each mixture component of the prior distribution corresponds to one of\nthe classes in the data. This enables us to perform selective classification,\nleading to the rejection of adversarial samples instead of misclassification.\nOur method inherently provides a way of learning a selective classifier in a\nsemi-supervised scenario as well, which can resist adversarial attacks. We also\nshow how one can reclassify the rejected adversarial samples.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00081v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1806.00069v3",
    "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning",
    "authors": [
      "Leilani H. Gilpin",
      "David Bau",
      "Ben Z. Yuan",
      "Ayesha Bajwa",
      "Michael Specter",
      "Lalana Kagal"
    ],
    "author_ids": [],
    "abstract": "There has recently been a surge of work in explanatory artificial\nintelligence (XAI). This research area tackles the important problem that\ncomplex machines and algorithms often cannot provide insights into their\nbehavior and thought processes. XAI allows users and parts of the internal\nsystem to be more transparent, providing explanations of their decisions in\nsome level of detail. These explanations are important to ensure algorithmic\nfairness, identify potential bias/problems in the training data, and to ensure\nthat the algorithms perform as expected. However, explanations produced by\nthese systems is neither standardized nor systematically assessed. In an effort\nto create best practices and identify open challenges, we provide our\ndefinition of explainability and show how it can be used to classify existing\nliterature. We discuss why current approaches to explanatory methods especially\nfor deep neural networks are insufficient. Finally, based on our survey, we\nconclude with suggested future research directions for explanatory artificial\nintelligence.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.00069v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.12505v2",
    "title": "The long-term impact of ranking algorithms in growing networks",
    "authors": [
      "Shilun Zhang",
      "Matúš Medo",
      "Linyuan Lü",
      "Manuel Sebastian Mariani"
    ],
    "author_ids": [],
    "abstract": "When we search online for content, we are constantly exposed to rankings. For\nexample, web search results are presented as a ranking, and online bookstores\noften show us lists of best-selling books. While popularity-based ranking\nalgorithms (like Google's PageRank) have been extensively studied in previous\nworks, we still lack a clear understanding of their potential systemic\nconsequences. In this work, we fill this gap by introducing a new model of\nnetwork growth that allows us to compare the properties of the networks\ngenerated under the influence of different ranking algorithms. We show that by\ncorrecting for the omnipresent age bias of popularity-based ranking algorithms,\nthe resulting networks exhibit a significantly larger agreement between the\nnodes' inherent quality and their long-term popularity, and a less concentrated\npopularity distribution. To further promote popularity diversity, we introduce\nand validate a perturbation of the original rankings where a small number of\nrandomly-selected nodes are promoted to the top of the ranking. Our findings\nmove the first steps toward a model-based understanding of the long-term impact\nof popularity-based ranking algorithms, and could be used as an informative\ntool for the design of improved information filtering tools.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.IR",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12505v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.12467v1",
    "title": "A Method Based on Convex Cone Model for Image-Set Classification with CNN Features",
    "authors": [
      "Naoya Sogi",
      "Taku Nakayama",
      "Kazuhiro Fukui"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a method for image-set classification based on\nconvex cone models, focusing on the effectiveness of convolutional neural\nnetwork (CNN) features as inputs. CNN features have non-negative values when\nusing the rectified linear unit as an activation function. This naturally leads\nus to model a set of CNN features by a convex cone and measure the geometric\nsimilarity of convex cones for classification. To establish this framework, we\nsequentially define multiple angles between two convex cones by repeating the\nalternating least squares method and then define the geometric similarity\nbetween the cones using the obtained angles. Moreover, to enhance our method,\nwe introduce a discriminant space, maximizing the between-class variance (gaps)\nand minimizes the within-class variance of the projected convex cones onto the\ndiscriminant space, similar to a Fisher discriminant analysis. Finally,\nclassification is based on the similarity between projected convex cones. The\neffectiveness of the proposed method was demonstrated experimentally using a\nprivate, multi-view hand shape dataset and two public databases.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12467v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.12388v1",
    "title": "Sample Reuse via Importance Sampling in Information Geometric Optimization",
    "authors": [
      "Shinichi Shirakawa",
      "Youhei Akimoto",
      "Kazuki Ouchi",
      "Kouzou Ohara"
    ],
    "author_ids": [],
    "abstract": "In this paper we propose a technique to reduce the number of function\nevaluations, which is often the bottleneck of the black-box optimization, in\nthe information geometric optimization (IGO) that is a generic framework of the\nprobability model-based black-box optimization algorithms and generalizes\nseveral well-known evolutionary algorithms, such as the population-based\nincremental learning (PBIL) and the pure rank-$\\mu$ update covariance matrix\nadaptation evolution strategy (CMA-ES). In each iteration, the IGO algorithms\nupdate the parameters of the probability distribution to the natural gradient\ndirection estimated by Monte-Carlo with the samples drawn from the current\ndistribution. Our strategy is to reuse previously generated and evaluated\nsamples based on the importance sampling. It is a technique to reduce the\nestimation variance without introducing a bias in Monte-Carlo estimation. We\napply the sample reuse technique to the PBIL and the pure rank-$\\mu$ update\nCMA-ES and empirically investigate its effect. The experimental results show\nthat the sample reuse helps to reduce the number of function evaluations on\nmany benchmark functions for both the PBIL and the pure rank-$\\mu$ update\nCMA-ES. Moreover, we demonstrate how to combine the importance sampling\ntechnique with a variant of the CMA-ES involving an algorithmic component that\nis not derived in the IGO framework.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12388v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.12317v2",
    "title": "Multiaccuracy: Black-Box Post-Processing for Fairness in Classification",
    "authors": [
      "Michael P. Kim",
      "Amirata Ghorbani",
      "James Zou"
    ],
    "author_ids": [],
    "abstract": "Prediction systems are successfully deployed in applications ranging from\ndisease diagnosis, to predicting credit worthiness, to image recognition. Even\nwhen the overall accuracy is high, these systems may exhibit systematic biases\nthat harm specific subpopulations; such biases may arise inadvertently due to\nunderrepresentation in the data used to train a machine-learning model, or as\nthe result of intentional malicious discrimination. We develop a rigorous\nframework of *multiaccuracy* auditing and post-processing to ensure accurate\npredictions across *identifiable subgroups*.\n  Our algorithm, MULTIACCURACY-BOOST, works in any setting where we have\nblack-box access to a predictor and a relatively small set of labeled data for\nauditing; importantly, this black-box framework allows for improved fairness\nand accountability of predictions, even when the predictor is minimally\ntransparent. We prove that MULTIACCURACY-BOOST converges efficiently and show\nthat if the initial model is accurate on an identifiable subgroup, then the\npost-processed model will be also. We experimentally demonstrate the\neffectiveness of the approach to improve the accuracy among minority subgroups\nin diverse applications (image classification, finance, population health).\nInterestingly, MULTIACCURACY-BOOST can improve subpopulation accuracy (e.g. for\n\"black women\") even when the sensitive features (e.g. \"race\", \"gender\") are not\ngiven to the algorithm explicitly.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12317v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.12267v1",
    "title": "Blockchain for Access Control in e-Health Scenarios",
    "authors": [
      "João Pedro Dias",
      "Luís Reis",
      "Hugo Sereno Ferreira",
      "Ângelo Martins"
    ],
    "author_ids": [],
    "abstract": "Access control is a crucial part of a system's security, restricting what\nactions users can perform on resources. Therefore, access control is a core\ncomponent when dealing with e-Health data and resources, discriminating which\nis available for a certain party. We consider that current systems that attempt\nto assure the share of policies between facilities are prone to system's and\nnetwork's faults and do not assure the integrity of policies lifecycle. By\napproaching this problem with the use of a distributed ledger, namely a\nconsortium blockchain, where the operations are stored as transactions, we\nensure that the different facilities have knowledge about all the parties that\ncan act over the e-Health resources while maintaining integrity, auditability,\nauthenticity, and scalability.",
    "published_date": "2018-05-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12267v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.12002v2",
    "title": "Why Is My Classifier Discriminatory?",
    "authors": [
      "Irene Chen",
      "Fredrik D. Johansson",
      "David Sontag"
    ],
    "author_ids": [],
    "abstract": "Recent attempts to achieve fairness in predictive models focus on the balance\nbetween fairness and accuracy. In sensitive applications such as healthcare or\ncriminal justice, this trade-off is often undesirable as any increase in\nprediction error could have devastating consequences. In this work, we argue\nthat the fairness of predictions should be evaluated in context of the data,\nand that unfairness induced by inadequate samples sizes or unmeasured\npredictive variables should be addressed through data collection, rather than\nby constraining the model. We decompose cost-based metrics of discrimination\ninto bias, variance, and noise, and propose actions aimed at estimating and\nreducing each term. Finally, we perform case-studies on prediction of income,\nmortality, and review ratings, confirming the value of this analysis. We find\nthat data collection is often a means to reduce discrimination without\nsacrificing accuracy.",
    "published_date": "2018-05-30T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12002v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.11722v2",
    "title": "Fairness and Sum-Rate Maximization via Joint Channel and Power Allocation in Uplink SCMA Networks",
    "authors": [
      "Joao V. C. Evangelista",
      "Zeeshan Sattar",
      "Georges Kaddoum",
      "Anas Chaaban"
    ],
    "author_ids": [],
    "abstract": "In this work, we consider a sparse code multiple access uplink system, where\n$J$ users simultaneously transmit data over $K$ subcarriers, such that $J > K$,\nwith a constraint on the power transmitted by each user. To jointly optimize\nthe subcarrier assignment and the transmitted power per subcarrier, two new\niterative algorithms are proposed, the first one aims to maximize the sum-rate\n(Max-SR) of the network, while the second aims to maximize the fairness\n(Max-Min). In both cases, the optimization problem is of the mixed-integer\nnonlinear programming (MINLP) type, with non-convex objective functions, which\nare generally not tractable. We prove that both joint allocation problems are\nNP-hard. To address these issues, we employ a variant of the block successive\nupper-bound minimization (BSUM) \\cite{razaviyayn.2013} framework, obtaining\npolynomial-time approximation algorithms to the original problem. Moreover, we\nevaluate the algorithms' robustness against outdated channel state information\n(CSI), present an analysis of the convergence of the algorithms, and a\ncomparison of the sum-rate and Jain's fairness index of the novel algorithms\nwith three other algorithms proposed in the literature. The Max-SR algorithm\noutperforms the others in the sum-rate sense, while the Max-Min outperforms\nthem in the fairness sense.",
    "published_date": "2018-05-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11722v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.11704v2",
    "title": "Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis",
    "authors": [
      "Arna Ghosh",
      "Fabien dal Maso",
      "Marc Roig",
      "Georgios D Mitsis",
      "Marie-Hélène Boudrias"
    ],
    "author_ids": [],
    "abstract": "Neuroimaging data analysis often involves \\emph{a-priori} selection of data\nfeatures to study the underlying neural activity. Since this could lead to\nsub-optimal feature selection and thereby prevent the detection of subtle\npatterns in neural activity, data-driven methods have recently gained\npopularity for optimizing neuroimaging data analysis pipelines and thereby,\nimproving our understanding of neural mechanisms. In this context, we developed\na deep convolutional architecture that can identify discriminating patterns in\nneuroimaging data and applied it to electroencephalography (EEG) recordings\ncollected from 25 subjects performing a hand motor task before and after a rest\nperiod or a bout of exercise. The deep network was trained to classify subjects\ninto exercise and control groups based on differences in their EEG signals.\nSubsequently, we developed a novel method termed the cue-combination for Class\nActivation Map (ccCAM), which enabled us to identify discriminating\nspatio-temporal features within definite frequency bands (23--33 Hz) and assess\nthe effects of exercise on the brain. Additionally, the proposed architecture\nallowed the visualization of the differences in the propagation of underlying\nneural activity across the cortex between the two groups, for the first time in\nour knowledge. Our results demonstrate the feasibility of using deep network\narchitectures for neuroimaging analysis in different contexts such as, for the\nidentification of robust brain biomarkers to better characterize and\npotentially treat neurological disorders.",
    "published_date": "2018-05-29T00:00:00",
    "year": 2018,
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "q-bio.QM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11704v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.11542v1",
    "title": "Forward Amortized Inference for Likelihood-Free Variational Marginalization",
    "authors": [
      "Luca Ambrogioni",
      "Umut Güçlü",
      "Julia Berezutskaya",
      "Eva W. P. van den Borne",
      "Yağmur Güçlütürk",
      "Max Hinne",
      "Eric Maris",
      "Marcel A. J. van Gerven"
    ],
    "author_ids": [],
    "abstract": "In this paper, we introduce a new form of amortized variational inference by\nusing the forward KL divergence in a joint-contrastive variational loss. The\nresulting forward amortized variational inference is a likelihood-free method\nas its gradient can be sampled without bias and without requiring any\nevaluation of either the model joint distribution or its derivatives. We prove\nthat our new variational loss is optimized by the exact posterior marginals in\nthe fully factorized mean-field approximation, a property that is not shared\nwith the more conventional reverse KL inference. Furthermore, we show that\nforward amortized inference can be easily marginalized over large families of\nlatent variables in order to obtain a marginalized variational posterior. We\nconsider two examples of variational marginalization. In our first example we\ntrain a Bayesian forecaster for predicting a simplified chaotic model of\natmospheric convection. In the second example we train an amortized variational\napproximation of a Bayesian optimal classifier by marginalizing over the model\nspace. The result is a powerful meta-classification network that can solve\narbitrary classification problems without further training.",
    "published_date": "2018-05-29T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11542v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.11295v2",
    "title": "Unsupervised detection of diachronic word sense evolution",
    "authors": [
      "Jean-François Delpech"
    ],
    "author_ids": [],
    "abstract": "Most words have several senses and connotations which evolve in time due to\nsemantic shift, so that closely related words may gain different or even\nopposite meanings over the years. This evolution is very relevant to the study\nof language and of cultural changes, but the tools currently available for\ndiachronic semantic analysis have significant, inherent limitations and are not\nsuitable for real-time analysis. In this article, we demonstrate how the\nlinearity of random vectors techniques enables building time series of\ncongruent word embeddings (or semantic spaces) which can then be compared and\ncombined linearly without loss of precision over any time period to detect\ndiachronic semantic shifts. We show how this approach yields time trajectories\nof polysemous words such as amazon or apple, enables following semantic drifts\nand gender bias across time, reveals the shifting instantiations of stable\nconcepts such as hurricane or president. This very fast, linear approach can\neasily be distributed over many processors to follow in real time streams of\nsocial media such as Twitter or Facebook; the resulting, time-dependent\nsemantic spaces can then be combined at will by simple additions or\nsubtractions.",
    "published_date": "2018-05-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11295v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.11260v1",
    "title": "Error Bounds on a Mixed Entropy Inequality",
    "authors": [
      "James Melbourne",
      "Saurav Talukdar",
      "Shreyas Bhaban",
      "Murti V. Salapaka"
    ],
    "author_ids": [],
    "abstract": "Motivated by the entropy computations relevant to the evaluation of decrease\nin entropy in bit reset operations, the authors investigate the deficit in an\nentropic inequality involving two independent random variables, one continuous\nand the other discrete. In the case where the continuous random variable is\nGaussian, we derive strong quantitative bounds on the deficit in the\ninequality. More explicitly it is shown that the decay of the deficit is\nsub-Gaussian with respect to the reciprocal of the standard deviation of the\nGaussian variable. What is more, up to rational terms these results are shown\nto be sharp.",
    "published_date": "2018-05-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11260v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.11202v1",
    "title": "FairGAN: Fairness-aware Generative Adversarial Networks",
    "authors": [
      "Depeng Xu",
      "Shuhan Yuan",
      "Lu Zhang",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Fairness-aware learning is increasingly important in data mining.\nDiscrimination prevention aims to prevent discrimination in the training data\nbefore it is used to conduct predictive analysis. In this paper, we focus on\nfair data generation that ensures the generated data is discrimination free.\nInspired by generative adversarial networks (GAN), we present fairness-aware\ngenerative adversarial networks, called FairGAN, which are able to learn a\ngenerator producing fair data and also preserving good data utility. Compared\nwith the naive fair data generation models, FairGAN further ensures the\nclassifiers which are trained on generated data can achieve fair classification\non real data. Experiments on a real dataset show the effectiveness of FairGAN.",
    "published_date": "2018-05-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.11202v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.10842v2",
    "title": "Approximating Real-Time Recurrent Learning with Random Kronecker Factors",
    "authors": [
      "Asier Mujika",
      "Florian Meier",
      "Angelika Steger"
    ],
    "author_ids": [],
    "abstract": "Despite all the impressive advances of recurrent neural networks, sequential\ndata is still in need of better modelling. Truncated backpropagation through\ntime (TBPTT), the learning algorithm most widely used in practice, suffers from\nthe truncation bias, which drastically limits its ability to learn long-term\ndependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses this\nissue, but its high computational requirements make it infeasible in practice.\nThe Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL\nwith a smaller runtime and memory cost, but with the disadvantage of obtaining\nnoisy gradients that also limit its practical applicability. In this paper we\npropose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker\nproduct decomposition to approximate the gradients for a large class of RNNs.\nWe show that KF-RTRL is an unbiased and memory efficient online learning\nalgorithm. Our theoretical analysis shows that, under reasonable assumptions,\nthe noise introduced by our algorithm is not only stable over time but also\nasymptotically much smaller than the one of the UORO algorithm. We also confirm\nthese theoretical results experimentally. Further, we show empirically that the\nKF-RTRL algorithm captures long-term dependencies and almost matches the\nperformance of TBPTT on real world tasks by training Recurrent Highway Networks\non a synthetic string memorization task and on the Penn TreeBank task,\nrespectively. These results indicate that RTRL based approaches might be a\npromising future alternative to TBPTT.",
    "published_date": "2018-05-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.10842v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.10389v1",
    "title": "A Study of Question Effectiveness Using Reddit \"Ask Me Anything\" Threads",
    "authors": [
      "Kristjan Arumae",
      "Guo-Jun Qi",
      "Fei Liu"
    ],
    "author_ids": [],
    "abstract": "Asking effective questions is a powerful social skill. In this paper we seek\nto build computational models that learn to discriminate effective questions\nfrom ineffective ones. Armed with such a capability, future advanced systems\ncan evaluate the quality of questions and provide suggestions for effective\nquestion wording. We create a large-scale, real-world dataset that contains\nover 400,000 questions collected from Reddit \"Ask Me Anything\" threads. Each\nthread resembles an online press conference where questions compete with each\nother for attention from the host. This dataset enables the development of a\nclass of computational models for predicting whether a question will be\nanswered. We develop a new convolutional neural network architecture with\nvariable-length context and demonstrate the efficacy of the model by comparing\nit with state-of-the-art baselines and human judges.",
    "published_date": "2018-05-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.10389v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.10318v1",
    "title": "Enhancing the Accuracy and Fairness of Human Decision Making",
    "authors": [
      "Isabel Valera",
      "Adish Singla",
      "Manuel Gomez Rodriguez"
    ],
    "author_ids": [],
    "abstract": "Societies often rely on human experts to take a wide variety of decisions\naffecting their members, from jail-or-release decisions taken by judges and\nstop-and-frisk decisions taken by police officers to accept-or-reject decisions\ntaken by academics. In this context, each decision is taken by an expert who is\ntypically chosen uniformly at random from a pool of experts. However, these\ndecisions may be imperfect due to limited experience, implicit biases, or\nfaulty probabilistic reasoning. Can we improve the accuracy and fairness of the\noverall decision making process by optimizing the assignment between experts\nand decisions?\n  In this paper, we address the above problem from the perspective of\nsequential decision making and show that, for different fairness notions from\nthe literature, it reduces to a sequence of (constrained) weighted bipartite\nmatchings, which can be solved efficiently using algorithms with approximation\nguarantees. Moreover, these algorithms also benefit from posterior sampling to\nactively trade off exploitation---selecting expert assignments which lead to\naccurate and fair decisions---and exploration---selecting expert assignments to\nlearn about the experts' preferences and biases. We demonstrate the\neffectiveness of our algorithms on both synthetic and real-world data and show\nthat they can significantly improve both the accuracy and fairness of the\ndecisions taken by pools of experts.",
    "published_date": "2018-05-25T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.10318v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.10109v1",
    "title": "Resisting hostility generated by terror: An agent-based study",
    "authors": [
      "Sylvie Huet",
      "Guillaume Deffuant",
      "Armelle Nugier",
      "Michel Streith",
      "Serge Guimond"
    ],
    "author_ids": [],
    "abstract": "We aim to study through an agent-based model the cultural conditions leading\nto a decrease or an increase of discrimination between groups after a major\ncultural threat such as a terrorist attack. We propose an agent-based model of\ncultural dynamics inspired from the social psychological theories. An agent has\na cultural identity comprised of the most acceptable positions about each of\nthe different cultural worldviews corresponding to the main cultural groups of\nthe considered society and a margin of acceptance around each of these most\nacceptable positions. An agent forms an attitude about another agent depending\non the similarity between their cultural identities. When a terrorist attack is\nperpetrated in the name of an extreme cultural identity, the negatively\nperceived agents from this extreme cultural identity modify their margins of\nacceptance in order to differentiate themselves more from the threatening\ncultural identity. We generated a set of populations with cultural identities\ncompatible with data given by a survey on groups' attitudes among a large\nsample representative of the population of France; we then simulated the\nreaction of these agents facing a threat. For most populations, the average\nattitude toward agents with the same preferred worldview as the terrorists\nbecomes more negative; however, when the population shows some cultural\nproperties, we noticed the opposite effect as the average attitude of the\npopulation becomes less negative. This particular context requires that the\nagents sharing the same preferred worldview with the terrorists strongly\ndifferentiate themselves from the terrorists' extreme cultural identity and\nthat the other agents be aware of these changes.",
    "published_date": "2018-05-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.10109v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.09966v2",
    "title": "Prestige drives epistemic inequality in the diffusion of scientific ideas",
    "authors": [
      "Allison C. Morgan",
      "Dimitrios J. Economou",
      "Samuel F. Way",
      "Aaron Clauset"
    ],
    "author_ids": [],
    "abstract": "The spread of ideas in the scientific community is often viewed as a\ncompetition, in which good ideas spread further because of greater intrinsic\nfitness, and publication venue and citation counts correlate with importance\nand impact. However, relatively little is known about how structural factors\ninfluence the spread of ideas, and specifically how where an idea originates\nmight influence how it spreads. Here, we investigate the role of faculty hiring\nnetworks, which embody the set of researcher transitions from doctoral to\nfaculty institutions, in shaping the spread of ideas in computer science, and\nthe importance of where in the network an idea originates. We consider\ncomprehensive data on the hiring events of 5032 faculty at all 205\nPh.D.-granting departments of computer science in the U.S. and Canada, and on\nthe timing and titles of 200,476 associated publications. Analyzing five\npopular research topics, we show empirically that faculty hiring can and does\nfacilitate the spread of ideas in science. Having established such a mechanism,\nwe then analyze its potential consequences using epidemic models to simulate\nthe generic spread of research ideas and quantify the impact of where an idea\noriginates on its longterm diffusion across the network. We find that research\nfrom prestigious institutions spreads more quickly and completely than work of\nsimilar quality originating from less prestigious institutions. Our analyses\nestablish the theoretical trade-offs between university prestige and the\nquality of ideas necessary for efficient circulation. Our results establish\nfaculty hiring as an underlying mechanism that drives the persistent epistemic\nadvantage observed for elite institutions, and provide a theoretical lower\nbound for the impact of structural inequality in shaping the spread of ideas in\nscience.",
    "published_date": "2018-05-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09966v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.09910v1",
    "title": "Fairness GAN",
    "authors": [
      "Prasanna Sattigeri",
      "Samuel C. Hoffman",
      "Vijil Chenthamarakshan",
      "Kush R. Varshney"
    ],
    "author_ids": [],
    "abstract": "In this paper, we introduce the Fairness GAN, an approach for generating a\ndataset that is plausibly similar to a given multimedia dataset, but is more\nfair with respect to protected attributes in allocative decision making. We\npropose a novel auxiliary classifier GAN that strives for demographic parity or\nequality of opportunity and show empirical results on several datasets,\nincluding the CelebFaces Attributes (CelebA) dataset, the Quick, Draw!\\\ndataset, and a dataset of soccer player images and the offenses they were\ncalled for. The proposed formulation is well-suited to absorbing unlabeled\ndata; we leverage this to augment the soccer dataset with the much larger\nCelebA dataset. The methodology tends to improve demographic parity and\nequality of opportunity while generating plausible images.",
    "published_date": "2018-05-24T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09910v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.09866v2",
    "title": "Pooling of Causal Models under Counterfactual Fairness via Causal Judgement Aggregation",
    "authors": [
      "Fabio Massimo Zennaro",
      "Magdalena Ivanovska"
    ],
    "author_ids": [],
    "abstract": "In this paper we consider the problem of combining multiple probabilistic\ncausal models, provided by different experts, under the requirement that the\naggregated model satisfy the criterion of counterfactual fairness. We build\nupon the work on causal models and fairness in machine learning, and we express\nthe problem of combining multiple models within the framework of opinion\npooling. We propose two simple algorithms, grounded in the theory of\ncounterfactual fairness and causal judgment aggregation, that are guaranteed to\ngenerate aggregated probabilistic causal models respecting the criterion of\nfairness, and we compare their behaviors on a toy case study.",
    "published_date": "2018-05-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09866v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.09799v1",
    "title": "Prediction of Autism Treatment Response from Baseline fMRI using Random Forests and Tree Bagging",
    "authors": [
      "Nicha C. Dvornek",
      "Daniel Yang",
      "Archana Venkataraman",
      "Pamela Ventola",
      "Lawrence H. Staib",
      "Kevin A. Pelphrey",
      "James S. Duncan"
    ],
    "author_ids": [],
    "abstract": "Treating children with autism spectrum disorders (ASD) with behavioral\ninterventions, such as Pivotal Response Treatment (PRT), has shown promise in\nrecent studies. However, deciding which therapy is best for a given patient is\nlargely by trial and error, and choosing an ineffective intervention results in\nloss of valuable treatment time. We propose predicting patient response to PRT\nfrom baseline task-based fMRI by the novel application of a random forest and\ntree bagging strategy. Our proposed learning pipeline uses random forest\nregression to determine candidate brain voxels that may be informative in\npredicting treatment response. The candidate voxels are then tested stepwise\nfor inclusion in a bagged tree ensemble. After the predictive model is\nconstructed, bias correction is performed to further increase prediction\naccuracy. Using data from 19 ASD children who underwent a 16 week trial of PRT\nand a leave-one-out cross-validation framework, the presented learning pipeline\nwas tested against several standard methods and variations of the pipeline and\nresulted in the highest prediction accuracy.",
    "published_date": "2018-05-24T00:00:00",
    "year": 2018,
    "categories": [
      "stat.AP",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09799v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.09090v1",
    "title": "Volunteers in the Smart City: Comparison of Contribution Strategies on Human-Centered Measures",
    "authors": [
      "Stefano Bennati",
      "Ivana Dusparic",
      "Rhythima Shinde",
      "Catholijn M. Jonker"
    ],
    "author_ids": [],
    "abstract": "Several smart city services rely on users contribution, e.g., data, which can\nbe costly for the users in terms of privacy. High costs lead to reduced user\nparticipation, which undermine the success of smart city technologies. This\nwork develops a scenario-independent design principle, based on public good\ntheory, for resource management in smart city applications, where provision of\na service depends on contributors and free-riders, which benefit from the\nservice without contributing own resources. Following this design principle,\ndifferent classes of algorithms for resource management are evaluated with\nrespect to human-centered measures, i.e., privacy, fairness and social welfare.\nTrade-offs that characterize algorithms are discussed across two smart city\napplication scenarios. These results might help Smart City application\ndesigners to choose a suitable algorithm given a scenario-specific set of\nrequirements, and users to choose a service based on an algorithm that matches\ntheir preferences.",
    "published_date": "2018-05-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09090v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08815v1",
    "title": "From Dissipativity Theory to Compositional Abstractions of Interconnected Stochastic Hybrid Systems",
    "authors": [
      "Asad Ullah Awan",
      "Majid Zamani"
    ],
    "author_ids": [],
    "abstract": "In this work, we derive conditions under which compositional abstractions of\nnetworks of stochastic hybrid systems can be constructed using the\ninterconnection topology and joint dissipativity-type properties of subsystems\nand their abstractions. In the proposed framework, the abstraction, itself a\nstochastic hybrid system (possibly with a lower dimension), can be used as a\nsubstitute of the original system in the controller design process. Moreover,\nwe derive conditions for the construction of abstractions for a class of\nstochastic hybrid systems involving nonlinearities satisfying an incremental\nquadratic inequality. In this work, unlike existing results, the stochastic\nnoises and jumps in the concrete subsystem and its abstraction need not to be\nthe same. We provide examples with numerical simulations to illustrate the\neffectiveness of the proposed dissipativity-type compositional reasoning for\ninterconnected stochastic hybrid systems.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08815v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08718v2",
    "title": "Inferring Human Traits From Facebook Statuses",
    "authors": [
      "Andrew Cutler",
      "Brian Kulis"
    ],
    "author_ids": [],
    "abstract": "This paper explores the use of language models to predict 20 human traits\nfrom users' Facebook status updates. The data was collected by the\nmyPersonality project, and includes user statuses along with their personality,\ngender, political identification, religion, race, satisfaction with life, IQ,\nself-disclosure, fair-mindedness, and belief in astrology. A single\ninterpretable model meets state of the art results for well-studied tasks such\nas predicting gender and personality; and sets the standard on other traits\nsuch as IQ, sensational interests, political identity, and satisfaction with\nlife. Additionally, highly weighted words are published for each trait. These\nlists are valuable for creating hypotheses about human behavior, as well as for\nunderstanding what information a model is extracting. Using performance and\nextracted features we analyze models built on social media. The real world\nproblems we explore include gendered classification bias and Cambridge\nAnalytica's use of psychographic models.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08718v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08717v3",
    "title": "Self-supervised Multi-view Person Association and Its Applications",
    "authors": [
      "Minh Vo",
      "Ersin Yumer",
      "Kalyan Sunkavalli",
      "Sunil Hadap",
      "Yaser Sheikh",
      "Srinivasa Narasimhan"
    ],
    "author_ids": [],
    "abstract": "Reliable markerless motion tracking of people participating in a complex\ngroup activity from multiple moving cameras is challenging due to frequent\nocclusions, strong viewpoint and appearance variations, and asynchronous video\nstreams. To solve this problem, reliable association of the same person across\ndistant viewpoints and temporal instances is essential. We present a\nself-supervised framework to adapt a generic person appearance descriptor to\nthe unlabeled videos by exploiting motion tracking, mutual exclusion\nconstraints, and multi-view geometry. The adapted discriminative descriptor is\nused in a tracking-by-clustering formulation. We validate the effectiveness of\nour descriptor learning on WILDTRACK [14] and three new complex social scenes\ncaptured by multiple cameras with up to 60 people \"in the wild\". We report\nsignificant improvement in association accuracy (up to 18%) and stable and\ncoherent 3D human skeleton tracking (5 to 10 times) over the baseline. Using\nthe reconstructed 3D skeletons, we cut the input videos into a multi-angle\nvideo where the image of a specified person is shown from the best visible\nfront-facing camera. Our algorithm detects inter-human occlusion to determine\nthe camera switching moment while still maintaining the flow of the action\nwell.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08717v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.08716v5",
    "title": "Reducing Disparate Exposure in Ranking: A Learning To Rank Approach",
    "authors": [
      "Meike Zehlike",
      "Carlos Castillo"
    ],
    "author_ids": [],
    "abstract": "Ranked search results have become the main mechanism by which we find\ncontent, products, places, and people online. Thus their ordering contributes\nnot only to the satisfaction of the searcher, but also to career and business\nopportunities, educational placement, and even social success of those being\nranked. Researchers have become increasingly concerned with systematic biases\nin data-driven ranking models, and various post-processing methods have been\nproposed to mitigate discrimination and inequality of opportunity. This\napproach, however, has the disadvantage that it still allows an unfair ranking\nmodel to be trained. In this paper we explore a new in-processing approach:\nDELTR, a learning-to-rank framework that addresses potential issues of\ndiscrimination and unequal opportunity in rankings at training time. We measure\nthese problems in terms of discrepancies in the average group exposure and\ndesign a ranker that optimizes search results in terms of relevance and in\nterms of reducing such discrepancies. We perform an extensive experimental\nstudy showing that being \"colorblind\" can be among the best or the worst\nchoices from the perspective of relevance and exposure, depending on how much\nand which kind of bias is present in the training set. We show that our\nin-processing method performs better in terms of relevance and exposure than a\npre-processing and a post-processing method across all tested scenarios.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CY",
      "H.3.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08716v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1806.01919v5",
    "title": "Intuitive Analyses via Drift Theory",
    "authors": [
      "Andreas Göbel",
      "Timo Kötzing",
      "Martin S. Krejca"
    ],
    "author_ids": [],
    "abstract": "Drift theory is an intuitive tool for reasoning about random processes: It\nallows turning expected stepwise changes into expected first-hitting times.\nWhile drift theory is used extensively by the community studying randomized\nsearch heuristics, it has seen hardly any applications outside of this field,\nin spite of many research questions that can be formulated as first-hitting\ntimes.\n  We state the most useful drift theorems and demonstrate their use for various\nrandomized processes, including the coupon collector process, winning streaks,\napproximating vertex cover, and a random sorting algorithm. We also consider\nprocesses without expected stepwise change and give theorems based on drift\ntheory applicable in such scenarios. We use these theorems for the analysis of\nthe gambler's ruin process, for a coloring algorithm, for an algorithm for\n2-SAT, and for a version of the Moran process without bias. A final tool we\npresent is a tight theorem for processes on finite state spaces, which we apply\nto the Moran process.\n  We aim to enable the reader to apply drift theory in their own research to\nderive accessible proofs and to teach it as a simple tool for the analysis of\nrandom processes.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "math.PR",
      "cs.DM",
      "F.2.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.01919v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08654v1",
    "title": "Universal discriminative quantum neural networks",
    "authors": [
      "Hongxiang Chen",
      "Leonard Wossnig",
      "Simone Severini",
      "Hartmut Neven",
      "Masoud Mohseni"
    ],
    "author_ids": [],
    "abstract": "Quantum mechanics fundamentally forbids deterministic discrimination of\nquantum states and processes. However, the ability to optimally distinguish\nvarious classes of quantum data is an important primitive in quantum\ninformation science. In this work, we train near-term quantum circuits to\nclassify data represented by non-orthogonal quantum probability distributions\nusing the Adam stochastic optimization algorithm. This is achieved by iterative\ninteractions of a classical device with a quantum processor to discover the\nparameters of an unknown non-unitary quantum circuit. This circuit learns to\nsimulates the unknown structure of a generalized quantum measurement, or\nPositive-Operator-Value-Measure (POVM), that is required to optimally\ndistinguish possible distributions of quantum inputs. Notably we use universal\ncircuit topologies, with a theoretically motivated circuit design, which\nguarantees that our circuits can in principle learn to perform arbitrary\ninput-output mappings. Our numerical simulations show that shallow quantum\ncircuits could be trained to discriminate among various pure and mixed quantum\nstates exhibiting a trade-off between minimizing erroneous and inconclusive\noutcomes with comparable performance to theoretically optimal POVMs. We train\nthe circuit on different classes of quantum data and evaluate the\ngeneralization error on unseen mixed quantum states. This generalization power\nhence distinguishes our work from standard circuit optimization and provides an\nexample of quantum machine learning for a task that has inherently no classical\nanalogue.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.NE",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08654v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.08522v5",
    "title": "Deep learning generalizes because the parameter-function map is biased towards simple functions",
    "authors": [
      "Guillermo Valle-Pérez",
      "Chico Q. Camargo",
      "Ard A. Louis"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08522v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.08429v3",
    "title": "Correctness and Fairness of Tendermint-core Blockchains",
    "authors": [
      "Yackolley Amoussou-Guenou",
      "Antonella Del Pozzo",
      "Maria Potop-Butucaru",
      "Sara Tucci-Piergiovanni"
    ],
    "author_ids": [],
    "abstract": "Tendermint-core blockchains (e.g. Cosmos) are considered today one of the\nmost viable alternatives for the highly energy consuming proof-of-work\nblockchains such as Bitcoin and Ethereum. Their particularity is that they aim\nat offering strong consistency (no forks) in an open system combining two\ningredients (i) a set of validators that generate blocks via a variant of\nPractical Byzantine Fault Tolerant (PBFT) consensus protocol and (ii) a\nselection strategy that dynamically selects nodes to be validators for the next\nblock via a proof-of-stake mechanism. However,the exact assumptions on the\nsystem model under which Tendermint underlying algorithms are correct and the\nexact properties Tendermint verifies have never been formally analyzed. The\ncontribution of this paper is two-fold. First, while formalizing Tendermint\nalgorithms we precisely characterize the system model and the exact problem\nsolved by Tendermint. We prove that in eventual synchronous systems a modified\nversion of Tendermint solves (i) under additional assumptions, a variant of\none-shot consensus for the validation of one single block and (ii) a variant of\nthe repeated consensus problem for multiple blocks. These results hold even if\nthe set of validators is hit by Byzantine failures, provided that for each\none-shot consensus instance less than one third of the validators is Byzantine.\nOur second contribution relates to the fairness of the rewarding mechanism. It\nis common knowledge that in permisionless blockchain systems the main threat is\nthe tragedy of commons that may yield the system to collapse if the rewarding\nmechanism is not adequate. Ad minimum the rewarding mechanism must be fair,\ni.e.distributing the rewards in proportion to the merit of participants. We\nprove, for the first time in blockchain systems, that in repeated-consensus\nbased blockchains there exists an (eventual) fair rewarding mechanism if and\nonly if the system is (eventual) synchronous. We also show that the original\nTendermint rewarding is not fair, however, a modification of the original\nprotocol makes it eventually fair.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DC",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08429v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08347v3",
    "title": "How To Solve Moral Conundrums with Computability Theory",
    "authors": [
      "Min Baek"
    ],
    "author_ids": [],
    "abstract": "Various moral conundrums plague population ethics: the Non-Identity Problem,\nthe Procreation Asymmetry, the Repugnant Conclusion, and more. I argue that the\naforementioned moral conundrums have a structure neatly accounted for, and\nsolved by, some ideas in computability theory. I introduce a mathematical model\nbased on computability theory and show how previous arguments pertaining to\nthese conundrums fit into the model. This paper proceeds as follows. First, I\ndo a very brief survey of the history of computability theory in moral\nphilosophy. Second, I follow various papers, and show how their arguments fit\ninto, or don't fit into, our model. Third, I discuss the implications of our\nmodel to the question why the human race should or should not continue to\nexist. Finally, I show that our model may be interpreted according to a\nConfucian-Taoist moral principle.",
    "published_date": "2018-05-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08347v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.08206v4",
    "title": "Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers",
    "authors": [
      "Yonatan Geifman",
      "Guy Uziel",
      "Ran El-Yaniv"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of uncertainty estimation in the context of\n(non-Bayesian) deep neural classification. In this context, all known methods\nare based on extracting uncertainty signals from a trained network optimized to\nsolve the classification problem at hand. We demonstrate that such techniques\ntend to introduce biased estimates for instances whose predictions are supposed\nto be highly confident. We argue that this deficiency is an artifact of the\ndynamics of training with SGD-like optimizers, and it has some properties\nsimilar to overfitting. Based on this observation, we develop an uncertainty\nestimation algorithm that selectively estimates the uncertainty of highly\nconfident points, using earlier snapshots of the trained model, before their\nestimates are jittered (and way before they are ready for actual\nclassification). We present extensive experiments indicating that the proposed\nalgorithm provides uncertainty estimates that are consistently better than all\nknown methods.",
    "published_date": "2018-05-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08206v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.08125v4",
    "title": "A Marketplace for Data: An Algorithmic Solution",
    "authors": [
      "Anish Agarwal",
      "Munther Dahleh",
      "Tuhin Sarkar"
    ],
    "author_ids": [],
    "abstract": "In this work, we aim to design a data marketplace; a robust real-time\nmatching mechanism to efficiently buy and sell training data for Machine\nLearning tasks. While the monetization of data and pre-trained models is an\nessential focus of industry today, there does not exist a market mechanism to\nprice training data and match buyers to sellers while still addressing the\nassociated (computational and other) complexity. The challenge in creating such\na market stems from the very nature of data as an asset: (i) it is freely\nreplicable; (ii) its value is inherently combinatorial due to correlation with\nsignal in other data; (iii) prediction tasks and the value of accuracy vary\nwidely; (iv) usefulness of training data is difficult to verify a priori\nwithout first applying it to a prediction task. As our main contributions we:\n(i) propose a mathematical model for a two-sided data market and formally\ndefine the key associated challenges; (ii) construct algorithms for such a\nmarket to function and analyze how they meet the challenges defined. We\nhighlight two technical contributions: (i) a new notion of 'fairness' required\nfor cooperative games with freely replicable goods; (ii) a truthful, zero\nregret mechanism to auction a class of combinatorial goods based on utilizing\nMyerson's payment function and the Multiplicative Weights algorithm. These\nmight be of independent interest.",
    "published_date": "2018-05-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08125v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.08006v2",
    "title": "Bidirectional Learning for Robust Neural Networks",
    "authors": [
      "Sidney Pontes-Filho",
      "Marcus Liwicki"
    ],
    "author_ids": [],
    "abstract": "A multilayer perceptron can behave as a generative classifier by applying\nbidirectional learning (BL). It consists of training an undirected neural\nnetwork to map input to output and vice-versa; therefore it can produce a\nclassifier in one direction, and a generator in the opposite direction for the\nsame data. The learning process of BL tries to reproduce the neuroplasticity\nstated in Hebbian theory using only backward propagation of errors. In this\npaper, two novel learning techniques are introduced which use BL for improving\nrobustness to white noise static and adversarial examples. The first method is\nbidirectional propagation of errors, which the error propagation occurs in\nbackward and forward directions. Motivated by the fact that its generative\nmodel receives as input a constant vector per class, we introduce as a second\nmethod the hybrid adversarial networks (HAN). Its generative model receives a\nrandom vector as input and its training is based on generative adversarial\nnetworks (GAN). To assess the performance of BL, we perform experiments using\nseveral architectures with fully and convolutional layers, with and without\nbias. Experimental results show that both methods improve robustness to white\nnoise static and adversarial examples, and even increase accuracy, but have\ndifferent behavior depending on the architecture and task, being more\nbeneficial to use the one or the other. Nevertheless, HAN using a convolutional\narchitecture with batch normalization presents outstanding robustness, reaching\nstate-of-the-art accuracy on adversarial examples of hand-written digits.",
    "published_date": "2018-05-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08006v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.07797v1",
    "title": "One Formalization of Virtue Ethics via Learning",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringjsord",
      "Rikhiya Ghosh"
    ],
    "author_ids": [],
    "abstract": "Given that there exist many different formal and precise treatments of\ndeontologi- cal and consequentialist ethics, we turn to virtue ethics and\nconsider what could be a formalization of virtue ethics that makes it amenable\nto automation. We present an embroyonic formalization in a cognitive calculus\n(which subsumes a quantified first-order logic) that has been previously used\nto model robust ethical principles, in both the deontological and\nconsequentialist traditions.",
    "published_date": "2018-05-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.07797v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.07667v1",
    "title": "The anatomy of a Web of Trust: the Bitcoin-OTC market",
    "authors": [
      "Ilaria Bertazzi",
      "Sylvie Huet",
      "Guillaume Deffuant",
      "Floriana Gargiulo"
    ],
    "author_ids": [],
    "abstract": "Bitcoin-otc is a peer to peer (over-the-counter) marketplace for trading with\nbit- coin crypto-currency. To mitigate the risks of the p2p unsupervised\nexchanges, the establishment of a reliable reputation systems is needed: for\nthis reason, a web of trust is implemented on the website. The availability of\nall the historic of the users interaction data makes this dataset a unique\nplayground for studying reputation dynamics through others evaluations. We\nanalyze the structure and the dynamics of this web of trust with a multilayer\nnetwork approach distin- guishing the rewarding and the punitive behaviors. We\nshow that the rewarding and the punitive behavior have similar emergent\ntopological properties (apart from the clustering coefficient being higher for\nthe rewarding layer) and that the resultant reputation originates from the\ncomplex interaction of the more regular behaviors on the layers. We show which\nare the behaviors that correlate (i.e. the rewarding activity) or not (i.e. the\npunitive activity) with reputation. We show that the network activity presents\nbursty behaviors on both the layers and that the inequality reaches a steady\nvalue (higher for the rewarding layer) with the network evolution. Finally, we\ncharacterize the reputation trajectories and we identify prototypical behaviors\nassociated to three classes of users: trustworthy, untrusted and controversial.",
    "published_date": "2018-05-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.07667v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.07647v1",
    "title": "Learning Hierarchical Visual Representations in Deep Neural Networks Using Hierarchical Linguistic Labels",
    "authors": [
      "Joshua C. Peterson",
      "Paul Soulos",
      "Aida Nematzadeh",
      "Thomas L. Griffiths"
    ],
    "author_ids": [],
    "abstract": "Modern convolutional neural networks (CNNs) are able to achieve human-level\nobject classification accuracy on specific tasks, and currently outperform\ncompeting models in explaining complex human visual representations. However,\nthe categorization problem is posed differently for these networks than for\nhumans: the accuracy of these networks is evaluated by their ability to\nidentify single labels assigned to each image. These labels often cut\narbitrarily across natural psychological taxonomies (e.g., dogs are separated\ninto breeds, but never jointly categorized as \"dogs\"), and bias the resulting\nrepresentations. By contrast, it is common for children to hear both \"dog\" and\n\"Dalmatian\" to describe the same stimulus, helping to group perceptually\ndisparate objects (e.g., breeds) into a common mental class. In this work, we\ntrain CNN classifiers with multiple labels for each image that correspond to\ndifferent levels of abstraction, and use this framework to reproduce classic\npatterns that appear in human generalization behavior.",
    "published_date": "2018-05-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.07647v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.07123v1",
    "title": "Tree Edit Distance Learning via Adaptive Symbol Embeddings: Supplementary Materials and Results",
    "authors": [
      "Benjamin Paaßen"
    ],
    "author_ids": [],
    "abstract": "Metric learning has the aim to improve classification accuracy by learning a\ndistance measure which brings data points from the same class closer together\nand pushes data points from different classes further apart. Recent research\nhas demonstrated that metric learning approaches can also be applied to trees,\nsuch as molecular structures, abstract syntax trees of computer programs, or\nsyntax trees of natural language, by learning the cost function of an edit\ndistance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.\nHowever, learning such costs directly may yield an edit distance which violates\nmetric axioms, is challenging to interpret, and may not generalize well. In\nthis contribution, we propose a novel metric learning approach for trees which\nlearns an edit distance indirectly by embedding the tree nodes as vectors, such\nthat the Euclidean distance between those vectors supports class\ndiscrimination. We learn such embeddings by reducing the distance to\nprototypical trees from the same class and increasing the distance to\nprototypical trees from different classes. In our experiments, we show that our\nproposed metric learning approach improves upon the state-of-the-art in metric\nlearning for trees on six benchmark data sets, ranging from computer science\nover biomedical data to a natural-language processing data set containing over\n300,000 nodes.",
    "published_date": "2018-05-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.07123v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.07051v2",
    "title": "Bayesian Joint Spike-and-Slab Graphical Lasso",
    "authors": [
      "Zehang Richard Li",
      "Tyler H. McCormick",
      "Samuel J. Clark"
    ],
    "author_ids": [],
    "abstract": "In this article, we propose a new class of priors for Bayesian inference with\nmultiple Gaussian graphical models. We introduce fully Bayesian treatments of\ntwo popular procedures, the group graphical lasso and the fused graphical\nlasso, and extend them to a continuous spike-and-slab framework to allow\nself-adaptive shrinkage and model selection simultaneously. We develop an EM\nalgorithm that performs fast and dynamic explorations of posterior modes. Our\napproach selects sparse models efficiently with substantially smaller bias than\nwould be induced by alternative regularization procedures. The performance of\nthe proposed methods are demonstrated through simulation and two real data\nexamples.",
    "published_date": "2018-05-18T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.07051v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06939v2",
    "title": "Event2Mind: Commonsense Inference on Events, Intents, and Reactions",
    "authors": [
      "Hannah Rashkin",
      "Maarten Sap",
      "Emily Allaway",
      "Noah A. Smith",
      "Yejin Choi"
    ],
    "author_ids": [],
    "abstract": "We investigate a new commonsense inference task: given an event described in\na short free-form text (\"X drinks coffee in the morning\"), a system reasons\nabout the likely intents (\"X wants to stay awake\") and reactions (\"X feels\nalert\") of the event's participants. To support this study, we construct a new\ncrowdsourced corpus of 25,000 event phrases covering a diverse range of\neveryday events and situations. We report baseline performance on this task,\ndemonstrating that neural encoder-decoder models can successfully compose\nembedding representations of previously unseen events and reason about the\nlikely intents and reactions of the event participants. In addition, we\ndemonstrate how commonsense inference on people's intents and reactions can\nhelp unveil the implicit gender inequality prevalent in modern movie scripts.",
    "published_date": "2018-05-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06939v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06693v1",
    "title": "Hierarchical Beamforming: Resource Allocation, Fairness and Flow Level Performance",
    "authors": [
      "Julien Floquet",
      "Richard Combes",
      "Zwi Altman"
    ],
    "author_ids": [],
    "abstract": "We consider hierarchical beamforming in wireless networks. For a given\npopulation of flows, we propose computationally efficient algorithms for fair\nrate allocation including proportional fairness and max-min fairness. We next\npropose closed-form formulas for flow level performance, for both elastic (with\neither proportional fairness and max-min fairness) and streaming traffic. We\nfurther assess the performance of hierarchical beamforming using numerical\nexperiments. Since the proposed solutions have low complexity compared to\nconventional beamforming, our work suggests that hierarchical beamforming is a\npromising candidate for the implementation of beamforming in future cellular\nnetworks.",
    "published_date": "2018-05-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI",
      "cs.IT",
      "cs.PF",
      "cs.SY",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06693v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.06670v1",
    "title": "Show me the Cache: Optimizing Cache-Friendly Recommendations for Sequential Content Access",
    "authors": [
      "Theodoros Giannakas",
      "Pavlos Sermpezis",
      "Thrasyvoulos Spyropoulos"
    ],
    "author_ids": [],
    "abstract": "Caching has been successfully applied in wired networks, in the context of\nContent Distribution Networks (CDNs), and is quickly gaining ground for\nwireless systems. Storing popular content at the edge of the network (e.g. at\nsmall cells) is seen as a `win-win' for both the user (reduced access latency)\nand the operator (reduced load on the transport network and core servers).\nNevertheless, the much smaller size of such edge caches, and the volatility of\nuser preferences suggest that standard caching methods do not suffice in this\ncontext. What is more, simple popularity-based models commonly used (e.g. IRM)\nare becoming outdated, as users often consume multiple contents in sequence\n(e.g. YouTube, Spotify), and this consumption is driven by recommendation\nsystems. The latter presents a great opportunity to bias the recommender to\nminimize content access cost (e.g. maximizing cache hit rates). To this end, in\nthis paper we first propose a Markovian model for recommendation-driven user\nrequests. We then formulate the problem of biasing the recommendation algorithm\nto minimize access cost, while maintaining acceptable recommendation quality.\nWe show that the problem is non-convex, and propose an iterative ADMM-based\nalgorithm that outperforms existing schemes, and shows significant potential\nfor performance improvement on real content datasets.",
    "published_date": "2018-05-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06670v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.06627v1",
    "title": "Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures",
    "authors": [
      "Luke Vilnis",
      "Xiang Li",
      "Shikhar Murty",
      "Andrew McCallum"
    ],
    "author_ids": [],
    "abstract": "Embedding methods which enforce a partial order or lattice structure over the\nconcept space, such as Order Embeddings (OE) (Vendrov et al., 2016), are a\nnatural way to model transitive relational data (e.g. entailment graphs).\nHowever, OE learns a deterministic knowledge base, limiting expressiveness of\nqueries and the ability to use uncertainty for both prediction and learning\n(e.g. learning from expectations). Probabilistic extensions of OE (Lai and\nHockenmaier, 2017) have provided the ability to somewhat calibrate these\ndenotational probabilities while retaining the consistency and inductive bias\nof ordered models, but lack the ability to model the negative correlations\nfound in real-world knowledge. In this work we show that a broad class of\nmodels that assign probability measures to OE can never capture negative\ncorrelation, which motivates our construction of a novel box lattice and\naccompanying probability measure to capture anticorrelation and even disjoint\nconcepts, while still providing the benefits of probabilistic modeling, such as\nthe ability to perform rich joint and conditional queries over arbitrary sets\nof concepts, and both learning from and predicting calibrated uncertainty. We\nshow improvements over previous approaches in modeling the Flickr and WordNet\nentailment graphs, and investigate the power of the model.",
    "published_date": "2018-05-17T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06627v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06618v1",
    "title": "Optimization of Transfer Learning for Sign Language Recognition Targeting Mobile Platform",
    "authors": [
      "Dhruv Rathi"
    ],
    "author_ids": [],
    "abstract": "The target of this research is to experiment, iterate and recommend a system\nthat is successful in recognition of American Sign Language (ASL). It is a\nchallenging as well as an interesting problem that if solved will bring a leap\nin social and technological aspects alike. In this paper, we propose a\nreal-time recognizer of ASL based on a mobile platform, so that it will have\nmore accessibility and provides an ease of use. The technique implemented is\nTransfer Learning of new data of Hand gestures for alphabets in ASL to be\nmodelled on various pre-trained high- end models and optimize the best model to\nrun on a mobile platform considering the various limitations of the same during\noptimization. The data used consists of 27,455 images of 24 alphabets of ASL.\nThe optimized model when ran over a memory-efficient mobile application,\nprovides an accuracy of 95.03% of accurate recognition with an average\nrecognition time of 2.42 seconds. This method ensures considerable\ndiscrimination in accuracy and recognition time than the previous research.",
    "published_date": "2018-05-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06618v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06549v1",
    "title": "Defoiling Foiled Image Captions",
    "authors": [
      "Pranava Madhyastha",
      "Josiah Wang",
      "Lucia Specia"
    ],
    "author_ids": [],
    "abstract": "We address the task of detecting foiled image captions, i.e. identifying\nwhether a caption contains a word that has been deliberately replaced by a\nsemantically similar word, thus rendering it inaccurate with respect to the\nimage being described. Solving this problem should in principle require a\nfine-grained understanding of images to detect linguistically valid\nperturbations in captions. In such contexts, encoding sufficiently descriptive\nimage information becomes a key challenge. In this paper, we demonstrate that\nit is possible to solve this task using simple, interpretable yet powerful\nrepresentations based on explicit object information. Our models achieve\nstate-of-the-art performance on a standard dataset, with scores exceeding those\nachieved by humans on the task. We also measure the upper-bound performance of\nour models using gold standard annotations. Our analysis reveals that the\nsimpler model performs well even without image information, suggesting that the\ndataset contains strong linguistic bias.",
    "published_date": "2018-05-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06549v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06248v3",
    "title": "Modeling Human Inference of Others' Intentions in Complex Situations with Plan Predictability Bias",
    "authors": [
      "Ryo Nakahashi",
      "Seiji Yamada"
    ],
    "author_ids": [],
    "abstract": "A recent approach based on Bayesian inverse planning for the \"theory of mind\"\nhas shown good performance in modeling human cognition. However, perfect\ninverse planning differs from human cognition during one kind of complex tasks\ndue to human bounded rationality. One example is an environment in which there\nare many available plans for achieving a specific goal. We propose a \"plan\npredictability oriented model\" as a model of inferring other peoples' goals in\ncomplex environments. This model adds the bias that people prefer predictable\nplans. This bias is calculated with simple plan prediction. We tested this\nmodel with a behavioral experiment in which humans observed the partial path of\ngoal-directed actions. Our model had a higher correlation with human inference.\nWe also confirmed the robustness of our model with complex tasks and determined\nthat it can be improved by taking account of individual differences in \"bounded\nrationality\".",
    "published_date": "2018-05-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06248v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06232v5",
    "title": "On Fair Division of Indivisible Items",
    "authors": [
      "Bhaskar Chaudhury",
      "Yun Kuen Cheung",
      "Jugal Garg",
      "Naveen Garg",
      "Martin Hoefer",
      "Kurt Mehlhorn"
    ],
    "author_ids": [],
    "abstract": "We consider the task of assigning indivisible goods to a set of agents in a\nfair manner. Our notion of fairness is Nash social welfare, i.e., the goal is\nto maximize the geometric mean of the utilities of the agents. Each good comes\nin multiple items or copies, and the utility of an agent diminishes as it\nreceives more items of the same good. The utility of a bundle of items for an\nagent is the sum of the utilities of the items in the bundle. Each agent has a\nutility cap beyond which he does not value additional items. We give a\npolynomial time approximation algorithm that maximizes Nash social welfare up\nto a factor of $e^{1/{e}} \\approx 1.445$. The computed allocation is\nPareto-optimal and approximates envy-freeness up to one item up to a factor of\n$2 + \\eps$",
    "published_date": "2018-05-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06232v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.06230v1",
    "title": "Towards Explaining Anomalies: A Deep Taylor Decomposition of One-Class Models",
    "authors": [
      "Jacob Kauffmann",
      "Klaus-Robert Müller",
      "Grégoire Montavon"
    ],
    "author_ids": [],
    "abstract": "A common machine learning task is to discriminate between normal and\nanomalous data points. In practice, it is not always sufficient to reach high\naccuracy at this task, one also would like to understand why a given data point\nhas been predicted in a certain way. We present a new principled approach for\none-class SVMs that decomposes outlier predictions in terms of input variables.\nThe method first recomposes the one-class model as a neural network with\ndistance functions and min-pooling, and then performs a deep Taylor\ndecomposition (DTD) of the model output. The proposed One-Class DTD is\napplicable to a number of common distance-based SVM kernels and is able to\nreliably explain a wide set of data anomalies. Furthermore, it outperforms\nbaselines such as sensitivity analysis, nearest neighbor, or simple edge\ndetection.",
    "published_date": "2018-05-16T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06230v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.06158v1",
    "title": "Investigating the Agility Bias in DNS Graph Mining",
    "authors": [
      "Jukka Ruohonen",
      "Ville Leppänen"
    ],
    "author_ids": [],
    "abstract": "The concept of agile domain name system (DNS) refers to dynamic and rapidly\nchanging mappings between domain names and their Internet protocol (IP)\naddresses. This empirical paper evaluates the bias from this kind of agility\nfor DNS-based graph theoretical data mining applications. By building on two\nconventional metrics for observing malicious DNS agility, the agility bias is\nobserved by comparing bipartite DNS graphs to different subgraphs from which\nvertices and edges are removed according to two criteria. According to an\nempirical experiment with two longitudinal DNS datasets, irrespective of the\ncriterion, the agility bias is observed to be severe particularly regarding the\neffect of outlying domains hosted and delivered via content delivery networks\nand cloud computing services. With these observations, the paper contributes to\nthe research domains of cyber security and DNS mining. In a larger context of\napplied graph mining, the paper further elaborates the practical concerns\nrelated to the learning of large and dynamic bipartite graphs.",
    "published_date": "2018-05-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.NI",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.06158v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05939v1",
    "title": "An Exploration of Verbatim Content Republishing by News Producers",
    "authors": [
      "Benjamin D. Horne",
      "Sibel Adali"
    ],
    "author_ids": [],
    "abstract": "In today's news ecosystem, news sources emerge frequently and can vary widely\nin intent. This intent can range from benign to malicious, with many tactics\nbeing used to achieve their goals. One lesser studied tactic is content\nrepublishing, which can be used to make specific stories seem more important,\ncreate uncertainty around an event, or create a perception of credibility for\nunreliable news sources. In this paper, we take a first step in understanding\nthis tactic by exploring verbatim content copying across 92 news producers of\nvarious characteristics. We find that content copying occurs more frequently\nbetween like-audience sources (eg. alternative news, mainstream news, etc.),\nbut there consistently exists sparse connections between these communities. We\nalso find that despite articles being verbatim, the headlines are often\nchanged. Specifically, we find that mainstream sources change more structural\nfeatures, while alternative sources change many more content features, often\nchanging the emotional tone and bias of the titles. We conclude that content\nrepublishing networks can help identify and label the intent of brand-new news\nsources using the tight-knit community they belong to. In addition, it is\npossible to use the network to find important content producers in each\ncommunity, producers that are used to amplify messages of other sources, and\nproducers that distort the messages of other sources.",
    "published_date": "2018-05-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05939v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05926v1",
    "title": "Predictable Performance and Fairness Through Accurate Slowdown Estimation in Shared Main Memory Systems",
    "authors": [
      "Lavanya Subramanian",
      "Vivek Seshadri",
      "Yoongu Kim",
      "Ben Jaiyen",
      "Onur Mutlu"
    ],
    "author_ids": [],
    "abstract": "This paper summarizes the ideas and key concepts in MISE (Memory\nInterference-induced Slowdown Estimation), which was published in HPCA 2013\n[97], and examines the work's significance and future potential. Applications\nrunning concurrently on a multicore system interfere with each other at the\nmain memory. This interference can slow down different applications\ndifferently. Accurately estimating the slowdown of each application in such a\nsystem can enable mechanisms that can enforce quality-of-service. While much\nprior work has focused on mitigating the performance degradation due to\ninter-application interference, there is little work on accurately estimating\nslowdown of individual applications in a multi-programmed environment. Our goal\nis to accurately estimate application slowdowns, towards providing predictable\nperformance.\n  To this end, we first build a simple Memory Interference-induced Slowdown\nEstimation (MISE) model, which accurately estimates slowdowns caused by memory\ninterference. We then leverage our MISE model to develop two new memory\nscheduling schemes: 1) one that provides soft quality-of-service guarantees,\nand 2) another that explicitly attempts to minimize maximum slowdown (i.e.,\nunfairness) in the system. Evaluations show that our techniques perform\nsignificantly better than state-of-the-art memory scheduling approaches to\naddress the same problems.\n  Our proposed model and techniques have enabled significant research in the\ndevelopment of accurate performance models [35, 59, 98, 110] and interference\nmanagement mechanisms [66, 99, 100, 108, 119, 120].",
    "published_date": "2018-05-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05926v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05859v1",
    "title": "Causal Reasoning for Algorithmic Fairness",
    "authors": [
      "Joshua R. Loftus",
      "Chris Russell",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "author_ids": [],
    "abstract": "In this work, we argue for the importance of causal reasoning in creating\nfair algorithms for decision making. We give a review of existing approaches to\nfairness, describe work in causality necessary for the understanding of causal\napproaches, argue why causality is necessary for any approach that wishes to be\nfair, and give a detailed analysis of the many recent approaches to\ncausality-based fairness.",
    "published_date": "2018-05-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05859v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.09139v1",
    "title": "Demographic differences in search engine use with implications for cohort selection",
    "authors": [
      "Elad Yom-Tov"
    ],
    "author_ids": [],
    "abstract": "The correlation between the demographics of users and the text they write has\nbeen investigated through literary texts and, more recently, social media.\nHowever, differences pertaining to language use in search engines has not been\nthoroughly analyzed, especially for age and gender differences. Such\ndifferences are important especially due to the growing use of search engine\ndata in the study of human health, where queries are used to identify patient\npopulations.\n  Using data from multiple general-purpose Internet search engines gathered\nover a period of one month we investigate the correlation between demography\n(age, gender, and income) and the text of queries submitted to search engines.\n  Our results show that females and younger people use longer queries. This\ndifference is such that females make approximately 25% more queries with 10 or\nmore words. In the case of queries which identify users as having specific\nmedical conditions we find that females make 50% more queries than expected,\nand that this results in patient cohorts which are highly skewed in gender and\nage, compared to known gender balance.\n  Our results indicate that studies where demographic representation is\nimportant, such as in the study of health aspect of users or when search\nengines are evaluated for fairness, care should be taken in the selection of\nsearch engine data so as to create a representative dataset.",
    "published_date": "2018-05-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.09139v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05135v2",
    "title": "A Note on Reverse Pinsker Inequalities",
    "authors": [
      "Olivier Binette"
    ],
    "author_ids": [],
    "abstract": "A simple method is shown to provide optimal variational bounds on\n$f$-divergences with possible constraints on relative information extremums.\nKnown results are refined or proved to be optimal as particular cases.",
    "published_date": "2018-05-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05135v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05009v1",
    "title": "Deep Decision Trees for Discriminative Dictionary Learning with Adversarial Multi-Agent Trajectories",
    "authors": [
      "Tharindu Fernando",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Simon Denman"
    ],
    "author_ids": [],
    "abstract": "With the explosion in the availability of spatio-temporal tracking data in\nmodern sports, there is an enormous opportunity to better analyse, learn and\npredict important events in adversarial group environments. In this paper, we\npropose a deep decision tree architecture for discriminative dictionary\nlearning from adversarial multi-agent trajectories. We first build up a\nhierarchy for the tree structure by adding each layer and performing feature\nweight based clustering in the forward pass. We then fine tune the player role\nweights using back propagation. The hierarchical architecture ensures the\ninterpretability and the integrity of the group representation. The resulting\narchitecture is a decision tree, with leaf-nodes capturing a dictionary of\nmulti-agent group interactions. Due to the ample volume of data available, we\nfocus on soccer tracking data, although our approach can be used in any\nadversarial multi-agent domain. We present applications of proposed method for\nsimulating soccer games as well as evaluating and quantifying team strategies.",
    "published_date": "2018-05-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05009v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.04924v2",
    "title": "Emergence and Evolution of Hierarchical Structure in Complex Systems",
    "authors": [
      "Payam Siyari",
      "Bistra Dilkina",
      "Constantine Dovrolis"
    ],
    "author_ids": [],
    "abstract": "It is well known that many complex systems, both in technology and nature,\nexhibit hierarchical modularity: smaller modules, each of them providing a\ncertain function, are used within larger modules that perform more complex\nfunctions. What is not well understood however is how this hierarchical\nstructure (which is fundamentally a network property) emerges, and how it\nevolves over time. We propose a modeling framework, referred to as Evo-Lexis,\nthat provides insight to some fundamental questions about evolving hierarchical\nsystems. Evo-Lexis models the most elementary modules of the system as symbols\n(\"sources\") and the modules at the highest level of the hierarchy as sequences\nof those symbols (\"targets\"). Evo-Lexis computes the optimized adjustment of a\ngiven hierarchy when the set of targets changes over time by additions and\nremovals (a process referred to as \"incremental design\"). In this paper we use\ncomputation modeling to show that:\n  - Low-cost and deep hierarchies emerge when the population of target\nsequences evolves through tinkering and mutation. - Strong selection on the\ncost of new candidate targets results in reuse of more complex (longer) nodes\nin an optimized hierarchy. - The bias towards reuse of complex nodes results in\nan \"hourglass architecture\" (i.e., few intermediate nodes that cover almost all\nsource-target paths). - With such bias, the core nodes are conserved for\nrelatively long time periods although still being vulnerable to major\ntransitions and punctuated equilibria. - Finally, we analyze the differences in\nterms of cost and structure between incrementally designed hierarchies and the\ncorresponding \"clean-slate\" hierarchies which result when the system is\ndesigned from scratch after a change.",
    "published_date": "2018-05-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE",
      "cs.SI",
      "stat.CO",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04924v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.04907v1",
    "title": "A Computational Framework for Modelling and Analyzing Ice Storms",
    "authors": [
      "Ranjini Swaminathan",
      "Mohan Sridharan",
      "Katharine Hayhoe"
    ],
    "author_ids": [],
    "abstract": "Ice storms are extreme weather events that can have devastating implications\nfor the sustainability of natural ecosystems as well as man made\ninfrastructure. Ice storms are caused by a complex mix of atmospheric\nconditions and are among the least understood of severe weather events. Our\nability to model ice storms and characterize storm features will go a long way\ntowards both enabling support systems that offset storm impacts and increasing\nour understanding of ice storms. In this paper, we present a holistic\ncomputational framework to answer key questions of interest about ice storms.\nWe model ice storms as a function of relevant surface and atmospheric\nvariables. We learn these models by adapting and applying supervised and\nunsupervised machine learning algorithms on data with missing or incorrect\nlabels. We also include a knowledge representation module that reasons with\ndomain knowledge to revise the output of the learned models. Our models are\ntrained using reanalysis data and historical records of storm events. We\nevaluate these models on reanalyis data as well as Global Climate Model (GCM)\ndata for historical and future climate change scenarios. Furthermore, we\ndiscuss the use of appropriate bias correction approaches to run such modeling\nframeworks with GCM data.",
    "published_date": "2018-05-13T00:00:00",
    "year": 2018,
    "categories": [
      "physics.ao-ph",
      "cs.OH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04907v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.04863v2",
    "title": "A Global, Continuous, and Exponentially Convergent Observer for Gyro Bias and Attitude of a Rigid Body",
    "authors": [
      "Dong Eui Chang",
      "Taeyoung Lee"
    ],
    "author_ids": [],
    "abstract": "We propose a 12-dimensional, global, continuous, and exponentially convergent\nobserver for gyro bias and attitude of a rigid body. Any attitude observer\ndeveloped on the special orthogonal group suffers from the topological\nrestriction that prohibits global attractivity in continuous flow. In this\npaper, the observer is designed in the set of 3 by 3 real matrices, thus making\nthe topological obstruction on the special orthogonal group irrelevant. The\nefficacy of the proposed approach against other attitude observers is\nillustrated by an indoor experiment utilizing visual landmarks.",
    "published_date": "2018-05-13T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04863v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.04754v1",
    "title": "Incremental Learning Framework Using Cloud Computing",
    "authors": [
      "Kumarjit Pathak",
      "Prabhukiran G",
      "Jitin Kapila",
      "Nikit Gawande"
    ],
    "author_ids": [],
    "abstract": "High volume of data, perceived as either challenge or opportunity. Deep\nlearning architecture demands high volume of data to effectively back propagate\nand train the weights without bias. At the same time, large volume of data\ndemands higher capacity of the machine where it could be executed seamlessly.\nBudding data scientist along with many research professionals face frequent\ndisconnection issue with cloud computing framework (working without dedicated\nconnection) due to free subscription to the platform. Similar issues also\nvisible while working on local computer where computer may run out of resource\nor power sometimes and researcher has to start training the models all over\nagain. In this paper, we intend to provide a way to resolve this issue and\nprogressively training the neural network even after having frequent\ndisconnection or resource outage without loosing much of the progress",
    "published_date": "2018-05-12T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04754v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.04508v1",
    "title": "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems",
    "authors": [
      "Svetlana Kiritchenko",
      "Saif M. Mohammad"
    ],
    "author_ids": [],
    "abstract": "Automatic machine learning systems can inadvertently accentuate and\nperpetuate inappropriate human biases. Past work on examining inappropriate\nbiases has largely focused on just individual systems. Further, there is no\nbenchmark dataset for examining inappropriate biases in systems. Here for the\nfirst time, we present the Equity Evaluation Corpus (EEC), which consists of\n8,640 English sentences carefully chosen to tease out biases towards certain\nraces and genders. We use the dataset to examine 219 automatic sentiment\nanalysis systems that took part in a recent shared task, SemEval-2018 Task 1\n'Affect in Tweets'. We find that several of the systems show statistically\nsignificant bias; that is, they consistently provide slightly higher sentiment\nintensity predictions for one race or one gender. We make the EEC freely\navailable.",
    "published_date": "2018-05-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04508v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.04457v3",
    "title": "Game Development-Based Learning Experience: Gender Differences in Game Design",
    "authors": [
      "Bernadette Spieler",
      "Wolfgang Slany"
    ],
    "author_ids": [],
    "abstract": "Learning theories emphasize the importance of intrinsic and extrinsic\nmotivators in curricula, and games are a promising way to provide both while\nconstructing the game and presenting or sharing it in public or with a\ncommunity. New technologies and the emerging mobile gaming sector further the\ncase that learning should be promoted everywhere and anytime. What seems to be\na promising opportunity for all pupils to learn coding in an entertaining way\nraises the question of whether such game based concepts also help to fix the\ngender gap of women in IT related fields. Gender differences are already\npresent in secondary schools. These are the years where first career choices\nbut also low levels of participation in technical subjects occur. To address\nthis gender bias, a goal of the European project No One Left Behind (NOLB) was\nto integrate Pocket Code, an app developed by Catrobat, a free open source\nnon-profit project at the University of Technology in Graz/Austria, into\ndifferent school subjects, thus making coding more accessible and attractive to\nfemale pupils. During the period of this project (2015-2017), teachers were\nsupported to guide their pupils in the learning processes by constructing ideas\nand realizing them through game design. For this paper an analysis of submitted\nprograms according to their game design has been performed. In detail, the\nevaluation considered formal game elements, gaming structures, and used\ngraphics, as well as Pocket Code specific aspects. The programs analysis showed\ncommonly used design patterns by genders and suggests preferred game design\ncharacteristics of female teenagers. This analysis helps to build a more\ncreative and inclusive Game Development-Based Learning (GDBL) environment that\nprovides room for self-expression and inspires by building on intrinsic and\nextrinsic motivators by constructing personal experiences.",
    "published_date": "2018-05-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04457v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.04366v2",
    "title": "Female Teenagers and Coding: Create Gender Sensitive and Creative Learning Environments",
    "authors": [
      "Bernadette Spieler",
      "Wolfgang Slany"
    ],
    "author_ids": [],
    "abstract": "The number of women in technical fields is far below the average number of\nmales, especially in developed countries. Gender differences in STEM are\nalready present in secondary schools in students aged between 12 to 15 years.\nAdolescence is a critical time for identity formation, and self-attributes are\na source for internal conflicts, especially for female teenagers. It is during\nthis intermediate female adolescence that girls begin to make critical career\nchoices, which therefore makes this a key age to reinforce them and reduce the\ngender disparities in ICT. Computational thinking skills are important from a\nphilosophical point of view, since they allow us to understand the foundations\nof rational thought in a clear, easily understandable, but also inspiring and\nchallenging way. To address the gender bias in schools, one of the goals of the\nEuropean H2020 project No One Left Behind (NOLB) included integrating Pocket\nCode, a free open source app developed by the non-profit project Catrobat, into\ndifferent school lessons. Through game design, Pocket Code allows teenage girls\nto incorporate diversity and inclusiveness, as well as the ability to reflect\ntheir cultural identity, their emotions, their likes, and their ways of\ninteracting and thinking. To evaluate the impact of the use of the app in these\ncourses, we captured the results on engaging girls in design and coding\nactivities. For this paper, the authors present the data of surveys during the\nsecond cycle of the project. With a focus on female teenagers, the results\nallow us to conclude that a suitable classroom setting is significantly more\nimportant for them than the coding tool itself.",
    "published_date": "2018-05-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04366v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.04288v2",
    "title": "Piecewise classifier mappings: Learning fine-grained learners for novel categories with few examples",
    "authors": [
      "Xiu-Shen Wei",
      "Peng Wang",
      "Lingqiao Liu",
      "Chunhua Shen",
      "Jianxin Wu"
    ],
    "author_ids": [],
    "abstract": "Humans are capable of learning a new fine-grained concept with very little\nsupervision, \\emph{e.g.}, few exemplary images for a species of bird, yet our\nbest deep learning systems need hundreds or thousands of labeled examples. In\nthis paper, we try to reduce this gap by studying the fine-grained image\nrecognition problem in a challenging few-shot learning setting, termed few-shot\nfine-grained recognition (FSFG). The task of FSFG requires the learning systems\nto build classifiers for novel fine-grained categories from few examples (only\none or less than five). To solve this problem, we propose an end-to-end\ntrainable deep network which is inspired by the state-of-the-art fine-grained\nrecognition model and is tailored for the FSFG task.\n  Specifically, our network consists of a bilinear feature learning module and\na classifier mapping module: while the former encodes the discriminative\ninformation of an exemplar image into a feature vector, the latter maps the\nintermediate feature into the decision boundary of the novel category. The key\nnovelty of our model is a \"piecewise mappings\" function in the classifier\nmapping module, which generates the decision boundary via learning a set of\nmore attainable sub-classifiers in a more parameter-economic way. We learn the\nexemplar-to-classifier mapping based on an auxiliary dataset in a meta-learning\nfashion, which is expected to be able to generalize to novel categories. By\nconducting comprehensive experiments on three fine-grained datasets, we\ndemonstrate that the proposed method achieves superior performance over the\ncompeting baselines.",
    "published_date": "2018-05-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.04288v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.03963v4",
    "title": "Monotone Learning with Rectified Wire Networks",
    "authors": [
      "Veit Elser",
      "Dan Schmidt",
      "Jonathan Yedidia"
    ],
    "author_ids": [],
    "abstract": "We introduce a new neural network model, together with a tractable and\nmonotone online learning algorithm. Our model describes feed-forward networks\nfor classification, with one output node for each class. The only nonlinear\noperation is rectification using a ReLU function with a bias. However, there is\na rectifier on every edge rather than at the nodes of the network. There are\nalso weights, but these are positive, static, and associated with the nodes.\nOur \"rectified wire\" networks are able to represent arbitrary Boolean\nfunctions. Only the bias parameters, on the edges of the network, are learned.\nAnother departure in our approach, from standard neural networks, is that the\nloss function is replaced by a constraint. This constraint is simply that the\nvalue of the output node associated with the correct class should be zero. Our\nmodel has the property that the exact norm-minimizing parameter update,\nrequired to correctly classify a training item, is the solution to a quadratic\nprogram that can be computed with a few passes through the network. We\ndemonstrate a training algorithm using this update, called sequential\ndeactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a\nnatural choice for the nodal weights, SDA has no hyperparameters other than\nthose describing the network structure. Our experiments explore behavior with\nrespect to network size and depth in a family of sparse expander networks.",
    "published_date": "2018-05-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.NE",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.03963v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.03922v1",
    "title": "Ensemble Soft-Margin Softmax Loss for Image Classification",
    "authors": [
      "Xiaobo Wang",
      "Shifeng Zhang",
      "Zhen Lei",
      "Si Liu",
      "Xiaojie Guo",
      "Stan Z. Li"
    ],
    "author_ids": [],
    "abstract": "Softmax loss is arguably one of the most popular losses to train CNN models\nfor image classification. However, recent works have exposed its limitation on\nfeature discriminability. This paper casts a new viewpoint on the weakness of\nsoftmax loss. On the one hand, the CNN features learned using the softmax loss\nare often inadequately discriminative. We hence introduce a soft-margin softmax\nfunction to explicitly encourage the discrimination between different classes.\nOn the other hand, the learned classifier of softmax loss is weak. We propose\nto assemble multiple these weak classifiers to a strong one, inspired by the\nrecognition that the diversity among weak classifiers is critical to a good\nensemble. To achieve the diversity, we adopt the Hilbert-Schmidt Independence\nCriterion (HSIC). Considering these two aspects in one framework, we design a\nnovel loss, named as Ensemble soft-Margin Softmax (EM-Softmax). Extensive\nexperiments on benchmark datasets are conducted to show the superiority of our\ndesign over the baseline softmax loss and several state-of-the-art\nalternatives.",
    "published_date": "2018-05-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.03922v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.03164v2",
    "title": "Fair Allocation of Indivisible Public Goods",
    "authors": [
      "Brandon Fain",
      "Kamesh Munagala",
      "Nisarg Shah"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of fairly allocating indivisible public goods. We\nmodel the public goods as elements with feasibility constraints on what subsets\nof elements can be chosen, and assume that agents have additive utilities\nacross elements. Our model generalizes existing frameworks such as fair public\ndecision making and participatory budgeting. We study a groupwise fairness\nnotion called the core, which generalizes well-studied notions of\nproportionality and Pareto efficiency, and requires that each subset of agents\nmust receive an outcome that is fair relative to its size.\n  In contrast to the case of divisible public goods (where fractional\nallocations are permitted), the core is not guaranteed to exist when allocating\nindivisible public goods. Our primary contributions are the notion of an\nadditive approximation to the core (with a tiny multiplicative loss), and\npolynomial time algorithms that achieve a small additive approximation, where\nthe additive factor is relative to the largest utility of an agent for an\nelement. If the feasibility constraints define a matroid, we show an additive\napproximation of 2. A similar approach yields a constant additive bound when\nthe feasibility constraints define a matching. More generally, if the\nfeasibility constraints define an arbitrary packing polytope with mild\nrestrictions, we show an additive guarantee that is logarithmic in the width of\nthe polytope. Our algorithms are based on variants of the convex program for\nmaximizing the Nash social welfare, but differ significantly from previous work\nin how it is used. Our guarantees are meaningful even when there are fewer\nelements than the number of agents. As far as we are aware, our work is the\nfirst to approximate the core in indivisible settings.",
    "published_date": "2018-05-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.CY",
      "cs.DS",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.03164v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.02982v1",
    "title": "Price-based Resource Allocation for Edge Computing: A Market Equilibrium Approach",
    "authors": [
      "Duong Tung Nguyen",
      "Long Bao Le",
      "Vijay Bhargava"
    ],
    "author_ids": [],
    "abstract": "The emerging edge computing paradigm promises to deliver superior user\nexperience and enable a wide range of Internet of Things (IoT) applications. In\nthis work, we propose a new market-based framework for efficiently allocating\nresources of heterogeneous capacity-limited edge nodes (EN) to multiple\ncompeting services at the network edge. By properly pricing the geographically\ndistributed ENs, the proposed framework generates a market equilibrium (ME)\nsolution that not only maximizes the edge computing resource utilization but\nalso allocates optimal (i.e., utility-maximizing) resource bundles to the\nservices given their budget constraints. When the utility of a service is\ndefined as the maximum revenue that the service can achieve from its resource\nallotment, the equilibrium can be computed centrally by solving the\nEisenberg-Gale (EG) convex program. drawn from the economics literature. We\nfurther show that the equilibrium allocation is Pareto-optimal and satisfies\ndesired fairness properties including sharing incentive, proportionality, and\nenvy-freeness. Also, two distributed algorithms are introduced, which\nefficiently converge to an ME. When each service aims to maximize its net\nprofit (i.e., revenue minus cost) instead of the revenue, we derive a novel\nconvex optimization problem and rigorously prove that its solution is exactly\nan ME. Extensive numerical results are presented to validate the effectiveness\nof the proposed techniques.",
    "published_date": "2018-05-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.02982v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.02087v1",
    "title": "A Constraint-Based Algorithm For Causal Discovery with Cycles, Latent Variables and Selection Bias",
    "authors": [
      "Eric V. Strobl"
    ],
    "author_ids": [],
    "abstract": "Causal processes in nature may contain cycles, and real datasets may violate\ncausal sufficiency as well as contain selection bias. No constraint-based\ncausal discovery algorithm can currently handle cycles, latent variables and\nselection bias (CLS) simultaneously. I therefore introduce an algorithm called\nCyclic Causal Inference (CCI) that makes sound inferences with a conditional\nindependence oracle under CLS, provided that we can represent the cyclic causal\nprocess as a non-recursive linear structural equation model with independent\nerrors. Empirical results show that CCI outperforms CCD in the cyclic case as\nwell as rivals FCI and RFCI in the acyclic case.",
    "published_date": "2018-05-05T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.02087v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.01978v1",
    "title": "Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination",
    "authors": [
      "Zhirong Wu",
      "Yuanjun Xiong",
      "Stella Yu",
      "Dahua Lin"
    ],
    "author_ids": [],
    "abstract": "Neural net classifiers trained on data with annotated class labels can also\ncapture apparent visual similarity among categories without being directed to\ndo so. We study whether this observation can be extended beyond the\nconventional domain of supervised learning: Can we learn a good feature\nrepresentation that captures apparent similarity among instances, instead of\nclasses, by merely asking the feature to be discriminative of individual\ninstances? We formulate this intuition as a non-parametric classification\nproblem at the instance-level, and use noise-contrastive estimation to tackle\nthe computational challenges imposed by the large number of instance classes.\nOur experimental results demonstrate that, under unsupervised learning\nsettings, our method surpasses the state-of-the-art on ImageNet classification\nby a large margin. Our method is also remarkable for consistently improving\ntest performance with more training data and better network architectures. By\nfine-tuning the learned feature, we further obtain competitive results for\nsemi-supervised learning and object detection tasks. Our non-parametric model\nis highly compact: With 128 features per image, our method requires only 600MB\nstorage for a million images, enabling fast nearest neighbour retrieval at the\nrun time.",
    "published_date": "2018-05-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01978v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.01960v1",
    "title": "Causal programming: inference with structural causal models as finding instances of a relation",
    "authors": [
      "Joshua Brulé"
    ],
    "author_ids": [],
    "abstract": "This paper proposes a causal inference relation and causal programming as\ngeneral frameworks for causal inference with structural causal models. A tuple,\n$\\langle M, I, Q, F \\rangle$, is an instance of the relation if a formula, $F$,\ncomputes a causal query, $Q$, as a function of known population probabilities,\n$I$, in every model entailed by a set of model assumptions, $M$. Many problems\nin causal inference can be viewed as the problem of enumerating instances of\nthe relation that satisfy given criteria. This unifies a number of previously\nstudied problems, including causal effect identification, causal discovery and\nrecovery from selection bias. In addition, the relation supports formalizing\nnew problems in causal inference with structural causal models, such as the\nproblem of research design. Causal programming is proposed as a further\ngeneralization of causal inference as the problem of finding optimal instances\nof the relation, with respect to a cost function.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01960v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.01817v1",
    "title": "Extreme Adaptation for Personalized Neural Machine Translation",
    "authors": [
      "Paul Michel",
      "Graham Neubig"
    ],
    "author_ids": [],
    "abstract": "Every person speaks or writes their own flavor of their native language,\ninfluenced by a number of factors: the content they tend to talk about, their\ngender, their social status, or their geographical origin.\n  When attempting to perform Machine Translation (MT), these variations have a\nsignificant effect on how the system should perform translation, but this is\nnot captured well by standard one-size-fits-all models.\n  In this paper, we propose a simple and parameter-efficient adaptation\ntechnique that only requires adapting the bias of the output softmax to each\nparticular user of the MT system, either directly or through a factored\napproximation.\n  Experiments on TED talks in three languages demonstrate improvements in\ntranslation accuracy, and better reflection of speaker traits in the target\ntext.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01817v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.01788v1",
    "title": "Equity of Attention: Amortizing Individual Fairness in Rankings",
    "authors": [
      "Asia J. Biega",
      "Krishna P. Gummadi",
      "Gerhard Weikum"
    ],
    "author_ids": [],
    "abstract": "Rankings of people and items are at the heart of selection-making,\nmatch-making, and recommender systems, ranging from employment sites to sharing\neconomy platforms. As ranking positions influence the amount of attention the\nranked subjects receive, biases in rankings can lead to unfair distribution of\nopportunities and resources, such as jobs or income.\n  This paper proposes new measures and mechanisms to quantify and mitigate\nunfairness from a bias inherent to all rankings, namely, the position bias,\nwhich leads to disproportionately less attention being paid to low-ranked\nsubjects. Our approach differs from recent fair ranking approaches in two\nimportant ways. First, existing works measure unfairness at the level of\nsubject groups while our measures capture unfairness at the level of individual\nsubjects, and as such subsume group unfairness. Second, as no single ranking\ncan achieve individual attention fairness, we propose a novel mechanism that\nachieves amortized fairness, where attention accumulated across a series of\nrankings is proportional to accumulated relevance.\n  We formulate the challenge of achieving amortized individual fairness subject\nto constraints on ranking quality as an online optimization problem and show\nthat it can be solved as an integer linear program. Our experimental evaluation\nreveals that unfair attention distribution in rankings can be substantial, and\ndemonstrates that our method can improve individual fairness while retaining\nhigh ranking quality.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01788v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.05401v1",
    "title": "Building Data Science Capabilities into University Data Warehouse to Predict Graduation",
    "authors": [
      "Joonas Pesonen",
      "Anna Fomkin",
      "Lauri Jokipii"
    ],
    "author_ids": [],
    "abstract": "The discipline of data science emerged to combine statistical methods with\ncomputing. At Aalto University, Finland, we have taken first steps to bring\neducational data science as a part of daily operations of Management\nInformation Services. This required changes in IT environment: we enhanced data\nwarehouse infrastructure with a data science lab, where we can read predictive\nmodel training data from data warehouse database and use the created predictive\nmodels in database queries. We then conducted a data science pilot with an\nobjective to predict students' graduation probability and time-to-degree with\nstudent registry data. Further ethical and legal considerations are needed\nbefore using predictions in daily operations of the university.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.05401v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.01681v1",
    "title": "Encoding fairness in a synchronous concurrent program algebra: extended version with proofs",
    "authors": [
      "Ian J. Hayes",
      "Larissa A. Meinicke"
    ],
    "author_ids": [],
    "abstract": "Concurrent program refinement algebra provides a suitable basis for\nsupporting mechanised reasoning about shared-memory concurrent programs in a\ncompositional manner, for example, it supports the rely/guarantee approach of\nJones. The algebra makes use of a synchronous parallel operator motivated by\nAczel's trace model of concurrency and with similarities to Milner's SCCS. This\npaper looks at defining a form of fairness within the program algebra. The\nencoding allows one to reason about the fair execution of a single process in\nisolation as well as define fair-parallel in terms of a base parallel operator,\nof which no fairness properties are assumed. An algebraic theory to support\nfairness and fair-parallel is developed.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LO",
      "cs.DC",
      "68Q60"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01681v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.01583v1",
    "title": "Fairness in Multiterminal Data Compression: A Splitting Method for The Egalitarian Solution",
    "authors": [
      "Ni Ding",
      "David Smith",
      "Parastoo Sadeghi",
      "Thierry Rakotoarivelo"
    ],
    "author_ids": [],
    "abstract": "This paper proposes a novel splitting (SPLIT) algorithm to achieve fairness\nin the multiterminal lossless data compression problem. It finds the\negalitarian solution in the Slepian-Wolf region and completes in strongly\npolynomial time. We show that the SPLIT algorithm adaptively updates the source\ncoding rates to the optimal solution, while recursively splitting the terminal\nset, enabling parallel and distributed computation. The result of an experiment\ndemonstrates a significant reduction in computation time by the parallel\nimplementation when the number of terminals becomes large. The achieved\negalitarian solution is also shown to be superior to the Shapley value in\ndistributed networks, e.g., wireless sensor networks, in that it best balances\nthe nodes' energy consumption and is far less computationally complex to\nobtain.",
    "published_date": "2018-05-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01583v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.01392v1",
    "title": "Prevalence of web trackers on hospital websites in Illinois",
    "authors": [
      "Robert Robinson"
    ],
    "author_ids": [],
    "abstract": "Web tracking technologies are pervasive and operated by a few large\ntechnology companies. This technology, and the use of the collected data has\nbeen implicated in influencing elections, fake news, discrimination, and even\nhealth decisions. Little is known about how this technology is deployed on\nhospital or other health related websites. The websites of the 210 public\nhospitals in the state of Illinois, USA were evaluated with a web tracker\nidentification tool. Web trackers were identified on 94% of hospital webs\nsites, with an average of 3.5 trackers on the websites of general hospitals.\nThe websites of smaller critical access hospitals used an average of 2 web\ntrackers. The most common web tracker identified was Google Analytics, found on\n74% of Illinois hospital websites. Of the web trackers discovered, 88% were\noperated by Google and 26% by Facebook. In light of revelations about how web\nbrowsing profiles have been used and misused, search bubbles, and the potential\nfor algorithmic discrimination hospital leadership and policy makers must\ncarefully consider if it is appropriate to use third party tracking technology\non hospital web sites.",
    "published_date": "2018-05-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.01392v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.00897v2",
    "title": "On the Design of Hybrid Pose and Velocity-bias Observers on Lie Group SE(3)",
    "authors": [
      "Miaomiao Wang",
      "Abdelhamid Tayebi"
    ],
    "author_ids": [],
    "abstract": "This paper deals with the design of globally exponentially stable invariant\nobservers on the Special Euclidian group SE(3). First, we propose a generic\nhybrid observer scheme (depending on a generic potential function) evolving on\n$SE(3)\\times \\mathbb{R}^6$ for pose (orientation and position) and\nvelocity-bias estimation. Thereafter, the proposed observer is formulated\nexplicitly in terms of inertial vectors and landmark measurements.\nInterestingly, the proposed observer leads to a decoupled rotational error\ndynamics from the translational dynamics, which is an interesting feature in\npractical applications with noisy measurements and disturbances.",
    "published_date": "2018-05-02T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.00897v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1805.00471v1",
    "title": "\"I ain't tellin' white folks nuthin\": A quantitative exploration of the race-related problem of candour in the WPA slave narratives",
    "authors": [
      "Soumya Kambhampati"
    ],
    "author_ids": [],
    "abstract": "From 1936-38, the Works Progress Administration interviewed thousands of\nformer slaves about their life experiences. While these interviews are crucial\nto understanding the \"peculiar institution\" from the standpoint of the slave\nhimself, issues relating to bias cloud analyses of these interviews. The\nproblem I investigate is the problem of candour in the WPA slave narratives: it\nis widely held in the historical community that the strict racial caste system\nof the Deep South compelled black ex-slaves to tell white interviewers what\nthey thought they wanted to hear, suggesting that there was a significant\ndifference candour depending on whether their interviewer was white or black.\nIn this work, I attempt to quantitatively characterise this race-related\nproblem of candour. Prior work has either been of an impressionistic,\nqualitative nature, or utilised exceedingly simple quantitative methodology. In\ncontrast, I use more sophisticated statistical methods: in particular word\nfrequency and sentiment analysis and comparative topic modelling with LDA to\ntry and identify differences in the content and sentiment expressed by\nex-slaves in front of white interviewers versus black interviewers. While my\nsentiment analysis methodology was ultimately unsuccessful due to the\ncomplexity of the task, my word frequency analysis and comparative topic\nmodelling methods both showed strong evidence that the content expressed in\nfront of white interviewers was different from that of black interviewers. In\nparticular, I found that the ex-slaves spoke much more about unfavourable\naspects of slavery like whipping and slave patrollers in front of interviewers\nof their own race. I hope that my more-sophisticated statistical methodology\nhelps improve the robustness of the argument for the existence of this problem\nof candour in the slave narratives, which some would seek to deny for\nrevisionist purposes.",
    "published_date": "2018-05-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.00471v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.00065v3",
    "title": "A General Framework for Counterfactual Learning-to-Rank",
    "authors": [
      "Aman Agarwal",
      "Kenta Takatsu",
      "Ivan Zaitsev",
      "Thorsten Joachims"
    ],
    "author_ids": [],
    "abstract": "Implicit feedback (e.g., click, dwell time) is an attractive source of\ntraining data for Learning-to-Rank, but its naive use leads to learning results\nthat are distorted by presentation bias. For the special case of optimizing\naverage rank for linear ranking functions, however, the recently developed\nSVM-PropRank method has shown that counterfactual inference techniques can be\nused to provably overcome the distorting effect of presentation bias. Going\nbeyond this special case, this paper provides a general and theoretically\nrigorous framework for counterfactual learning-to-rank that enables unbiased\ntraining for a broad class of additive ranking metrics (e.g., Discounted\nCumulative Gain (DCG)) as well as a broad class of models (e.g., deep\nnetworks). Specifically, we derive a relaxation for propensity-weighted\nrank-based metrics which is subdifferentiable and thus suitable for\ngradient-based optimization. We demonstrate the effectiveness of this general\napproach by instantiating two new learning methods. One is a new type of\nunbiased SVM that optimizes DCG -- called SVM PropDCG --, and we show how the\nresulting optimization problem can be solved via the Convex Concave Procedure\n(CCP). The other is Deep PropDCG, where the ranking function can be an\narbitrary deep network. In addition to the theoretical support, we empirically\nfind that SVM PropDCG significantly outperforms existing linear rankers in\nterms of DCG. Moreover, the ability to train non-linear ranking functions via\nDeep PropDCG further improves performance.",
    "published_date": "2018-04-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.00065v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.11270v3",
    "title": "Dynamic Active Constraints for Surgical Robots using Vector Field Inequalities",
    "authors": [
      "Murilo M. Marinho",
      "Bruno V. Adorno",
      "Kanako Harada",
      "Mamoru Mitsuishi"
    ],
    "author_ids": [],
    "abstract": "Robotic assistance allows surgeons to perform dexterous and tremor-free\nprocedures, but robotic aid is still underrepresented in procedures with\nconstrained workspaces, such as deep brain neurosurgery and endonasal surgery.\nIn these procedures, surgeons have restricted vision to areas near the surgical\ntooltips, which increases the risk of unexpected collisions between the shafts\nof the instruments and their surroundings. In this work, our\nvector-field-inequalities method is extended to provide dynamic\nactive-constraints to any number of robots and moving objects sharing the same\nworkspace. The method is evaluated with experiments and simulations in which\nrobot tools have to avoid collisions autonomously and in real-time, in a\nconstrained endonasal surgical environment. Simulations show that with our\nmethod the combined trajectory error of two robotic systems is optimal.\nExperiments using a real robotic system show that the method can autonomously\nprevent collisions between the moving robots themselves and between the robots\nand the environment. Moreover, the framework is also successfully verified\nunder teleoperation with tool-tissue interactions.",
    "published_date": "2018-04-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.11270v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.11254v3",
    "title": "Inherent Biases in Reference based Evaluation for Grammatical Error Correction and Text Simplification",
    "authors": [
      "Leshem Choshen",
      "Omri Abend"
    ],
    "author_ids": [],
    "abstract": "The prevalent use of too few references for evaluating text-to-text\ngeneration is known to bias estimates of their quality ({\\it low coverage bias}\nor LCB). This paper shows that overcoming LCB in Grammatical Error Correction\n(GEC) evaluation cannot be attained by re-scaling or by increasing the number\nof references in any feasible range, contrary to previous suggestions. This is\ndue to the long-tailed distribution of valid corrections for a sentence.\nConcretely, we show that LCB incentivizes GEC systems to avoid correcting even\nwhen they can generate a valid correction. Consequently, existing systems\nobtain comparable or superior performance compared to humans, by making few but\ntargeted changes to the input. Similar effects on Text Simplification further\nsupport our claims.",
    "published_date": "2018-04-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.11254v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.11021v3",
    "title": "On the Effect of Suboptimal Estimation of Mutual Information in Feature Selection and Classification",
    "authors": [
      "Kiran Karra",
      "Lamine Mili"
    ],
    "author_ids": [],
    "abstract": "This paper introduces a new property of estimators of the strength of\nstatistical association, which helps characterize how well an estimator will\nperform in scenarios where dependencies between continuous and discrete random\nvariables need to be rank ordered. The new property, termed the estimator\nresponse curve, is easily computable and provides a marginal distribution\nagnostic way to assess an estimator's performance. It overcomes notable\ndrawbacks of current metrics of assessment, including statistical power, bias,\nand consistency. We utilize the estimator response curve to test various\nmeasures of the strength of association that satisfy the data processing\ninequality (DPI), and show that the CIM estimator's performance compares\nfavorably to kNN, vME, AP, and H_{MI} estimators of mutual information. The\nestimators which were identified to be suboptimal, according to the estimator\nresponse curve, perform worse than the more optimal estimators when tested with\nreal-world data from four different areas of science, all with varying\ndimensionalities and sizes.",
    "published_date": "2018-04-30T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.11021v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.10899v2",
    "title": "Scalable Angular Discriminative Deep Metric Learning for Face Recognition",
    "authors": [
      "Bowen Wu",
      "Huaming Wu",
      "Monica M. Y. Zhang"
    ],
    "author_ids": [],
    "abstract": "With the development of deep learning, Deep Metric Learning (DML) has\nachieved great improvements in face recognition. Specifically, the widely used\nsoftmax loss in the training process often bring large intra-class variations,\nand feature normalization is only exploited in the testing process to compute\nthe pair similarities. To bridge the gap, we impose the intra-class cosine\nsimilarity between the features and weight vectors in softmax loss larger than\na margin in the training step, and extend it from four aspects. First, we\nexplore the effect of a hard sample mining strategy. To alleviate the human\nlabor of adjusting the margin hyper-parameter, a self-adaptive margin updating\nstrategy is proposed. Then, a normalized version is given to take full\nadvantage of the cosine similarity constraint. Furthermore, we enhance the\nformer constraint to force the intra-class cosine similarity larger than the\nmean inter-class cosine similarity with a margin in the exponential feature\nprojection space. Extensive experiments on Labeled Face in the Wild (LFW),\nYoutube Faces (YTF) and IARPA Janus Benchmark A (IJB-A) datasets demonstrate\nthat the proposed methods outperform the mainstream DML methods and approach\nthe state-of-the-art performance.",
    "published_date": "2018-04-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.10899v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1805.00801v1",
    "title": "Credit risk prediction in an imbalanced social lending environment",
    "authors": [
      "Anahita Namvar",
      "Mohammad Siami",
      "Fethi Rabhi",
      "Mohsen Naderpour"
    ],
    "author_ids": [],
    "abstract": "Credit risk prediction is an effective way of evaluating whether a potential\nborrower will repay a loan, particularly in peer-to-peer lending where class\nimbalance problems are prevalent. However, few credit risk prediction models\nfor social lending consider imbalanced data and, further, the best resampling\ntechnique to use with imbalanced data is still controversial. In an attempt to\naddress these problems, this paper presents an empirical comparison of various\ncombinations of classifiers and resampling techniques within a novel risk\nassessment methodology that incorporates imbalanced data. The credit\npredictions from each combination are evaluated with a G-mean measure to avoid\nbias towards the majority class, which has not been considered in similar\nstudies. The results reveal that combining random forest and random\nunder-sampling may be an effective strategy for calculating the credit risk\nassociated with loan applicants in social lending markets.",
    "published_date": "2018-04-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.00801v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.10764v1",
    "title": "Detect, Quantify, and Incorporate Dataset Bias: A Neuroimaging Analysis on 12,207 Individuals",
    "authors": [
      "Christian Wachinger",
      "Benjamin Gutierrez Becker",
      "Anna Rieckmann"
    ],
    "author_ids": [],
    "abstract": "Neuroimaging datasets keep growing in size to address increasingly complex\nmedical questions. However, even the largest datasets today alone are too small\nfor training complex models or for finding genome wide associations. A solution\nis to grow the sample size by merging data across several datasets. However,\nbias in datasets complicates this approach and includes additional sources of\nvariation in the data instead. In this work, we combine 15 large neuroimaging\ndatasets to study bias. First, we detect bias by demonstrating that scans can\nbe correctly assigned to a dataset with 73.3% accuracy. Next, we introduce\nmetrics to quantify the compatibility across datasets and to create embeddings\nof neuroimaging sites. Finally, we incorporate the presence of bias for the\nselection of a training set for predicting autism. For the quantification of\nthe dataset bias, we introduce two metrics: the Bhattacharyya distance between\ndatasets and the age prediction error. The presented embedding of neuroimaging\nsites provides an interesting new visualization about the similarity of\ndifferent sites. This could be used to guide the merging of data sources, while\nlimiting the introduction of unwanted variation. Finally, we demonstrate a\nclear performance increase when incorporating dataset bias for training set\nselection in autism prediction. Overall, we believe that the growing amount of\nneuroimaging data necessitates to incorporate data-driven methods for\nquantifying dataset bias in future analyses.",
    "published_date": "2018-04-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.10764v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.10644v2",
    "title": "Urban contact structures for epidemic simulations: Correcting biases in data-driven approaches",
    "authors": [
      "Zhanwei Du",
      "Chao Gao",
      "Yuan Bai",
      "Yongjian Yang",
      "Petter Holme"
    ],
    "author_ids": [],
    "abstract": "Epidemics are emergent phenomena depending on the epidemiological\ncharacteristics of pathogens and the interaction and movement of people. Public\ntransit systems have provided much important information about the movement of\npeople, but there are also other means of transportation (e.g., bicycle and\nprivate car), that are invisible to public transit data. This discrepancy can\ninduce a bias in disease models that leads to mispredictions of epidemic growth\n(e.g., peak prevalence and time). In our study, we aim to advance and compare\nthe epidemic spreading dynamics using public transit trips, in contrast to more\naccurate estimates of population movement using mobile phones traces. In our\nstudy, we simulate epidemic outbreaks in a cohort of two million mobile phone\nusers. We use a metapopulation model incorporating\nsusceptible-infected-recovered dynamics to analyze and compare different\neffective contract matrices, constructed by the public transit systems and\nmobile phones respectively, on the process of epidemics. We find that epidemic\noutbreaks using public transit trips tend to be underestimated in terms of the\nepidemic spreading dynamics, reaching epidemic peaks weaker and later. This is\nrooted in a later introduction of new infectious people into uninfected\nlocations.",
    "published_date": "2018-04-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.10644v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.10140v3",
    "title": "Securing Distributed Gradient Descent in High Dimensional Statistical Learning",
    "authors": [
      "Lili Su",
      "Jiaming Xu"
    ],
    "author_ids": [],
    "abstract": "We consider unreliable distributed learning systems wherein the training data\nis kept confidential by external workers, and the learner has to interact\nclosely with those workers to train a model. In particular, we assume that\nthere exists a system adversary that can adaptively compromise some workers;\nthe compromised workers deviate from their local designed specifications by\nsending out arbitrarily malicious messages.\n  We assume in each communication round, up to $q$ out of the $m$ workers\nsuffer Byzantine faults. Each worker keeps a local sample of size $n$ and the\ntotal sample size is $N=nm$. We propose a secured variant of the gradient\ndescent method that can tolerate up to a constant fraction of Byzantine\nworkers, i.e., $q/m = O(1)$. Moreover, we show the statistical estimation error\nof the iterates converges in $O(\\log N)$ rounds to $O(\\sqrt{q/N} +\n\\sqrt{d/N})$, where $d$ is the model dimension. As long as $q=O(d)$, our\nproposed algorithm achieves the optimal error rate $O(\\sqrt{d/N})$. Our results\nare obtained under some technical assumptions. Specifically, we assume\nstrongly-convex population risk. Nevertheless, the empirical risk (sample\nversion) is allowed to be non-convex. The core of our method is to robustly\naggregate the gradients computed by the workers based on the filtering\nprocedure proposed by Steinhardt et al. On the technical front, deviating from\nthe existing literature on robustly estimating a finite-dimensional mean\nvector, we establish a {\\em uniform} concentration of the sample covariance\nmatrix of gradients, and show that the aggregated gradient, as a function of\nmodel parameter, converges uniformly to the true gradient function. To get a\nnear-optimal uniform concentration bound, we develop a new matrix concentration\ninequality, which might be of independent interest.",
    "published_date": "2018-04-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DC",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.10140v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.09705v1",
    "title": "Positive Solutions of Systems of Signed Parametric Polynomial Inequalities",
    "authors": [
      "Hoon Hong",
      "Thomas Sturm"
    ],
    "author_ids": [],
    "abstract": "We consider systems of strict multivariate polynomial inequalities over the\nreals. All polynomial coefficients are parameters ranging over the reals, where\nfor each coefficient we prescribe its sign. We are interested in the existence\nof positive real solutions of our system for all choices of coefficients\nsubject to our sign conditions. We give a decision procedure for the existence\nof such solutions. In the positive case our procedure yields a parametric\npositive solution as a rational function in the coefficients. Our framework\nallows to reformulate heuristic subtropical approaches for non-parametric\nsystems of polynomial inequalities that have been recently used in qualitative\nbiological network analysis and, independently, in satisfiability modulo theory\nsolving. We apply our results to characterize the incompleteness of those\nmethods.",
    "published_date": "2018-04-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SC",
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.09705v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.09648v1",
    "title": "Structure Discrimination in Block-Oriented Models Using Linear Approximations: A Theoretic Framework",
    "authors": [
      "Johan Schoukens",
      "Rik Pintelon",
      "Yves Rolain",
      "Maarten Schoukens",
      "Koen Tiels",
      "Laurent Vanbeylen",
      "Anne Van Mulders",
      "Gerd Vandersteen"
    ],
    "author_ids": [],
    "abstract": "In this paper we show that it is possible to retrieve structural information\nabout complex block-oriented nonlinear systems, starting from linear\napproximations of the nonlinear system around different setpoints.The key idea\nis to monitor the movements of the poles and zeros of the linearized models and\nto reduce the number of candidate models on the basis of these observations.\nBesides the well known open loop single branch Wiener-, Hammerstein-, and\nWiener-Hammerstein systems, we also cover a number of more general structures\nlike parallel (multi branch) Wiener-Hammerstein models, and closed loop block\noriented models, including linear fractional representation (LFR) models.",
    "published_date": "2018-04-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.09648v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.09477v1",
    "title": "Bribery Games on Interdependent Complex Networks",
    "authors": [
      "Prateek Verma",
      "Anjan K. Nandi",
      "Supratim Sengupta"
    ],
    "author_ids": [],
    "abstract": "Bribe demands present a social conflict scenario where decisions have\nwide-ranging economic and ethical consequences. Nevertheless, such incidents\noccur daily in many countries across the globe. Harassment bribery constitute a\nsignificant sub-set of such bribery incidents where a government official\ndemands a bribe for providing a service to a citizen legally entitled to it. We\nemploy an evolutionary game-theoretic framework to analyse the evolution of\ncorrupt and honest strategies in structured populations characterized by an\ninterdependent complex network. The effects of changing network topology,\naverage number of links and asymmetry in size of the citizen and officer\npopulation on the proliferation of incidents of bribery are explored. A complex\nnetwork topology is found to be beneficial for the dominance of corrupt\nstrategies over a larger region of phase space when compared with the outcome\nfor a regular network, for equal citizen and officer population sizes. However,\nthe extent of the advantage depends critically on the network degree and\ntopology. A different trend is observed when there is a difference between the\ncitizen and officer population sizes. Under those circumstances, increasing\nrandomness of the underlying citizen network can be beneficial to the fixation\nof honest officers up to a certain value of the network degree. Our analysis\nreveals how the interplay between network topology, connectivity and strategy\nupdate rules can affect population level outcomes in such asymmetric games.",
    "published_date": "2018-04-25T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.09477v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.09301v1",
    "title": "Gender Bias in Coreference Resolution",
    "authors": [
      "Rachel Rudinger",
      "Jason Naradowsky",
      "Brian Leonard",
      "Benjamin Van Durme"
    ],
    "author_ids": [],
    "abstract": "We present an empirical study of gender bias in coreference resolution\nsystems. We first introduce a novel, Winograd schema-style set of minimal pair\nsentences that differ only by pronoun gender. With these \"Winogender schemas,\"\nwe evaluate and confirm systematic gender bias in three publicly-available\ncoreference resolution systems, and correlate this bias with real-world and\ntextual gender statistics.",
    "published_date": "2018-04-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.09301v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.09124v2",
    "title": "On Multilinear Forms: Bias, Correlation, and Tensor Rank",
    "authors": [
      "Abhishek Bhrushundi",
      "Prahladh Harsha",
      "Pooya Hatami",
      "Swastik Kopparty",
      "Mrinal Kumar"
    ],
    "author_ids": [],
    "abstract": "In this paper, we prove new relations between the bias of multilinear forms,\nthe correlation between multilinear forms and lower degree polynomials, and the\nrank of tensors over $GF(2)= \\{0,1\\}$. We show the following results for\nmultilinear forms and tensors.\n  1. Correlation bounds : We show that a random $d$-linear form has\nexponentially low correlation with low-degree polynomials. More precisely, for\n$d \\ll 2^{o(k)}$, we show that a random $d$-linear form $f(X_1,X_2, \\dots, X_d)\n: \\left(GF(2)^{k}\\right)^d \\rightarrow GF(2)$ has correlation $2^{-k(1-o(1))}$\nwith any polynomial of degree at most $d/10$. This result is proved by giving\nnear-optimal bounds on the bias of random $d$-linear form, which is in turn\nproved by giving near-optimal bounds on the probability that a random rank-$t$\n$d$-linear form is identically zero.\n  2. Tensor-rank vs Bias : We show that if a $d$-dimensional tensor has small\nrank, then the bias of the associated $d$-linear form is large. More precisely,\ngiven any $d$-dimensional tensor $$T :\\underbrace{[k]\\times \\ldots\n[k]}_{\\text{$d$ times}}\\to GF(2)$$ of rank at most $t$, the bias of the\nassociated $d$-linear form $$f_T(X_1,\\ldots,X_d) := \\sum_{(i_1,\\dots,i_d) \\in\n[k]^d} T(i_1,i_2,\\ldots, i_d) X_{1,i_1}\\cdot X_{1,i_2}\\cdots X_{d,i_d}$$ is at\nleast $\\left(1-\\frac1{2^{d-1}}\\right)^t$.\n  The above bias vs tensor-rank connection suggests a natural approach to\nproving nontrivial tensor-rank lower bounds for $d=3$. In particular, we use\nthis approach to prove that the finite field multiplication tensor has tensor\nrank at least $3.52 k$ matching the best known lower bound for any explicit\ntensor in three dimensions over $GF(2)$.",
    "published_date": "2018-04-24T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.09124v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.08595v1",
    "title": "Single-User mmWave Massive MIMO: SVD-based ADC Bit Allocation and Combiner Design",
    "authors": [
      "I. Zakir Ahmed",
      "Hamid Sadjadpour",
      "Shahram Yousefi"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a Singular-Value-Decomposition-based\nvariable-resolution Analog to Digital Converter (ADC) bit allocation design for\na single-user Millimeter wave massive Multiple-Input Multiple-Output receiver.\nWe derive the optimality condition for bit allocation under a power constraint.\nThis condition ensures optimal receiver performance in the Mean Squared Error\n(MSE) sense. We derive the MSE expression and show that it approaches the\nCramer-Rao Lower Bound (CRLB). The CRLB is seen to be a function of the analog\ncombiner, the digital combiner, and the bit allocation matrix. We attempt to\nminimize the CRLB with respect to the bit allocation matrix by making suitable\nassumptions regarding the structure of the combiners. In doing so, the bit\nallocation design reduces to a set of simple inequalities consisting of ADC\nbits, channel singular values and covariance of the quantization noise along\neach RF path. This results in a simple and computationally efficient bit\nallocation algorithm. Using simulations, we show that the MSE performance of\nour proposed bit allocation is very close to that of the Full Search (FS) bit\nallocation. We also show that the computational complexity of our proposed\nmethod has an order of magnitude improvement compared to FS and Genetic\nAlgorithm based bit allocation of $\\cite{Zakir1}$",
    "published_date": "2018-04-23T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08595v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.08348v2",
    "title": "Deep Facial Expression Recognition: A Survey",
    "authors": [
      "Shan Li",
      "Weihong Deng"
    ],
    "author_ids": [],
    "abstract": "With the transition of facial expression recognition (FER) from\nlaboratory-controlled to challenging in-the-wild conditions and the recent\nsuccess of deep learning techniques in various fields, deep neural networks\nhave increasingly been leveraged to learn discriminative representations for\nautomatic FER. Recent deep FER systems generally focus on two important issues:\noverfitting caused by a lack of sufficient training data and\nexpression-unrelated variations, such as illumination, head pose and identity\nbias. In this paper, we provide a comprehensive survey on deep FER, including\ndatasets and algorithms that provide insights into these intrinsic problems.\nFirst, we describe the standard pipeline of a deep FER system with the related\nbackground knowledge and suggestions of applicable implementations for each\nstage. We then introduce the available datasets that are widely used in the\nliterature and provide accepted data selection and evaluation principles for\nthese datasets. For the state of the art in deep FER, we review existing novel\ndeep neural networks and related training strategies that are designed for FER\nbased on both static images and dynamic image sequences, and discuss their\nadvantages and limitations. Competitive performances on widely used benchmarks\nare also summarized in this section. We then extend our survey to additional\nrelated issues and application scenarios. Finally, we review the remaining\nchallenges and corresponding opportunities in this field as well as future\ndirections for the design of robust deep FER systems.",
    "published_date": "2018-04-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08348v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.08313v2",
    "title": "Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks",
    "authors": [
      "Diego Marcheggiani",
      "Jasmijn Bastings",
      "Ivan Titov"
    ],
    "author_ids": [],
    "abstract": "Semantic representations have long been argued as potentially useful for\nenforcing meaning preservation and improving generalization performance of\nmachine translation methods. In this work, we are the first to incorporate\ninformation about predicate-argument structure of source sentences (namely,\nsemantic-role representations) into neural machine translation. We use Graph\nConvolutional Networks (GCNs) to inject a semantic bias into sentence encoders\nand achieve improvements in BLEU scores over the linguistic-agnostic and\nsyntax-aware versions on the English--German language pair.",
    "published_date": "2018-04-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08313v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.08133v2",
    "title": "SolidWorx: A Resilient and Trustworthy Transactive Platform for Smart and Connected Communities",
    "authors": [
      "Scott Eisele",
      "Aron Laszka",
      "Anastasia Mavridou",
      "Abhishek Dubey"
    ],
    "author_ids": [],
    "abstract": "Internet of Things and data sciences are fueling the development of\ninnovative solutions for various applications in Smart and Connected\nCommunities (SCC). These applications provide participants with the capability\nto exchange not only data but also resources, which raises the concerns of\nintegrity, trust, and above all the need for fair and optimal solutions to the\nproblem of resource allocation. This exchange of information and resources\nleads to a problem where the stakeholders of the system may have limited trust\nin each other. Thus, collaboratively reaching consensus on when, how, and who\nshould access certain resources becomes problematic. This paper presents\nSolidWorx, a blockchain-based platform that provides key mechanisms required\nfor arbitrating resource consumption across different SCC applications in a\ndomain-agnostic manner. For example, it introduces and implements a\nhybrid-solver pattern, where complex optimization computation is handled\noff-blockchain while solution validation is performed by a smart contract. To\nensure correctness, the smart contract of SolidWorx is generated and verified.",
    "published_date": "2018-04-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08133v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.08117v1",
    "title": "Performance Impact Caused by Hidden Bias of Training Data for Recognizing Textual Entailment",
    "authors": [
      "Masatoshi Tsuchiya"
    ],
    "author_ids": [],
    "abstract": "The quality of training data is one of the crucial problems when a\nlearning-centered approach is employed. This paper proposes a new method to\ninvestigate the quality of a large corpus designed for the recognizing textual\nentailment (RTE) task. The proposed method, which is inspired by a statistical\nhypothesis test, consists of two phases: the first phase is to introduce the\npredictability of textual entailment labels as a null hypothesis which is\nextremely unacceptable if a target corpus has no hidden bias, and the second\nphase is to test the null hypothesis using a Naive Bayes model. The\nexperimental result of the Stanford Natural Language Inference (SNLI) corpus\ndoes not reject the null hypothesis. Therefore, it indicates that the SNLI\ncorpus has a hidden bias which allows prediction of textual entailment labels\nfrom hypothesis sentences even if no context information is given by a premise\nsentence. This paper also presents the performance impact of NN models for RTE\ncaused by this hidden bias.",
    "published_date": "2018-04-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08117v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.08087v1",
    "title": "Anchor-based Nearest Class Mean Loss for Convolutional Neural Networks",
    "authors": [
      "Fusheng Hao",
      "Jun Cheng",
      "Lei Wang",
      "Xinchao Wang",
      "Jianzhong Cao",
      "Xiping Hu",
      "Dapeng Tao"
    ],
    "author_ids": [],
    "abstract": "Discriminative features are critical for machine learning applications. Most\nexisting deep learning approaches, however, rely on convolutional neural\nnetworks (CNNs) for learning features, whose discriminant power is not\nexplicitly enforced. In this paper, we propose a novel approach to train deep\nCNNs by imposing the intra-class compactness and the inter-class separability,\nso as to enhance the learned features' discriminant power. To this end, we\nintroduce anchors, which are predefined vectors regarded as the centers for\neach class and fixed during training. Discriminative features are obtained by\nconstraining the deep CNNs to map training samples to the corresponding anchors\nas close as possible. We propose two principles to select the anchors, and\nmeasure the proximity of two points using the Euclidean and cosine distance\nmetric functions, which results in two novel loss functions. These loss\nfunctions require no sample pairs or triplets and can be efficiently optimized\nby batch stochastic gradient descent. We test the proposed method on three\nbenchmark image classification datasets and demonstrate its promising results.",
    "published_date": "2018-04-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08087v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.08017v1",
    "title": "Tracing Equilibrium in Dynamic Markets via Distributed Adaptation",
    "authors": [
      "Yun Kuen Cheung",
      "Martin Hoefer",
      "Paresh Nakhe"
    ],
    "author_ids": [],
    "abstract": "Competitive equilibrium is a central concept in economics with numerous\napplications beyond markets, such as scheduling, fair allocation of goods, or\nbandwidth distribution in networks. Computation of competitive equilibria has\nreceived a significant amount of interest in algorithmic game theory, mainly\nfor the prominent case of Fisher markets. Natural and decentralized processes\nlike tatonnement and proportional response dynamics (PRD) converge quickly\ntowards equilibrium in large classes of Fisher markets. Almost all of the\nliterature assumes that the market is a static environment and that the\nparameters of agents and goods do not change over time. In contrast, many large\nreal-world markets are subject to frequent and dynamic changes. In this paper,\nwe provide the first provable performance guarantees of discrete-time\ntatonnement and PRD in markets that are subject to perturbation over time. We\nanalyze the prominent class of Fisher markets with CES utilities and quantify\nthe impact of changes in supplies of goods, budgets of agents, and utility\nfunctions of agents on the convergence of tatonnement to market equilibrium.\nSince the equilibrium becomes a dynamic object and will rarely be reached, our\nanalysis provides bounds expressing the distance to equilibrium that will be\nmaintained via tatonnement and PRD updates. Our results indicate that in many\ncases, tatonnement and PRD follow the equilibrium rather closely and quickly\nrecover conditions of approximate market clearing. Our approach can be\ngeneralized to analyzing a general class of Lyapunov dynamical systems with\nchanging system parameters, which might be of independent interest.",
    "published_date": "2018-04-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.08017v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.07890v1",
    "title": "A Nutritional Label for Rankings",
    "authors": [
      "Ke Yang",
      "Julia Stoyanovich",
      "Abolfazl Asudeh",
      "Bill Howe",
      "HV Jagadish",
      "Gerome Miklau"
    ],
    "author_ids": [],
    "abstract": "Algorithmic decisions often result in scoring and ranking individuals to\ndetermine credit worthiness, qualifications for college admissions and\nemployment, and compatibility as dating partners. While automatic and seemingly\nobjective, ranking algorithms can discriminate against individuals and\nprotected groups, and exhibit low diversity. Furthermore, ranked results are\noften unstable --- small changes in the input data or in the ranking\nmethodology may lead to drastic changes in the output, making the result\nuninformative and easy to manipulate. Similar concerns apply in cases where\nitems other than individuals are ranked, including colleges, academic\ndepartments, or products.\n  In this demonstration we present Ranking Facts, a Web-based application that\ngenerates a \"nutritional label\" for rankings. Ranking Facts is made up of a\ncollection of visual widgets that implement our latest research results on\nfairness, stability, and transparency for rankings, and that communicate\ndetails of the ranking methodology, or of the output, to the end user. We will\nshowcase Ranking Facts on real datasets from different domains, including\ncollege rankings, criminal risk assessment, and financial services.",
    "published_date": "2018-04-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.DB",
      "cs.HC",
      "68U01, 68P01",
      "H.2, H.2.8, K.4.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07890v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.07529v3",
    "title": "Bias-variance tradeoff in MIMO channel estimation",
    "authors": [
      "Luc Le Magoarou",
      "Stéphane Paquelet"
    ],
    "author_ids": [],
    "abstract": "Channel estimation is challenging in multi-antenna communication systems,\nbecause of the large number of parameters to estimate. It is possible to\nfacilitate this task by using a physical model describing the multiple paths\nconstituting the channel, in the hope of reducing the number of unknowns in the\nproblem. Adjusting the number of estimated paths leads to a bias-variance\ntradeoff. This paper explores this tradeoff, aiming to find the optimal number\nof paths to estimate. Moreover, the approach based on a physical model is\ncompared to the classical least squares and Bayesian techniques. Finally, the\nimpact of channel estimation error on the system data rate is assessed.",
    "published_date": "2018-04-20T00:00:00",
    "year": 2018,
    "categories": [
      "eess.SP",
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07529v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.07391v3",
    "title": "Don't Mine, Wait in Line: Fair and Efficient Blockchain Consensus with Robust Round Robin",
    "authors": [
      "Mansoor Ahmed-Rengers",
      "Kari Kostiainen"
    ],
    "author_ids": [],
    "abstract": "Proof-of-Stake systems randomly choose, on each round, one of the\nparticipants as a consensus leader that extends the chain with the next block\nsuch that the selection probability is proportional to the owned stake.\nHowever, distributed random number generation is notoriously difficult. Systems\nthat derive randomness from the previous blocks are completely insecure;\nsolutions that provide secure random selection are inefficient due to their\nhigh communication complexity; and approaches that balance security and\nperformance exhibit selection bias. When block creation is rewarded with new\nstake, even a minor bias can have a severe cumulative effect.\n  In this paper, we propose Robust Round Robin, a new consensus scheme that\naddresses this selection problem. We create reliable long-term identities by\nbootstrapping from an existing infrastructure, such as Intel's SGX processors,\nor by mining them starting from an initial fair distribution. For leader\nselection we use a deterministic approach. On each round, we select a set of\nthe previously created identities as consensus leader candidates in round robin\nmanner. Because simple round-robin alone is vulnerable to attacks and offers\npoor liveness, we complement such deterministic selection policy with a\nlightweight endorsement mechanism that is an interactive protocol between the\nleader candidates and a small subset of other system participants. Our solution\nhas low good efficiency as it requires no expensive distributed randomness\ngeneration and it provides block creation fairness which is crucial in\ndeployments that reward it with new stake.",
    "published_date": "2018-04-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07391v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.07237v2",
    "title": "Multi-view Hybrid Embedding: A Divide-and-Conquer Approach",
    "authors": [
      "Jiamiao Xu",
      "Shujian Yu",
      "Xinge You",
      "Mengjun Leng",
      "Xiao-Yuan Jing",
      "C. L. Philip Chen"
    ],
    "author_ids": [],
    "abstract": "We present a novel cross-view classification algorithm where the gallery and\nprobe data come from different views. A popular approach to tackle this problem\nis the multi-view subspace learning (MvSL) that aims to learn a latent subspace\nshared by multi-view data. Despite promising results obtained on some\napplications, the performance of existing methods deteriorates dramatically\nwhen the multi-view data is sampled from nonlinear manifolds or suffers from\nheavy outliers. To circumvent this drawback, motivated by the\nDivide-and-Conquer strategy, we propose Multi-view Hybrid Embedding (MvHE), a\nunique method of dividing the problem of cross-view classification into three\nsubproblems and building one model for each subproblem. Specifically, the first\nmodel is designed to remove view discrepancy, whereas the second and third\nmodels attempt to discover the intrinsic nonlinear structure and to increase\ndiscriminability in intra-view and inter-view samples respectively. The kernel\nextension is conducted to further boost the representation power of MvHE.\nExtensive experiments are conducted on four benchmark datasets. Our methods\ndemonstrate overwhelming advantages against the state-of-the-art MvSL based\ncross-view classification approaches in terms of classification accuracy and\nrobustness.",
    "published_date": "2018-04-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07237v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.07121v1",
    "title": "Finite Biased Teaching with Infinite Concept Classes",
    "authors": [
      "Jose Hernandez-Orallo",
      "Jan Arne Telle"
    ],
    "author_ids": [],
    "abstract": "We investigate the teaching of infinite concept classes through the effect of\nthe learning bias (which is used by the learner to prefer some concepts over\nothers and by the teacher to devise the teaching examples) and the sampling\nbias (which determines how the concepts are sampled from the class). We analyse\ntwo important classes: Turing machines and finite-state machines. We derive\nbounds for the biased teaching dimension when the learning bias is derived from\na complexity measure (Kolmogorov complexity and minimal number of states\nrespectively) and analyse the sampling distributions that lead to finite\nexpected biased teaching dimensions. We highlight the existing trade-off\nbetween the bound and the representativeness of the sample, and its\nimplications for the understanding of what teaching rich concepts to machines\nentails.",
    "published_date": "2018-04-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07121v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.06909v1",
    "title": "Modeling and Simultaneously Removing Bias via Adversarial Neural Networks",
    "authors": [
      "John Moore",
      "Joel Pfeiffer",
      "Kai Wei",
      "Rishabh Iyer",
      "Denis Charles",
      "Ran Gilad-Bachrach",
      "Levi Boyles",
      "Eren Manavoglu"
    ],
    "author_ids": [],
    "abstract": "In real world systems, the predictions of deployed Machine Learned models\naffect the training data available to build subsequent models. This introduces\na bias in the training data that needs to be addressed. Existing solutions to\nthis problem attempt to resolve the problem by either casting this in the\nreinforcement learning framework or by quantifying the bias and re-weighting\nthe loss functions. In this work, we develop a novel Adversarial Neural Network\n(ANN) model, an alternative approach which creates a representation of the data\nthat is invariant to the bias. We take the Paid Search auction as our working\nexample and ad display position features as the confounding features for this\nsetting. We show the success of this approach empirically on both synthetic\ndata as well as real world paid search auction data from a major search engine.",
    "published_date": "2018-04-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06909v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.06876v1",
    "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods",
    "authors": [
      "Jieyu Zhao",
      "Tianlu Wang",
      "Mark Yatskar",
      "Vicente Ordonez",
      "Kai-Wei Chang"
    ],
    "author_ids": [],
    "abstract": "We introduce a new benchmark, WinoBias, for coreference resolution focused on\ngender bias. Our corpus contains Winograd-schema style sentences with entities\ncorresponding to people referred by their occupation (e.g. the nurse, the\ndoctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a\nneural coreference system all link gendered pronouns to pro-stereotypical\nentities with higher accuracy than anti-stereotypical entities, by an average\ndifference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation\napproach that, in combination with existing word-embedding debiasing\ntechniques, removes the bias demonstrated by these systems in WinoBias without\nsignificantly affecting their performance on existing coreference benchmark\ndatasets. Our dataset and code are available at http://winobias.org.",
    "published_date": "2018-04-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06876v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.06817v1",
    "title": "Automated detection of vulnerable plaque in intravascular ultrasound images",
    "authors": [
      "Tae Joon Jun",
      "Soo-Jin Kang",
      "June-Goo Lee",
      "Jihoon Kweon",
      "Wonjun Na",
      "Daeyoun Kang",
      "Dohyeun Kim",
      "Daeyoung Kim",
      "Young-Hak Kim"
    ],
    "author_ids": [],
    "abstract": "Acute Coronary Syndrome (ACS) is a syndrome caused by a decrease in blood\nflow in the coronary arteries. The ACS is usually related to coronary\nthrombosis and is primarily caused by plaque rupture followed by plaque erosion\nand calcified nodule. Thin-cap fibroatheroma (TCFA) is known to be the most\nsimilar lesion morphologically to a plaque rupture. In this paper, we propose\nmethods to classify TCFA using various machine learning classifiers including\nFeed-forward Neural Network (FNN), K-Nearest Neighbor (KNN), Random Forest (RF)\nand Convolutional Neural Network (CNN) to figure out a classifier that shows\noptimal TCFA classification accuracy. In addition, we suggest pixel range based\nfeature extraction method to extract the ratio of pixels in the different\nregion of interests to reflect the physician's TCFA discrimination criteria. A\ntotal of 12,325 IVUS images were labeled with corresponding OCT images to train\nand evaluate the classifiers. We achieved 0.884, 0.890, 0.878 and 0.933 Area\nUnder the ROC Curve (AUC) in the order of using FNN, KNN, RF and CNN\nclassifier. As a result, the CNN classifier performed best and the top 10\nfeatures of the feature-based classifiers (FNN, KNN, RF) were found to be\nsimilar to the physician's TCFA diagnostic criteria.",
    "published_date": "2018-04-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06817v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.06653v1",
    "title": "Consensus Community Detection in Multilayer Networks using Parameter-free Graph Pruning",
    "authors": [
      "Domenico Mandaglio",
      "Alessia Amelio",
      "Andrea Tagarelli"
    ],
    "author_ids": [],
    "abstract": "The clustering ensemble paradigm has emerged as an effective tool for\ncommunity detection in multilayer networks, which allows for producing\nconsensus solutions that are designed to be more robust to the algorithmic\nselection and configuration bias. However, one limitation is related to the\ndependency on a co-association threshold that controls the degree of consensus\nin the community structure solution. The goal of this work is to overcome this\nlimitation with a new framework of ensemble-based multilayer community\ndetection, which features parameter-free identification of consensus\ncommunities based on generative models of graph pruning that are able to filter\nout noisy co-associations. We also present an enhanced version of the\nmodularity-driven ensemble-based multilayer community detection method, in\nwhich community memberships of nodes are reconsidered to optimize the\nmultilayer modularity of the consensus solution. Experimental evidence on\nreal-world networks confirms the beneficial effect of using model-based\nfiltering methods and also shows the superiority of the proposed method on\nstate-of-the-art multilayer community detection.",
    "published_date": "2018-04-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB",
      "cs.SI",
      "physics.data-an"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06653v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.07265v1",
    "title": "Deep Transfer Network with Joint Distribution Adaptation: A New Intelligent Fault Diagnosis Framework for Industry Application",
    "authors": [
      "Te Han",
      "Chao Liu",
      "Wenguang Yang",
      "Dongxiang Jiang"
    ],
    "author_ids": [],
    "abstract": "In recent years, an increasing popularity of deep learning model for\nintelligent condition monitoring and diagnosis as well as prognostics used for\nmechanical systems and structures has been observed. In the previous studies,\nhowever, a major assumption accepted by default, is that the training and\ntesting data are taking from same feature distribution. Unfortunately, this\nassumption is mostly invalid in real application, resulting in a certain lack\nof applicability for the traditional diagnosis approaches. Inspired by the idea\nof transfer learning that leverages the knowledge learnt from rich labeled data\nin source domain to facilitate diagnosing a new but similar target task, a new\nintelligent fault diagnosis framework, i.e., deep transfer network (DTN), which\ngeneralizes deep learning model to domain adaptation scenario, is proposed in\nthis paper. By extending the marginal distribution adaptation (MDA) to joint\ndistribution adaptation (JDA), the proposed framework can exploit the\ndiscrimination structures associated with the labeled data in source domain to\nadapt the conditional distribution of unlabeled target data, and thus guarantee\na more accurate distribution matching. Extensive empirical evaluations on three\nfault datasets validate the applicability and practicability of DTN, while\nachieving many state-of-the-art transfer results in terms of diverse operating\nconditions, fault severities and fault types.",
    "published_date": "2018-04-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07265v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.06334v3",
    "title": "On $f$-Divergences: Integral Representations, Local Behavior, and Inequalities",
    "authors": [
      "Igal Sason"
    ],
    "author_ids": [],
    "abstract": "This paper is focused on $f$-divergences, consisting of three main\ncontributions. The first one introduces integral representations of a general\n$f$-divergence by means of the relative information spectrum. The second part\nprovides a new approach for the derivation of $f$-divergence inequalities, and\nit exemplifies their utility in the setup of Bayesian binary hypothesis\ntesting. The last part of this paper further studies the local behavior of\n$f$-divergences.",
    "published_date": "2018-04-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06334v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.06081v1",
    "title": "Optimal Multiphase Investment Strategies for Influencing Opinions in a Social Network",
    "authors": [
      "Swapnil Dhamal",
      "Walid Ben-Ameur",
      "Tijani Chahed",
      "Eitan Altman"
    ],
    "author_ids": [],
    "abstract": "We study the problem of optimally investing in nodes of a social network in a\ncompetitive setting, where two camps aim to maximize adoption of their opinions\nby the population. In particular, we consider the possibility of campaigning in\nmultiple phases, where the final opinion of a node in a phase acts as its\ninitial biased opinion for the following phase. Using an extension of the\npopular DeGroot-Friedkin model, we formulate the utility functions of the\ncamps, and show that they involve what can be interpreted as multiphase Katz\ncentrality. Focusing on two phases, we analytically derive Nash equilibrium\ninvestment strategies, and the extent of loss that a camp would incur if it\nacted myopically. Our simulation study affirms that nodes attributing higher\nweightage to initial biases necessitate higher investment in the first phase,\nso as to influence these biases for the terminal phase. We then study the\nsetting in which a camp's influence on a node depends on its initial bias. For\nsingle camp, we present a polynomial time algorithm for determining an optimal\nway to split the budget between the two phases. For competing camps, we show\nthe existence of Nash equilibria under reasonable assumptions, and that they\ncan be computed in polynomial time.",
    "published_date": "2018-04-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06081v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.06034v2",
    "title": "Set-membership NLMS algorithm based on bias-compensated and regression noise variance estimation for noisy inputs",
    "authors": [
      "Kaili Yin",
      "Haiquan Zhao",
      "Lu Lu"
    ],
    "author_ids": [],
    "abstract": "The bias-compensated set-membership normalised LMS (BCSMNLMS) algorithm is\nproposed based on the concept of set-membership filtering, which incorporates\nthe bias-compensation technique to mitigate the negative effect of noisy\ninputs. Moreover, an efficient regression noise variance estimation method is\ndeveloped by taking the iterative-shrinkage method. Simulations in the context\nof system identification demonstrate that the misalignment of the proposed\nBCSM-NLMS algorithm is low for noisy inputs.",
    "published_date": "2018-04-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.06034v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.05560v2",
    "title": "Deep Bayesian Trust : A Dominant and Fair Incentive Mechanism for Crowd",
    "authors": [
      "Naman Goel",
      "Boi Faltings"
    ],
    "author_ids": [],
    "abstract": "An important class of game-theoretic incentive mechanisms for eliciting\neffort from a crowd are the peer based mechanisms, in which workers are paid by\nmatching their answers with one another. The other classic mechanism is to have\nthe workers solve some gold standard tasks and pay them according to their\naccuracy on gold tasks. This mechanism ensures stronger incentive compatibility\nthan the peer based mechanisms but assigning gold tasks to all workers becomes\ninefficient at large scale. We propose a novel mechanism that assigns gold\ntasks to only a few workers and exploits transitivity to derive accuracy of the\nrest of the workers from their peers' accuracy. We show that the resulting\nmechanism ensures a dominant notion of incentive compatibility and fairness.",
    "published_date": "2018-04-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.05560v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.05454v1",
    "title": "A refinement of Bennett's inequality with applications to portfolio optimization",
    "authors": [
      "Tony Jebara"
    ],
    "author_ids": [],
    "abstract": "A refinement of Bennett's inequality is introduced which is strictly tighter\nthan the classical bound. The new bound establishes the convergence of the\naverage of independent random variables to its expected value. It also\ncarefully exploits information about the potentially heterogeneous mean,\nvariance, and ceiling of each random variable. The bound is strictly sharper in\nthe homogeneous setting and very often significantly sharper in the\nheterogeneous setting. The improved convergence rates are obtained by\nleveraging Lambert's W function. We apply the new bound in a portfolio\noptimization setting to allocate a budget across investments with heterogeneous\nreturns.",
    "published_date": "2018-04-16T00:00:00",
    "year": 2018,
    "categories": [
      "math.ST",
      "cs.LG",
      "q-fin.PM",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.05454v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.05420v1",
    "title": "A Weighted Generalization of the Graham-Diaconis Inequality for Ranked List Similarity",
    "authors": [
      "Ali Dasdan"
    ],
    "author_ids": [],
    "abstract": "The Graham-Diaconis inequality shows the equivalence between two well-known\nmethods of measuring the similarity of two given ranked lists of items:\nSpearman's footrule and Kendall's tau. The original inequality assumes\nunweighted items in input lists. In this paper, we first define versions of\nthese methods for weighted items. We then prove a generalization of the\ninequality for the weighted versions.",
    "published_date": "2018-04-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.05420v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.05105v3",
    "title": "Recognizing Visibility Graphs of Polygons with Holes and Internal-External Visibility Graphs of Polygons",
    "authors": [
      "Hossein Boomari",
      "Mojtaba Ostovari",
      "Alireza Zarei"
    ],
    "author_ids": [],
    "abstract": "Visibility graph of a polygon corresponds to its internal diagonals and\nboundary edges. For each vertex on the boundary of the polygon, we have a\nvertex in this graph and if two vertices of the polygon see each other there is\nan edge between their corresponding vertices in the graph. Two vertices of a\npolygon see each other if and only if their connecting line segment completely\nlies inside the polygon, and they are externally visible if and only if this\nline segment completely lies outside the polygon. Recognizing visibility graphs\nis the problem of deciding whether there is a simple polygon whose visibility\ngraph is isomorphic to a given input graph. This problem is well-known and\nwell-studied, but yet widely open in geometric graphs and computational\ngeometry.\n  Existential Theory of the Reals is the complexity class of problems that can\nbe reduced to the problem of deciding whether there exists a solution to a\nquantifier-free formula F(X1,X2,...,Xn), involving equalities and inequalities\nof real polynomials with real variables. The complete problems for this\ncomplexity class are called Existential Theory of the Reals Complete.\n  In this paper we show that recognizing visibility graphs of polygons with\nholes is Existential Theory of the Reals Complete. Moreover, we show that\nrecognizing visibility graphs of simple polygons when we have the internal and\nexternal visibility graphs, is also Existential Theory of the Reals Complete.",
    "published_date": "2018-04-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CG",
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.05105v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.04854v1",
    "title": "Tightly-coupled Monocular Visual-odometric SLAM using Wheels and a MEMS Gyroscope",
    "authors": [
      "Meixiang Quan",
      "Songhao Piao",
      "Minglang Tan",
      "Shi-Sheng Huang"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a novel tightly-coupled probabilistic monocular\nvisual-odometric Simultaneous Localization and Mapping algorithm using wheels\nand a MEMS gyroscope, which can provide accurate, robust and long-term\nlocalization for the ground robot moving on a plane. Firstly, we present an\nodometer preintegration theory that integrates the wheel encoder measurements\nand gyroscope measurements to a local frame. The preintegration theory properly\naddresses the manifold structure of the rotation group SO(3) and carefully\ndeals with uncertainty propagation and bias correction. Then the novel odometer\nerror term is formulated using the odometer preintegration model and it is\ntightly integrated into the visual optimization framework. Furthermore, we\nintroduce a complete tracking framework to provide different strategies for\nmotion tracking when (1) both measurements are available, (2) visual\nmeasurements are not available, and (3) wheel encoder experiences slippage,\nwhich leads the system to be accurate and robust. Finally, the proposed\nalgorithm is evaluated by performing extensive experiments, the experimental\nresults demonstrate the superiority of the proposed system.",
    "published_date": "2018-04-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.04854v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.04314v2",
    "title": "A Large-scale Attribute Dataset for Zero-shot Learning",
    "authors": [
      "Bo Zhao",
      "Yanwei Fu",
      "Rui Liang",
      "Jiahong Wu",
      "Yonggang Wang",
      "Yizhou Wang"
    ],
    "author_ids": [],
    "abstract": "Zero-Shot Learning (ZSL) has attracted huge research attention over the past\nfew years; it aims to learn the new concepts that have never been seen before.\nIn classical ZSL algorithms, attributes are introduced as the intermediate\nsemantic representation to realize the knowledge transfer from seen classes to\nunseen classes. Previous ZSL algorithms are tested on several benchmark\ndatasets annotated with attributes. However, these datasets are defective in\nterms of the image distribution and attribute diversity. In addition, we argue\nthat the \"co-occurrence bias problem\" of existing datasets, which is caused by\nthe biased co-occurrence of objects, significantly hinders models from\ncorrectly learning the concept. To overcome these problems, we propose a\nLarge-scale Attribute Dataset (LAD). Our dataset has 78,017 images of 5\nsuper-classes, 230 classes. The image number of LAD is larger than the sum of\nthe four most popular attribute datasets. 359 attributes of visual, semantic\nand subjective properties are defined and annotated in instance-level. We\nanalyze our dataset by conducting both supervised learning and zero-shot\nlearning tasks. Seven state-of-the-art ZSL algorithms are tested on this new\ndataset. The experimental results reveal the challenge of implementing\nzero-shot learning on our dataset.",
    "published_date": "2018-04-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.04314v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.04215v2",
    "title": "Optimal Unbiased Estimation for Expected Cumulative Cost",
    "authors": [
      "Zhenyu Cui",
      "Michael C. Fu",
      "Yijie Peng",
      "Lingjiong Zhu"
    ],
    "author_ids": [],
    "abstract": "We consider estimating an expected infinite-horizon cumulative discounted\ncost/reward contingent on an underlying stochastic process by Monte Carlo\nsimulation. An unbiased estimator based on truncating the cumulative cost at a\nrandom horizon is proposed. Explicit forms for the optimal distributions of the\nrandom horizon are given, and explicit expressions for the optimal random\ntruncation level are obtained, leading to a full analysis of the bias-variance\ntradeoff when comparing this new class of randomized estimators with\ntraditional fixed truncation estimators. Moreover, we characterize when the\noptimal randomized estimator is preferred over a fixed truncation estimator by\nconsidering the tradeoff between bias and variance. This comparison provides\nguidance on when to choose randomized estimators over fixed truncation\nestimators in practice. Numerical experiments substantiate the theoretical\nresults.",
    "published_date": "2018-04-11T00:00:00",
    "year": 2018,
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.04215v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.04096v1",
    "title": "Analyzing Right-wing YouTube Channels: Hate, Violence and Discrimination",
    "authors": [
      "Raphael Ottoni",
      "Evandro Cunha",
      "Gabriel Magno",
      "Pedro Bernadina",
      "Wagner Meira Jr",
      "Virgilio Almeida"
    ],
    "author_ids": [],
    "abstract": "As of 2018, YouTube, the major online video sharing website, hosts multiple\nchannels promoting right-wing content. In this paper, we observe issues related\nto hate, violence and discriminatory bias in a dataset containing more than\n7,000 videos and 17 million comments. We investigate similarities and\ndifferences between users' comments and video content in a selection of\nright-wing channels and compare it to a baseline set using a three-layered\napproach, in which we analyze (a) lexicon, (b) topics and (c) implicit biases\npresent in the texts. Among other results, our analyses show that right-wing\nchannels tend to (a) contain a higher degree of words from \"negative\" semantic\nfields, (b) raise more topics related to war and terrorism, and (c) demonstrate\nmore discriminatory bias against Muslims (in videos) and towards LGBT people\n(in comments). Our findings shed light not only into the collective conduct of\nthe YouTube community promoting and consuming right-wing content, but also into\nthe general behavior of YouTube users.",
    "published_date": "2018-04-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.04096v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.03946v1",
    "title": "The Evolution of User-Selected Passwords: A Quantitative Analysis of Publicly Available Datasets",
    "authors": [
      "Theodosis Mourouzis",
      "Kyriacos E. Pavlou",
      "Stylianos Kampakis"
    ],
    "author_ids": [],
    "abstract": "The aim of this work is to study the evolution of password selection among\nusers. We investigate whether users follow best practices when selecting\npasswords and identify areas in need of improvement.\n  Four distinct publicly-available password datasets (obtained from security\nbreaches, compiled by security experts, and designated as containing bad\npasswords) are employed. As these datasets were released at different times,\nthe distributions characterizing these datasets suggest a chronological\nevolution of password selection.\n  A similarity metric, Levenshtein distance, is used to compare passwords in\neach dataset against the designated benchmark of bad passwords. The resulting\ndistributions of normalized similarity scores are then compared to each other.\nThe comparison reveals an overall increase in the mean of the similarity\ndistributions corresponding to more recent datasets, implying a shift away from\nthe use of bad passwords.\n  This conclusion is corroborated by the passwords' clustering behavior. An\nencoding capturing best practices maps passwords to a high dimensional space\nover which a $k$-means clustering (with silhouette coefficient) analysis is\nperformed. Cluster comparison and character frequency analysis indicates an\nimprovement in password selection over time with respect to certain features\n(length, mixing character types), yet certain discouraged practices (name\ninclusion, selection bias) still persist.",
    "published_date": "2018-04-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "D.4.6; K.6.5"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.03946v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.03883v1",
    "title": "Active Constraints using Vector Field Inequalities for Surgical Robots",
    "authors": [
      "Murilo M. Marinho",
      "Bruno V. Adorno",
      "Kanako Harada",
      "Mamoru Mitsuishi"
    ],
    "author_ids": [],
    "abstract": "Robotic assistance allows surgeons to perform dexterous and tremor-free\nprocedures, but is still underrepresented in deep brain neurosurgery and\nendonasal surgery where the workspace is constrained. In these conditions, the\nvision of surgeons is restricted to areas near the surgical tool tips, which\nincreases the risk of unexpected collisions between the shafts of the\ninstruments and their surroundings, in particular in areas outside the surgical\nfield-of-view. Active constraints can be used to prevent the tools from\nentering restricted zones and thus avoid collisions. In this paper, a vector\nfield inequality is proposed that guarantees that tools do not enter restricted\nzones. Moreover, in contrast with early techniques, the proposed method limits\nthe tool approach velocity in the direction of the forbidden zone boundary,\nguaranteeing a smooth behavior and that tangential velocities will not be\ndisturbed. The proposed method is evaluated in simulations featuring two eight\ndegrees-of-freedom manipulators that were custom-designed for deep\nneurosurgery. The results show that both manipulator-manipulator and\nmanipulator-boundary collisions can be avoided using the vector field\ninequalities.",
    "published_date": "2018-04-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.03883v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.03581v1",
    "title": "New inequalities for families without k pairwise disjoint members",
    "authors": [
      "Peter Frankl",
      "Andrey Kupavskii"
    ],
    "author_ids": [],
    "abstract": "Some best possible inequalities are established for k-partition-free families\n(cf. Definition 1) and they are applied to prove a sharpening of a classical\nresult of Kleitman concerning families without k pairwise disjoint members.",
    "published_date": "2018-04-10T00:00:00",
    "year": 2018,
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.03581v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.03564v1",
    "title": "Some parametrized dynamic priority policies for 2-class M/G/1 queues: completeness and applications",
    "authors": [
      "Manu K. Gupta",
      "N. Hemachandra",
      "J. Venkateswaran"
    ],
    "author_ids": [],
    "abstract": "Completeness of a dynamic priority scheduling scheme is of fundamental\nimportance for the optimal control of queues in areas as diverse as computer\ncommunications, communication networks, supply chains and manufacturing\nsystems. Our first main contribution is to identify the mean waiting time\ncompleteness as a unifying aspect for four different dynamic priority\nscheduling schemes by proving their completeness and equivalence in 2-class\nM/G/1 queue. These dynamic priority schemes are earliest due date based, head\nof line priority jump, relative priority, and probabilistic priority.\n  In our second main contribution, we characterize the optimal scheduling\npolicies for the case studies in different domains by exploiting the\ncompleteness of above dynamic priority schemes. The major theme of second main\ncontribution is resource allocation/optimal control in revenue management\nproblems for contemporary systems such as cloud computing, high-performance\ncomputing, etc., where congestion is inherent. Using completeness and\ntheoretically tractable nature of relative priority policy, we study the impact\nof approximation in a fairly generic data network utility framework. We\nintroduce the notion of min-max fairness in multi-class queues and show that a\nsimple global FCFS policy is min-max fair. Next, we re-derive the celebrated\n$c/\\rho$ rule for 2-class M/G/1 queues by an elegant argument and also simplify\na complex joint pricing and scheduling problem for a wider class of scheduling\npolicies.",
    "published_date": "2018-04-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.PF"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.03564v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.03116v1",
    "title": "On Analyzing Self-Driving Networks: A Systems Thinking Approach",
    "authors": [
      "Touseef Yaqoob",
      "Muhammad Usama",
      "Junaid Qadir",
      "Gareth Tyson"
    ],
    "author_ids": [],
    "abstract": "The networking field has recently started to incorporate artificial\nintelligence (AI), machine learning (ML), big data analytics combined with\nadvances in networking (such as software-defined networks, network functions\nvirtualization, and programmable data planes) in a bid to construct highly\noptimized self-driving and self-organizing networks. It is worth remembering\nthat the modern Internet that interconnects millions of networks is a `complex\nadaptive social system', in which interventions not only cause effects but the\neffects have further knock-on effects (not all of which are desirable or\nanticipated). We believe that self-driving networks will likely raise new\nunanticipated challenges (particularly in the human-facing domains of ethics,\nprivacy, and security). In this paper, we propose the use of insights and tools\nfrom the field of \"systems thinking\"---a rich discipline developing for more\nthan half a century, which encompasses qualitative and quantitative nonlinear\nmodels of complex social systems---and highlight their relevance for studying\nthe long-term effects of network architectural interventions, particularly for\nself-driving networks. We show that these tools complement existing simulation\nand modeling tools and provide new insights and capabilities. To the best of\nour knowledge, this is the first study that has considered the relevance of\nformal systems thinking tools for the analysis of self-driving networks.",
    "published_date": "2018-04-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.03116v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.02414v1",
    "title": "Higher-Order Nonlinear Complementary Filtering on Lie Groups",
    "authors": [
      "David Evan Zlotnik",
      "James Richard Forbes"
    ],
    "author_ids": [],
    "abstract": "Nonlinear observer design for systems whose state space evolves on Lie groups\nis considered. The proposed method is similar to previously developed nonlinear\nobservers in that it involves propagating the state estimate using a process\nmodel and corrects the propagated state estimate using an innovation term on\nthe tangent space of the Lie group. In the proposed method, the innovation term\nis constructed by passing the gradient of an invariant cost function, resolved\nin a basis of the tangent space, through a linear time-invariant system. The\nintroduction of the linear system completes the extension of linear\ncomplementary filters to nonlinear Lie group observers by allowing higher-order\nfiltering. In practice, the proposed method allows for greater design freedom\nand, with the appropriate selection of the linear filter, the ability to filter\nbias and noise over specific bandwidths. A disturbance observer that accounts\nfor constant and harmonic disturbances in group velocity measurements is also\nconsidered. Local asymptotic stability about the desired equilibrium point is\ndemonstrated. A numerical example that demonstrates the desirable properties of\nthe observer is presented in the context of pose estimation.",
    "published_date": "2018-04-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.02414v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.02386v1",
    "title": "Inferring transportation modes from GPS trajectories using a convolutional neural network",
    "authors": [
      "Sina Dabiri",
      "Kevin Heaslip"
    ],
    "author_ids": [],
    "abstract": "Identifying the distribution of users' transportation modes is an essential\npart of travel demand analysis and transportation planning. With the advent of\nubiquitous GPS-enabled devices (e.g., a smartphone), a cost-effective approach\nfor inferring commuters' mobility mode(s) is to leverage their GPS\ntrajectories. A majority of studies have proposed mode inference models based\non hand-crafted features and traditional machine learning algorithms. However,\nmanual features engender some major drawbacks including vulnerability to\ntraffic and environmental conditions as well as possessing human's bias in\ncreating efficient features. One way to overcome these issues is by utilizing\nConvolutional Neural Network (CNN) schemes that are capable of automatically\ndriving high-level features from the raw input. Accordingly, in this paper, we\ntake advantage of CNN architectures so as to predict travel modes based on only\nraw GPS trajectories, where the modes are labeled as walk, bike, bus, driving,\nand train. Our key contribution is designing the layout of the CNN's input\nlayer in such a way that not only is adaptable with the CNN schemes but\nrepresents fundamental motion characteristics of a moving object including\nspeed, acceleration, jerk, and bearing rate. Furthermore, we ameliorate the\nquality of GPS logs through several data preprocessing steps. Using the clean\ninput layer, a variety of CNN configurations are evaluated to achieve the best\nCNN architecture. The highest accuracy of 84.8% has been achieved through the\nensemble of the best CNN configuration. In this research, we contrast our\nmethodology with traditional machine learning algorithms as well as the seminal\nand most related studies to demonstrate the superiority of our framework.",
    "published_date": "2018-04-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.02386v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.01785v1",
    "title": "Fairness in Multiterminal Data Compression: Decomposition of Shapley Value",
    "authors": [
      "Ni Ding",
      "David Smith",
      "Parastoo Sadeghi",
      "Thierry Rakotoarivelo"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of how to determine a fair source coding rate\nallocation method for the lossless data compression problem in multiterminal\nnetworks, e.g, the wireless sensor network where there are a large number of\nsources to be encoded. We model this problem by a game-theoretic approach and\npresent a decomposition method for obtaining the Shapley value, a fair source\ncoding rate vector in the Slepian-Wolf achievable region. We formulate a\ncoalitional game model where the entropy function quantifies the cost incurred\ndue to the source coding rates in each coalition. In the typical case for which\nthe game is decomposable, we show that the Shapley value can be obtained\nseparately for each subgame. The complexity of this decomposition method is\ndetermined by the maximum size of subgames, which is strictly smaller than the\ntotal number of sources and contributes to a considerable reduction in\ncomputational complexity. Experiments demonstrate large complexity reduction\nwhen the number of sources becomes large.",
    "published_date": "2018-04-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.01785v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.01349v3",
    "title": "The role of geography in the complex diffusion of innovations",
    "authors": [
      "Balázs Lengyel",
      "Eszter Bokányi",
      "Riccardo Di Clemente",
      "János Kertész",
      "Marta C. González"
    ],
    "author_ids": [],
    "abstract": "The urban-rural divide is increasing in modern societies calling for\ngeographical extensions of social influence modelling. Improved understanding\nof innovation diffusion across locations and through social connections can\nprovide us with new insights into the spread of information, technological\nprogress and economic development. In this work, we analyze the spatial\nadoption dynamics of iWiW, an Online Social Network (OSN) in Hungary and\nuncover empirical features about the spatial adoption in social networks.\nDuring its entire life cycle from 2002 to 2012, iWiW reached up to 300 million\nfriendship ties of 3 million users. We find that the number of adopters as a\nfunction of town population follows a scaling law that reveals a strongly\nconcentrated early adoption in large towns and a less concentrated late\nadoption. We also discover a strengthening distance decay of spread over the\nlife-cycle indicating high fraction of distant diffusion in early stages but\nthe dominance of local diffusion in late stages. The spreading process is\nmodelled within the Bass diffusion framework that enables us to compare the\ndifferential equation version with an agent-based version of the model run on\nthe empirical network. Although both models can capture the macro trend of\nadoption, they have limited capacity to describe the observed trends of urban\nscaling and distance decay. We find, however that incorporating adoption\nthresholds, defined by the fraction of social connections that adopt a\ntechnology before the individual adopts, improves the network model fit to the\nurban scaling of early adopters. Controlling for the threshold distribution\nenables us to eliminate the bias induced by local network structure on\npredicting local adoption peaks. Finally, we show that geographical features\nsuch as distance from the innovation origin and town size influence prediction\nof adoption peak at local scales.",
    "published_date": "2018-04-04T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.01349v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.01117v1",
    "title": "Visual Object Categorization Based on Hierarchical Shape Motifs Learned From Noisy Point Cloud Decompositions",
    "authors": [
      "Christian A. Mueller",
      "Andreas Birk"
    ],
    "author_ids": [],
    "abstract": "Object shape is a key cue that contributes to the semantic understanding of\nobjects. In this work we focus on the categorization of real-world object point\nclouds to particular shape types. Therein surface description and\nrepresentation of object shape structure have significant influence on shape\ncategorization accuracy, when dealing with real-world scenes featuring noisy,\npartial and occluded object observations. An unsupervised hierarchical learning\nprocedure is utilized here to symbolically describe surface characteristics on\nmultiple semantic levels. Furthermore, a constellation model is proposed that\nhierarchically decomposes objects. The decompositions are described as\nconstellations of symbols (shape motifs) in a gradual order, hence reflecting\nshape structure from local to global, i.e., from parts over groups of parts to\nentire objects. The combination of this multi-level description of surfaces and\nthe hierarchical decomposition of shapes leads to a representation which allows\nto conceptualize shapes. An object discrimination has been observed in\nexperiments with seven categories featuring instances with sensor noise,\nocclusions as well as inter-category and intra-category similarities.\nExperiments include the evaluation of the proposed description and shape\ndecomposition approach, and comparisons to Fast Point Feature Histograms, a\nVocabulary Tree and a neural network-based Deep Learning method. Furthermore,\nexperiments are conducted with alternative datasets which analyze the\ngeneralization capability of the proposed approach.",
    "published_date": "2018-04-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.01117v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.01044v1",
    "title": "Social versus Moral preferences in the Ultimatum Game: A theoretical model and an experiment",
    "authors": [
      "Valerio Capraro"
    ],
    "author_ids": [],
    "abstract": "In the Ultimatum Game (UG) one player, named \"proposer\", has to decide how to\nallocate a certain amount of money between herself and a \"responder\". If the\noffer is greater than or equal to the responder's minimum acceptable offer\n(MAO), then the money is split as proposed, otherwise, neither the proposer nor\nthe responder get anything. The UG has intrigued generations of behavioral\nscientists because people in experiments blatantly violate the equilibrium\npredictions that self-interested proposers offer the minimum available non-zero\namount, and self-interested responders accept. Why are these predictions\nviolated? Previous research has mainly focused on the role of social\npreferences. Little is known about the role of general moral preferences for\ndoing the right thing, preferences that have been shown to play a major role in\nother social interactions (e.g., Dictator Game and Prisoner's Dilemma). Here I\ndevelop a theoretical model and an experiment designed to pit social\npreferences against moral preferences. I find that, although people recognize\nthat offering half and rejecting low offers are the morally right things to do,\nmoral preferences have no causal impact on UG behavior. The experimental data\nare indeed well fit by a model according to which: (i) high UG offers are\nmotivated by inequity aversion and, to a lesser extent, self-interest; (ii)\nhigh MAOs are motivated by inequity aversion.",
    "published_date": "2018-04-03T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.GT",
      "q-bio.PE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.01044v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.00871v3",
    "title": "Development and Validation of the Japanese Moral Foundations Dictionary",
    "authors": [
      "Akiko Matsuo",
      "Kazutoshi Sasahara",
      "Yasuhiro Taguchi",
      "Minoru Karasawa"
    ],
    "author_ids": [],
    "abstract": "The Moral Foundations Dictionary (MFD) is a useful tool for applying the\nconceptual framework developed in Moral Foundations Theory and quantifying the\nmoral meanings implicated in the linguistic information people convey. However,\nthe applicability of the MFD is limited because it is available only in\nEnglish. Translated versions of the MFD are therefore needed to study morality\nacross various cultures, including non-Western cultures. The contribution of\nthis paper is two-fold. We developed the first Japanese version of the MFD\n(referred to as the J-MFD) by introducing a semi-automated method---this serves\nas a reference when translating the MFD into other languages. We next tested\nthe validity of the J-MFD by analyzing open-ended written texts about the\nsituations that Japanese participants thought followed and violated the five\nmoral foundations. We found that the J-MFD correctly categorized the Japanese\nparticipants' descriptions into the corresponding moral foundations, and that\nthe Moral Foundations Questionnaire (MFQ) scores were correlated with the\nfrequency of situations, of total words, and of J-MFD words in the\nparticipants' descriptions for the Harm and Fairness foundations. The J-MFD can\nbe used to study morality unique to the Japanese and cultural differences in\nmoral behavior.",
    "published_date": "2018-04-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00871v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.00480v2",
    "title": "Tight Revenue Gaps among Simple Mechanisms",
    "authors": [
      "Yaonan Jin",
      "Pinyan Lu",
      "Zhihao Gavin Tang",
      "Tao Xiao"
    ],
    "author_ids": [],
    "abstract": "We consider a fundamental problem in microeconomics: selling a single item to\na number of potential buyers, whose values are drawn from known independent and\nregular (not necessarily identical) distributions. There are four widely-used\nand widely-studied mechanisms in the literature: {\\sf Myerson Auction}~({\\sf\nOPT}), {\\sf Sequential Posted-Pricing}~({\\sf SPM}), {\\sf Second-Price Auction\nwith Anonymous Reserve}~({\\sf AR}), and {\\sf Anonymous Pricing}~({\\sf AP}).\n  {\\sf OPT} is revenue-optimal but complicated, which also experiences several\nissues in practice such as fairness; {\\sf AP} is the simplest mechanism, but\nalso generates the lowest revenue among these four mechanisms; {\\sf SPM} and\n{\\sf AR} are of intermediate complexity and revenue. We explore revenue gaps\namong these mechanisms, each of which is defined as the largest ratio between\nrevenues from a pair of mechanisms. We establish two tight bounds and one\nimproved bound:\n  1. {\\sf SPM} vs.\\ {\\sf AP}: this ratio studies the power of discrimination in\npricing schemes. We obtain the tight ratio of $\\mathcal{C^*} \\approx 2.62$,\nclosing the gap between $\\big[\\frac{e}{e - 1}, e\\big]$ left before.\n  2. {\\sf AR} vs.\\ {\\sf AP}: this ratio measures the relative power of auction\nscheme vs.\\ pricing scheme, when no discrimination is allowed. We attain the\ntight ratio of $\\frac{\\pi^2}{6} \\approx 1.64$, closing the previously known\nbounds $\\big[\\frac{e}{e - 1}, e\\big]$.\n  3. {\\sf OPT} vs.\\ {\\sf AR}: this ratio quantifies the power of discrimination\nin auction schemes, and is previously known to be somewhere between $\\big[2,\ne\\big]$. The lower-bound of $2$ was conjectured to be tight by Hartline and\nRoughgarden (2009) and Alaei et al.\\ (2015). We acquire a better lower-bound of\n$2.15$, and thus disprove this conjecture.",
    "published_date": "2018-04-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00480v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.11560v1",
    "title": "Substitute Teacher Networks: Learning with Almost No Supervision",
    "authors": [
      "Samuel Albanie",
      "James Thewlis",
      "Joao F. Henriques"
    ],
    "author_ids": [],
    "abstract": "Learning through experience is time-consuming, inefficient and often bad for\nyour cortisol levels. To address this problem, a number of recently proposed\nteacher-student methods have demonstrated the benefits of private tuition, in\nwhich a single model learns from an ensemble of more experienced tutors.\nUnfortunately, the cost of such supervision restricts good representations to a\nprivileged minority. Unsupervised learning can be used to lower tuition fees,\nbut runs the risk of producing networks that require extracurriculum learning\nto strengthen their CVs and create their own LinkedIn profiles. Inspired by the\nlogo on a promotional stress ball at a local recruitment fair, we make the\nfollowing three contributions. First, we propose a novel almost no supervision\ntraining algorithm that is effective, yet highly scalable in the number of\nstudent networks being supervised, ensuring that education remains affordable.\nSecond, we demonstrate our approach on a typical use case: learning to bake,\ndeveloping a method that tastily surpasses the current state of the art.\nFinally, we provide a rigorous quantitive analysis of our method, proving that\nwe have access to a calculator. Our work calls into question the long-held\ndogma that life is the best teacher.",
    "published_date": "2018-04-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.11560v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.00206v2",
    "title": "Symbolic Algorithms for Graphs and Markov Decision Processes with Fairness Objectives",
    "authors": [
      "Krishnendu Chatterjee",
      "Monika Henzinger",
      "Veronika Loitzenbauer",
      "Simin Oraee",
      "Viktor Toman"
    ],
    "author_ids": [],
    "abstract": "Given a model and a specification, the fundamental model-checking problem\nasks for algorithmic verification of whether the model satisfies the\nspecification. We consider graphs and Markov decision processes (MDPs), which\nare fundamental models for reactive systems. One of the very basic\nspecifications that arise in verification of reactive systems is the strong\nfairness (aka Streett) objective. Given different types of requests and\ncorresponding grants, the objective requires that for each type, if the request\nevent happens infinitely often, then the corresponding grant event must also\nhappen infinitely often. All $\\omega$-regular objectives can be expressed as\nStreett objectives and hence they are canonical in verification. To handle the\nstate-space explosion, symbolic algorithms are required that operate on a\nsuccinct implicit representation of the system rather than explicitly accessing\nthe system. While explicit algorithms for graphs and MDPs with Streett\nobjectives have been widely studied, there has been no improvement of the basic\nsymbolic algorithms. The worst-case numbers of symbolic steps required for the\nbasic symbolic algorithms are as follows: quadratic for graphs and cubic for\nMDPs. In this work we present the first sub-quadratic symbolic algorithm for\ngraphs with Streett objectives, and our algorithm is sub-quadratic even for\nMDPs. Based on our algorithmic insights we present an implementation of the new\nsymbolic approach and show that it improves the existing approach on several\nacademic benchmark examples.",
    "published_date": "2018-03-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00206v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.00084v1",
    "title": "Characterizing Interconnections and Linguistic Patterns in Twitter",
    "authors": [
      "Johnnatan Messias"
    ],
    "author_ids": [],
    "abstract": "Social media is considered a democratic space in which people connect and\ninteract with each other regardless of their gender, race, or any other\ndemographic aspect. Despite numerous efforts that explore demographic aspects\nin social media, it is still unclear whether social media perpetuates old\ninequalities from the offline world. In this dissertation, we attempt to\nidentify gender and race of Twitter users located in the United States using\nadvanced image processing algorithms from Face++. We investigate how different\ndemographic groups connect with each other and differentiate them regarding\nlinguistic styles and also their interests. We quantify to what extent one\ngroup follows and interacts with each other and the extent to which these\nconnections and interactions reflect in inequalities in Twitter. We also\nextract linguistic features from six categories (affective attributes,\ncognitive attributes, lexical density and awareness, temporal references,\nsocial and personal concerns, and interpersonal focus) in order to identify the\nsimilarities and the differences in the messages they share in Twitter.\nFurthermore, we extract the absolute ranking difference of top phrases between\ndemographic groups. As a dimension of diversity, we use the topics of interest\nthat we retrieve from each user. Our analysis shows that users identified as\nwhite and male tend to attain higher positions, in terms of the number of\nfollowers and number of times in another user's lists, in Twitter. There are\nclear differences in the way of writing across different demographic groups in\nboth gender and race domains as well as in the topic of interest. We hope our\neffort can stimulate the development of new theories of demographic information\nin the online space. Finally, we developed a Web-based system that leverages\nthe demographic aspects of users to provide transparency to the Twitter\ntrending topics system.",
    "published_date": "2018-03-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00084v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.11550v1",
    "title": "Multi-modal Disease Classification in Incomplete Datasets Using Geometric Matrix Completion",
    "authors": [
      "Gerome Vivar",
      "Andreas Zwergal",
      "Nassir Navab",
      "Seyed-Ahmad Ahmadi"
    ],
    "author_ids": [],
    "abstract": "In large population-based studies and in clinical routine, tasks like disease\ndiagnosis and progression prediction are inherently based on a rich set of\nmulti-modal data, including imaging and other sensor data, clinical scores,\nphenotypes, labels and demographics. However, missing features, rater bias and\ninaccurate measurements are typical ailments of real-life medical datasets.\nRecently, it has been shown that deep learning with graph convolution neural\nnetworks (GCN) can outperform traditional machine learning in disease\nclassification, but missing features remain an open problem. In this work, we\nfollow up on the idea of modeling multi-modal disease classification as a\nmatrix completion problem, with simultaneous classification and non-linear\nimputation of features. Compared to methods before, we arrange subjects in a\ngraph-structure and solve classification through geometric matrix completion,\nwhich simulates a heat diffusion process that is learned and solved with a\nrecurrent neural network. We demonstrate the potential of this method on the\nADNI-based TADPOLE dataset and on the task of predicting the transition from\nMCI to Alzheimer's disease. With an AUC of 0.950 and classification accuracy of\n87%, our approach outperforms standard linear and non-linear classifiers, as\nwell as several state-of-the-art results in related literature, including a\nrecently proposed GCN-based approach.",
    "published_date": "2018-03-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.11550v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.11320v1",
    "title": "Transductive Unbiased Embedding for Zero-Shot Learning",
    "authors": [
      "Jie Song",
      "Chengchao Shen",
      "Yezhou Yang",
      "Yang Liu",
      "Mingli Song"
    ],
    "author_ids": [],
    "abstract": "Most existing Zero-Shot Learning (ZSL) methods have the strong bias problem,\nin which instances of unseen (target) classes tend to be categorized as one of\nthe seen (source) classes. So they yield poor performance after being deployed\nin the generalized ZSL settings. In this paper, we propose a straightforward\nyet effective method named Quasi-Fully Supervised Learning (QFSL) to alleviate\nthe bias problem. Our method follows the way of transductive learning, which\nassumes that both the labeled source images and unlabeled target images are\navailable for training. In the semantic embedding space, the labeled source\nimages are mapped to several fixed points specified by the source categories,\nand the unlabeled target images are forced to be mapped to other points\nspecified by the target categories. Experiments conducted on AwA2, CUB and SUN\ndatasets demonstrate that our method outperforms existing state-of-the-art\napproaches by a huge margin of 9.3~24.5% following generalized ZSL settings,\nand by a large margin of 0.2~16.2% following conventional ZSL settings.",
    "published_date": "2018-03-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.11320v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.11266v1",
    "title": "Performance evaluation and hyperparameter tuning of statistical and machine-learning models using spatial data",
    "authors": [
      "Patrick Schratz",
      "Jannes Muenchow",
      "Eugenia Iturritxa",
      "Jakob Richter",
      "Alexander Brenning"
    ],
    "author_ids": [],
    "abstract": "Machine-learning algorithms have gained popularity in recent years in the\nfield of ecological modeling due to their promising results in predictive\nperformance of classification problems. While the application of such\nalgorithms has been highly simplified in the last years due to their\nwell-documented integration in commonly used statistical programming languages\nsuch as R, there are several practical challenges in the field of ecological\nmodeling related to unbiased performance estimation, optimization of algorithms\nusing hyperparameter tuning and spatial autocorrelation. We address these\nissues in the comparison of several widely used machine-learning algorithms\nsuch as Boosted Regression Trees (BRT), k-Nearest Neighbor (WKNN), Random\nForest (RF) and Support Vector Machine (SVM) to traditional parametric\nalgorithms such as logistic regression (GLM) and semi-parametric ones like\ngeneralized additive models (GAM). Different nested cross-validation methods\nincluding hyperparameter tuning methods are used to evaluate model performances\nwith the aim to receive bias-reduced performance estimates. As a case study the\nspatial distribution of forest disease Diplodia sapinea in the Basque Country\nin Spain is investigated using common environmental variables such as\ntemperature, precipitation, soil or lithology as predictors. Results show that\nGAM and RF (mean AUROC estimates 0.708 and 0.699) outperform all other methods\nin predictive accuracy. The effect of hyperparameter tuning saturates at around\n50 iterations for this data set. The AUROC differences between the bias-reduced\n(spatial cross-validation) and overoptimistic (non-spatial cross-validation)\nperformance estimates of the GAM and RF are 0.167 (24%) and 0.213 (30%),\nrespectively. It is recommended to also use spatial partitioning for\ncross-validation hyperparameter tuning of spatial data.",
    "published_date": "2018-03-29T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.11266v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.10892v1",
    "title": "Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks",
    "authors": [
      "Agrim Gupta",
      "Justin Johnson",
      "Li Fei-Fei",
      "Silvio Savarese",
      "Alexandre Alahi"
    ],
    "author_ids": [],
    "abstract": "Understanding human motion behavior is critical for autonomous moving\nplatforms (like self-driving cars and social robots) if they are to navigate\nhuman-centric environments. This is challenging because human motion is\ninherently multimodal: given a history of human motion paths, there are many\nsocially plausible ways that people could move in the future. We tackle this\nproblem by combining tools from sequence prediction and generative adversarial\nnetworks: a recurrent sequence-to-sequence model observes motion histories and\npredicts future behavior, using a novel pooling mechanism to aggregate\ninformation across people. We predict socially plausible futures by training\nadversarially against a recurrent discriminator, and encourage diverse\npredictions with a novel variety loss. Through experiments on several datasets\nwe demonstrate that our approach outperforms prior work in terms of accuracy,\nvariety, collision avoidance, and computational complexity.",
    "published_date": "2018-03-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.10892v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.10329v1",
    "title": "Gender Bias in Sharenting: Both Men and Women Mention Sons More Often Than Daughters on Social Media",
    "authors": [
      "Elizaveta Sivak",
      "Ivan Smirnov"
    ],
    "author_ids": [],
    "abstract": "Gender inequality starts before birth. Parents tend to prefer boys over\ngirls, which is manifested in reproductive behavior, marital life, and parents'\npastimes and investments in their children. While social media and sharing\ninformation about children (so-called \"sharenting\") have become an integral\npart of parenthood, it is not well-known if and how gender preference shapes\nonline behavior of users. In this paper, we investigate public mentions of\ndaughters and sons on social media. We use data from a popular social\nnetworking site on public posts from 635,665 users. We find that both men and\nwomen mention sons more often than daughters in their posts. We also find that\nposts featuring sons get more \"likes\" on average. Our results indicate that\ngirls are underrepresented in parents' digital narratives about their children.\nThis gender imbalance may send a message that girls are less important than\nboys, or that they deserve less attention, thus reinforcing gender inequality.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.10329v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.10124v4",
    "title": "Sampling the News Producers: A Large News and Feature Data Set for the Study of the Complex Media Landscape",
    "authors": [
      "Benjamin D. Horne",
      "William Dron",
      "Sara Khedr",
      "Sibel Adali"
    ],
    "author_ids": [],
    "abstract": "The complexity and diversity of today's media landscape provides many\nchallenges for researchers studying news producers. These producers use many\ndifferent strategies to get their message believed by readers through the\nwriting styles they employ, by repetition across different media sources with\nor without attribution, as well as other mechanisms that are yet to be studied\ndeeply. To better facilitate systematic studies in this area, we present a\nlarge political news data set, containing over 136K news articles, from 92 news\nsources, collected over 7 months of 2017. These news sources are carefully\nchosen to include well-established and mainstream sources, maliciously fake\nsources, satire sources, and hyper-partisan political blogs. In addition to\neach article we compute 130 content-based and social media engagement features\ndrawn from a wide range of literature on political bias, persuasion, and\nmisinformation. With the release of the data set, we also provide the source\ncode for feature computation. In this paper, we discuss the first release of\nthe data set and demonstrate 4 use cases of the data and features: news\ncharacterization, engagement characterization, news attribution and content\ncopying, and discovering news narratives.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.10124v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.10016v1",
    "title": "Cross-validation in high-dimensional spaces: a lifeline for least-squares models and multi-class LDA",
    "authors": [
      "Matthias S. Treder"
    ],
    "author_ids": [],
    "abstract": "Least-squares models such as linear regression and Linear Discriminant\nAnalysis (LDA) are amongst the most popular statistical learning techniques.\nHowever, since their computation time increases cubically with the number of\nfeatures, they are inefficient in high-dimensional neuroimaging datasets.\nFortunately, for k-fold cross-validation, an analytical approach has been\ndeveloped that yields the exact cross-validated predictions in least-squares\nmodels without explicitly training the model. Its computation time grows with\nthe number of test samples. Here, this approach is systematically investigated\nin the context of cross-validation and permutation testing. LDA is used\nexemplarily but results hold for all other least-squares methods. Furthermore,\na non-trivial extension to multi-class LDA is formally derived. The analytical\napproach is evaluated using complexity calculations, simulations, and\npermutation testing of an EEG/MEG dataset. Depending on the ratio between\nfeatures and samples, the analytical approach is up to 10,000x faster than the\nstandard approach (retraining the model on each training set). This allows for\na fast cross-validation of least-squares models and multi-class LDA in\nhigh-dimensional data, with obvious applications in multi-dimensional datasets,\nRepresentational Similarity Analysis, and permutation testing.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.10016v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.09967v1",
    "title": "Reinforcement Learning for Fair Dynamic Pricing",
    "authors": [
      "Roberto Maestre",
      "Juan Duque",
      "Alberto Rubio",
      "Juan Arévalo"
    ],
    "author_ids": [],
    "abstract": "Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09967v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.09930v3",
    "title": "Worst-Case Optimal Join Algorithms: Techniques, Results, and Open Problems",
    "authors": [
      "Hung Q. Ngo"
    ],
    "author_ids": [],
    "abstract": "Worst-case optimal join algorithms are the class of join algorithms whose\nruntime match the worst-case output size of a given join query. While the first\nprovably worst-case optimal join algorithm was discovered relatively recently,\nthe techniques and results surrounding these algorithms grow out of decades of\nresearch from a wide range of areas, intimately connecting graph theory,\nalgorithms, information theory, constraint satisfaction, database theory, and\ngeometric inequalities. These ideas are not just paperware: in addition to\nacademic project implementations, two variations of such algorithms are the\nwork-horse join algorithms of commercial database and data analytics engines.\n  This paper aims to be a brief introduction to the design and analysis of\nworst-case optimal join algorithms. We discuss the key techniques for proving\nruntime and output size bounds. We particularly focus on the fascinating\nconnection between join algorithms and information theoretic inequalities, and\nthe idea of how one can turn a proof into an algorithm. Finally, we conclude\nwith a representative list of fundamental open problems in this area.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09930v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.09928v4",
    "title": "Entropy based Independent Learning in Anonymous Multi-Agent Settings",
    "authors": [
      "Tanvi Verma",
      "Pradeep Varakantham",
      "Hoong Chuin Lau"
    ],
    "author_ids": [],
    "abstract": "Efficient sequential matching of supply and demand is a problem of interest\nin many online to offline services. For instance, Uber, Lyft, Grab for matching\ntaxis to customers; Ubereats, Deliveroo, FoodPanda etc for matching restaurants\nto customers. In these online to offline service problems, individuals who are\nresponsible for supply (e.g., taxi drivers, delivery bikes or delivery van\ndrivers) earn more by being at the \"right\" place at the \"right\" time. We are\ninterested in developing approaches that learn to guide individuals to be in\nthe \"right\" place at the \"right\" time (to maximize revenue) in the presence of\nother similar \"learning\" individuals and only local aggregated observation of\nother agents states (e.g., only number of other taxis in same zone as current\nagent).\n  A key characteristic of the domains of interest is that the interactions\nbetween individuals are anonymous, i.e., the outcome of an interaction\n(competing for demand) is dependent only on the number and not on the identity\nof the agents. We model these problems using the Anonymous MARL (AyMARL) model.\nThe key contribution of this paper is in employing principle of maximum entropy\nto provide a general framework of independent learning that is both empirically\neffective (even with only local aggregated information of agent population\ndistribution) and theoretically justified.\n  Finally, our approaches provide a significant improvement with respect to\njoint and individual revenue on a generic simulator for online to offline\nservices and a real world taxi problem over existing approaches. More\nimportantly, this is achieved while having the least variance in revenues\nearned by the learning individuals, an indicator of fairness.",
    "published_date": "2018-03-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09928v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.09797v4",
    "title": "Women also Snowboard: Overcoming Bias in Captioning Models",
    "authors": [
      "Kaylee Burns",
      "Lisa Anne Hendricks",
      "Kate Saenko",
      "Trevor Darrell",
      "Anna Rohrbach"
    ],
    "author_ids": [],
    "abstract": "Most machine learning methods are known to capture and exploit biases of the\ntraining data. While some biases are beneficial for learning, others are\nharmful. Specifically, image captioning models tend to exaggerate biases\npresent in training data (e.g., if a word is present in 60% of training\nsentences, it might be predicted in 70% of sentences at test time). This can\nlead to incorrect captions in domains where unbiased captions are desired, or\nrequired, due to over-reliance on the learned prior and image context. In this\nwork we investigate generation of gender-specific caption words (e.g. man,\nwoman) based on the person's appearance or the image context. We introduce a\nnew Equalizer model that ensures equal gender probability when gender evidence\nis occluded in a scene and confident predictions when gender evidence is\npresent. The resulting model is forced to look at a person rather than use\ncontextual cues to make a gender-specific predictions. The losses that comprise\nour model, the Appearance Confusion Loss and the Confident Loss, are general,\nand can be added to any description model in order to mitigate impacts of\nunwanted bias in a description dataset. Our proposed model has lower error than\nprior work when describing images with people and mentioning their gender and\nmore closely matches the ground truth ratio of sentences including women to\nsentences including men. We also show that unlike other approaches, our model\nis indeed more often looking at people when predicting their gender.",
    "published_date": "2018-03-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09797v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.09792v1",
    "title": "Min-Max Tours for Task Allocation to Heterogeneous Agents",
    "authors": [
      "Amritha Prasad",
      "Han-Lim Choi",
      "Shreyas Sundaram"
    ],
    "author_ids": [],
    "abstract": "We consider a scenario consisting of a set of heterogeneous mobile agents\nlocated at a depot, and a set of tasks dispersed over a geographic area. The\nagents are partitioned into different types. The tasks are partitioned into\nspecialized tasks that can only be done by agents of a certain type, and\ngeneric tasks that can be done by any agent. The distances between each pair of\ntasks are specified, and satisfy the triangle inequality. Given this scenario,\nwe address the problem of allocating these tasks among the available agents\n(subject to type compatibility constraints) while minimizing the maximum cost\nto tour the allocation by any agent and return to the depot. This problem is\nNP-hard, and we give a three phase algorithm to solve this problem that\nprovides 5-factor approximation, regardless of the total number of agents and\nthe number of agents of each type. We also show that in the special case where\nthere is only one agent of each type, the algorithm has an approximation factor\nof 4.",
    "published_date": "2018-03-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.RO",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09792v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.09375v2",
    "title": "Correcting differences in multi-site neuroimaging data using Generative Adversarial Networks",
    "authors": [
      "Harrison Nguyen",
      "Richard W. Morris",
      "Anthony W. Harris",
      "Mayuresh S. Korgoankar",
      "Fabio Ramos"
    ],
    "author_ids": [],
    "abstract": "Magnetic Resonance Imaging (MRI) of the brain has been used to investigate a\nwide range of neurological disorders, but data acquisition can be expensive,\ntime-consuming, and inconvenient. Multi-site studies present a valuable\nopportunity to advance research by pooling data in order to increase\nsensitivity and statistical power. However images derived from MRI are\nsusceptible to both obvious and non-obvious differences between sites which can\nintroduce bias and subject variance, and so reduce statistical power. To\nrectify these differences, we propose a data driven approach using a deep\nlearning architecture known as generative adversarial networks (GANs). GANs\nlearn to estimate two distributions, and can then be used to transform examples\nfrom one distribution into the other distribution. Here we transform\nT1-weighted brain images collected from two different sites into MR images from\nthe same site. We evaluate whether our model can reduce site-specific\ndifferences without loss of information related to gender (male, female) or\nclinical diagnosis (schizophrenia, bipolar disorder, healthy). When trained\nappropriately, our model is able to normalise imaging sets to a common scanner\nset with less information loss compared to current approaches. An important\nadvantage is our method can be treated as a black box that does not require any\nknowledge of the sources of bias but only needs at least two distinct imaging\nsets.",
    "published_date": "2018-03-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.09375v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.10219v1",
    "title": "Learning Environmental Sounds with Multi-scale Convolutional Neural Network",
    "authors": [
      "Boqing Zhu",
      "Changjian Wang",
      "Feng Liu",
      "Jin Lei",
      "Zengquan Lu",
      "Yuxing Peng"
    ],
    "author_ids": [],
    "abstract": "Deep learning has dramatically improved the performance of sounds\nrecognition. However, learning acoustic models directly from the raw waveform\nis still challenging. Current waveform-based models generally use time-domain\nconvolutional layers to extract features. The features extracted by single size\nfilters are insufficient for building discriminative representation of audios.\nIn this paper, we propose multi-scale convolution operation, which can get\nbetter audio representation by improving the frequency resolution and learning\nfilters cross all frequency area. For leveraging the waveform-based features\nand spectrogram-based features in a single model, we introduce two-phase method\nto fuse the different features. Finally, we propose a novel end-to-end network\ncalled WaveMsNet based on the multi-scale convolution operation and two-phase\nmethod. On the environmental sounds classification datasets ESC-10 and ESC-50,\nthe classification accuracies of our WaveMsNet achieve 93.75% and 79.10%\nrespectively, which improve significantly from the previous methods.",
    "published_date": "2018-03-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.10219v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.08884v3",
    "title": "Inequity aversion improves cooperation in intertemporal social dilemmas",
    "authors": [
      "Edward Hughes",
      "Joel Z. Leibo",
      "Matthew G. Phillips",
      "Karl Tuyls",
      "Edgar A. Duéñez-Guzmán",
      "Antonio García Castañeda",
      "Iain Dunning",
      "Tina Zhu",
      "Kevin R. McKee",
      "Raphael Koster",
      "Heather Roff",
      "Thore Graepel"
    ],
    "author_ids": [],
    "abstract": "Groups of humans are often able to find ways to cooperate with one another in\ncomplex, temporally extended social dilemmas. Models based on behavioral\neconomics are only able to explain this phenomenon for unrealistic stateless\nmatrix games. Recently, multi-agent reinforcement learning has been applied to\ngeneralize social dilemma problems to temporally and spatially extended Markov\ngames. However, this has not yet generated an agent that learns to cooperate in\nsocial dilemmas as humans do. A key insight is that many, but not all, human\nindividuals have inequity averse social preferences. This promotes a particular\nresolution of the matrix game social dilemma wherein inequity-averse\nindividuals are personally pro-social and punish defectors. Here we extend this\nidea to Markov games and show that it promotes cooperation in several types of\nsequential social dilemma, via a profitable interaction with policy\nlearnability. In particular, we find that inequity aversion improves temporal\ncredit assignment for the important class of intertemporal social dilemmas.\nThese results help explain how large-scale cooperation may emerge and persist.",
    "published_date": "2018-03-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.GT",
      "cs.MA",
      "q-bio.PE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08884v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.08823v3",
    "title": "A high-bias, low-variance introduction to Machine Learning for physicists",
    "authors": [
      "Pankaj Mehta",
      "Marin Bukov",
      "Ching-Hao Wang",
      "Alexandre G. R. Day",
      "Clint Richardson",
      "Charles K. Fisher",
      "David J. Schwab"
    ],
    "author_ids": [],
    "abstract": "Machine Learning (ML) is one of the most exciting and dynamic areas of modern\nresearch and application. The purpose of this review is to provide an\nintroduction to the core concepts and tools of machine learning in a manner\neasily understood and intuitive to physicists. The review begins by covering\nfundamental concepts in ML and modern statistics such as the bias-variance\ntradeoff, overfitting, regularization, generalization, and gradient descent\nbefore moving on to more advanced topics in both supervised and unsupervised\nlearning. Topics covered in the review include ensemble models, deep learning\nand neural networks, clustering and data visualization, energy-based models\n(including MaxEnt models and Restricted Boltzmann Machines), and variational\nmethods. Throughout, we emphasize the many natural connections between ML and\nstatistical physics. A notable aspect of the review is the use of Python\nJupyter notebooks to introduce modern ML/statistical packages to readers using\nphysics-inspired datasets (the Ising Model and Monte-Carlo simulations of\nsupersymmetric decays of proton-proton collisions). We conclude with an\nextended outlook discussing possible uses of machine learning for furthering\nour understanding of the physical world as well as open problems in ML where\nphysicists may be able to contribute. (Notebooks are available at\nhttps://physics.bu.edu/~pankajm/MLnotebooks.html )",
    "published_date": "2018-03-23T00:00:00",
    "year": 2018,
    "categories": [
      "physics.comp-ph",
      "cond-mat.stat-mech",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08823v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.08634v2",
    "title": "Joint Head Selection and Airtime Allocation for Data Dissemination in Mobile Social Networks",
    "authors": [
      "Zhifei Mao",
      "Yuming Jiang",
      "Xiaoqiang Di",
      "Yordanos Woldeyohannes"
    ],
    "author_ids": [],
    "abstract": "Mobile social networks (MSNs) enable people with similar interests to\ninteract without Internet access. By forming a temporary group, users can\ndisseminate their data to other interested users in proximity with short-range\ncommunication technologies. However, due to user mobility, airtime available\nfor users in the same group to disseminate data is limited. In addition, for\npractical consideration, a star network topology among users in the group is\nexpected. For the former, unfair airtime allocation among the users will\nundermine their willingness to participate in MSNs. For the latter, a group\nhead is required to connect other users. These two problems have to be properly\naddressed to enable real implementation and adoption of MSNs. To this aim, we\npropose a Nash bargaining-based joint head selection and airtime allocation\nscheme for data dissemination within the group. Specifically, the bargaining\ngame of joint head selection and airtime allocation is first formulated. Then,\nNash bargaining solution (NBS) based optimization problems are proposed for a\nhomogeneous case and a more general heterogeneous case. For both cases, the\nexistence of solution to the optimization problem is proved, which guarantees\nPareto optimality and proportional fairness. Next, an algorithm, allowing\ndistributed implementation, for join head selection and airtime allocation is\nintroduced. Finally, numerical results are presented to evaluate the\nperformance, validate intuitions and derive insights of the proposed scheme.",
    "published_date": "2018-03-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08634v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.08579v1",
    "title": "The Roots of Bias on Uber",
    "authors": [
      "Benjamin V. Hanrahan",
      "Ning F. Ma",
      "Chien Wen Yuan"
    ],
    "author_ids": [],
    "abstract": "In the last decade, there has been a growth in, what we call, digitally\nmediated workplaces. A digitally mediated workplace is one where interactions\nbetween stakeholders are primarily managed by proprietary, algorithmically\nmanaged digital platform. The replacement of the relationships between the\nstakeholders by the platform is a key feature of these workplaces, and is a\ncontributing factor to the decrease in contractual responsibilities each\nstakeholder has to one another. In this paper, we discuss some of the ways in\nwhich this structure and lack of accountability serves as a root of, or at\nleast an enabler to, the realization of biases in the ridesharing application\nUber, a digitally mediated workplace.",
    "published_date": "2018-03-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08579v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.08103v2",
    "title": "A Unified Framework for Multi-View Multi-Class Object Pose Estimation",
    "authors": [
      "Chi Li",
      "Jin Bai",
      "Gregory D. Hager"
    ],
    "author_ids": [],
    "abstract": "One core challenge in object pose estimation is to ensure accurate and robust\nperformance for large numbers of diverse foreground objects amidst complex\nbackground clutter. In this work, we present a scalable framework for\naccurately inferring six Degree-of-Freedom (6-DoF) pose for a large number of\nobject classes from single or multiple views. To learn discriminative pose\nfeatures, we integrate three new capabilities into a deep Convolutional Neural\nNetwork (CNN): an inference scheme that combines both classification and pose\nregression based on a uniform tessellation of the Special Euclidean group in\nthree dimensions (SE(3)), the fusion of class priors into the training process\nvia a tiled class map, and an additional regularization using deep supervision\nwith an object mask. Further, an efficient multi-view framework is formulated\nto address single-view ambiguity. We show that this framework consistently\nimproves the performance of the single-view network. We evaluate our method on\nthree large-scale benchmarks: YCB-Video, JHUScene-50 and ObjectNet-3D. Our\napproach achieves competitive or superior performance over the current\nstate-of-the-art methods.",
    "published_date": "2018-03-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08103v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.08010v2",
    "title": "Social Media Would Not Lie: Prediction of the 2016 Taiwan Election via Online Heterogeneous Data",
    "authors": [
      "Zheng Xie",
      "Guannan Liu",
      "Junjie Wu",
      "Yong Tan"
    ],
    "author_ids": [],
    "abstract": "The prevalence of online media has attracted researchers from various domains\nto explore human behavior and make interesting predictions. In this research,\nwe leverage heterogeneous social media data collected from various online\nplatforms to predict Taiwan's 2016 presidential election. In contrast to most\nexisting research, we take a \"signal\" view of heterogeneous information and\nadopt the Kalman filter to fuse multiple signals into daily vote predictions\nfor the candidates. We also consider events that influenced the election in a\nquantitative manner based on the so-called event study model that originated in\nthe field of financial research. We obtained the following interesting\nfindings. First, public opinions in online media dominate traditional polls in\nTaiwan election prediction in terms of both predictive power and timeliness.\nBut offline polls can still function on alleviating the sample bias of online\nopinions. Second, although online signals converge as election day approaches,\nthe simple Facebook \"Like\" is consistently the strongest indicator of the\nelection result. Third, most influential events have a strong connection to\ncross-strait relations, and the Chou Tzu-yu flag incident followed by the\napology video one day before the election increased the vote share of Tsai\nIng-Wen by 3.66%. This research justifies the predictive power of online media\nin politics and the advantages of information fusion. The combined use of the\nKalman filter and the event study method contributes to the data-driven\npolitical analytics paradigm for both prediction and attribution purposes.",
    "published_date": "2018-03-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "stat.AP",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08010v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.08000v3",
    "title": "Boosting Random Forests to Reduce Bias; One-Step Boosted Forest and its Variance Estimate",
    "authors": [
      "Indrayudh Ghosal",
      "Giles Hooker"
    ],
    "author_ids": [],
    "abstract": "In this paper we propose using the principle of boosting to reduce the bias\nof a random forest prediction in the regression setting. From the original\nrandom forest fit we extract the residuals and then fit another random forest\nto these residuals. We call the sum of these two random forests a\n\\textit{one-step boosted forest}. We show with simulated and real data that the\none-step boosted forest has a reduced bias compared to the original random\nforest. The paper also provides a variance estimate of the one-step boosted\nforest by an extension of the infinitesimal Jackknife estimator. Using this\nvariance estimate we can construct prediction intervals for the boosted forest\nand we show that they have good coverage probabilities. Combining the bias\nreduction and the variance estimate we show that the one-step boosted forest\nhas a significant reduction in predictive mean squared error and thus an\nimprovement in predictive performance. When applied on datasets from the UCI\ndatabase, one-step boosted forest performs better than random forest and\ngradient boosting machine algorithms. Theoretically we can also extend such a\nboosting process to more than one step and the same principles outlined in this\npaper can be used to find variance estimates for such predictors. Such boosting\nwill reduce bias even further but it risks over-fitting and also increases the\ncomputational burden.",
    "published_date": "2018-03-21T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.08000v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.07739v1",
    "title": "Assessing Shape Bias Property of Convolutional Neural Networks",
    "authors": [
      "Hossein Hosseini",
      "Baicen Xiao",
      "Mayoore Jaiswal",
      "Radha Poovendran"
    ],
    "author_ids": [],
    "abstract": "It is known that humans display \"shape bias\" when classifying new items,\ni.e., they prefer to categorize objects based on their shape rather than color.\nConvolutional Neural Networks (CNNs) are also designed to take into account the\nspatial structure of image data. In fact, experiments on image datasets,\nconsisting of triples of a probe image, a shape-match and a color-match, have\nshown that one-shot learning models display shape bias as well.\n  In this paper, we examine the shape bias property of CNNs. In order to\nconduct large scale experiments, we propose using the model accuracy on images\nwith reversed brightness as a metric to evaluate the shape bias property. Such\nimages, called negative images, contain objects that have the same shape as\noriginal images, but with different colors. Through extensive systematic\nexperiments, we investigate the role of different factors, such as training\ndata, model architecture, initialization and regularization techniques, on the\nshape bias property of CNNs. We show that it is possible to design different\nCNNs that achieve similar accuracy on original images, but perform\nsignificantly different on negative images, suggesting that CNNs do not\nintrinsically display shape bias. We then show that CNNs are able to learn and\ngeneralize the structures, when the model is properly initialized or data is\nproperly augmented, and if batch normalization is used.",
    "published_date": "2018-03-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.07739v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.07517v2",
    "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges",
    "authors": [
      "Gabrielle Ras",
      "Marcel van Gerven",
      "Pim Haselager"
    ],
    "author_ids": [],
    "abstract": "Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.",
    "published_date": "2018-03-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "68-02"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.07517v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.07506v1",
    "title": "Ideas from Developmental Robotics and Embodied AI on the Questions of Ethics in Robots",
    "authors": [
      "Alexandre Pitti"
    ],
    "author_ids": [],
    "abstract": "Advances in Artificial Intelligence and robotics are currently questioning\ntheethical framework of their applications to deal with potential drifts, as\nwell as the way inwhich these algorithms learn because they will have a strong\nimpact on the behavior ofrobots and the type of robots. interactions with\npeople. We would like to highlight someprinciples and ideas from cognitive\nneuroscience and development sciences based on theimportance of the body for\nintelligence, contrary to the theory of the all-brain or all-algorithm, to\nrepresent the world and interacting with others, and their current\napplicationsin embodied AI and developmental robotics to propose models of\narchitectures andmechanisms for agency, representation of the body, recognition\nof the intention of others,predictive coding, active inference, the role of\nfeedback and error, imitation, artificialcuriosity and contextual learning. We\nwill explain how these are important for the design ofautonomous systems and\nbeyond what they can tell us for the ethics of systems.",
    "published_date": "2018-03-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.07506v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.07395v3",
    "title": "Max-Min Fairness User Scheduling and Power Allocation in Full-Duplex OFDMA Systems",
    "authors": [
      "Xiaozhou Zhang",
      "Tsung-Hui Chang",
      "Ya-Feng Liu",
      "Chao Shen",
      "Gang Zhu"
    ],
    "author_ids": [],
    "abstract": "In a full-duplex (FD) multi-user network, the system performance is not only\nlimited by the self-interference but also by the co-channel interference due to\nthe simultaneous uplink and downlink transmissions. Joint design of the\nuplink/downlink transmission direction of users and the power allocation is\ncrucial for achieving high system performance in the FD multi-user network. In\nthis paper, we investigate the joint uplink/downlink transmission direction\nassignment (TDA), user paring (UP) and power allocation problem for maximizing\nthe system max-min fairness (MMF) rate in a FD multi-user orthogonal frequency\ndivision multiple access (OFDMA) system. The problem is formulated with a\ntwo-time-scale structure where the TDA and the UP variables are for optimizing\na long-term MMF rate while the power allocation is for optimizing an\ninstantaneous MMF rate during each channel coherence interval. We show that the\nstudied joint MMF rate maximization problem is NP-hard in general. To obtain\nhigh-quality suboptimal solutions, we propose efficient methods based on simple\nrelaxation and greedy rounding techniques. Simulation results are presented to\nshow that the proposed algorithms are effective and achieve higher MMF rates\nthan the existing heuristic methods.",
    "published_date": "2018-03-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.07395v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.07233v1",
    "title": "Closing the AI Knowledge Gap",
    "authors": [
      "Ziv Epstein",
      "Blakeley H. Payne",
      "Judy Hanwen Shen",
      "Abhimanyu Dubey",
      "Bjarke Felbo",
      "Matthew Groh",
      "Nick Obradovich",
      "Manuel Cebrian",
      "Iyad Rahwan"
    ],
    "author_ids": [],
    "abstract": "AI researchers employ not only the scientific method, but also methodology\nfrom mathematics and engineering. However, the use of the scientific method -\nspecifically hypothesis testing - in AI is typically conducted in service of\nengineering objectives. Growing interest in topics such as fairness and\nalgorithmic bias show that engineering-focused questions only comprise a subset\nof the important questions about AI systems. This results in the AI Knowledge\nGap: the number of unique AI systems grows faster than the number of studies\nthat characterize these systems' behavior. To close this gap, we argue that the\nstudy of AI could benefit from the greater inclusion of researchers who are\nwell positioned to formulate and test hypotheses about the behavior of AI\nsystems. We examine the barriers preventing social and behavioral scientists\nfrom conducting such studies. Our diagnosis suggests that accelerating the\nscientific study of AI systems requires new incentives for academia and\nindustry, mediated by new tools and institutions. To address these needs, we\npropose a two-sided marketplace called TuringBox. On one side, AI contributors\nupload existing and novel algorithms to be studied scientifically by others. On\nthe other side, AI examiners develop and post machine intelligence tasks\ndesigned to evaluate and characterize algorithmic behavior. We discuss this\nmarket's potential to democratize the scientific study of AI behavior, and thus\nnarrow the AI Knowledge Gap.",
    "published_date": "2018-03-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.07233v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.00506v2",
    "title": "Towards Explanation of DNN-based Prediction with Guided Feature Inversion",
    "authors": [
      "Mengnan Du",
      "Ninghao Liu",
      "Qingquan Song",
      "Xia Hu"
    ],
    "author_ids": [],
    "abstract": "While deep neural networks (DNN) have become an effective computational tool,\nthe prediction results are often criticized by the lack of interpretability,\nwhich is essential in many real-world applications such as health informatics.\nExisting attempts based on local interpretations aim to identify relevant\nfeatures contributing the most to the prediction of DNN by monitoring the\nneighborhood of a given input. They usually simply ignore the intermediate\nlayers of the DNN that might contain rich information for interpretation. To\nbridge the gap, in this paper, we propose to investigate a guided feature\ninversion framework for taking advantage of the deep architectures towards\neffective interpretation. The proposed framework not only determines the\ncontribution of each feature in the input but also provides insights into the\ndecision-making process of DNN models. By further interacting with the neuron\nof the target category at the output layer of the DNN, we enforce the\ninterpretation result to be class-discriminative. We apply the proposed\ninterpretation model to different CNN architectures to provide explanations for\nimage data and conduct extensive experiments on ImageNet and PASCAL VOC07\ndatasets. The interpretation results demonstrate the effectiveness of our\nproposed framework in providing class-discriminative interpretation for\nDNN-based prediction.",
    "published_date": "2018-03-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00506v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.06797v5",
    "title": "Revenue Management on an On-Demand Service Platform",
    "authors": [
      "Vijay Kamble"
    ],
    "author_ids": [],
    "abstract": "I consider the optimal hourly (or per-unit-time in general) pricing problem\nfaced by a freelance worker (or a service provider) on an on-demand service\nplatform. Service requests arriving while the worker is busy are lost forever.\nThus, the optimal hourly prices need to capture the average hourly opportunity\ncosts incurred by accepting jobs. Due to potential asymmetries in these costs,\nprice discrimination across jobs based on duration, characteristics of the\narrival process, etc., may be necessary for optimality, even if the customers'\nhourly willingness to pay is identically distributed. I first establish that\nsuch price discrimination is not necessary if the customer arrival process is\nPoisson: in this case, the optimal policy charges an identical hourly rate for\nall jobs. This result holds even if the earnings are discounted over time. I\nthen consider the case where the customers belong to different classes that are\ndifferentiated in their willingness to pay. I present a simple and practical\niterative procedure to compute the optimal prices in this case under standard\nregularity assumptions on the distributions of customer valuations. I finally\nshow that these insights continue to hold in the presence of competition\nbetween multiple quality-differentiated workers, assuming a natural customer\nchoice model in which a customer always chooses the best available worker that\nshe can afford.",
    "published_date": "2018-03-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.06797v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.06657v3",
    "title": "Sdf-GAN: Semi-supervised Depth Fusion with Multi-scale Adversarial Networks",
    "authors": [
      "Can Pu",
      "Runzi Song",
      "Radim Tylecek",
      "Nanbo Li",
      "Robert B Fisher"
    ],
    "author_ids": [],
    "abstract": "Refining raw disparity maps from different algorithms to exploit their\ncomplementary advantages is still challenging. Uncertainty estimation and\ncomplex disparity relationships among pixels limit the accuracy and robustness\nof existing methods and there is no standard method for fusion of different\nkinds of depth data. In this paper, we introduce a new method to fuse disparity\nmaps from different sources, while incorporating supplementary information\n(intensity, gradient, etc.) into a refiner network to better refine raw\ndisparity inputs. A discriminator network classifies disparities at different\nreceptive fields and scales. Assuming a Markov Random Field for the refined\ndisparity map produces better estimates of the true disparity distribution.\nBoth fully supervised and semi-supervised versions of the algorithm are\nproposed. The approach includes a more robust loss function to inpaint invalid\ndisparity values and requires much less labeled data to train in the\nsemi-supervised learning mode. The algorithm can be generalized to fuse depths\nfrom different kinds of depth sources. Experiments explored different fusion\nopportunities: stereo-monocular fusion, stereo-ToF fusion and stereo-stereo\nfusion. The experiments show the superiority of the proposed algorithm compared\nwith the most recent algorithms on public synthetic datasets (Scene Flow,\nSYNTH3, our synthetic garden dataset) and real datasets (Kitti2015 dataset and\nTrimbot2020 Garden dataset).",
    "published_date": "2018-03-18T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.06657v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.06377v1",
    "title": "Spread of Information with Confirmation Bias in Cyber-Social Networks",
    "authors": [
      "Yanbing Mao",
      "Sadegh Bolouki",
      "Emrah Akyol"
    ],
    "author_ids": [],
    "abstract": "This paper provides a model to investigate information spreading over\ncyber-social network of agents communicating with each other. The cyber-social\nnetwork considered here comprises individuals and news agencies. Each\nindividual holds a belief represented by a scalar. Individuals receive\ninformation from news agencies that are closer to their belief, confirmation\nbias is explicitly incorporated into the model. The proposed dynamics of\ncyber-social networks is adopted from DeGroot-Friedkin model, where the\nindividual's opinion update mechanism is a convex combination of his innate\nopinion, his neighbors' opinions at the previous time step (obtained from the\nsocial network), and the opinions passed along by news agencies from cyber\nlayer which he follows. The characteristics of the interdependent social and\ncyber networks are radically different here: the social network relies on trust\nand hence static while the news agencies are highly dynamic since they are\nweighted as a function of the distance between an individual state and the\nstate of news agency to account for confirmation bias. The conditions for\nconvergence of the aforementioned dynamics to a unique equilibrium are\ncharacterized. The estimation and exact computation of the steady-state values\nunder non-linear and linear state-dependent weight functions are provided.\nFinally, the impact of polarization in the opinions of news agencies on the\npublic opinion evolution is numerically analyzed in the context of the\nwell-known Krackhardt's advice network.",
    "published_date": "2018-03-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.MA",
      "cs.SY",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.06377v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1804.00499v1",
    "title": "Semantic Adversarial Examples",
    "authors": [
      "Hossein Hosseini",
      "Radha Poovendran"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%.",
    "published_date": "2018-03-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.00499v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.06174v1",
    "title": "Some HCI Priorities for GDPR-Compliant Machine Learning",
    "authors": [
      "Michael Veale",
      "Reuben Binns",
      "Max Van Kleek"
    ],
    "author_ids": [],
    "abstract": "In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing.",
    "published_date": "2018-03-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.06174v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.05513v2",
    "title": "Limitations of P-Values and $R^2$ for Stepwise Regression Building: A Fairness Demonstration in Health Policy Risk Adjustment",
    "authors": [
      "Sherri Rose",
      "Thomas G. McGuire"
    ],
    "author_ids": [],
    "abstract": "Stepwise regression building procedures are commonly used applied statistical\ntools, despite their well-known drawbacks. While many of their limitations have\nbeen widely discussed in the literature, other aspects of the use of individual\nstatistical fit measures, especially in high-dimensional stepwise regression\nsettings, have not. Giving primacy to individual fit, as is done with p-values\nand $R^2$, when group fit may be the larger concern, can lead to misguided\ndecision making. One of the most consequential uses of stepwise regression is\nin health care, where these tools allocate hundreds of billions of dollars to\nhealth plans enrolling individuals with different predicted health care costs.\nThe main goal of this \"risk adjustment\" system is to convey incentives to\nhealth plans such that they provide health care services fairly, a component of\nwhich is not to discriminate in access or care for persons or groups likely to\nbe expensive. We address some specific limitations of p-values and $R^2$ for\nhigh-dimensional stepwise regression in this policy problem through an\nillustrated example by additionally considering a group-level fairness metric.",
    "published_date": "2018-03-14T00:00:00",
    "year": 2018,
    "categories": [
      "econ.EM",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.05513v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.05495v1",
    "title": "Challenges in Discriminating Profanity from Hate Speech",
    "authors": [
      "Shervin Malmasi",
      "Marcos Zampieri"
    ],
    "author_ids": [],
    "abstract": "In this study we approach the problem of distinguishing general profanity\nfrom hate speech in social media, something which has not been widely\nconsidered. Using a new dataset annotated specifically for this task, we employ\nsupervised classification along with a set of features that includes n-grams,\nskip-grams and clustering-based word representations. We apply approaches based\non single classifiers as well as more advanced ensemble classifiers and stacked\ngeneralization, achieving the best result of 80% accuracy for this 3-class\nclassification task. Analysis of the results reveals that discriminating hate\nspeech and profanity is not a simple task, which may require features that\ncapture a deeper understanding of the text not always possible with surface\nn-grams. The variability of gold labels in the annotated data, due to\ndifferences in the subjective adjudications of the annotators, is also an\nissue. Other directions for future work are discussed.",
    "published_date": "2018-03-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.05495v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1804.01576v1",
    "title": "A Bayesian Model for False Information Belief Impact, Optimal Design, and Fake News Containment",
    "authors": [
      "Amin Khajehnejad",
      "Shima Hajimirza"
    ],
    "author_ids": [],
    "abstract": "This work is a technical approach to modeling false information nature,\ndesign, belief impact and containment in multi-agent networks. We present a\nBayesian mathematical model for source information and viewer's belief, and how\nthe former impacts the latter in a media (network) of broadcasters and viewers.\nGiven the proposed model, we study how a particular information (true or false)\ncan be optimally designed into a report, so that on average it conveys the most\namount of the original intended information to the viewers of the network.\nConsequently, the model allows us to study susceptibility of a particular group\nof viewers to false information, as a function of statistical metrics of the\ntheir prior beliefs (e.g. bias, hesitation, open-mindedness, credibility\nassessment etc.). In addition, based on the same model we can study false\ninformation \"containment\" strategies imposed by network administrators.\nSpecifically, we study a credibility assessment strategy, where every\ndisseminated report must be within a certain distance of the truth. We study\nthe trade-off between false and true information-belief convergence using this\nscheme which leads to ways for optimally deciding how truth sensitive an\ninformation dissemination network should operate.",
    "published_date": "2018-03-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.01576v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.05046v1",
    "title": "Caveat Emptor, Computational Social Science: Large-Scale Missing Data in a Widely-Published Reddit Corpus",
    "authors": [
      "Devin Gaffney",
      "J. Nathan Matias"
    ],
    "author_ids": [],
    "abstract": "As researchers use computational methods to study complex social behaviors at\nscale, the validity of this computational social science depends on the\nintegrity of the data. On July 2, 2015, Jason Baumgartner published a dataset\nadvertised to include ``every publicly available Reddit comment'' which was\nquickly shared on Bittorrent and the Internet Archive. This data quickly became\nthe basis of many academic papers on topics including machine learning, social\nbehavior, politics, breaking news, and hate speech. We have discovered\nsubstantial gaps and limitations in this dataset which may contribute to bias\nin the findings of that research. In this paper, we document the dataset,\nsubstantial missing observations in the dataset, and the risks to research\nvalidity from those gaps. In summary, we identify strong risks to research that\nconsiders user histories or network analysis, moderate risks to research that\ncompares counts of participation, and lesser risk to machine learning research\nthat avoids making representative claims about behavior and participation on\nReddit.",
    "published_date": "2018-03-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.05046v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.04562v2",
    "title": "Bias in OLAP Queries: Detection, Explanation, and Removal",
    "authors": [
      "Babak Salimi",
      "Johannes Gehrke",
      "Dan Suciu"
    ],
    "author_ids": [],
    "abstract": "On line analytical processing (OLAP) is an essential element of\ndecision-support systems. OLAP tools provide insights and understanding needed\nfor improved decision making. However, the answers to OLAP queries can be\nbiased and lead to perplexing and incorrect insights. In this paper, we propose\nHypDB, a system to detect, explain, and to resolve bias in decision-support\nqueries. We give a simple definition of a \\emph{biased query}, which performs a\nset of independence tests on the data to detect bias. We propose a novel\ntechnique that gives explanations for bias, thus assisting an analyst in\nunderstanding what goes on. Additionally, we develop an automated method for\nrewriting a biased query into an unbiased query, which shows what the analyst\nintended to examine. In a thorough evaluation on several real datasets we show\nboth the quality and the performance of our techniques, including the\ncompletely automatic discovery of the revolutionary insights from a famous 1973\ndiscrimination case.",
    "published_date": "2018-03-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.04562v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.04548v1",
    "title": "Taking Turing by Surprise? Designing Digital Computers for morally-loaded contexts",
    "authors": [
      "Sylvie Delacroix"
    ],
    "author_ids": [],
    "abstract": "There is much to learn from what Turing hastily dismissed as Lady Lovelace s\nobjection. Digital computers can indeed surprise us. Just like a piece of art,\nalgorithms can be designed in such a way as to lead us to question our\nunderstanding of the world, or our place within it. Some humans do lose the\ncapacity to be surprised in that way. It might be fear, or it might be the\ncomfort of ideological certainties. As lazy normative animals, we do need to be\nable to rely on authorities to simplify our reasoning: that is ok. Yet the\ngrowing sophistication of systems designed to free us from the constraints of\nnormative engagement may take us past a point of no-return. What if, through\nlack of normative exercise, our moral muscles became so atrophied as to leave\nus unable to question our social practices? This paper makes two distinct\nnormative claims:\n  1. Decision-support systems should be designed with a view to regularly\njolting us out of our moral torpor.\n  2. Without the depth of habit to somatically anchor model certainty, a\ncomputer s experience of something new is very different from that which in\nhumans gives rise to non-trivial surprises. This asymmetry has key\nrepercussions when it comes to the shape of ethical agency in artificial moral\nagents. The worry is not just that they would be likely to leap morally ahead\nof us, unencumbered by habits. The main reason to doubt that the moral\ntrajectories of humans v. autonomous systems might remain compatible stems from\nthe asymmetry in the mechanisms underlying moral change. Whereas in humans\nsurprises will continue to play an important role in waking us to the need for\nmoral change, cognitive processes will rule when it comes to machines. This\nasymmetry will translate into increasingly different moral outlooks, to the\npoint of likely unintelligibility. The latter prospect is enough to doubt the\ndesirability of autonomous moral agents.",
    "published_date": "2018-03-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.04548v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.04383v2",
    "title": "Delayed Impact of Fair Machine Learning",
    "authors": [
      "Lydia T. Liu",
      "Sarah Dean",
      "Esther Rolf",
      "Max Simchowitz",
      "Moritz Hardt"
    ],
    "author_ids": [],
    "abstract": "Fairness in machine learning has predominantly been studied in static\nclassification settings without concern for how decisions change the underlying\npopulation over time. Conventional wisdom suggests that fairness criteria\npromote the long-term well-being of those groups they aim to protect.\n  We study how static fairness criteria interact with temporal indicators of\nwell-being, such as long-term improvement, stagnation, and decline in a\nvariable of interest. We demonstrate that even in a one-step feedback model,\ncommon fairness criteria in general do not promote improvement over time, and\nmay in fact cause harm in cases where an unconstrained objective would not.\n  We completely characterize the delayed impact of three standard criteria,\ncontrasting the regimes in which these exhibit qualitatively different\nbehavior. In addition, we find that a natural form of measurement error\nbroadens the regime in which fairness criteria perform favorably.\n  Our results highlight the importance of measurement and temporal modeling in\nthe evaluation of fairness criteria, suggesting a range of new challenges and\ntrade-offs.",
    "published_date": "2018-03-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.04383v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.04137v1",
    "title": "Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-wise Loss",
    "authors": [
      "Xuefei Zhe",
      "Shifeng Chen",
      "Hong Yan"
    ],
    "author_ids": [],
    "abstract": "Deep supervised hashing has emerged as an influential solution to large-scale\nsemantic image retrieval problems in computer vision. In the light of recent\nprogress, convolutional neural network based hashing methods typically seek\npair-wise or triplet labels to conduct the similarity preserving learning.\nHowever, complex semantic concepts of visual contents are hard to capture by\nsimilar/dissimilar labels, which limits the retrieval performance. Generally,\npair-wise or triplet losses not only suffer from expensive training costs but\nalso lack in extracting sufficient semantic information. In this regard, we\npropose a novel deep supervised hashing model to learn more compact class-level\nsimilarity preserving binary codes. Our deep learning based model is motivated\nby deep metric learning that directly takes semantic labels as supervised\ninformation in training and generates corresponding discriminant hashing code.\nSpecifically, a novel cubic constraint loss function based on Gaussian\ndistribution is proposed, which preserves semantic variations while penalizes\nthe overlap part of different classes in the embedding space. To address the\ndiscrete optimization problem introduced by binary codes, a two-step\noptimization strategy is proposed to provide efficient training and avoid the\nproblem of gradient vanishing. Extensive experiments on four large-scale\nbenchmark databases show that our model can achieve the state-of-the-art\nretrieval performance. Moreover, when training samples are limited, our method\nsurpasses other supervised deep hashing methods with non-negligible margins.",
    "published_date": "2018-03-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.04137v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.03756v1",
    "title": "Influence of the Event Rate on Discrimination Abilities of Bankruptcy Prediction Models",
    "authors": [
      "Lili Zhang",
      "Jennifer Priestley",
      "Xuelei Ni"
    ],
    "author_ids": [],
    "abstract": "In bankruptcy prediction, the proportion of events is very low, which is\noften oversampled to eliminate this bias. In this paper, we study the influence\nof the event rate on discrimination abilities of bankruptcy prediction models.\nFirst the statistical association and significance of public records and\nfirmographics indicators with the bankruptcy were explored. Then the event rate\nwas oversampled from 0.12% to 10%, 20%, 30%, 40%, and 50%, respectively. Seven\nmodels were developed, including Logistic Regression, Decision Tree, Random\nForest, Gradient Boosting, Support Vector Machine, Bayesian Network, and Neural\nNetwork. Under different event rates, models were comprehensively evaluated and\ncompared based on Kolmogorov-Smirnov Statistic, accuracy, F1 score, Type I\nerror, Type II error, and ROC curve on the hold-out dataset with their best\nprobability cut-offs. Results show that Bayesian Network is the most\ninsensitive to the event rate, while Support Vector Machine is the most\nsensitive.",
    "published_date": "2018-03-10T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03756v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.03729v2",
    "title": "A Large-Scale Multi-Institutional Evaluation of Advanced Discrimination Algorithms for Buried Threat Detection in Ground Penetrating Radar",
    "authors": [
      "Jordan M. Malof",
      "Daniel Reichman",
      "Andrew Karem",
      "Hichem Frigui",
      "Dominic K. C. Ho",
      "Joseph N. Wilson",
      "Wen-Hsiung Lee",
      "William Cummings",
      "Leslie M. Collins"
    ],
    "author_ids": [],
    "abstract": "In this paper we consider the development of algorithms for the automatic\ndetection of buried threats using ground penetrating radar (GPR) measurements.\nGPR is one of the most studied and successful modalities for automatic buried\nthreat detection (BTD), and a large variety of BTD algorithms have been\nproposed for it. Despite this, large-scale comparisons of GPR-based BTD\nalgorithms are rare in the literature. In this work we report the results of a\nmulti-institutional effort to develop advanced buried threat detection\nalgorithms for a real-world GPR BTD system. The effort involved five\ninstitutions with substantial experience with the development of GPR-based BTD\nalgorithms. In this paper we report the technical details of the advanced\nalgorithms submitted by each institution, representing their latest technical\nadvances, and many state-of-the-art GPR-based BTD algorithms. We also report\nthe results of evaluating the algorithms from each institution on the large\nexperimental dataset used for development. The experimental dataset comprised\n120,000 m^2 of GPR data using surface area, from 13 different lanes across two\nUS test sites. The data was collected using a vehicle-mounted GPR system, the\nvariants of which have supplied data for numerous publications. Using these\nresults, we identify the most successful and common processing strategies among\nthe submitted algorithms, and make recommendations for GPR-based BTD algorithm\ndesign.",
    "published_date": "2018-03-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03729v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.03559v1",
    "title": "Homomorphic Encryption for Speaker Recognition: Protection of Biometric Templates and Vendor Model Parameters",
    "authors": [
      "Andreas Nautsch",
      "Sergey Isadskiy",
      "Jascha Kolberg",
      "Marta Gomez-Barrero",
      "Christoph Busch"
    ],
    "author_ids": [],
    "abstract": "Data privacy is crucial when dealing with biometric data. Accounting for the\nlatest European data privacy regulation and payment service directive,\nbiometric template protection is essential for any commercial application.\nEnsuring unlinkability across biometric service operators, irreversibility of\nleaked encrypted templates, and renewability of e.g., voice models following\nthe i-vector paradigm, biometric voice-based systems are prepared for the\nlatest EU data privacy legislation. Employing Paillier cryptosystems, Euclidean\nand cosine comparators are known to ensure data privacy demands, without loss\nof discrimination nor calibration performance. Bridging gaps from template\nprotection to speaker recognition, two architectures are proposed for the\ntwo-covariance comparator, serving as a generative model in this study. The\nfirst architecture preserves privacy of biometric data capture subjects. In the\nsecond architecture, model parameters of the comparator are encrypted as well,\nsuch that biometric service providers can supply the same comparison modules\nemploying different key pairs to multiple biometric service operators. An\nexperimental proof-of-concept and complexity analysis is carried out on the\ndata from the 2013-2014 NIST i-vector machine learning challenge.",
    "published_date": "2018-03-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03559v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.03428v1",
    "title": "A Bias Aware News Recommendation System",
    "authors": [
      "Anish Anil Patankar",
      "Joy Bose",
      "Harshit Khanna"
    ],
    "author_ids": [],
    "abstract": "In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.",
    "published_date": "2018-03-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.HC",
      "H.5.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03428v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.03346v1",
    "title": "Positivity Bias in Customer Satisfaction Ratings",
    "authors": [
      "Kunwoo Park",
      "Meeyoung Cha",
      "Eunhee Rhim"
    ],
    "author_ids": [],
    "abstract": "Customer ratings are valuable sources to understand their satisfaction and\nare critical for designing better customer experiences and recommendations. The\nmajority of customers, however, do not respond to rating surveys, which makes\nthe result less representative. To understand overall satisfaction, this paper\naims to investigate how likely customers without responses had satisfactory\nexperiences compared to those respondents. To infer customer satisfaction of\nsuch unlabeled sessions, we propose models using recurrent neural networks\n(RNNs) that learn continuous representations of unstructured text conversation.\nBy analyzing online chat logs of over 170,000 sessions from Samsung's customer\nservice department, we make a novel finding that while labeled sessions\ncontributed by a small fraction of customers received overwhelmingly positive\nreviews, the majority of unlabeled sessions would have received lower ratings\nby customers. The data analytics presented in this paper not only have\npractical implications for helping detect dissatisfied customers on live chat\nservices but also make theoretical contributions on discovering the level of\nbiases in online rating platforms.",
    "published_date": "2018-03-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03346v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.03242v2",
    "title": "Probably Approximately Metric-Fair Learning",
    "authors": [
      "Guy N. Rothblum",
      "Gal Yona"
    ],
    "author_ids": [],
    "abstract": "The seminal work of Dwork {\\em et al.} [ITCS 2012] introduced a metric-based\nnotion of individual fairness. Given a task-specific similarity metric, their\nnotion required that every pair of similar individuals should be treated\nsimilarly. In the context of machine learning, however, individual fairness\ndoes not generalize from a training set to the underlying population. We show\nthat this can lead to computational intractability even for simple\nfair-learning tasks.\n  With this motivation in mind, we introduce and study a relaxed notion of {\\em\napproximate metric-fairness}: for a random pair of individuals sampled from the\npopulation, with all but a small probability of error, if they are similar then\nthey should be treated similarly. We formalize the goal of achieving\napproximate metric-fairness simultaneously with best-possible accuracy as\nProbably Approximately Correct and Fair (PACF) Learning. We show that\napproximate metric-fairness {\\em does} generalize, and leverage these\ngeneralization guarantees to construct polynomial-time PACF learning algorithms\nfor the classes of linear and logistic predictors.",
    "published_date": "2018-03-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03242v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.03239v2",
    "title": "Fairness Through Computationally-Bounded Awareness",
    "authors": [
      "Michael P. Kim",
      "Omer Reingold",
      "Guy N. Rothblum"
    ],
    "author_ids": [],
    "abstract": "We study the problem of fair classification within the versatile framework of\nDwork et al. [ITCS '12], which assumes the existence of a metric that measures\nsimilarity between pairs of individuals. Unlike earlier work, we do not assume\nthat the entire metric is known to the learning algorithm; instead, the learner\ncan query this arbitrary metric a bounded number of times. We propose a new\nnotion of fairness called metric multifairness and show how to achieve this\nnotion in our setting. Metric multifairness is parameterized by a similarity\nmetric $d$ on pairs of individuals to classify and a rich collection ${\\cal C}$\nof (possibly overlapping) \"comparison sets\" over pairs of individuals. At a\nhigh level, metric multifairness guarantees that similar subpopulations are\ntreated similarly, as long as these subpopulations are identified within the\nclass ${\\cal C}$.",
    "published_date": "2018-03-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03239v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.02887v1",
    "title": "A first look at browser-based Cryptojacking",
    "authors": [
      "Shayan Eskandari",
      "Andreas Leoutsarakos",
      "Troy Mursch",
      "Jeremy Clark"
    ],
    "author_ids": [],
    "abstract": "In this paper, we examine the recent trend towards in-browser mining of\ncryptocurrencies; in particular, the mining of Monero through Coinhive and\nsimilar code- bases. In this model, a user visiting a website will download a\nJavaScript code that executes client-side in her browser, mines a\ncryptocurrency, typically without her consent or knowledge, and pays out the\nseigniorage to the website. Websites may consciously employ this as an\nalternative or to supplement advertisement revenue, may offer premium content\nin exchange for mining, or may be unwittingly serving the code as a result of a\nbreach (in which case the seigniorage is collected by the attacker). The\ncryptocurrency Monero is preferred seemingly for its unfriendliness to\nlarge-scale ASIC mining that would drive browser-based efforts out of the\nmarket, as well as for its purported privacy features. In this paper, we survey\nthis landscape, conduct some measurements to establish its prevalence and\nprofitability, outline an ethical framework for considering whether it should\nbe classified as an attack or business opportunity, and make suggestions for\nthe detection, mitigation and/or prevention of browser-based mining for non-\nconsenting users.",
    "published_date": "2018-03-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC",
      "econ.EM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02887v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02857v2",
    "title": "Gerrymandering and Compactness: Implementation Flexibility and Abuse",
    "authors": [
      "Richard Barnes",
      "Justin Solomon"
    ],
    "author_ids": [],
    "abstract": "Political districts may be drawn to favor one group or political party over\nanother, or gerrymandered. A number of measurements have been suggested as ways\nto detect and prevent such behavior. These measures give concrete axes along\nwhich districts and districting plans can be compared. However, measurement\nvalues are affected by both noise and the compounding effects of seemingly\ninnocuous implementation decisions. Such issues will arise for any measure. As\na case study demonstrating the effect, we show that commonly-used measures of\ngeometric compactness for district boundaries are affected by several factors\nirrelevant to fairness or compliance with civil rights law. We further show\nthat an adversary could manipulate measurements to affect the assessment of a\ngiven plan. This instability complicates using these measurements as\nlegislative or judicial standards to counteract unfair redistricting practices.\nThis paper accompanies the release of packages in C++, Python, and R that\ncorrectly, efficiently, and reproducibly calculate a variety of compactness\nscores.",
    "published_date": "2018-03-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.CG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02857v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02509v1",
    "title": "An Application of HodgeRank to Online Peer Assessment",
    "authors": [
      "Tse-Yu Lin",
      "Yen-Lung Tsai"
    ],
    "author_ids": [],
    "abstract": "Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics.",
    "published_date": "2018-03-07T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02509v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.02504v1",
    "title": "Exponential Discriminative Metric Embedding in Deep Learning",
    "authors": [
      "Bowen Wu",
      "Zhangling Chen",
      "Jun Wang",
      "Huaming Wu"
    ],
    "author_ids": [],
    "abstract": "With the remarkable success achieved by the Convolutional Neural Networks\n(CNNs) in object recognition recently, deep learning is being widely used in\nthe computer vision community. Deep Metric Learning (DML), integrating deep\nlearning with conventional metric learning, has set new records in many fields,\nespecially in classification task. In this paper, we propose a replicable DML\nmethod, called Include and Exclude (IE) loss, to force the distance between a\nsample and its designated class center away from the mean distance of this\nsample to other class centers with a large margin in the exponential feature\nprojection space. With the supervision of IE loss, we can train CNNs to enhance\nthe intra-class compactness and inter-class separability, leading to great\nimprovements on several public datasets ranging from object recognition to face\nverification. We conduct a comparative study of our algorithm with several\ntypical DML methods on three kinds of networks with different capacity.\nExtensive experiments on three object recognition datasets and two face\nrecognition datasets demonstrate that IE loss is always superior to other\nmainstream DML methods and approach the state-of-the-art results.",
    "published_date": "2018-03-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02504v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.02422v1",
    "title": "Towards Quantifying Sampling Bias in Network Inference",
    "authors": [
      "Lisette Espín-Noboa",
      "Claudia Wagner",
      "Fariba Karimi",
      "Kristina Lerman"
    ],
    "author_ids": [],
    "abstract": "Relational inference leverages relationships between entities and links in a\nnetwork to infer information about the network from a small sample. This method\nis often used when global information about the network is not available or\ndifficult to obtain. However, how reliable is inference from a small labelled\nsample? How should the network be sampled, and what effect does it have on\ninference error? How does the structure of the network impact the sampling\nstrategy? We address these questions by systematically examining how network\nsampling strategy and sample size affect accuracy of relational inference in\nnetworks. To this end, we generate a family of synthetic networks where nodes\nhave a binary attribute and a tunable level of homophily. As expected, we find\nthat in heterophilic networks, we can obtain good accuracy when only small\nsamples of the network are initially labelled, regardless of the sampling\nstrategy. Surprisingly, this is not the case for homophilic networks, and\nsampling strategies that work well in heterophilic networks lead to large\ninference errors. These findings suggest that the impact of network structure\non relational classification is more complex than previously thought.",
    "published_date": "2018-03-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02422v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02111v1",
    "title": "Algorithmic bias amplifies opinion polarization: A bounded confidence model",
    "authors": [
      "Alina Sîrbu",
      "Dino Pedreschi",
      "Fosca Giannotti",
      "János Kertész"
    ],
    "author_ids": [],
    "abstract": "The flow of information reaching us via the online media platforms is\noptimized not by the information content or relevance but by popularity and\nproximity to the target. This is typically performed in order to maximise\nplatform usage. As a side effect, this introduces an algorithmic bias that is\nbelieved to enhance polarization of the societal debate. To study this\nphenomenon, we modify the well-known continuous opinion dynamics model of\nbounded confidence in order to account for the algorithmic bias and investigate\nits consequences. In the simplest version of the original model the pairs of\ndiscussion participants are chosen at random and their opinions get closer to\neach other if they are within a fixed tolerance level. We modify the selection\nrule of the discussion partners: there is an enhanced probability to choose\nindividuals whose opinions are already close to each other, thus mimicking the\nbehavior of online media which suggest interaction with similar peers. As a\nresult we observe: a) an increased tendency towards polarization, which emerges\nalso in conditions where the original model would predict convergence, and b) a\ndramatic slowing down of the speed at which the convergence at the asymptotic\nstate is reached, which makes the system highly unstable. Polarization is\naugmented by a fragmented initial population.",
    "published_date": "2018-03-06T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.MA",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02111v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02023v1",
    "title": "Accumulate Then Transmit: Multi-user Scheduling in Full-Duplex Wireless-Powered IoT Systems",
    "authors": [
      "Di Zhai",
      "He Chen",
      "Zihuai Lin",
      "Yonghui Li",
      "Branka Vucetic"
    ],
    "author_ids": [],
    "abstract": "This paper develops and evaluates an accumulate-then-transmit framework for\nmulti-user scheduling in a full-duplex (FD) wireless-powered Internet-of-Things\nsystem, consisting of multiple energy harvesting (EH) IoT devices (IoDs) and\none FD hybrid access point (HAP). All IoDs have no embedded energy supply and\nthus need to perform EH before transmitting their data to the HAP. Thanks to\nits FD capability, the HAP can simultaneously receive data uplink and broadcast\nenergy-bearing signals downlink to charge IoDs. The instantaneous channel\ninformation is assumed unavailable throughout this paper. To maximize the\nsystem average throughput, we design a new throughput-oriented scheduling\nscheme, in which a single IoD with the maximum weighted residual energy is\nselected to transmit information to the HAP, while the other IoDs harvest and\naccumulate energy from the signals broadcast by the HAP. However, similar to\nmost of the existing throughput-oriented schemes, the proposed\nthroughout-oriented scheme also leads to unfair inter-user throughput because\nIoDs with better channel performance will be granted more transmission\nopportunities. To strike a balance between the system throughput and user\nfairness, we then propose a fairness-oriented scheduling scheme based on the\nnormalized accumulated energy. To evaluate the system performance, we model the\ndynamic charging/discharging processes of each IoD as a finite-state Markov\nChain. Analytical expressions of the system outage probability and average\nthroughput are derived over Rician fading channels for both proposed schemes.\nSimulation results validate the performance analysis and demonstrate the\nperformance superiority of both proposed schemes over the existing schemes.",
    "published_date": "2018-03-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02023v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02021v1",
    "title": "Understanding Short-Horizon Bias in Stochastic Meta-Optimization",
    "authors": [
      "Yuhuai Wu",
      "Mengye Ren",
      "Renjie Liao",
      "Roger Grosse"
    ],
    "author_ids": [],
    "abstract": "Careful tuning of the learning rate, or even schedules thereof, can be\ncrucial to effective neural net training. There has been much recent interest\nin gradient-based meta-optimization, where one tunes hyperparameters, or even\nlearns an optimizer, in order to minimize the expected loss when the training\nprocedure is unrolled. But because the training procedure must be unrolled\nthousands of times, the meta-objective must be defined with an\norders-of-magnitude shorter time horizon than is typical for neural net\ntraining. We show that such short-horizon meta-objectives cause a serious bias\ntowards small step sizes, an effect we term short-horizon bias. We introduce a\ntoy problem, a noisy quadratic cost function, on which we analyze short-horizon\nbias by deriving and comparing the optimal schedules for short and long time\nhorizons. We then run meta-optimization experiments (both offline and online)\non standard benchmark datasets, showing that meta-optimization chooses too\nsmall a learning rate by multiple orders of magnitude, even when run with a\nmoderately long time horizon (100 steps) typical of work in the area. We\nbelieve short-horizon bias is a fundamental problem that needs to be addressed\nif meta-optimization is to scale to practical neural net training regimes.",
    "published_date": "2018-03-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02021v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.01901v1",
    "title": "On Discrimination Discovery and Removal in Ranked Data using Causal Graph",
    "authors": [
      "Yongkai Wu",
      "Lu Zhang",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches.",
    "published_date": "2018-03-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.01901v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.01798v2",
    "title": "One-Class Adversarial Nets for Fraud Detection",
    "authors": [
      "Panpan Zheng",
      "Shuhan Yuan",
      "Xintao Wu",
      "Jun Li",
      "Aidong Lu"
    ],
    "author_ids": [],
    "abstract": "Many online applications, such as online social networks or knowledge bases,\nare often attacked by malicious users who commit different types of actions\nsuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most\nof the fraud detection approaches require a training dataset that contains\nrecords of both benign and malicious users. However, in practice, there are\noften no or very few records of malicious users. In this paper, we develop\none-class adversarial nets (OCAN) for fraud detection using training data with\nonly benign users. OCAN first uses LSTM-Autoencoder to learn the\nrepresentations of benign users from their sequences of online activities. It\nthen detects malicious users by training a discriminator with a complementary\nGAN model that is different from the regular GAN model. Experimental results\nshow that our OCAN outperforms the state-of-the-art one-class classification\nmodels and achieves comparable performance with the latest multi-source LSTM\nmodel that requires both benign and malicious users in the training phase.",
    "published_date": "2018-03-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.01798v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.01626v1",
    "title": "Variance-Aware Regret Bounds for Undiscounted Reinforcement Learning in MDPs",
    "authors": [
      "Mohammad Sadegh Talebi",
      "Odalric-Ambrym Maillard"
    ],
    "author_ids": [],
    "abstract": "The problem of reinforcement learning in an unknown and discrete Markov\nDecision Process (MDP) under the average-reward criterion is considered, when\nthe learner interacts with the system in a single stream of observations,\nstarting from an initial state without any reset. We revisit the minimax lower\nbound for that problem by making appear the local variance of the bias function\nin place of the diameter of the MDP. Furthermore, we provide a novel analysis\nof the KL-UCRL algorithm establishing a high-probability regret bound scaling\nas $\\widetilde {\\mathcal O}\\Bigl({\\textstyle \\sqrt{S\\sum_{s,a}{\\bf\nV}^\\star_{s,a}T}}\\Big)$ for this algorithm for ergodic MDPs, where $S$ denotes\nthe number of states and where ${\\bf V}^\\star_{s,a}$ is the variance of the\nbias function with respect to the next-state distribution following action $a$\nin state $s$. The resulting bound improves upon the best previously known\nregret bound $\\widetilde {\\mathcal O}(DS\\sqrt{AT})$ for that algorithm, where\n$A$ and $D$ respectively denote the maximum number of actions (per state) and\nthe diameter of MDP. We finally compare the leading terms of the two bounds in\nsome benchmark MDPs indicating that the derived bound can provide an order of\nmagnitude improvement in some cases. Our analysis leverages novel variations of\nthe transportation lemma combined with Kullback-Leibler concentration\ninequalities, that we believe to be of independent interest.",
    "published_date": "2018-03-05T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.01626v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.01431v2",
    "title": "Design of a Low Voltage Analog-to-Digital Converter using Voltage Controlled Stochastic Switching of Low Barrier Nanomagnets",
    "authors": [
      "Indranil Chakraborty",
      "Amogh Agrawal",
      "Kaushik Roy"
    ],
    "author_ids": [],
    "abstract": "The inherent stochasticity in many nano-scale devices makes them prospective\ncandidates for low-power computations. Such devices have been demonstrated to\nexhibit probabilistic switching between two stable states to achieve stochastic\nbehavior. Recently, superparamagnetic nanomagnets (having low energy barrier EB\n$\\sim$ 1kT) have shown promise of achieving stochastic switching at GHz rates,\nwith very low currents. On the other hand, voltage-controlled switching of\nnanomagnets through the Magneto-electric (ME) effect has shown further\nimprovements in energy efficiency. In this simulation paper, we first analyze\nthe stochastic switching characteristics of such super-paramagnetic nanomagnets\nin a voltage-controlled spintronic device. We study the influence of external\nbias on the switching behavior. Subsequently, we show that our proposed device\nleverages the voltage controlled stochasticity in performing low-voltage 8-bit\nanalog to digital conversions. This eliminates the need for comparators, unlike\nthe Complementary Metal-Oxide Semiconductor (CMOS)-based flash\nAnalog-to-Digital converters (ADC). This device allows for a simple and compact\ndesign which can potentially be applied in implementing sensors which desire\nlow voltage conversions.",
    "published_date": "2018-03-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.ET"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.01431v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.02444v1",
    "title": "Analytical Modeling of Wi-Fi and LTE-LAA Coexistence: Throughput and Impact of Energy Detection Threshold",
    "authors": [
      "Morteza Mehrnoush",
      "Vanlin Sathya",
      "Sumit Roy",
      "Monisha Ghosh"
    ],
    "author_ids": [],
    "abstract": "With both small-cell LTE and Wi-Fi networks available as alternatives for\ndeployment in unlicensed bands (notably 5 GHz), the investigation into their\ncoexistence is a topic of active interest, primarily driven by industry groups.\n3GPP has recently standardized LTE Licensed Assisted Access (LTE-LAA) that\nseeks to make LTE more co-existence friendly with Wi-Fi by incorporating\nsimilar sensing and back-off features. Nonetheless, the results presented by\nindustry groups offer little consensus on important issues like respective\nnetwork parameter settings that promote \"fair access\" as required by 3GPP.\nAnswers to such key system deployment aspects, in turn, require credible\nanalytical models, on which there has been little progress to date.\nAccordingly, in one of the first work of its kind, we develop a new framework\nfor estimating the throughput of Wi-Fi and LTE-LAA in coexistence scenarios via\nsuitable modifications to the celebrated Bianchi \\cite{Bianchi} model. The\nimpact of various network parameters such as energy detection (ED) threshold on\nWi-Fi and LTE-LAA coexistence is explored as a byproduct and corroborated via a\nNational Instrument (NI) experimental testbed that validates the results for\nLTE-LAA access priority class 1 and 3.",
    "published_date": "2018-03-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.02444v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.00502v4",
    "title": "Understand Functionality and Dimensionality of Vector Embeddings: the Distributional Hypothesis, the Pairwise Inner Product Loss and Its Bias-Variance Trade-off",
    "authors": [
      "Zi Yin"
    ],
    "author_ids": [],
    "abstract": "Vector embedding is a foundational building block of many deep learning\nmodels, especially in natural language processing. In this paper, we present a\ntheoretical framework for understanding the effect of dimensionality on vector\nembeddings. We observe that the distributional hypothesis, a governing\nprinciple of statistical semantics, requires a natural unitary-invariance for\nvector embeddings. Motivated by the unitary-invariance observation, we propose\nthe Pairwise Inner Product (PIP) loss, a unitary-invariant metric on the\nsimilarity between two embeddings. We demonstrate that the PIP loss captures\nthe difference in functionality between embeddings, and that the PIP loss is\ntightly connect with two basic properties of vector embeddings, namely\nsimilarity and compositionality. By formulating the embedding training process\nas matrix factorization with noise, we reveal a fundamental bias-variance\ntrade-off between the signal spectrum and noise power in the dimensionality\nselection process. This bias-variance trade-off sheds light on many empirical\nobservations which have not been thoroughly explained, for example the\nexistence of an optimal dimensionality. Moreover, we discover two new results\nabout vector embeddings, namely their robustness against over-parametrization\nand their forward stability. The bias-variance trade-off of the PIP loss\nexplicitly answers the fundamental open problem of dimensionality selection for\nvector embeddings.",
    "published_date": "2018-03-01T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.00502v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.00470v2",
    "title": "The conditional entropy power inequality for quantum additive noise channels",
    "authors": [
      "Giacomo De Palma",
      "Stefan Huber"
    ],
    "author_ids": [],
    "abstract": "We prove the quantum conditional Entropy Power Inequality for quantum\nadditive noise channels. This inequality lower bounds the quantum conditional\nentropy of the output of an additive noise channel in terms of the quantum\nconditional entropies of the input state and the noise when they are\nconditionally independent given the memory. We also show that this conditional\nEntropy Power Inequality is optimal in the sense that we can achieve equality\nasymptotically by choosing a suitable sequence of Gaussian input states. We\napply the conditional Entropy Power Inequality to find an array of\ninformation-theoretic inequalities for conditional entropies which are the\nanalogues of inequalities which have already been established in the\nunconditioned setting. Furthermore, we give a simple proof of the convergence\nrate of the quantum Ornstein-Uhlenbeck semigroup based on Entropy Power\nInequalities.",
    "published_date": "2018-03-01T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math-ph",
      "math.IT",
      "math.MP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.00470v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.00429v2",
    "title": "Learning Human-Aware Path Planning with Fully Convolutional Networks",
    "authors": [
      "Noé Pérez-Higueras",
      "Fernando Caballero",
      "Luis Merino"
    ],
    "author_ids": [],
    "abstract": "This work presents an approach to learn path planning for robot social\nnavigation by demonstration. We make use of Fully Convolutional Neural Networks\n(FCNs) to learn from expert's path demonstrations a map that marks a feasible\npath to the goal as a classification problem. The use of FCNs allows us to\novercome the problem of manually designing/identifying the cost-map and\nrelevant features for the task of robot navigation. The method makes use of\noptimal Rapidly-exploring Random Tree planner (RRT*) to overcome eventual\nerrors in the path prediction; the FCNs prediction is used as cost-map and also\nto partially bias the sampling of the configuration space, leading the planner\nto behave similarly to the learned expert behavior. The approach is evaluated\nin experiments with real trajectories and compared with Inverse Reinforcement\nLearning algorithms that use RRT* as underlying planner.",
    "published_date": "2018-03-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.00429v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.10568v3",
    "title": "Machine learning and genomics: precision medicine vs. patient privacy",
    "authors": [
      "Chloé-Agathe Azencott"
    ],
    "author_ids": [],
    "abstract": "Machine learning can have major societal impact in computational biology\napplications. In particular, it plays a central role in the development of\nprecision medicine, whereby treatment is tailored to the clinical or genetic\nfeatures of the patient. However, these advances require collecting and sharing\namong researchers large amounts of genomic data, which generates much concern\nabout privacy. Researchers, study participants and governing bodies should be\naware of the ways in which the privacy of participants might be compromised, as\nwell as of the large body of research on technical solutions to these issues.\nWe review how breaches in patient privacy can occur, present recent\ndevelopments in computational data protection, and discuss how they can be\ncombined with legal and ethical perspectives to provide secure frameworks for\ngenomic data sharing.",
    "published_date": "2018-02-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10568v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.10551v5",
    "title": "A Variational Inequality Perspective on Generative Adversarial Networks",
    "authors": [
      "Gauthier Gidel",
      "Hugo Berard",
      "Gaëtan Vignoud",
      "Pascal Vincent",
      "Simon Lacoste-Julien"
    ],
    "author_ids": [],
    "abstract": "Generative adversarial networks (GANs) form a generative modeling approach\nknown for producing appealing samples, but they are notably difficult to train.\nOne common way to tackle this issue has been to propose new formulations of the\nGAN objective. Yet, surprisingly few studies have looked at optimization\nmethods designed for this adversarial training. In this work, we cast GAN\noptimization problems in the general variational inequality framework. Tapping\ninto the mathematical programming literature, we counter some common\nmisconceptions about the difficulties of saddle point optimization and propose\nto extend techniques designed for variational inequalities to the training of\nGANs. We apply averaging, extrapolation and a computationally cheaper variant\nthat we call extrapolation from the past to the stochastic gradient method\n(SGD) and Adam.",
    "published_date": "2018-02-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML",
      "I.2.6; G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10551v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.10527v1",
    "title": "Approaching near-perfect state discrimination of photonic Bell states through the use of unentangled ancilla photons",
    "authors": [
      "Jake A. Smith",
      "Lev Kaplan"
    ],
    "author_ids": [],
    "abstract": "Despite well-established no-go theorems on a perfect linear optical Bell\nstate analyzer, we find a numerical trend that appears to approach a\nnear-perfect measurement if we incorporate eight or more un-entangled ancilla\nphotons into our device. Following this trend, we begin a promising inductive\napproach to building an ideal optical Bell measurement device. In the process,\nwe determine that any Bell state analyzer that (even occasionally) bunches all\nphotons into only two of the output modes cannot perform an ideal measurement\nand we find a set of conditions on our linear optical circuit that prevent this\noutcome.",
    "published_date": "2018-02-28T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10527v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.10519v1",
    "title": "On the Lie bracket approximation approach to distributed optimization: Extensions and limitations",
    "authors": [
      "Simon Michalowsky",
      "Bahman Gharesifard",
      "Christian Ebenbauer"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of solving a smooth convex optimization problem with\nequality and inequality constraints in a distributed fashion. Assuming that we\nhave a group of agents available capable of communicating over a communication\nnetwork described by a time-invariant directed graph, we derive distributed\ncontinuous-time agent dynamics that ensure convergence to a neighborhood of the\noptimal solution of the optimization problem. Following the ideas introduced in\nour previous work, we combine saddle-point dynamics with Lie bracket\napproximation techniques. While the methodology was previously limited to\nlinear constraints and objective functions given by a sum of strictly convex\nseparable functions, we extend these result here and show that it applies to a\nvery general class of optimization problems under mild assumptions on the\ncommunication topology.",
    "published_date": "2018-02-28T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10519v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.10408v3",
    "title": "A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments",
    "authors": [
      "German I. Parisi",
      "Pablo Barros",
      "Di Fu",
      "Sven Magg",
      "Haiyan Wu",
      "Xun Liu",
      "Stefan Wermter"
    ],
    "author_ids": [],
    "abstract": "Crossmodal conflict resolution is crucial for robot sensorimotor coupling\nthrough the interaction with the environment, yielding swift and robust\nbehaviour also in noisy conditions. In this paper, we propose a neurorobotic\nexperiment in which an iCub robot exhibits human-like responses in a complex\ncrossmodal environment. To better understand how humans deal with multisensory\nconflicts, we conducted a behavioural study exposing 33 subjects to congruent\nand incongruent dynamic audio-visual cues. In contrast to previous studies\nusing simplified stimuli, we designed a scenario with four animated avatars and\nobserved that the magnitude and extension of the visual bias are related to the\nsemantics embedded in the scene, i.e., visual cues that are congruent with\nenvironmental statistics (moving lips and vocalization) induce the strongest\nbias. We implement a deep learning model that processes stereophonic sound,\nfacial features, and body motion to trigger a discrete behavioural response.\nAfter training the model, we exposed the iCub to the same experimental\nconditions as the human subjects, showing that the robot can replicate similar\nresponses in real time. Our interdisciplinary work provides important insights\ninto how crossmodal conflict resolution can be modelled in robots and\nintroduces future research directions for the efficient combination of sensory\nobservations with internally generated knowledge and expectations.",
    "published_date": "2018-02-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10408v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.10188v2",
    "title": "Safety Control Synthesis with Input Limits: a Hybrid Approach",
    "authors": [
      "Gray C. Thomas",
      "Binghan He",
      "Luis Sentis"
    ],
    "author_ids": [],
    "abstract": "We introduce a hybrid (discrete--continuous) safety controller which enforces\nstrict state and input constraints on a system---but only acts when necessary,\npreserving transparent operation of the original system within some safe region\nof the state space. We define this space using a Min-Quadratic Barrier\nfunction, which we construct along the equilibrium manifold using the Lyapunov\nfunctions which result from linear matrix inequality controller synthesis for\nlocally valid uncertain linearizations. We also introduce the concept of a\nbarrier pair, which makes it easy to extend the approach to include\ntrajectory-based augmentations to the safe region, in the style of LQR-Trees.\nWe demonstrate our controller and barrier pair synthesis method in\nsimulation-based examples.",
    "published_date": "2018-02-27T00:00:00",
    "year": 2018,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10188v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1803.03662v2",
    "title": "Hate Speech Detection: A Solved Problem? The Challenging Case of Long Tail on Twitter",
    "authors": [
      "Ziqi Zhang",
      "Lei Luo"
    ],
    "author_ids": [],
    "abstract": "In recent years, the increasing propagation of hate speech on social media\nand the urgent need for effective counter-measures have drawn significant\ninvestment from governments, companies, and researchers. A large number of\nmethods have been developed for automated hate speech detection online. This\naims to classify textual content into non-hate or hate speech, in which case\nthe method may also identify the targeting characteristics (i.e., types of\nhate, such as race, and religion) in the hate speech. However, we notice\nsignificant difference between the performance of the two (i.e., non-hate v.s.\nhate). In this work, we argue for a focus on the latter problem for practical\nreasons. We show that it is a much more challenging task, as our analysis of\nthe language in the typical datasets shows that hate speech lacks unique,\ndiscriminative features and therefore is found in the 'long tail' in a dataset\nthat is difficult to discover. We then propose Deep Neural Network structures\nserving as feature extractors that are particularly effective for capturing the\nsemantics of hate speech. Our methods are evaluated on the largest collection\nof hate speech datasets based on Twitter, and are shown to be able to\noutperform the best performing method by up to 5 percentage points in\nmacro-average F1, or 8 percentage points in the more challenging case of\nidentifying hateful content.",
    "published_date": "2018-02-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.03662v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.10031v3",
    "title": "The Mirage of Action-Dependent Baselines in Reinforcement Learning",
    "authors": [
      "George Tucker",
      "Surya Bhupatiraju",
      "Shixiang Gu",
      "Richard E. Turner",
      "Zoubin Ghahramani",
      "Sergey Levine"
    ],
    "author_ids": [],
    "abstract": "Policy gradient methods are a widely used class of model-free reinforcement\nlearning algorithms where a state-dependent baseline is used to reduce gradient\nestimator variance. Several recent papers extend the baseline to depend on both\nthe state and action and suggest that this significantly reduces variance and\nimproves sample efficiency without introducing bias into the gradient\nestimates. To better understand this development, we decompose the variance of\nthe policy gradient estimator and numerically show that learned\nstate-action-dependent baselines do not in fact reduce variance over a\nstate-dependent baseline in commonly tested benchmark domains. We confirm this\nunexpected result by reviewing the open-source code accompanying these prior\npapers, and show that subtle implementation decisions cause deviations from the\nmethods presented in the papers and explain the source of the previously\nobserved empirical gains. Furthermore, the variance decomposition highlights\nareas for improvement, which we demonstrate by illustrating a simple change to\nthe typical value function parameterization that can significantly improve\nperformance.",
    "published_date": "2018-02-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10031v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.10089v4",
    "title": "Friction Variability in Planar Pushing Data: Anisotropic Friction and Data-collection Bias",
    "authors": [
      "Daolin Ma",
      "Alberto Rodriguez"
    ],
    "author_ids": [],
    "abstract": "Friction plays a key role in manipulating objects. Most of what we do with\nour hands, and most of what robots do with their grippers, is based on the\nability to control frictional forces. This paper aims to better understand the\nvariability and predictability of planar friction. In particular, we focus on\nthe analysis of a recent dataset on planar pushing by Yu et al. [1] devised to\ncreate a data-driven footprint of planar friction.\n  We show in this paper how we can explain a significant fraction of the\nobserved unconventional phenomena, e.g., stochasticity and multi-modality, by\ncombining the effects of material non-homogeneity, anisotropy of friction and\nbiases due to data collection dynamics, hinting that the variability is\nexplainable but inevitable in practice.\n  We introduce an anisotropic friction model and conduct simulation experiments\ncomparing with more standard isotropic friction models. The anisotropic\nfriction between object and supporting surface results in convergence of\ninitial condition during the automated data collection. Numerical results\nconfirm that the anisotropic friction model explains the bias in the dataset\nand the apparent stochasticity in the outcome of a push. The fact that the data\ncollection process itself can originate biases in the collected datasets,\nresulting in deterioration of trained models, calls attention to the data\ncollection dynamics.",
    "published_date": "2018-02-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO",
      "physics.data-an",
      "70F40"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.10089v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.09617v2",
    "title": "Multiscale Planar Graph Generation",
    "authors": [
      "Varsha Chauhan",
      "Alexander Gutfraind",
      "Ilya Safro"
    ],
    "author_ids": [],
    "abstract": "The study of network representations of physical, biological, and social\nphenomena can help us better understand the structural and functional dynamics\nof their networks and formulate predictive models of these phenomena. However,\ndue to the scarcity of real-world network data owing to factors such as cost\nand effort required in collection of network data and the sensitivity of this\ndata towards theft and misuse, engineers and researchers often rely on\nsynthetic data for simulations, hypothesis testing, decision making, and\nalgorithm engineering. An important characteristic of infrastructure networks\nsuch as roads, water distribution and other utility systems is that they can be\nembedded in a plane, therefore to simulate these system we need realistic\nnetworks which are also planar. While the currently-available synthetic network\ngenerators can model networks that exhibit realism, they do not guarantee or\nachieve planarity. Therefore, in this paper we present a flexible algorithm\nthat can synthesize realistic networks that are planar. The method follows a\nmulti-scale randomized editing approach generating a hierarchy of coarsened\nnetworks of a given planar graph and introducing edits at various levels in the\nhierarchy. The method preserves the structural properties with minimal bias\nincluding the planarity of the network, while introducing realistic variability\nat multiple scales.",
    "published_date": "2018-02-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.09617v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.09426v2",
    "title": "Tone Biased MMR Text Summarization",
    "authors": [
      "Mayank Chaudhari",
      "Aakash Nelson Mattukoyya"
    ],
    "author_ids": [],
    "abstract": "Text summarization is an interesting area for researchers to develop new\ntechniques to provide human like summaries for vast amounts of information.\nSummarization techniques tend to focus on providing accurate representation of\ncontent, and often the tone of the content is ignored. Tone of the content sets\na baseline for how a reader perceives the content. As such being able to\ngenerate summary with tone that is appropriate for the reader is important. In\nour work we implement Maximal Marginal Relevance [MMR] based multi-document\ntext summarization and propose a naive model to change tone of the\nsummarization by setting a bias to specific set of words and restricting other\nwords in the summarization output. This bias towards a specified set of words\nproduces a summary whose tone is same as tone of specified words.",
    "published_date": "2018-02-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.09426v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.09269v1",
    "title": "Wealth Inequality and the Price of Anarchy",
    "authors": [
      "Kurtuluş Gemici",
      "Elias Koutsoupias",
      "Barnabé Monnot",
      "Christos Papadimitriou",
      "Georgios Piliouras"
    ],
    "author_ids": [],
    "abstract": "Price of anarchy quantifies the degradation of social welfare in games due to\nthe lack of a centralized authority that can enforce the optimal outcome. At\nits antipodes, mechanism design studies how to ameliorate these effects by\nincentivizing socially desirable behavior and implementing the optimal state as\nequilibrium. In practice, the responsiveness to such measures depends on the\nwealth of each individual. This leads to a natural, but largely unexplored,\nquestion. Does optimal mechanism design entrench, or maybe even exacerbate,\nsocial inequality?\n  We study this question in nonatomic congestion games, arguably one of the\nmost thoroughly studied settings from the perspectives of price of anarchy as\nwell as mechanism design. We introduce a new model that incorporates the wealth\ndistribution of the population and captures the income elasticity of travel\ntime. This allows us to argue about the equality of wealth distribution both\nbefore and after employing a mechanism. We start our analysis by establishing a\nbroad qualitative result, showing that tolls always increase inequality in\nsymmetric congestion games under any reasonable metric of inequality, e.g., the\nGini index. Next, we introduce the iniquity index, a novel measure for\nquantifying the magnitude of these forces towards a more unbalanced wealth\ndistribution and show it has good normative properties (robustness to scaling\nof income, no-regret learning). We analyze iniquity both in theoretical\nsettings (Pigou's network under various wealth distributions) as well as\nexperimental ones (based on a large scale field experiment in Singapore).\nFinally, we provide an algorithm for computing optimal tolls for any point of\nthe trade-off of relative importance of efficiency and equality. We conclude\nwith a discussion of our findings in the context of theories of justice as\ndeveloped in contemporary social sciences.",
    "published_date": "2018-02-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.09269v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.09091v3",
    "title": "Revisiting the poverty of the stimulus: hierarchical generalization without a hierarchical bias in recurrent neural networks",
    "authors": [
      "R. Thomas McCoy",
      "Robert Frank",
      "Tal Linzen"
    ],
    "author_ids": [],
    "abstract": "Syntactic rules in natural language typically need to make reference to\nhierarchical sentence structure. However, the simple examples that language\nlearners receive are often equally compatible with linear rules. Children\nconsistently ignore these linear explanations and settle instead on the correct\nhierarchical one. This fact has motivated the proposal that the learner's\nhypothesis space is constrained to include only hierarchical rules. We examine\nthis proposal using recurrent neural networks (RNNs), which are not constrained\nin such a way. We simulate the acquisition of question formation, a\nhierarchical transformation, in a fragment of English. We find that some RNN\narchitectures tend to learn the hierarchical rule, suggesting that hierarchical\ncues within the language, combined with the implicit architectural biases\ninherent in certain RNNs, may be sufficient to induce hierarchical\ngeneralizations. The likelihood of acquiring the hierarchical generalization\nincreased when the language included an additional cue to hierarchy in the form\nof subject-verb agreement, underscoring the role of cues to hierarchy in the\nlearner's input.",
    "published_date": "2018-02-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.09091v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08674v1",
    "title": "An Algorithmic Framework to Control Bias in Bandit-based Personalization",
    "authors": [
      "L. Elisa Celis",
      "Sayash Kapoor",
      "Farnood Salehi",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue.",
    "published_date": "2018-02-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08674v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08626v3",
    "title": "Empirical Risk Minimization under Fairness Constraints",
    "authors": [
      "Michele Donini",
      "Luca Oneto",
      "Shai Ben-David",
      "John Shawe-Taylor",
      "Massimiliano Pontil"
    ],
    "author_ids": [],
    "abstract": "We address the problem of algorithmic fairness: ensuring that sensitive\nvariables do not unfairly influence the outcome of a classifier. We present an\napproach based on empirical risk minimization, which incorporates a fairness\nconstraint into the learning problem. It encourages the conditional risk of the\nlearned classifier to be approximately constant with respect to the sensitive\nvariable. We derive both risk and fairness bounds that support the statistical\nconsistency of our approach. We specify our approach to kernel methods and\nobserve that the fairness requirement implies an orthogonality constraint which\ncan be easily added to these methods. We further observe that for linear models\nthe constraint translates into a simple data preprocessing step. Experiments\nindicate that the method is empirically effective and performs favorably\nagainst state-of-the-art approaches.",
    "published_date": "2018-02-23T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08626v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08535v1",
    "title": "Can Neural Networks Understand Logical Entailment?",
    "authors": [
      "Richard Evans",
      "David Saxton",
      "David Amos",
      "Pushmeet Kohli",
      "Edward Grefenstette"
    ],
    "author_ids": [],
    "abstract": "We introduce a new dataset of logical entailments for the purpose of\nmeasuring models' ability to capture and exploit the structure of logical\nexpressions against an entailment prediction task. We use this task to compare\na series of architectures which are ubiquitous in the sequence-processing\nliterature, in addition to a new model class---PossibleWorldNets---which\ncomputes entailment as a \"convolution over possible worlds\". Results show that\nconvolutional networks present the wrong inductive bias for this class of\nproblems relative to LSTM RNNs, tree-structured neural networks outperform LSTM\nRNNs due to their enhanced ability to exploit the syntax of logic, and\nPossibleWorldNets outperform all benchmarks.",
    "published_date": "2018-02-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08535v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08407v2",
    "title": "Exponentially Consistent Kernel Two-Sample Tests",
    "authors": [
      "Shengyu Zhu",
      "Biao Chen",
      "Zhitang Chen"
    ],
    "author_ids": [],
    "abstract": "Given two sets of independent samples from unknown distributions $P$ and $Q$,\na two-sample test decides whether to reject the null hypothesis that $P=Q$.\nRecent attention has focused on kernel two-sample tests as the test statistics\nare easy to compute, converge fast, and have low bias with their finite sample\nestimates. However, there still lacks an exact characterization on the\nasymptotic performance of such tests, and in particular, the rate at which the\ntype-II error probability decays to zero in the large sample limit. In this\nwork, we establish that a class of kernel two-sample tests are exponentially\nconsistent with Polish, locally compact Hausdorff sample space, e.g., $\\mathbb\nR^d$. The obtained exponential decay rate is further shown to be optimal among\nall two-sample tests satisfying the level constraint, and is independent of\nparticular kernels provided that they are bounded continuous and\ncharacteristic. Our results gain new insights into related issues such as fair\nalternative for testing and kernel selection strategy. Finally, as an\napplication, we show that a kernel based test achieves the optimal detection\nfor off-line change detection in the nonparametric setting.",
    "published_date": "2018-02-23T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08407v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08290v2",
    "title": "Locally Adaptive Learning Loss for Semantic Image Segmentation",
    "authors": [
      "Jinjiang Guo",
      "Pengyuan Ren",
      "Aiguo Gu",
      "Jian Xu",
      "Weixin Wu"
    ],
    "author_ids": [],
    "abstract": "We propose a novel locally adaptive learning estimator for enhancing the\ninter- and intra- discriminative capabilities of Deep Neural Networks, which\ncan be used as improved loss layer for semantic image segmentation tasks. Most\nloss layers compute pixel-wise cost between feature maps and ground truths,\nignoring spatial layouts and interactions between neighboring pixels with same\nobject category, and thus networks cannot be effectively sensitive to\nintra-class connections. Stride by stride, our method firstly conducts adaptive\npooling filter operating over predicted feature maps, aiming to merge predicted\ndistributions over a small group of neighboring pixels with same category, and\nthen it computes cost between the merged distribution vector and their category\nlabel. Such design can make groups of neighboring predictions from same\ncategory involved into estimations on predicting correctness with respect to\ntheir category, and hence train networks to be more sensitive to regional\nconnections between adjacent pixels based on their categories. In the\nexperiments on Pascal VOC 2012 segmentation datasets, the consistently improved\nresults show that our proposed approach achieves better segmentation masks\nagainst previous counterparts.",
    "published_date": "2018-02-23T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08290v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.08351v3",
    "title": "A Cut-And-Choose Mechanism to Prevent Gerrymandering",
    "authors": [
      "Jamie Tucker-Foltz"
    ],
    "author_ids": [],
    "abstract": "This paper presents a novel mechanism to endogenously determine the fair\ndivision of a state into electoral districts in a two-party setting. No\ngeometric constraints are imposed on voter distributions or district shapes;\ninstead, it is assumed that any partition of the population into districts of\nequal population is feasible. One party divides the map, then the other party\nchooses a minimum threshold level of support needed to win a district.\nDistricts in which neither party meets this threshold are awarded randomly.\nDespite the inherent asymmetry, the equilibria of this mechanism always yield\nfair outcomes, up to integer rounding.",
    "published_date": "2018-02-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08351v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.08246v3",
    "title": "Characterizing Implicit Bias in Terms of Optimization Geometry",
    "authors": [
      "Suriya Gunasekar",
      "Jason Lee",
      "Daniel Soudry",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "We study the implicit bias of generic optimization methods, such as mirror\ndescent, natural gradient descent, and steepest descent with respect to\ndifferent potentials and norms, when optimizing underdetermined linear\nregression or separable linear classification problems. We explore the question\nof whether the specific global minimum (among the many possible global minima)\nreached by an algorithm can be characterized in terms of the potential or norm\nof the optimization geometry, and independently of hyperparameter choices such\nas step-size and momentum.",
    "published_date": "2018-02-22T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.08246v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.07805v1",
    "title": "The Signpost Platform for City-Scale Sensing",
    "authors": [
      "Joshua Adkins",
      "Branden Ghena",
      "Neal Jackson",
      "Pat Pannuto",
      "Samuel Rohrer",
      "Bradford Campbell",
      "Prabal Dutta"
    ],
    "author_ids": [],
    "abstract": "City-scale sensing holds the promise of enabling a deeper understanding of\nour urban environments. However, a city-scale deployment requires physical\ninstallation, power management, and communications---all challenging tasks\nstanding between a good idea and a realized one. This indicates the need for a\nplatform that enables easy deployment and experimentation for applications\noperating at city scale. To address these challenges, we present Signpost, a\nmodular, energy-harvesting platform for city-scale sensing. Signpost simplifies\ndeployment by eliminating the need for connection to wired infrastructure and\ninstead harvesting energy from an integrated solar panel. The platform\nfurnishes the key resources necessary to support multiple, pluggable sensor\nmodules while providing fair, safe, and reliable sharing in the face of dynamic\nenergy constraints. We deploy Signpost with several sensor modules, showing the\nviability of an energy-harvesting, multi-tenant, sensing system, and evaluate\nits ability to support sensing applications. We believe Signpost reduces the\ndifficulty inherent in city-scale deployments, enables new experimentation, and\nprovides improved insights into urban health.",
    "published_date": "2018-02-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.07805v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.07572v2",
    "title": "Information Theoretic Co-Training",
    "authors": [
      "David McAllester"
    ],
    "author_ids": [],
    "abstract": "This paper introduces an information theoretic co-training objective for\nunsupervised learning. We consider the problem of predicting the future. Rather\nthan predict future sensations (image pixels or sound waves) we predict\n\"hypotheses\" to be confirmed by future sensations. More formally, we assume a\npopulation distribution on pairs $(x,y)$ where we can think of $x$ as a past\nsensation and $y$ as a future sensation. We train both a predictor model\n$P_\\Phi(z|x)$ and a confirmation model $P_\\Psi(z|y)$ where we view $z$ as\nhypotheses (when predicted) or facts (when confirmed). For a population\ndistribution on pairs $(x,y)$ we focus on the problem of measuring the mutual\ninformation between $x$ and $y$. By the data processing inequality this mutual\ninformation is at least as large as the mutual information between $x$ and $z$\nunder the distribution on triples $(x,z,y)$ defined by the confirmation model\n$P_\\Psi(z|y)$. The information theoretic training objective for $P_\\Phi(z|x)$\nand $P_\\Psi(z|y)$ can be viewed as a form of co-training where we want the\nprediction from $x$ to match the confirmation from $y$.",
    "published_date": "2018-02-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.07572v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.07281v2",
    "title": "Fairness of Exposure in Rankings",
    "authors": [
      "Ashudeep Singh",
      "Thorsten Joachims"
    ],
    "author_ids": [],
    "abstract": "Rankings are ubiquitous in the online world today. As we have transitioned\nfrom finding books in libraries to ranking products, jobs, job applicants,\nopinions and potential romantic partners, there is a substantial precedent that\nranking systems have a responsibility not only to their users but also to the\nitems being ranked. To address these often conflicting responsibilities, we\npropose a conceptual and computational framework that allows the formulation of\nfairness constraints on rankings in terms of exposure allocation. As part of\nthis framework, we develop efficient algorithms for finding rankings that\nmaximize the utility for the user while provably satisfying a specifiable\nnotion of fairness. Since fairness goals can be application specific, we show\nhow a broad range of fairness constraints can be implemented using our\nframework, including forms of demographic parity, disparate treatment, and\ndisparate impact constraints. We illustrate the effect of these constraints by\nproviding empirical results on two ranking problems.",
    "published_date": "2018-02-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IR",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.07281v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.07105v1",
    "title": "Bias Compensation in Iterative Soft-Feedback Algorithms with Application to (Discrete) Compressed Sensing",
    "authors": [
      "Susanne Sparrer",
      "Robert F. H. Fischer"
    ],
    "author_ids": [],
    "abstract": "In all applications in digital communications, it is crucial for an estimator\nto be unbiased. Although so-called soft feedback is widely employed in many\ndifferent fields of engineering, typically the biased estimate is used. In this\npaper, we contrast the fundamental unbiasing principles, which can be directly\napplied whenever soft feedback is required. To this end, the problem is treated\nfrom a signal-based perspective, as well as from the approach of estimating the\nsignal based on an estimate of the noise. Numerical results show that when\nemployed in iterative reconstruction algorithms for Compressed Sensing, a gain\nof 1.2 dB due to proper unbiasing is possible.",
    "published_date": "2018-02-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.07105v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.06936v2",
    "title": "Online Learning with an Unknown Fairness Metric",
    "authors": [
      "Stephen Gillen",
      "Christopher Jung",
      "Michael Kearns",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of online learning in the linear contextual bandits\nsetting, but in which there are also strong individual fairness constraints\ngoverned by an unknown similarity metric. These constraints demand that we\nselect similar actions or individuals with approximately equal probability\n(arXiv:1104.3913), which may be at odds with optimizing reward, thus modeling\nsettings where profit and social policy are in tension. We assume we learn\nabout an unknown Mahalanobis similarity metric from only weak feedback that\nidentifies fairness violations, but does not quantify their extent. This is\nintended to represent the interventions of a regulator who \"knows unfairness\nwhen he sees it\" but nevertheless cannot enunciate a quantitative fairness\nmetric over individuals. Our main result is an algorithm in the adversarial\ncontext setting that has a number of fairness violations that depends only\nlogarithmically on $T$, while obtaining an optimal $O(\\sqrt{T})$ regret bound\nto the best fair policy.",
    "published_date": "2018-02-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06936v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.06926v1",
    "title": "Scale Optimization for Full-Image-CNN Vehicle Detection",
    "authors": [
      "Yang Gao",
      "Shouyan Guo",
      "Kaimin Huang",
      "Jiaxin Chen",
      "Qian Gong",
      "Yang Zou",
      "Tong Bai",
      "Gary Overett"
    ],
    "author_ids": [],
    "abstract": "Many state-of-the-art general object detection methods make use of shared\nfull-image convolutional features (as in Faster R-CNN). This achieves a\nreasonable test-phase computation time while enjoys the discriminative power\nprovided by large Convolutional Neural Network (CNN) models. Such designs excel\non benchmarks which contain natural images but which have very unnatural\ndistributions, i.e. they have an unnaturally high-frequency of the target\nclasses and a bias towards a \"friendly\" or \"dominant\" object scale. In this\npaper we present further study of the use and adaptation of the Faster R-CNN\nobject detection method for datasets presenting natural scale distribution and\nunbiased real-world object frequency. In particular, we show that better\nalignment of the detector scale sensitivity to the extant distribution improves\nvehicle detection performance. We do this by modifying both the selection of\nRegion Proposals, and through using more scale-appropriate full-image\nconvolution features within the CNN model. By selecting better scales in the\nregion proposal input and by combining feature maps through careful design of\nthe convolutional neural network, we improve performance on smaller objects. We\nsignificantly increase detection AP for the KITTI dataset car class from 76.3%\non our baseline Faster R-CNN detector to 83.6% in our improved detector.",
    "published_date": "2018-02-20T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06926v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.06547v1",
    "title": "Weighted Linear Discriminant Analysis based on Class Saliency Information",
    "authors": [
      "Lei Xu",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a new variant of Linear Discriminant Analysis to\novercome underlying drawbacks of traditional LDA and other LDA variants\ntargeting problems involving imbalanced classes. Traditional LDA sets\nassumptions related to Gaussian class distribution and neglects influence of\noutlier classes, that might hurt in performance. We exploit intuitions coming\nfrom a probabilistic interpretation of visual saliency estimation in order to\ndefine saliency of a class in multi-class setting. Such information is then\nused to redefine the between-class and within-class scatters in a more robust\nmanner. Compared to traditional LDA and other weight-based LDA variants, the\nproposed method has shown certain improvements on facial image classification\nproblems in publicly available datasets.",
    "published_date": "2018-02-19T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06547v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.06309v3",
    "title": "Learning Adversarially Fair and Transferable Representations",
    "authors": [
      "David Madras",
      "Elliot Creager",
      "Toniann Pitassi",
      "Richard Zemel"
    ],
    "author_ids": [],
    "abstract": "In this paper, we advocate for representation learning as the key to\nmitigating unfair prediction outcomes downstream. Motivated by a scenario where\nlearned representations are used by third parties with unknown objectives, we\npropose and explore adversarial representation learning as a natural method of\nensuring those parties act fairly. We connect group fairness (demographic\nparity, equalized odds, and equal opportunity) to different adversarial\nobjectives. Through worst-case theoretical guarantees and experimental\nvalidation, we show that the choice of this objective is crucial to fair\nprediction. Furthermore, we present the first in-depth experimental\ndemonstration of fair transfer learning and demonstrate empirically that our\nlearned representations admit fair predictions on new tasks while maintaining\nutility, an essential goal of fair representation learning.",
    "published_date": "2018-02-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06309v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.07132v1",
    "title": "Capstone: Mobility Modeling on Smartphones to Achieve Privacy by Design",
    "authors": [
      "Vaibhav Kulkarni",
      "Arielle Moro",
      "Bertil Chapuis",
      "Benoit Garbinato"
    ],
    "author_ids": [],
    "abstract": "Sharing location traces with context-aware service providers has privacy\nimplications. Location-privacy preserving mechanisms, such as obfuscation,\nanonymization and cryptographic primitives, have been shown to have impractical\nutility/privacy tradeoff. Another solution for enhancing user privacy is to\nminimize data sharing by executing the tasks conventionally carried out at the\nservice providers' end on the users' smartphones. Although the data volume\nshared with the untrusted entities is significantly reduced, executing\ncomputationally demanding server-side tasks on resource-constrained smartphones\nis often impracticable. To this end, we propose a novel perspective on lowering\nthe computational complexity by treating spatiotemporal trajectories as\nspace-time signals. Lowering the data dimensionality facilitates offloading the\ncomputational tasks onto the digital-signal processors and the usage of the\nnon-blocking signal-processing pipelines. While focusing on the task of user\nmobility modeling, we achieve the following results in comparison to the state\nof the art techniques: (i) mobility models with precision and recall greater\nthan 80%, (ii) reduction in computational complexity by a factor of 2.5, and\n(iii) reduction in power consumption by a factor of 0.5. Furthermore, our\ntechnique does not rely on users' behavioral parameters that usually result in\nprivacy-leakage and conclusive bias in the existing techniques. Using three\nreal-world mobility datasets, we demonstrate that our technique addresses these\nweaknesses while formulating accurate user mobility models.",
    "published_date": "2018-02-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.07132v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.06209v1",
    "title": "Sentiment Analysis on Speaker Specific Speech Data",
    "authors": [
      "Maghilnan S",
      "Rajesh Kumar M"
    ],
    "author_ids": [],
    "abstract": "Sentiment analysis has evolved over past few decades, most of the work in it\nrevolved around textual sentiment analysis with text mining techniques. But\naudio sentiment analysis is still in a nascent stage in the research community.\nIn this proposed research, we perform sentiment analysis on speaker\ndiscriminated speech transcripts to detect the emotions of the individual\nspeakers involved in the conversation. We analyzed different techniques to\nperform speaker discrimination and sentiment analysis to find efficient\nalgorithms to perform this task.",
    "published_date": "2018-02-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06209v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.06138v2",
    "title": "Detecting Social Influence in Event Cascades by Comparing Discriminative Rankers",
    "authors": [
      "Sandeep Soni",
      "Shawn Ling Ramirez",
      "Jacob Eisenstein"
    ],
    "author_ids": [],
    "abstract": "The global dynamics of event cascades are often governed by the local\ndynamics of peer influence. However, detecting social influence from\nobservational data is challenging due to confounds like homophily and practical\nissues like missing data. We propose a simple discriminative method to detect\ninfluence from observational data. The core of the approach is to train a\nranking algorithm to predict the source of the next event in a cascade, and\ncompare its out-of-sample accuracy against a competitive baseline which lacks\naccess to features corresponding to social influence. We analyze synthetically\ngenerated data to show that this method correctly identifies influence in the\npresence of confounds, and is robust to both missing data and misspecification\n--- unlike well-known alternatives. We apply the method to two real-world\ndatasets: (1) the co-sponsorship of legislation in the U.S. House of\nRepresentatives on a social network of shared campaign donors; (2) rumors about\nthe Higgs boson discovery on a follower network of $10^5$ Twitter accounts. Our\nmodel identifies the role of social influence in these scenarios and uses it to\nmake more accurate predictions about the future trajectory of cascades.",
    "published_date": "2018-02-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.LG",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06138v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.06108v3",
    "title": "Modeling the Formation of Social Conventions from Embodied Real-Time Interactions",
    "authors": [
      "Ismael T. Freire",
      "Clement Moulin-Frier",
      "Marti Sanchez-Fibla",
      "Xerxes D. Arsiwalla",
      "Paul Verschure"
    ],
    "author_ids": [],
    "abstract": "What is the role of real-time control and learning in the formation of social\nconventions? To answer this question, we propose a computational model that\nmatches human behavioral data in a social decision-making game that was\nanalyzed both in discrete-time and continuous-time setups. Furthermore, unlike\nprevious approaches, our model takes into account the role of sensorimotor\ncontrol loops in embodied decision-making scenarios. For this purpose, we\nintroduce the Control-based Reinforcement Learning (CRL) model. CRL is grounded\nin the Distributed Adaptive Control (DAC) theory of mind and brain, where\nlow-level sensorimotor control is modulated through perceptual and behavioral\nlearning in a layered structure. CRL follows these principles by implementing a\nfeedback control loop handling the agent's reactive behaviors (pre-wired\nreflexes), along with an adaptive layer that uses reinforcement learning to\nmaximize long-term reward. We test our model in a multi-agent game-theoretic\ntask in which coordination must be achieved to find an optimal solution. We\nshow that CRL is able to reach human-level performance on standard\ngame-theoretic metrics such as efficiency in acquiring rewards and fairness in\nreward distribution.",
    "published_date": "2018-02-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "q-bio.NC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.06108v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.05814v1",
    "title": "Variational Autoencoders for Collaborative Filtering",
    "authors": [
      "Dawen Liang",
      "Rahul G. Krishnan",
      "Matthew D. Hoffman",
      "Tony Jebara"
    ],
    "author_ids": [],
    "abstract": "We extend variational autoencoders (VAEs) to collaborative filtering for\nimplicit feedback. This non-linear probabilistic model enables us to go beyond\nthe limited modeling capacity of linear factor models which still largely\ndominate collaborative filtering research.We introduce a generative model with\nmultinomial likelihood and use Bayesian inference for parameter estimation.\nDespite widespread use in language modeling and economics, the multinomial\nlikelihood receives less attention in the recommender systems literature. We\nintroduce a different regularization parameter for the learning objective,\nwhich proves to be crucial for achieving competitive performance. Remarkably,\nthere is an efficient way to tune the parameter using annealing. The resulting\nmodel and learning algorithm has information-theoretic connections to maximum\nentropy discrimination and the information bottleneck principle. Empirically,\nwe show that the proposed approach significantly outperforms several\nstate-of-the-art baselines, including two recently-proposed neural network\napproaches, on several real-world datasets. We also provide extended\nexperiments comparing the multinomial likelihood with other commonly used\nlikelihood functions in the latent factor collaborative filtering literature\nand show favorable results. Finally, we identify the pros and cons of employing\na principled Bayesian inference approach and characterize settings where it\nprovides the most significant improvements.",
    "published_date": "2018-02-16T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.IR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.05814v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.05484v1",
    "title": "On the P vs NP question: a proof of inequality",
    "authors": [
      "Angelo Raffaele Meo"
    ],
    "author_ids": [],
    "abstract": "The analysis discussed in this paper is based on a well-known NP-complete\nproblem which is called satisfiability problem or SAT. From SAT a new\nNP-complete problem is derived, which is described by a Boolean function called\ncore function. In this paper it is proved that the cost of the minimal\nimplementation of core function increases with n exponentially. Since the\nsynthesis of core function is an NP-complete problem, this result is equivalent\nto proving that P and NP do not coincide.",
    "published_date": "2018-02-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.05484v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.04951v1",
    "title": "Optimal Fairness-Aware Time and Power Allocation in Wireless Powered Communication Networks",
    "authors": [
      "Zhaohui Yang",
      "Wei Xu",
      "Yijin Pan",
      "Cunhua Pan",
      "Ming Chen"
    ],
    "author_ids": [],
    "abstract": "In this paper, we consider the sum $\\alpha$-fair utility maximization problem\nfor joint downlink (DL) and uplink (UL) transmissions of a wireless powered\ncommunication network (WPCN) via time and power allocation. In the DL, the\nusers with energy harvesting receiver architecture decode information and\nharvest energy based on simultaneous wireless information and power transfer.\nWhile in the UL, the users utilize the harvested energy for information\ntransmission, and harvest energy when other users transmit UL information. We\nshow that the general sum $\\alpha$-fair utility maximization problem can be\ntransformed into an equivalent convex one. Tradeoffs between sum rate and user\nfairness can be balanced via adjusting the value of $\\alpha$. In particular,\nfor zero fairness, i.e., $\\alpha=0$, the optimal allocated time for both DL and\nUL is proportional to the overall available transmission power. Tradeoffs\nbetween sum rate and user fairness are presented through simulations.",
    "published_date": "2018-02-14T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04951v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.04769v1",
    "title": "Edge Caching in Delay-Constrained Virtualized Cellular Networks: Analysis and Market",
    "authors": [
      "Tachporn Sanguanpuak",
      "Sudarshan Guruacharya",
      "Ekram Hossain",
      "Dusit Niyato",
      "Nandana Rajatheva",
      "Matti Latva-aho"
    ],
    "author_ids": [],
    "abstract": "Caching of popular contents at cellular base stations, i.e., edge caching, in\norder to eliminate duplicate transmission through the backhaul can reduce the\nlatency of data delivery in $5$G networks. However, since caching can only\nreduce the backhaul delay, techniques such as base station densification will\nalso need to be used to reduce the fronthaul delay. In this paper, using\nresults from stochastic geometry, we first model the effects of base station\ndensification and cache size on the latency of the system. We then derive a\ntight approximation for the cache hit probability. To optimize the network cost\ndue to the deployment of base station (BS) and cache storage, a minimization\nproblem for the product of the BS intensity and cache size is formulated under\nprobabilistic delay constraint, which is converted into a geometric program and\nsolved analytically. The results are then used to analyze the economics of a\ncache-enabled virtualized cellular network where the network infrastructure,\ni.e., BSs and cache storage, owned by an infrastructure provider (InP) is\nshared among multiple mobile network operators (MNOs). For the pricing between\nthe InP and the MNOs, we formulate a Stackelberg game with the InP as the\nleader and multiple MNOs as the followers. In this virtualized scenario, the\ncommon cost of renting the infrastructure is shared in a fair manner among the\nMNOs by using the Shapely value. An efficient algorithm is provided to divide\nthe rent among MNOs.",
    "published_date": "2018-02-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04769v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.04668v1",
    "title": "Weakly supervised collective feature learning from curated media",
    "authors": [
      "Yusuke Mukuta",
      "Akisato Kimura",
      "David B Adrian",
      "Zoubin Ghahramani"
    ],
    "author_ids": [],
    "abstract": "The current state-of-the-art in feature learning relies on the supervised\nlearning of large-scale datasets consisting of target content items and their\nrespective category labels. However, constructing such large-scale\nfully-labeled datasets generally requires painstaking manual effort. One\npossible solution to this problem is to employ community contributed text tags\nas weak labels, however, the concepts underlying a single text tag strongly\ndepends on the users. We instead present a new paradigm for learning\ndiscriminative features by making full use of the human curation process on\nsocial networking services (SNSs). During the process of content curation, SNS\nusers collect content items manually from various sources and group them by\ncontext, all for their own benefit. Due to the nature of this process, we can\nassume that (1) content items in the same group share the same semantic concept\nand (2) groups sharing the same images might have related semantic concepts.\nThrough these insights, we can define human curated groups as weak labels from\nwhich our proposed framework can learn discriminative features as a\nrepresentation in the space of semantic concepts the users intended when\ncreating the groups. We show that this feature learning can be formulated as a\nproblem of link prediction for a bipartite graph whose nodes corresponds to\ncontent items and human curated groups, and propose a novel method for feature\nlearning based on sparse coding or network fine-tuning.",
    "published_date": "2018-02-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV",
      "cs.MM",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04668v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.04460v1",
    "title": "Parameterized Bilinear Matrix Inequality Techniques in ${\\cal H}_{\\infty}$ Fuzzy PID Control Design",
    "authors": [
      "Y. Shi",
      "H. D. Tuan"
    ],
    "author_ids": [],
    "abstract": "Proportional-integral-derivative (PID) structured controller is the most\npopular class of industrial control but still could not be appropriately\nexploited in fuzzy systems. To gain the practicability and tractability of\nfuzzy systems, this paper develops a parameterized bilinear matrix inequality\ncharacterization for the ${\\cal H}_{\\infty}$ fuzzy PID control design, which is\nthen relaxed into a bilinear matrix inequality optimization problem of\nnonconvex optimization. Several computational procedures are then developed for\nits solution. The merit of the developed algorithms is shown through the\nbenchmark examples.",
    "published_date": "2018-02-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04460v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.04422v1",
    "title": "A comparative study of fairness-enhancing interventions in machine learning",
    "authors": [
      "Sorelle A. Friedler",
      "Carlos Scheidegger",
      "Suresh Venkatasubramanian",
      "Sonam Choudhary",
      "Evan P. Hamilton",
      "Derek Roth"
    ],
    "author_ids": [],
    "abstract": "Computers are increasingly used to make decisions that have significant\nimpact in people's lives. Often, these predictions can affect different\npopulation subgroups disproportionately. As a result, the issue of fairness has\nreceived much recent interest, and a number of fairness-enhanced classifiers\nand predictors have appeared in the literature. This paper seeks to study the\nfollowing questions: how do these different techniques fundamentally compare to\none another, and what accounts for the differences? Specifically, we seek to\nbring attention to many under-appreciated aspects of such fairness-enhancing\ninterventions. Concretely, we present the results of an open benchmark we have\ndeveloped that lets us compare a number of different algorithms under a variety\nof fairness measures, and a large number of existing datasets. We find that\nalthough different algorithms tend to prefer specific formulations of fairness\npreservations, many of these measures strongly correlate with one another. In\naddition, we find that fairness-preserving algorithms tend to be sensitive to\nfluctuations in dataset composition (simulated in our benchmark by varying\ntraining-test splits), indicating that fairness interventions might be more\nbrittle than previously thought.",
    "published_date": "2018-02-13T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04422v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.04420v2",
    "title": "Towards Understanding the Generalization Bias of Two Layer Convolutional Linear Classifiers with Gradient Descent",
    "authors": [
      "Yifan Wu",
      "Barnabas Poczos",
      "Aarti Singh"
    ],
    "author_ids": [],
    "abstract": "A major challenge in understanding the generalization of deep learning is to\nexplain why (stochastic) gradient descent can exploit the network architecture\nto find solutions that have good generalization performance when using high\ncapacity models. We find simple but realistic examples showing that this\nphenomenon exists even when learning linear classifiers --- between two linear\nnetworks with the same capacity, the one with a convolutional layer can\ngeneralize better than the other when the data distribution has some underlying\nspatial structure. We argue that this difference results from a combination of\nthe convolution architecture, data distribution and gradient descent, all of\nwhich are necessary to be included in a meaningful analysis. We provide a\ngeneral analysis of the generalization performance as a function of data\ndistribution and convolutional filter size, given gradient descent as the\noptimization algorithm, then interpret the results using concrete examples.\nExperimental results show that our analysis is able to explain what happens in\nour introduced examples.",
    "published_date": "2018-02-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04420v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1803.04478v1",
    "title": "Bridge type classification: supervised learning on a modified NBI dataset",
    "authors": [
      "Achyuthan Jootoo",
      "David Lattanzi"
    ],
    "author_ids": [],
    "abstract": "A key phase in the bridge design process is the selection of the structural\nsystem. Due to budget and time constraints, engineers typically rely on\nengineering judgment and prior experience when selecting a structural system,\noften considering a limited range of design alternatives. The objective of this\nstudy was to explore the suitability of supervised machine learning as a\npreliminary design aid that provides guidance to engineers with regards to the\nstatistically optimal bridge type to choose, ultimately improving the\nlikelihood of optimized design, design standardization, and reduced maintenance\ncosts. In order to devise this supervised learning system, data for over\n600,000 bridges from the National Bridge Inventory database were analyzed. Key\nattributes for determining the bridge structure type were identified through\nthree feature selection techniques. Potentially useful attributes like seismic\nintensity and historic data on the cost of materials (steel and concrete) were\nthen added from the US Geological Survey (USGS) database and Engineering News\nRecord. Decision tree, Bayes network and Support Vector Machines were used for\npredicting the bridge design type. Due to state-to-state variations in material\navailability, material costs, and design codes, supervised learning models\nbased on the complete data set did not yield favorable results. Supervised\nlearning models were then trained and tested using 10-fold cross validation on\ndata for each state. Inclusion of seismic data improved the model performance\nnoticeably. The data was then resampled to reduce the bias of the models\ntowards more common design types, and the supervised learning models thus\nconstructed showed further improvements in performance. The average recall and\nprecision for the state models was 88.6% and 88.0% using Decision Trees, 84.0%\nand 83.7% using Bayesian Networks, and 80.8% and 75.6% using SVM.",
    "published_date": "2018-02-12T00:00:00",
    "year": 2018,
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.04478v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.04023v1",
    "title": "Fair and Diverse DPP-based Data Summarization",
    "authors": [
      "L. Elisa Celis",
      "Vijay Keswani",
      "Damian Straszak",
      "Amit Deshpande",
      "Tarun Kathuria",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Sampling methods that choose a subset of the data proportional to its\ndiversity in the feature space are popular for data summarization. However,\nrecent studies have noted the occurrence of bias (under- or over-representation\nof a certain gender or race) in such data summarization methods. In this paper\nwe initiate a study of the problem of outputting a diverse and fair summary of\na given dataset. We work with a well-studied determinantal measure of diversity\nand corresponding distributions (DPPs) and present a framework that allows us\nto incorporate a general class of fairness constraints into such distributions.\nComing up with efficient algorithms to sample from these constrained\ndeterminantal distributions, however, suffers from a complexity barrier and we\npresent a fast sampler that is provably good when the input vectors satisfy a\nnatural property. Our experimental results on a real-world and an image dataset\nshow that the diversity of the samples produced by adding fairness constraints\nis not too far from the unconstrained case, and we also provide a theoretical\nexplanation of it.",
    "published_date": "2018-02-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.IR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04023v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.03765v3",
    "title": "Convex Formulations for Fair Principal Component Analysis",
    "authors": [
      "Matt Olfat",
      "Anil Aswani"
    ],
    "author_ids": [],
    "abstract": "Though there is a growing body of literature on fairness for supervised\nlearning, the problem of incorporating fairness into unsupervised learning has\nbeen less well-studied. This paper studies fairness in the context of principal\ncomponent analysis (PCA). We first present a definition of fairness for\ndimensionality reduction, and our definition can be interpreted as saying that\na reduction is fair if information about a protected class (e.g., race or\ngender) cannot be inferred from the dimensionality-reduced data points. Next,\nwe develop convex optimization formulations that can improve the fairness (with\nrespect to our definition) of PCA and kernel PCA. These formulations are\nsemidefinite programs (SDP's), and we demonstrate the effectiveness of our\nformulations using several datasets. We conclude by showing how our approach\ncan be used to perform a fair (with respect to age) clustering of health data\nthat may be used to set health insurance rates.",
    "published_date": "2018-02-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.03765v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.04255v2",
    "title": "Systems of Global Governance in the Era of Human-Machine Convergence",
    "authors": [
      "Eugenio Maria Battaglia",
      "Jie Mei",
      "Guillaume Dumas"
    ],
    "author_ids": [],
    "abstract": "Technology is increasingly shaping our social structures and is becoming a\ndriving force in altering human biology. Besides, human activities already\nproved to have a significant impact on the Earth system which in turn generates\ncomplex feedback loops between social and ecological systems. Furthermore,\nsince our species evolved relatively fast from small groups of hunter-gatherers\nto large and technology-intensive urban agglomerations, it is not a surprise\nthat the major institutions of human society are no longer fit to cope with the\npresent complexity. In this note we draw foundational parallelisms between\nneurophysiological systems and ICT-enabled social systems, discussing how\nframeworks rooted in biology and physics could provide heuristic value in the\ndesign of evolutionary systems relevant to politics and economics. In this\nregard we highlight how the governance of emerging technology (i.e.\nnanotechnology, biotechnology, information technology, and cognitive science),\nand the one of climate change both presently confront us with a number of\nconnected challenges. In particular: historically high level of inequality; the\nco-existence of growing multipolar cultural systems in an unprecedentedly\nconnected world; the unlikely reaching of the institutional agreements required\nto deviate abnormal trajectories of development. We argue that wise general\nsolutions to such interrelated issues should embed the deep understanding of\nhow to elicit mutual incentives in the socio-economic subsystems of Earth\nsystem in order to jointly concur to a global utility function (e.g. avoiding\nthe reach of planetary boundaries and widespread social unrest). We leave some\nopen questions on how techno-social systems can effectively learn and adapt\nwith respect to our understanding of geopolitical complexity.",
    "published_date": "2018-02-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "physics.soc-ph",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04255v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.03358v1",
    "title": "Deep Learning for Malicious Flow Detection",
    "authors": [
      "Yun-Chun Chen",
      "Yu-Jhe Li",
      "Aragorn Tseng",
      "Tsungnan Lin"
    ],
    "author_ids": [],
    "abstract": "Cyber security has grown up to be a hot issue in recent years. How to\nidentify potential malware becomes a challenging task. To tackle this\nchallenge, we adopt deep learning approaches and perform flow detection on real\ndata. However, real data often encounters an issue of imbalanced data\ndistribution which will lead to a gradient dilution issue. When training a\nneural network, this problem will not only result in a bias toward the majority\nclass but show the inability to learn from the minority classes. In this paper,\nwe propose an end-to-end trainable Tree-Shaped Deep Neural Network (TSDNN)\nwhich classifies the data in a layer-wise manner. To better learn from the\nminority classes, we propose a Quantity Dependent Backpropagation (QDBP)\nalgorithm which incorporates the knowledge of the disparity between classes. We\nevaluate our method on an imbalanced data set. Experimental result demonstrates\nthat our approach outperforms the state-of-the-art methods and justifies that\nthe proposed method is able to overcome the difficulty of imbalanced learning.\nWe also conduct a partial flow experiment which shows the feasibility of\nreal-time detection and a zero-shot learning experiment which justifies the\ngeneralization capability of deep learning in cyber security.",
    "published_date": "2018-02-09T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.03358v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.02745v2",
    "title": "Learning Inductive Biases with Simple Neural Networks",
    "authors": [
      "Reuben Feinman",
      "Brenden M. Lake"
    ],
    "author_ids": [],
    "abstract": "People use rich prior knowledge about the world in order to efficiently learn\nnew concepts. These priors - also known as \"inductive biases\" - pertain to the\nspace of internal models considered by a learner, and they help the learner\nmake inferences that go beyond the observed data. A recent study found that\ndeep neural networks optimized for object recognition develop the shape bias\n(Ritter et al., 2017), an inductive bias possessed by children that plays an\nimportant role in early word learning. However, these networks use\nunrealistically large quantities of training data, and the conditions required\nfor these biases to develop are not well understood. Moreover, it is unclear\nhow the learning dynamics of these networks relate to developmental processes\nin childhood. We investigate the development and influence of the shape bias in\nneural networks using controlled datasets of abstract patterns and synthetic\nimages, allowing us to systematically vary the quantity and form of the\nexperience provided to the learning algorithms. We find that simple neural\nnetworks develop a shape bias after seeing as few as 3 examples of 4 object\ncategories. The development of these biases predicts the onset of vocabulary\nacceleration in our networks, consistent with the developmental process in\nchildren.",
    "published_date": "2018-02-08T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.02745v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.02531v6",
    "title": "Fair comparison of skin detection approaches on publicly available datasets",
    "authors": [
      "Alessandra Lumini",
      "Loris Nanni"
    ],
    "author_ids": [],
    "abstract": "Skin detection is the process of discriminating skin and non-skin regions in\na digital image and it is widely used in several applications ranging from hand\ngesture analysis to track body parts and face detection. Skin detection is a\nchallenging problem which has drawn extensive attention from the research\ncommunity, nevertheless a fair comparison among approaches is very difficult\ndue to the lack of a common benchmark and a unified testing protocol. In this\nwork, we investigate the most recent researches in this field and we propose a\nfair comparison among approaches using several different datasets. The major\ncontributions of this work are an exhaustive literature review of skin color\ndetection approaches, a framework to evaluate and combine different skin\ndetector approaches, whose source code is made freely available for future\nresearch, and an extensive experimental comparison among several recent methods\nwhich have also been used to define an ensemble that works well in many\ndifferent problems. Experiments are carried out in 10 different datasets\nincluding more than 10000 labelled images: experimental results confirm that\nthe best method here proposed obtains a very good performance with respect to\nother stand-alone approaches, without requiring ad hoc parameter tuning. A\nMATLAB version of the framework for testing and of the methods proposed in this\npaper will be freely available from https://github.com/LorisNanni",
    "published_date": "2018-02-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.02531v6",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.02297v2",
    "title": "3D Point Cloud Descriptors in Hand-crafted and Deep Learning Age: State-of-the-Art",
    "authors": [
      "Xian-Feng Han",
      "Shi-Jie Sun",
      "Xiang-Yu Song",
      "Guo-Qiang Xiao"
    ],
    "author_ids": [],
    "abstract": "The introduction of inexpensive 3D data acquisition devices has promisingly\nfacilitated the wide availability and popularity of 3D point cloud, which\nattracts more attention to the effective extraction of novel 3D point cloud\ndescriptors for accuracy of the efficiency of 3D computer vision tasks in\nrecent years. However, how to develop discriminative and robust feature\ndescriptors from 3D point cloud remains a challenging task due to their\nintrinsic characteristics. In this paper, we give a comprehensively insightful\ninvestigation of the existing 3D point cloud descriptors. These methods can\nprincipally be divided into two categories according to the advancement of\ndescriptors: hand-crafted based and deep learning-based apporaches, which will\nbe further discussed from the perspective of elaborate classification, their\nadvantages, and limitations. Finally, we present the future research direction\nof the extraction of 3D point cloud descriptors.",
    "published_date": "2018-02-07T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.02297v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.02188v1",
    "title": "Uptake and outcome of manuscripts in Nature journals by review model and author characteristics",
    "authors": [
      "Barbara McGillivray",
      "Elisa De Ranieri"
    ],
    "author_ids": [],
    "abstract": "Double-blind peer review has been proposed as a possible solution to avoid\nimplicit referee bias in academic publishing. The aims of this study are to\nanalyse the demographics of corresponding authors choosing double blind peer\nreview, and to identify differences in the editorial outcome of manuscripts\ndepending on their review model. Data includes 128,454 manuscripts received\nbetween March 2015 and February 2017 by 25 Nature-branded journals. Author\nuptake for double-blind was 12%. We found a small but significant association\nbetween journal tier and review type. We found no statistically significant\ndifference in the distribution of peer review model between males and females.\nWe found that corresponding authors from the less prestigious institutions are\nmore likely to choose double-blind review. In the ten countries with the\nhighest number of submissions, we found a small but significant association\nbetween country and review type. The outcome at both first decision and post\nreview is significantly more negative (i.e. a higher likelihood for rejection)\nfor double than single-blind papers. Authors choose double-blind review more\nfrequently when they submit to more prestigious journals, they are affiliated\nwith less prestigious institutions or they are from specific countries; the\ndouble-blind option is also linked to less successful editorial outcomes.",
    "published_date": "2018-02-06T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.02188v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.04103v1",
    "title": "Ethical and Social Aspects of Self-Driving Cars",
    "authors": [
      "Tobias Holstein",
      "Gordana Dodig-Crnkovic",
      "Patrizio Pelliccione"
    ],
    "author_ids": [],
    "abstract": "As an envisaged future of transportation, self-driving cars are being\ndiscussed from various perspectives, including social, economical, engineering,\ncomputer science, design, and ethics. On the one hand, self-driving cars\npresent new engineering problems that are being gradually successfully solved.\nOn the other hand, social and ethical problems are typically being presented in\nthe form of an idealized unsolvable decision-making problem, the so-called\ntrolley problem, which is grossly misleading. We argue that an applied\nengineering ethical approach for the development of new technology is what is\nneeded; the approach should be applied, meaning that it should focus on the\nanalysis of complex real-world engineering problems. Software plays a crucial\nrole for the control of self-driving cars; therefore, software engineering\nsolutions should seriously handle ethical and social considerations. In this\npaper we take a closer look at the regulative instruments, standards, design,\nand implementations of components, systems, and services and we present\npractical social and ethical challenges that have to be met, as well as novel\nexpectations for software engineering.",
    "published_date": "2018-02-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.04103v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.01483v2",
    "title": "Explicit Inductive Bias for Transfer Learning with Convolutional Networks",
    "authors": [
      "Xuhong Li",
      "Yves Grandvalet",
      "Franck Davoine"
    ],
    "author_ids": [],
    "abstract": "In inductive transfer learning, fine-tuning pre-trained convolutional\nnetworks substantially outperforms training from scratch. When using\nfine-tuning, the underlying assumption is that the pre-trained model extracts\ngeneric features, which are at least partially relevant for solving the target\ntask, but would be difficult to extract from the limited amount of data\navailable on the target task. However, besides the initialization with the\npre-trained model and the early stopping, there is no mechanism in fine-tuning\nfor retaining the features learned on the source task. In this paper, we\ninvestigate several regularization schemes that explicitly promote the\nsimilarity of the final solution with the initial model. We show the benefit of\nhaving an explicit inductive bias towards the initial model, and we eventually\nrecommend a simple $L^2$ penalty with the pre-trained model being a reference\nas the baseline of penalty for transfer learning tasks.",
    "published_date": "2018-02-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01483v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.01400v1",
    "title": "Polarization and Fake News: Early Warning of Potential Misinformation Targets",
    "authors": [
      "Michela Del Vicario",
      "Walter Quattrociocchi",
      "Antonio Scala",
      "Fabiana Zollo"
    ],
    "author_ids": [],
    "abstract": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.",
    "published_date": "2018-02-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01400v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.01270v1",
    "title": "The Social Structure of Consensus in Scientific Review",
    "authors": [
      "Misha Teplitskiy",
      "Daniel Acuna",
      "Aida Elamrani-Raoult",
      "Konrad Kording",
      "James Evans"
    ],
    "author_ids": [],
    "abstract": "Personal connections between creators and evaluators of scientific works are\nubiquitous, and the possibility of bias ever-present. Although connections have\nbeen shown to bias prospective judgments of (uncertain) future performance, it\nis unknown whether such biases occur in the much more concrete task of\nassessing the scientific validity of already completed work, and if so, why.\nThis study presents evidence that personal connections between authors and\nreviewers of neuroscience manuscripts are associated with biased judgments and\nexplores the mechanisms driving the effect. Using reviews from 7,981\nneuroscience manuscripts submitted to the journal PLOS ONE, which instructs\nreviewers to evaluate manuscripts only on scientific validity, we find that\nreviewers favored authors close in the co-authorship network by ~0.11 points on\na 1.0 - 4.0 scale for each step of proximity. PLOS ONE's validity-focused\nreview and the substantial amount of favoritism shown by distant vs. very\ndistant reviewers, both of whom should have little to gain from nepotism, point\nto the central role of substantive disagreements between scientists in\ndifferent \"schools of thought.\" The results suggest that removing bias from\npeer review cannot be accomplished simply by recusing the closely-connected\nreviewers, and highlight the value of recruiting reviewers embedded in diverse\nprofessional networks.",
    "published_date": "2018-02-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01270v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.01167v1",
    "title": "Industrial Symbiotic Relations as Cooperative Games",
    "authors": [
      "Vahid Yazdanpanah",
      "Devrim Murat Yazan"
    ],
    "author_ids": [],
    "abstract": "In this paper, we introduce a game-theoretical formulation for a specific\nform of collaborative industrial relations called \"Industrial Symbiotic\nRelation (ISR) games\" and provide a formal framework to model, verify, and\nsupport collaboration decisions in this new class of two-person operational\ngames. ISR games are formalized as cooperative cost-allocation games with the\naim to allocate the total ISR-related operational cost to involved industrial\nfirms in a fair and stable manner by taking into account their contribution to\nthe total traditional ISR-related cost. We tailor two types of allocation\nmechanisms using which firms can implement cost allocations that result in a\ncollaboration that satisfies the fairness and stability properties. Moreover,\nwhile industries receive a particular ISR proposal, our introduced methodology\nis applicable as a managerial decision support to systematically verify the\nquality of the ISR in question. This is achievable by analyzing if the\nimplemented allocation mechanism is a stable/fair allocation.",
    "published_date": "2018-02-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01167v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.01052v1",
    "title": "Dynamics of Opinions with Social Biases",
    "authors": [
      "Zihan Chen",
      "Jiahu Qin",
      "Bo Li",
      "Hongsheng Qi",
      "Peter Buchhorn",
      "Guodong Shi"
    ],
    "author_ids": [],
    "abstract": "This paper aims to provide a systemic analysis to social opinion dynamics\nsubject to individual biases. As a generalization of the classical DeGroot\nsocial interactions, defined by linearly coupled dynamics of peer opinions that\nevolve over time, biases add to state-dependent edge weights and therefore lead\nto highly nonlinear network dynamics. Previous studies have dealt with\nconvergence and stability analysis of such systems for a few specific initial\nnode opinions and network structures, and here we focus on how individual\nbiases affect social equilibria and their stabilities. First of all, we prove\nthat when the initial network opinions are polarized towards one side of the\nstate space, node biases will drive the opinion evolution to the corresponding\ninterval boundaries. Such polarization attraction effect continues to hold\nunder even directed and switching network structures. Next, for a few\nfundamental network structures, some important interior network equilibria are\npresented explicitly for a wide range of system parameters, which are shown to\nbe locally unstable in general. Particularly, the interval centroid is proven\nto be unstable regardless of the bias level and the network topologies.",
    "published_date": "2018-02-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01052v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.01029v1",
    "title": "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making",
    "authors": [
      "Michael Veale",
      "Max Van Kleek",
      "Reuben Binns"
    ],
    "author_ids": [],
    "abstract": "Calls for heightened consideration of fairness and accountability in\nalgorithmically-informed public decisions---like taxation, justice, and child\nprotection---are now commonplace. How might designers support such human\nvalues? We interviewed 27 public sector machine learning practitioners across 5\nOECD countries regarding challenges understanding and imbuing public values\ninto their work. The results suggest a disconnect between organisational and\ninstitutional realities, constraints and needs, and those addressed by current\nresearch into usable, transparent and 'discrimination-aware' machine\nlearning---absences likely to undermine practical initiatives unless addressed.\nWe see design opportunities in this disconnect, such as in supporting the\ntracking of concept drift in secondary data sources, and in building usable\ntransparency tools to identify risks and incorporate domain knowledge, aimed\nboth at managers and at the 'street-level bureaucrats' on the frontlines of\npublic service. We conclude by outlining ethical challenges and future\ndirections for collaboration in these high-stakes applications.",
    "published_date": "2018-02-03T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "K.4.1; H.1.2; J.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.01029v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.00252v1",
    "title": "Energy Harvesting Fairness in AN-aided Secure MU-MIMO SWIPT Systems with Cooperative Jammer",
    "authors": [
      "Zhengyu Zhu",
      "Zheng Chu",
      "Ning Wang",
      "Zhongyong Wang",
      "Inkyu Lee"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study a multi-user multiple-input-multiple-output secrecy\nsimultaneous wireless information and power transfer (SWIPT) channel which\nconsists of one transmitter, one cooperative jammer (CJ), multiple energy\nreceivers (potential eavesdroppers, ERs), and multiple co-located receivers\n(CRs). We exploit the dual of artificial noise (AN) generation for facilitating\nefficient wireless energy transfer and secure transmission. Our aim is to\nmaximize the minimum harvested energy among ERs and CRs subject to secrecy rate\nconstraints for each CR and total transmit power constraint. By incorporating\nnorm-bounded channel uncertainty model, we propose a iterative algorithm based\non sequential parametric convex approximation to find a near-optimal solution.\nFinally, simulation results are presented to validate the performance of the\nproposed algorithm outperforms that of the conventional AN-aided scheme and\nCJ-aided scheme.",
    "published_date": "2018-02-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.00252v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1802.00237v1",
    "title": "Face Aging with Contextual Generative Adversarial Nets",
    "authors": [
      "Si Liu",
      "Yao Sun",
      "Defa Zhu",
      "Renda Bao",
      "Wei Wang",
      "Xiangbo Shu",
      "Shuicheng Yan"
    ],
    "author_ids": [],
    "abstract": "Face aging, which renders aging faces for an input face, has attracted\nextensive attention in the multimedia research. Recently, several conditional\nGenerative Adversarial Nets (GANs) based methods have achieved great success.\nThey can generate images fitting the real face distributions conditioned on\neach individual age group. However, these methods fail to capture the\ntransition patterns, e.g., the gradual shape and texture changes between\nadjacent age groups. In this paper, we propose a novel Contextual Generative\nAdversarial Nets (C-GANs) to specifically take it into consideration. The\nC-GANs consists of a conditional transformation network and two discriminative\nnetworks. The conditional transformation network imitates the aging procedure\nwith several specially designed residual blocks. The age discriminative network\nguides the synthesized face to fit the real conditional distribution. The\ntransition pattern discriminative network is novel, aiming to distinguish the\nreal transition patterns with the fake ones. It serves as an extra\nregularization term for the conditional transformation network, ensuring the\ngenerated image pairs to fit the corresponding real transition pattern\ndistribution. Experimental results demonstrate the proposed framework produces\nappealing results by comparing with the state-of-the-art and ground truth. We\nalso observe performance gain for cross-age face verification.",
    "published_date": "2018-02-01T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.00237v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1802.00160v5",
    "title": "Bipartite discrimination of independently prepared quantum states as a counterexample to a parallel repetition conjecture",
    "authors": [
      "Seiseki Akibue",
      "Go Kato"
    ],
    "author_ids": [],
    "abstract": "For distinguishing quantum states sampled from a fixed ensemble, the gap in\nbipartite and single-party distinguishability can be interpreted as a\nnonlocality of the ensemble. In this paper, we consider bipartite state\ndiscrimination in a composite system consisting of $N$ subsystems, where each\nsubsystem is shared between two parties and the state of each subsystem is\nrandomly sampled from a particular ensemble comprising the Bell states. We show\nthat the success probability of perfectly identifying the state converges to\n$1$ as $N\\rightarrow\\infty$ if the entropy of the probability distribution\nassociated with the ensemble is less than $1$, even if the success probability\nis less than $1$ for any finite $N$. In other words, the nonlocality of the\n$N$-fold ensemble asymptotically disappears if the probability distribution\nassociated with each ensemble is concentrated. Furthermore, we show that the\ndisappearance of the nonlocality can be regarded as a remarkable counterexample\nof a fundamental open question in theoretical computer science, called a\nparallel repetition conjecture of interactive games with two classically\ncommunicating players. Measurements for the discrimination task include a\nprojective measurement of one party represented by stabilizer states, which\nenable the other party to perfectly distinguish states that are sampled with\nhigh probability.",
    "published_date": "2018-02-01T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1802.00160v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.10546v3",
    "title": "Multi-Layer Competitive-Cooperative Framework for Performance Enhancement of Differential Evolution",
    "authors": [
      "Sheng Xin Zhang",
      "Li Ming Zheng",
      "Kit Sang Tang",
      "Shao Yong Zheng",
      "Wing Shing Chan"
    ],
    "author_ids": [],
    "abstract": "Differential Evolution (DE) is recognized as one of the most powerful\noptimizers in the evolutionary algorithm (EA) family. Many DE variants were\nproposed in recent years, but significant differences in performances between\nthem are hardly observed. Therefore, this paper suggests a multi-layer\ncompetitive-cooperative (MLCC) framework to facilitate the competition and\ncooperation of multiple DEs, which in turns, achieve a significant performance\nimprovement. Unlike other multi-method strategies which adopt a\nmulti-population based structure, with individuals only evolving in their\ncorresponding subpopulations, MLCC implements a parallel structure with the\nentire population simultaneously monitored by multiple DEs assigned to their\ncorresponding layers. An individual can store, utilize and update its evolution\ninformation in different layers based on an individual preference based layer\nselecting (IPLS) mechanism and a computational resource allocation bias (RAB)\nmechanism. In IPLS, individuals connect to only one favorite layer. While in\nRAB, high-quality solutions are evolved by considering all the layers. Thus DEs\nassociated in the layers work in a competitive and cooperative manner. The\nproposed MLCC framework has been implemented on several highly competitive DEs.\nExperimental studies show that the MLCC variants significantly outperform the\nbaseline DEs as well as several state-of-the-art and up-to-date DEs on CEC\nbenchmark functions.",
    "published_date": "2018-01-31T00:00:00",
    "year": 2018,
    "categories": [
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.10546v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.10110v1",
    "title": "Surprise in Elections",
    "authors": [
      "Palash Dey",
      "Pravesh K. Kothari",
      "Swaprava Nath"
    ],
    "author_ids": [],
    "abstract": "Elections involving a very large voter population often lead to outcomes that\nsurprise many. This is particularly important for the elections in which\nresults affect the economy of a sizable population. A better prediction of the\ntrue outcome helps reduce the surprise and keeps the voters prepared. This\npaper starts from the basic observation that individuals in the underlying\npopulation build estimates of the distribution of preferences of the whole\npopulation based on their local neighborhoods. The outcome of the election\nleads to a surprise if these local estimates contradict the outcome of the\nelection for some fixed voting rule. To get a quantitative understanding, we\npropose a simple mathematical model of the setting where the individuals in the\npopulation and their connections (through geographical proximity, social\nnetworks etc.) are described by a random graph with connection probabilities\nthat are biased based on the preferences of the individuals. Each individual\nalso has some estimate of the bias in their connections.\n  We show that the election outcome leads to a surprise if the discrepancy\nbetween the estimated bias and the true bias in the local connections exceeds a\ncertain threshold, and confirm the phenomenon that surprising outcomes are\nassociated only with {\\em closely contested elections}. We compare standard\nvoting rules based on their performance on surprise and show that they have\ndifferent behavior for different parts of the population. It also hints at an\nimpossibility that a single voting rule will be less surprising for {\\em all}\nparts of a population. Finally, we experiment with the UK-EU referendum\n(a.k.a.\\ Brexit) dataset that attest some of our theoretical predictions.",
    "published_date": "2018-01-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.10110v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.09946v2",
    "title": "\"23andMe confirms: I'm super white\" -- Analyzing Twitter Discourse On Genetic Testing",
    "authors": [
      "Alexandros Mittos",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro"
    ],
    "author_ids": [],
    "abstract": "Recent progress in genomics is bringing genetic testing to the masses.\nParticipatory public initiatives are underway to sequence the genome of\nmillions of volunteers, and a new market is booming with a number of companies\nlike 23andMe and AncestryDNA offering affordable tests directly to consumers.\nConsequently, news, experiences, and views on genetic testing are increasingly\nshared and discussed online and on social networks like Twitter. In this paper,\nwe present a large-scale analysis of Twitter discourse on genetic testing. We\ncollect 302K tweets from 113K users, posted over 2.5 years, by using thirteen\nkeywords related to genetic testing companies and public initiatives as search\nkeywords. We study both the tweets and the users posting them along several\naxes, aiming to understand who tweets about genetic testing, what they talk\nabout, and how they use Twitter for that. Among other things, we find that\ntweets about genetic testing originate from accounts that overall appear to be\ninterested in digital health and technology. Also, marketing efforts as well as\nannouncements, such as the FDA's suspension of 23andMe's health reports,\ninfluence the type and the nature of user engagement.Finally, we report on\nusers who share screenshots of their results, and raise a few ethical and\nsocietal questions as we find evidence of groups associating genetic testing to\nracist ideologies.",
    "published_date": "2018-01-30T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09946v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.09913v1",
    "title": "Dynamical Networks of Influence in Small Group Discussions",
    "authors": [
      "Mehdi Moussaid",
      "Alejandro Noriega Campero",
      "Abdullah Almaatouq"
    ],
    "author_ids": [],
    "abstract": "In many domains of life, business and management, numerous problems are\naddressed by small groups of individuals engaged in face-to-face discussions.\nWhile research in social psychology has a long history of studying the\ndeterminants of small group performances, the internal dynamics that govern a\ngroup discussion is not yet well understood. Here, we rely on computational\nmethods based on network analyses and opinion dynamics to described how\nindividuals influence each other during a group discussion. We consider the\nsituation in which a small group of three individuals engages in a discussion\nto solve an estimation task. We propose a model describing how group members\ngradually influence each other and revise their judgments over the course of\nthe discussion. The main component of the model is an influence network - a\nweighted, directed graph that determines the extent to which individuals\ninfluence each other during the discussion. In simulations, we first study the\noptimal structure of the influence network that yields the best group\nperformances. Then, we implement a social learning process by which individuals\nadapt to the past performance of their peers, thereby affecting the structure\nof the influence network in the long run. We explore the mechanisms underlying\nthe emergence of efficient or maladaptive networks and show that the influence\nnetwork can converge towards the optimal one, but only when individuals exhibit\na social discounting bias by downgrading the relative performances of their\npeers. Finally, we find a late-speaker effect, whereby individuals who speak\nlater in the discussion are perceived more positively in the long run and are\nthus more influential. The numerous predictions of the model can serve as a\nbasis for future experiments, and this work opens research on small group\ndiscussion to computational social sciences.",
    "published_date": "2018-01-30T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09913v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.09584v1",
    "title": "A Unifying Framework for Manipulation Problems",
    "authors": [
      "Dušan Knop",
      "Martin Koutecký",
      "Matthias Mnich"
    ],
    "author_ids": [],
    "abstract": "Manipulation models for electoral systems are a core research theme in social\nchoice theory; they include bribery (unweighted, weighted, swap, shift, ...),\ncontrol (by adding or deleting voters or candidates), lobbying in referenda and\nothers.\n  We develop a unifying framework for manipulation models with few types of\npeople, one of the most commonly studied scenarios. A critical insight of our\nframework is to separate the descriptive complexity of the voting rule R from\nthe number of types of people. This allows us to finally settle the\ncomputational complexity of R-Swap Bribery, one of the most fundamental\nmanipulation problems. In particular, we prove that R-Swap Bribery is\nfixed-parameter tractable when R is Dodgson's rule and Young's rule, when\nparameterized by the number of candidates. This way, we resolve a long-standing\nopen question from 2007 which was explicitly asked by Faliszewski et al. [JAIR\n40, 2011].\n  Our algorithms reveal that the true hardness of bribery problems often stems\nfrom the complexity of the voting rules. On one hand, we give a fixed-parameter\nalgorithm parameterized by number of types of people for complex voting rules.\nThus, we reveal that R-Swap Bribery with Dodgson's rule is much harder than\nwith Condorcet's rule, which can be expressed by a conjunction of linear\ninequalities, while Dodson's rule requires quantifier alternation and a bounded\nnumber of disjunctions of linear systems. On the other hand, we give an\nalgorithm for quantifier-free voting rules which is parameterized only by the\nnumber of conjunctions of the voting rule and runs in time polynomial in the\nnumber of types of people. This way, our framework explains why Shift Bribery\nis polynomial-time solvable for the plurality voting rule, making explicit that\nthe rule is simple in that it can be expressed with a single linear inequality,\nand that the number of voter types is polynomial.",
    "published_date": "2018-01-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.MA",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09584v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.09414v2",
    "title": "CosFace: Large Margin Cosine Loss for Deep Face Recognition",
    "authors": [
      "Hao Wang",
      "Yitong Wang",
      "Zheng Zhou",
      "Xing Ji",
      "Dihong Gong",
      "Jingchao Zhou",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "author_ids": [],
    "abstract": "Face recognition has made extraordinary progress owing to the advancement of\ndeep convolutional neural networks (CNNs). The central task of face\nrecognition, including face verification and identification, involves face\nfeature discrimination. However, the traditional softmax loss of deep CNNs\nusually lacks the power of discrimination. To address this problem, recently\nseveral loss functions such as center loss, large margin softmax loss, and\nangular softmax loss have been proposed. All these improved losses share the\nsame idea: maximizing inter-class variance and minimizing intra-class variance.\nIn this paper, we propose a novel loss function, namely large margin cosine\nloss (LMCL), to realize this idea from a different perspective. More\nspecifically, we reformulate the softmax loss as a cosine loss by $L_2$\nnormalizing both features and weight vectors to remove radial variations, based\non which a cosine margin term is introduced to further maximize the decision\nmargin in the angular space. As a result, minimum intra-class variance and\nmaximum inter-class variance are achieved by virtue of normalization and cosine\ndecision margin maximization. We refer to our model trained with LMCL as\nCosFace. Extensive experimental evaluations are conducted on the most popular\npublic-domain face recognition datasets such as MegaFace Challenge, Youtube\nFaces (YTF) and Labeled Face in the Wild (LFW). We achieve the state-of-the-art\nperformance on these benchmarks, which confirms the effectiveness of our\nproposed approach.",
    "published_date": "2018-01-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09414v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.09354v2",
    "title": "On the Inter-relationships among Drift rate, Forgetting rate, Bias/variance profile and Error",
    "authors": [
      "Nayyar A. Zaidi",
      "Geoffrey I. Webb",
      "Francois Petitjean",
      "Germain Forestier"
    ],
    "author_ids": [],
    "abstract": "We propose two general and falsifiable hypotheses about expectations on\ngeneralization error when learning in the context of concept drift. One posits\nthat as drift rate increases, the forgetting rate that minimizes generalization\nerror will also increase and vice versa. The other posits that as a learner's\nforgetting rate increases, the bias/variance profile that minimizes\ngeneralization error will have lower variance and vice versa. These hypotheses\nlead to the concept of the sweet path, a path through the 3-d space of\nalternative drift rates, forgetting rates and bias/variance profiles on which\ngeneralization error will be minimized, such that slow drift is coupled with\nlow forgetting and low bias, while rapid drift is coupled with fast forgetting\nand low variance. We present experiments that support the existence of such a\nsweet path. We also demonstrate that simple learners that select appropriate\nforgetting rates and bias/variance profiles are highly competitive with the\nstate-of-the-art in incremental learners for concept drift on real-world drift\nproblems.",
    "published_date": "2018-01-29T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09354v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.09212v4",
    "title": "BOPS, Not FLOPS! A New Metric and Roofline Performance Model For Datacenter Computing",
    "authors": [
      "Lei Wang",
      "Jianfeng Zhan",
      "Wanling Gao",
      "KaiYong Yang",
      "ZiHan Jiang",
      "Rui Ren",
      "Xiwen He",
      "Chunjie Luo"
    ],
    "author_ids": [],
    "abstract": "For emerging datacenter (in short, DC) workloads, such as online Internet\nservices or offline data analytics, how to evaluate the upper bound performance\nand provide apple-to-apple comparisons are fundamental problems. To this end, a\nunified computation-centric metric is an essential requirement. As the most\nimportant computation-centric performance metric, FLOPS has guided computing\nsystems evolutions for many years. However, our observations demonstrate that\nthe average FLOPS efficiency of the DC workloads is only 0.1%, which implies\nthat FLOPS is inappropriate for DC computing. To address the above issue, we\npropose BOPS (Basic Operations Per Second), which is the average number of BOPs\n(Basic OPerations) completed per second. We conduct the analysis on the\ncharacteristics of seventeen typical DC workloads and extract the minimum\nrepresentative computation operations set, which is composed of integer and\nfloating point computation operations of arithmetic, comparing and array\naddressing. Then, we propose the formalized BOPS definition and the BOPS based\nupper bound performance model. Finally, the BOPS measuring tool is also\nimplemented. We perform experiments with seventeen DC workloads on three\ntypical Intel processors platforms. First, BOPS can reflect the performance gap\nof different computing systems, the bias between the peak BOPS performance gap\nand the average DC workloads' wall clock time gap is no more than 10%. Second,\nthe Sort workload can achieve 32% BOPS efficiency on the experimental platform.\nAt last, we present two use cases of BOPS. One is the BOPS based system\nevaluation, we illustrate that BOPS can compare performance of workloads from\nmultiple domains. The other is BOPS based optimizations. We show that under the\nguiding of the BOPS based upper bound model, the Sort workload and the Redis\nworkload achieve 4.4X and 1.2X performance improvements respectively.",
    "published_date": "2018-01-28T00:00:00",
    "year": 2018,
    "categories": [
      "cs.PF"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09212v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.09046v1",
    "title": "Greedy Algorithms for Maximizing Nash Social Welfare",
    "authors": [
      "Siddharth Barman",
      "Sanath Kumar Krishnamurthy",
      "Rohit Vaish"
    ],
    "author_ids": [],
    "abstract": "We study the problem of fairly allocating a set of indivisible goods among\nagents with additive valuations. The extent of fairness of an allocation is\nmeasured by its Nash social welfare, which is the geometric mean of the\nvaluations of the agents for their bundles. While the problem of maximizing\nNash social welfare is known to be APX-hard in general, we study the\neffectiveness of simple, greedy algorithms in solving this problem in two\ninteresting special cases.\n  First, we show that a simple, greedy algorithm provides a 1.061-approximation\nguarantee when agents have identical valuations, even though the problem of\nmaximizing Nash social welfare remains NP-hard for this setting. Second, we\nshow that when agents have binary valuations over the goods, an exact solution\n(i.e., a Nash optimal allocation) can be found in polynomial time via a greedy\nalgorithm. Our results in the binary setting extend to provide novel, exact\nalgorithms for optimizing Nash social welfare under concave valuations.\nNotably, for the above mentioned scenarios, our techniques provide a simple\nalternative to several of the existing, more sophisticated techniques for this\nproblem such as constructing equilibria of Fisher markets or using real stable\npolynomials.",
    "published_date": "2018-01-27T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "econ.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.09046v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.08850v1",
    "title": "On bounded pitch inequalities for the min-knapsack polytope",
    "authors": [
      "Yuri Faenza",
      "Igor Malinović",
      "Monaldo Mastrolilli",
      "Ola Svensson"
    ],
    "author_ids": [],
    "abstract": "In the min-knapsack problem one aims at choosing a set of objects with\nminimum total cost and total profit above a given threshold. In this paper, we\nstudy a class of valid inequalities for min-knapsack known as bounded pitch\ninequalities, which generalize the well-known unweighted cover inequalities.\nWhile separating over pitch-1 inequalities is NP-hard, we show that approximate\nseparation over the set of pitch-1 and pitch-2 inequalities can be done in\npolynomial time. We also investigate integrality gaps of linear relaxations for\nmin-knapsack when these inequalities are added. Among other results, we show\nthat, for any fixed $t$, the $t$-th CG closure of the natural linear relaxation\nhas the unbounded integrality gap.",
    "published_date": "2018-01-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.08850v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.08737v1",
    "title": "Lattice-Based Group Signatures: Achieving Full Dynamicity (and Deniability) with Ease",
    "authors": [
      "San Ling",
      "Khoa Nguyen",
      "Huaxiong Wang",
      "Yanhong Xu"
    ],
    "author_ids": [],
    "abstract": "In this work, we provide the first lattice-based group signature that offers\nfull dynamicity (i.e., users have the flexibility in joining and leaving the\ngroup), and thus, resolve a prominent open problem posed by previous works.\nMoreover, we achieve this non-trivial feat in a relatively simple manner.\nStarting with Libert et al.'s fully static construction (Eurocrypt 2016) -\nwhich is arguably the most efficient lattice-based group signature to date, we\nintroduce simple-but-insightful tweaks that allow to upgrade it directly into\nthe fully dynamic setting. More startlingly, our scheme even produces slightly\nshorter signatures than the former, thanks to an adaptation of a technique\nproposed by Ling et al. (PKC 2013), allowing to prove inequalities in\nzero-knowledge. Our design approach consists of upgrading Libert et al.'s\nstatic construction (EUROCRYPT 2016) - which is arguably the most efficient\nlattice-based group signature to date - into the fully dynamic setting.\nSomewhat surprisingly, our scheme produces slightly shorter signatures than the\nformer, thanks to a new technique for proving inequality in zero-knowledge\nwithout relying on any inequality check. The scheme satisfies the strong\nsecurity requirements of Bootle et al.'s model (ACNS 2016), under the Short\nInteger Solution (SIS) and the Learning With Errors (LWE) assumptions.\n  Furthermore, we demonstrate how to equip the obtained group signature scheme\nwith the deniability functionality in a simple way. This attractive\nfunctionality, put forward by Ishida et al. (CANS 2016), enables the tracing\nauthority to provide an evidence that a given user is not the owner of a\nsignature in question. In the process, we design a zero-knowledge protocol for\nproving that a given LWE ciphertext does not decrypt to a particular message.",
    "published_date": "2018-01-26T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CR",
      "CS-CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.08737v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.08558v1",
    "title": "Deep Learning for End-to-End Automatic Target Recognition from Synthetic Aperture Radar Imagery",
    "authors": [
      "Hidetoshi Furukawa"
    ],
    "author_ids": [],
    "abstract": "The standard architecture of synthetic aperture radar (SAR) automatic target\nrecognition (ATR) consists of three stages: detection, discrimination, and\nclassification. In recent years, convolutional neural networks (CNNs) for SAR\nATR have been proposed, but most of them classify target classes from a target\nchip extracted from SAR imagery, as a classification for the third stage of SAR\nATR. In this report, we propose a novel CNN for end-to-end ATR from SAR\nimagery. The CNN named verification support network (VersNet) performs all\nthree stages of SAR ATR end-to-end. VersNet inputs a SAR image of arbitrary\nsizes with multiple classes and multiple targets, and outputs a SAR ATR image\nrepresenting the position, class, and pose of each detected target. This report\ndescribes the evaluation results of VersNet which trained to output scores of\nall 12 classes: 10 target classes, a target front class, and a background\nclass, for each pixel using the moving and stationary target acquisition and\nrecognition (MSTAR) public dataset.",
    "published_date": "2018-01-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.08558v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.08341v1",
    "title": "The Price of Indivisibility in Cake Cutting",
    "authors": [
      "Eshwar Ram Arunachaleswaran",
      "Ragavendran Gopalakrishnan"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of envy-free cake cutting, which is the distribution\nof a continuous heterogeneous resource among self interested players such that\nnobody prefers what somebody else receives to what they get. Existing work has\nfocused on two distinct classes of solutions to this problem - allocations\nwhich give each player a continuous piece of cake and allocations which give\neach player arbitrarily many disjoint pieces of cake. Our aim is to investigate\nallocations between these two extremes by parameterizing the maximum number of\ndisjoint pieces each player may receive. We characterize the Price of\nIndivisibility (POI) as the gain achieved in social welfare (utilitarian and\negalitarian), by moving from allocations which give each player a continuous\npiece of cake to allocations that may give each player up to $k$ disjoint\npieces of cake. Our results contain bounds for the Price of Indivisibility for\nutilitarian as well as egalitarian social welfare, and for envy-free cake\ncutting as well as cake cutting without any fairness constraints.",
    "published_date": "2018-01-25T00:00:00",
    "year": 2018,
    "categories": [
      "cs.GT",
      "math.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.08341v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.07593v1",
    "title": "Mitigating Unwanted Biases with Adversarial Learning",
    "authors": [
      "Brian Hu Zhang",
      "Blake Lemoine",
      "Margaret Mitchell"
    ],
    "author_ids": [],
    "abstract": "Machine learning is a tool for building models that accurately represent\ninput training data. When undesired biases concerning demographic groups are in\nthe training data, well-trained models will reflect those biases. We present a\nframework for mitigating such biases by including a variable for the group of\ninterest and simultaneously learning a predictor and an adversary. The input to\nthe network X, here text or census data, produces a prediction Y, such as an\nanalogy completion or income bracket, while the adversary tries to model a\nprotected variable Z, here gender or zip code.\n  The objective is to maximize the predictor's ability to predict Y while\nminimizing the adversary's ability to predict Z. Applied to analogy completion,\nthis method results in accurate predictions that exhibit less evidence of\nstereotyping Z. When applied to a classification task using the UCI Adult\n(Census) Dataset, it results in a predictive model that does not lose much\naccuracy while achieving very close to equality of odds (Hardt, et al., 2016).\nThe method is flexible and applicable to multiple definitions of fairness as\nwell as a wide range of gradient-based learning models, including both\nregression and classification tasks.",
    "published_date": "2018-01-22T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.07593v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.06867v1",
    "title": "Scene recognition with CNNs: objects, scales and dataset bias",
    "authors": [
      "Luis Herranz",
      "Shuqiang Jiang",
      "Xiangyang Li"
    ],
    "author_ids": [],
    "abstract": "Since scenes are composed in part of objects, accurate recognition of scenes\nrequires knowledge about both scenes and objects. In this paper we address two\nrelated problems: 1) scale induced dataset bias in multi-scale convolutional\nneural network (CNN) architectures, and 2) how to combine effectively\nscene-centric and object-centric knowledge (i.e. Places and ImageNet) in CNNs.\nAn earlier attempt, Hybrid-CNN, showed that incorporating ImageNet did not help\nmuch. Here we propose an alternative method taking the scale into account,\nresulting in significant recognition gains. By analyzing the response of\nImageNet-CNNs and Places-CNNs at different scales we find that both operate in\ndifferent scale ranges, so using the same network for all the scales induces\ndataset bias resulting in limited performance. Thus, adapting the feature\nextractor to each particular scale (i.e. scale-specific CNNs) is crucial to\nimprove recognition, since the objects in the scenes have their specific range\nof scales. Experimental results show that the recognition accuracy highly\ndepends on the scale, and that simple yet carefully chosen multi-scale\ncombinations of ImageNet-CNNs and Places-CNNs, can push the state-of-the-art\nrecognition accuracy in SUN397 up to 66.26% (and even 70.17% with deeper\narchitectures, comparable to human performance).",
    "published_date": "2018-01-21T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.06867v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.05734v1",
    "title": "Eliminating the effect of rating bias on reputation systems",
    "authors": [
      "Leilei Wu",
      "Zhuoming Ren",
      "Xiao-Long Ren",
      "Jianlin Zhang",
      "Linyuan Lü"
    ],
    "author_ids": [],
    "abstract": "The ongoing rapid development of the e-commercial and interest-base websites\nmake it more pressing to evaluate objects' accurate quality before\nrecommendation by employing an effective reputation system. The objects'\nquality are often calculated based on their historical information, such as\nselected records or rating scores, to help visitors to make decisions before\nwatching, reading or buying. Usually high quality products obtain a higher\naverage ratings than low quality products regardless of rating biases or\nerrors. However many empirical cases demonstrate that consumers may be misled\nby rating scores added by unreliable users or deliberate tampering. In this\ncase, users' reputation, i.e., the ability to rating trustily and precisely,\nmake a big difference during the evaluating process. Thus, one of the main\nchallenges in designing reputation systems is eliminating the effects of users'\nrating bias on the evaluation results. To give an objective evaluation of each\nuser's reputation and uncover an object's intrinsic quality, we propose an\niterative balance (IB) method to correct users' rating biases. Experiments on\ntwo online video-provided Web sites, namely MovieLens and Netflix datasets,\nshow that the IB method is a highly self-consistent and robust algorithm and it\ncan accurately quantify movies' actual quality and users' stability of rating.\nCompared with existing methods, the IB method has higher ability to find the\n\"dark horses\", i.e., not so popular yet good movies, in the Academy Awards.",
    "published_date": "2018-01-17T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.IR",
      "cs.SI",
      "econ.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.05734v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.05678v1",
    "title": "Face Recognition via Centralized Coordinate Learning",
    "authors": [
      "Xianbiao Qi",
      "Lei Zhang"
    ],
    "author_ids": [],
    "abstract": "Owe to the rapid development of deep neural network (DNN) techniques and the\nemergence of large scale face databases, face recognition has achieved a great\nsuccess in recent years. During the training process of DNN, the face features\nand classification vectors to be learned will interact with each other, while\nthe distribution of face features will largely affect the convergence status of\nnetwork and the face similarity computing in test stage. In this work, we\nformulate jointly the learning of face features and classification vectors, and\npropose a simple yet effective centralized coordinate learning (CCL) method,\nwhich enforces the features to be dispersedly spanned in the coordinate space\nwhile ensuring the classification vectors to lie on a hypersphere. An adaptive\nangular margin is further proposed to enhance the discrimination capability of\nface features. Extensive experiments are conducted on six face benchmarks,\nincluding those have large age gap and hard negative samples. Trained only on\nthe small-scale CASIA Webface dataset with 460K face images from about 10K\nsubjects, our CCL model demonstrates high effectiveness and generality, showing\nconsistently competitive performance across all the six benchmark databases.",
    "published_date": "2018-01-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.05678v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.05627v2",
    "title": "On the Reduction of Biases in Big Data Sets for the Detection of Irregular Power Usage",
    "authors": [
      "Patrick Glauner",
      "Radu State",
      "Petko Valtchev",
      "Diogo Duarte"
    ],
    "author_ids": [],
    "abstract": "In machine learning, a bias occurs whenever training sets are not\nrepresentative for the test data, which results in unreliable models. The most\ncommon biases in data are arguably class imbalance and covariate shift. In this\nwork, we aim to shed light on this topic in order to increase the overall\nattention to this issue in the field of machine learning. We propose a scalable\nnovel framework for reducing multiple biases in high-dimensional data sets in\norder to train more reliable predictors. We apply our methodology to the\ndetection of irregular power usage from real, noisy industrial data. In\nemerging markets, irregular power usage, and electricity theft in particular,\nmay range up to 40% of the total electricity distributed. Biased data sets are\nof particular issue in this domain. We show that reducing these biases\nincreases the accuracy of the trained predictors. Our models have the potential\nto generate significant economic value in a real world application, as they are\nbeing deployed in a commercial software for the detection of irregular power\nusage.",
    "published_date": "2018-01-17T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.05627v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.05449v1",
    "title": "ConvSRC: SmartPhone based Periocular Recognition using Deep Convolutional Neural Network and Sparsity Augmented Collaborative Representation",
    "authors": [
      "Amani Alahmadi",
      "Muhammad Hussain",
      "Hatim Aboalsamh",
      "Mansour Zuair"
    ],
    "author_ids": [],
    "abstract": "Smartphone based periocular recognition has gained significant attention from\nbiometric research community because of the limitations of biometric modalities\nlike face, iris etc. Most of the existing methods for periocular recognition\nemploy hand-crafted features. Recently, learning based image representation\ntechniques like deep Convolutional Neural Network (CNN) have shown outstanding\nperformance in many visual recognition tasks. CNN needs a huge volume of data\nfor its learning, but for periocular recognition only limited amount of data is\navailable. The solution is to use CNN pre-trained on the dataset from the\nrelated domain, in this case the challenge is to extract efficiently the\ndiscriminative features. Using a pertained CNN model (VGG-Net), we propose a\nsimple, efficient and compact image representation technique that takes into\naccount the wealth of information and sparsity existing in the activations of\nthe convolutional layers and employs principle component analysis. For\nrecognition, we use an efficient and robust Sparse Augmented Collaborative\nRepresentation based Classification (SA-CRC) technique. For thorough evaluation\nof ConvSRC (the proposed system), experiments were carried out on the VISOB\nchallenging database which was presented for periocular recognition competition\nin ICIP2016. The obtained results show the superiority of ConvSRC over the\nstate-of-the-art methods; it obtains a GMR of more than 99% at FMR = 10-3 and\noutperforms the first winner of ICIP2016 challenge by 10%.",
    "published_date": "2018-01-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.05449v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.05398v3",
    "title": "On the Direction of Discrimination: An Information-Theoretic Analysis of Disparate Impact in Machine Learning",
    "authors": [
      "Hao Wang",
      "Berk Ustun",
      "Flavio P. Calmon"
    ],
    "author_ids": [],
    "abstract": "In the context of machine learning, disparate impact refers to a form of\nsystematic discrimination whereby the output distribution of a model depends on\nthe value of a sensitive attribute (e.g., race or gender). In this paper, we\npropose an information-theoretic framework to analyze the disparate impact of a\nbinary classification model. We view the model as a fixed channel, and quantify\ndisparate impact as the divergence in output distributions over two groups. Our\naim is to find a correction function that can perturb the input distributions\nof each group to align their output distributions. We present an optimization\nproblem that can be solved to obtain a correction function that will make the\noutput distributions statistically indistinguishable. We derive closed-form\nexpressions to efficiently compute the correction function, and demonstrate the\nbenefits of our framework on a recidivism prediction problem based on the\nProPublica COMPAS dataset.",
    "published_date": "2018-01-16T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.05398v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.04678v2",
    "title": "Learning a Bias Correction for Lidar-only Motion Estimation",
    "authors": [
      "Tim Y. Tang",
      "David J. Yoon",
      "François Pomerleau",
      "Timothy D. Barfoot"
    ],
    "author_ids": [],
    "abstract": "This paper presents a novel technique to correct for bias in a classical\nestimator using a learning approach. We apply a learned bias correction to a\nlidar-only motion estimation pipeline. Our technique trains a Gaussian process\n(GP) regression model using data with ground truth. The inputs to the model are\nhigh-level features derived from the geometry of the point-clouds, and the\noutputs are the predicted biases between poses computed by the estimator and\nthe ground truth. The predicted biases are applied as a correction to the poses\ncomputed by the estimator.\n  Our technique is evaluated on over 50km of lidar data, which includes the\nKITTI odometry benchmark and lidar datasets collected around the University of\nToronto campus. After applying the learned bias correction, we obtained\nsignificant improvements to lidar odometry in all datasets tested. We achieved\naround 10% reduction in errors on all datasets from an already accurate lidar\nodometry algorithm, at the expense of only less than 1% increase in\ncomputational cost at run-time.",
    "published_date": "2018-01-15T00:00:00",
    "year": 2018,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.04678v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.08409v1",
    "title": "Computation of the State Bias and Initial States for Stochastic State Space Systems in the General 2-D Roesser Model Form",
    "authors": [
      "José A. Ramos",
      "Guillaume Mercère"
    ],
    "author_ids": [],
    "abstract": "Recently \\cite{Ramos2017a} presented a subspace system identification\nalgorithm for 2-D purely stochastic state space models in the general Roesser\nform. However, since the exact problem requires an oblique projection of\n$Y_f^h$ projected onto $W_p^h$ along $\\widehat{X}_f^{vh}$, where $W_p^h=\n\\begin{bmatrix}\\widehat{X}_p^{vh} \\\\ Y_p^h \\end{bmatrix}$, this presents a\nproblem since $\\{\\widehat{X}_p^{vh},\\widehat{X}_f^{vh}\\}$ are unknown. In the\nabove mentioned paper, the authors found that by doing an orthogonal projection\n$Y_f^h/Y_p^h$, one can identify the future horizontal state matrix\n$\\widehat{X}_f^{h}$ with a small bias due to the initial conditions that depend\non $\\{\\widehat{X}_p^{vh},\\widehat{X}_f^{vh}\\}$. Nevertheless, the results on\nmodeling 2-D images were very good despite lack of knowledge of\n$\\{\\widehat{X}_p^{vh},\\widehat{X}_f^{vh}\\}$. In this note we delve into the\nbias term and prove that it is insignificant, provided $i$ is chosen large\nenough and the vertical and horizontal states are uncorrelated. That is, the\ncross covariance of the state estimates $x_{r,s}^{h}$ and $x_{r,s}^{v}$ is\nzero, or $P_{hv}=0_{n_x\\times n_x}$ and $P_{vh}=0_{n_x\\times n_x}$. Our\nsimulations use $i=30$. We also present a second iteration to improve the state\nestimates by including the vertical states computed from a vertical data\nprocessing step, i.e., by doing an orthogonal projection $Y_f^v/Y_p^v$. In this\nrevised algorithm we include a step to compute the initial states. This new\nportion, in addition to the algorithm presented in \\cite{Ramos2017a}, forms a\ncomplete 2-D stochastic subspace system identification algorithm.",
    "published_date": "2018-01-14T00:00:00",
    "year": 2018,
    "categories": [
      "math.NA",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.08409v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.04403v2",
    "title": "Social Advantage with Mixed Entangled States",
    "authors": [
      "Aritra Das",
      "Pratyusha Chowdhury"
    ],
    "author_ids": [],
    "abstract": "It has been extensively shown in past literature that Bayesian Game Theory\nand Quantum Non-locality have strong ties between them. Pure Entangled States\nhave been used, in both common and conflict interest games, to gain\nadvantageous payoffs, both at the individual and social level. In this paper we\nconstruct a game for a Mixed Entangled State such that this state gives higher\npayoffs than classically possible, both at the individual level and the social\nlevel. Also, we use the I-3322 inequality so that states that aren't helpful as\nadvice for Bell-CHSH inequality can also be used. Finally, the measurement\nsetting we use is a Restricted Social Welfare Strategy (given this particular\nstate).",
    "published_date": "2018-01-13T00:00:00",
    "year": 2018,
    "categories": [
      "quant-ph",
      "cs.GT",
      "physics.comp-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.04403v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.04378v2",
    "title": "Fairness in Supervised Learning: An Information Theoretic Approach",
    "authors": [
      "AmirEmad Ghassami",
      "Sajad Khodadadian",
      "Negar Kiyavash"
    ],
    "author_ids": [],
    "abstract": "Automated decision making systems are increasingly being used in real-world\napplications. In these systems for the most part, the decision rules are\nderived by minimizing the training error on the available historical data.\nTherefore, if there is a bias related to a sensitive attribute such as gender,\nrace, religion, etc. in the data, say, due to cultural/historical\ndiscriminatory practices against a certain demographic, the system could\ncontinue discrimination in decisions by including the said bias in its decision\nrule. We present an information theoretic framework for designing fair\npredictors from data, which aim to prevent discrimination against a specified\nsensitive attribute in a supervised learning setting. We use equalized odds as\nthe criterion for discrimination, which demands that the prediction should be\nindependent of the protected attribute conditioned on the actual label. To\nensure fairness and generalization simultaneously, we compress the data to an\nauxiliary variable, which is used for the prediction task. This auxiliary\nvariable is chosen such that it is decontaminated from the discriminatory\nattribute in the sense of equalized odds. The final predictor is obtained by\napplying a Bayesian decision rule to the auxiliary variable.",
    "published_date": "2018-01-13T00:00:00",
    "year": 2018,
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.04378v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.04346v1",
    "title": "A Computational Model of Commonsense Moral Decision Making",
    "authors": [
      "Richard Kim",
      "Max Kleiman-Weiner",
      "Andres Abeliuk",
      "Edmond Awad",
      "Sohan Dsouza",
      "Josh Tenenbaum",
      "Iyad Rahwan"
    ],
    "author_ids": [],
    "abstract": "We introduce a new computational model of moral decision making, drawing on a\nrecent theory of commonsense moral learning via social dynamics. Our model\ndescribes moral dilemmas as a utility function that computes trade-offs in\nvalues over abstract moral dimensions, which provide interpretable parameter\nvalues when implemented in machine-led ethical decision-making. Moreover,\ncharacterizing the social structures of individuals and groups as a\nhierarchical Bayesian model, we show that a useful description of an\nindividual's moral values - as well as a group's shared values - can be\ninferred from a limited amount of observed data. Finally, we apply and evaluate\nour approach to data from the Moral Machine, a web application that collects\nhuman judgments on moral dilemmas involving autonomous vehicles.",
    "published_date": "2018-01-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.04346v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.04297v1",
    "title": "Optimizing Floating Locations in Hard Disk Drive by Solving Max-min Optimization",
    "authors": [
      "Victor Liu",
      "Hongtao Yang",
      "Haiming Li",
      "Chifu Yang"
    ],
    "author_ids": [],
    "abstract": "Floating operation is very critical in power management in hard disk drive\n(HDD), during which no control command is applied to the read/write head but a\nfixed current to counteract actuator flex bias. External disturbance induced\ndrift of head may result in interference of head and bump on the disk during\ndrifting, leading to consequent scratches and head degradation, which is a\nsevere reliability concern in HDD. This paper proposes a unique systematic\nmethodology to minimize the chances of hitting bump on the disk during drive\nfloating. Essentially, it provides a heuristic solution to a class of max-min\noptimization problem which achieves desirable trade-off between optimality and\ncomputation complexity. Multivariable nonlinear optimization problem of this\nsort is reduced from NP-hard to an arithmetic problem. Also, worst-case is\nderived for arbitrary bump locations.",
    "published_date": "2018-01-12T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.04297v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.03868v1",
    "title": "An entropy inequality for symmetric random variables",
    "authors": [
      "Jing Hao",
      "Varun Jog"
    ],
    "author_ids": [],
    "abstract": "We establish a lower bound on the entropy of weighted sums of (possibly\ndependent) random variables $(X_1, X_2, \\dots, X_n)$ possessing a symmetric\njoint distribution. Our lower bound is in terms of the joint entropy of $(X_1,\nX_2, \\dots, X_n)$. We show that for $n \\geq 3$, the lower bound is tight if and\nonly if $X_i$'s are i.i.d.\\ Gaussian random variables. For $n=2$ there are\nnumerous other cases of equality apart from i.i.d.\\ Gaussians, which we\ncompletely characterize. Going beyond sums, we also present an inequality for\ncertain linear transformations of $(X_1, \\dots, X_n)$. Our primary technical\ncontribution lies in the analysis of the equality cases, and our approach\nrelies on the geometry and the symmetry of the problem.",
    "published_date": "2018-01-11T00:00:00",
    "year": 2018,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.03868v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.03299v1",
    "title": "Simultaneous Tensor Completion and Denoising by Noise Inequality Constrained Convex Optimization",
    "authors": [
      "Tatsuya Yokota",
      "Hidekata Hontani"
    ],
    "author_ids": [],
    "abstract": "Tensor completion is a technique of filling missing elements of the\nincomplete data tensors. It being actively studied based on the convex\noptimization scheme such as nuclear-norm minimization. When given data tensors\ninclude some noises, the nuclear-norm minimization problem is usually converted\nto the nuclear-norm `regularization' problem which simultaneously minimize\npenalty and error terms with some trade-off parameter. However, the good value\nof trade-off is not easily determined because of the difference of two units\nand the data dependence. In the sense of trade-off tuning, the noisy tensor\ncompletion problem with the `noise inequality constraint' is better choice than\nthe `regularization' because the good noise threshold can be easily bounded\nwith noise standard deviation. In this study, we tackle to solve the convex\ntensor completion problems with two types of noise inequality constraints:\nGaussian and Laplace distributions. The contributions of this study are\nfollows: (1) New tensor completion and denoising models using tensor total\nvariation and nuclear-norm are proposed which can be characterized as a\ngeneralization/extension of many past matrix and tensor completion models, (2)\nproximal mappings for noise inequalities are derived which are analytically\ncomputable with low computational complexity, (3) convex optimization algorithm\nis proposed based on primal-dual splitting framework, (4) new step-size\nadaptation method is proposed to accelerate the optimization, and (5) extensive\nexperiments demonstrated the advantages of the proposed method for visual data\nretrieval such as for color images, movies, and 3D-volumetric data.",
    "published_date": "2018-01-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.03299v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.03261v1",
    "title": "Exploring Stereotypes and Biased Data with the Crowd",
    "authors": [
      "Zeyuan Hu",
      "Julia Strout"
    ],
    "author_ids": [],
    "abstract": "The goal of our research is to contribute information about how useful the\ncrowd is at anticipating stereotypes that may be biasing a data set without a\nresearcher's knowledge. The results of the crowd's prediction can potentially\nbe used during data collection to help prevent the suspected stereotypes from\nintroducing bias to the dataset. We conduct our research by asking the crowd on\nAmazon's Mechanical Turk (AMT) to complete two similar Human Intelligence Tasks\n(HITs) by suggesting stereotypes relating to their personal experience. Our\nanalysis of these responses focuses on determining the level of diversity in\nthe workers' suggestions and their demographics. Through this process we begin\na discussion on how useful the crowd can be in tackling this difficult problem\nwithin machine learning data collection.",
    "published_date": "2018-01-10T00:00:00",
    "year": 2018,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.03261v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.01869v1",
    "title": "The dynamical structure of political corruption networks",
    "authors": [
      "Haroldo V. Ribeiro",
      "Luiz G. A. Alves",
      "Alvaro F. Martins",
      "Ervin K. Lenzi",
      "Matjaz Perc"
    ],
    "author_ids": [],
    "abstract": "Corruptive behaviour in politics limits economic growth, embezzles public\nfunds, and promotes socio-economic inequality in modern democracies. We analyse\nwell-documented political corruption scandals in Brazil over the past 27 years,\nfocusing on the dynamical structure of networks where two individuals are\nconnected if they were involved in the same scandal. Our research reveals that\ncorruption runs in small groups that rarely comprise more than eight people, in\nnetworks that have hubs and a modular structure that encompasses more than one\ncorruption scandal. We observe abrupt changes in the size of the largest\nconnected component and in the degree distribution, which are due to the\ncoalescence of different modules when new scandals come to light or when\ngovernments change. We show further that the dynamical structure of political\ncorruption networks can be used for successfully predicting partners in future\nscandals. We discuss the important role of network science in detecting and\nmitigating political corruption.",
    "published_date": "2018-01-05T00:00:00",
    "year": 2018,
    "categories": [
      "physics.soc-ph",
      "cs.SI",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.01869v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1801.01726v2",
    "title": "Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption",
    "authors": [
      "Peilun Li",
      "Xiaodan Liang",
      "Daoyuan Jia",
      "Eric P. Xing"
    ],
    "author_ids": [],
    "abstract": "Recent advances in vision tasks (e.g., segmentation) highly depend on the\navailability of large-scale real-world image annotations obtained by cumbersome\nhuman labors. Moreover, the perception performance often drops significantly\nfor new scenarios, due to the poor generalization capability of models trained\non limited and biased annotations. In this work, we resort to transfer\nknowledge from automatically rendered scene annotations in virtual-world to\nfacilitate real-world visual tasks. Although virtual-world annotations can be\nideally diverse and unlimited, the discrepant data distributions between\nvirtual and real-world make it challenging for knowledge transferring. We thus\npropose a novel Semantic-aware Grad-GAN (SG-GAN) to perform virtual-to-real\ndomain adaption with the ability of retaining vital semantic information.\nBeyond the simple holistic color/texture transformation achieved by prior\nworks, SG-GAN successfully personalizes the appearance adaption for each\nsemantic region in order to preserve their key characteristic for better\nrecognition. It presents two main contributions to traditional GANs: 1) a soft\ngradient-sensitive objective for keeping semantic boundaries; 2) a\nsemantic-aware discriminator for validating the fidelity of personalized\nadaptions with respect to each semantic region. Qualitative and quantitative\nexperiments demonstrate the superiority of our SG-GAN in scene adaption over\nstate-of-the-art GANs. Further evaluations on semantic segmentation on\nCityscapes show using adapted virtual images by SG-GAN dramatically improves\nsegmentation performance than original virtual data. We release our code at\nhttps://github.com/Peilun-Li/SG-GAN.",
    "published_date": "2018-01-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.01726v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.01705v1",
    "title": "Gatekeeping Algorithms with Human Ethical Bias: The ethics of algorithms in archives, libraries and society",
    "authors": [
      "Martijn van Otterlo"
    ],
    "author_ids": [],
    "abstract": "In the age of algorithms, I focus on the question of how to ensure algorithms\nthat will take over many of our familiar archival and library tasks, will\nbehave according to human ethical norms that have evolved over many years. I\nstart by characterizing physical archives in the context of related\ninstitutions such as libraries and museums. In this setting I analyze how\nethical principles, in particular about access to information, have been\nformalized and communicated in the form of ethical codes, or: codes of\nconducts. After that I describe two main developments: digitalization, in which\nphysical aspects of the world are turned into digital data, and\nalgorithmization, in which intelligent computer programs turn this data into\npredictions and decisions. Both affect interactions that were once physical but\nnow digital. In this new setting I survey and analyze the ethical aspects of\nalgorithms and how they shape a vision on the future of archivists and\nlibrarians, in the form of algorithmic documentalists, or: codementalists.\nFinally I outline a general research strategy, called IntERMEeDIUM, to obtain\nalgorithms that obey are human ethical values encoded in code of ethics.",
    "published_date": "2018-01-05T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.01705v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.01528v1",
    "title": "A deep learning approach for detecting traffic accidents from social media data",
    "authors": [
      "Zhenhua Zhang",
      "Qing Heb",
      "Jing Gao",
      "Ming Ni"
    ],
    "author_ids": [],
    "abstract": "This paper employs deep learning in detecting the traffic accident from\nsocial media data. First, we thoroughly investigate the 1-year over 3 million\ntweet contents in two metropolitan areas: Northern Virginia and New York City.\nOur results show that paired tokens can capture the association rules inherent\nin the accident-related tweets and further increase the accuracy of the traffic\naccident detection. Second, two deep learning methods: Deep Belief Network\n(DBN) and Long Short-Term Memory (LSTM) are investigated and implemented on the\nextracted token. Results show that DBN can obtain an overall accuracy of 85%\nwith about 44 individual token features and 17 paired token features. The\nclassification results from DBN outperform those of Support Vector Machines\n(SVMs) and supervised Latent Dirichlet allocation (sLDA). Finally, to validate\nthis study, we compare the accident-related tweets with both the traffic\naccident log on freeways and traffic data on local roads from 15,000 loop\ndetectors. It is found that nearly 66% of the accident-related tweets can be\nlocated by the accident log and more than 80% of them can be tied to nearby\nabnormal traffic data. Several important issues of using Twitter to detect\ntraffic accidents have been brought up by the comparison including the location\nand time bias, as well as the characteristics of influential users and\nhashtags.",
    "published_date": "2018-01-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.SI",
      "stat.OT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.01528v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.01422v1",
    "title": "Practical Challenges in Explicit Ethical Machine Reasoning",
    "authors": [
      "Louise Dennis",
      "Michael Fisher"
    ],
    "author_ids": [],
    "abstract": "We examine implemented systems for ethical machine reasoning with a view to\nidentifying the practical challenges (as opposed to philosophical challenges)\nposed by the area. We identify a need for complex ethical machine reasoning not\nonly to be multi-objective, proactive, and scrutable but that it must draw on\nheterogeneous evidential reasoning. We also argue that, in many cases, it needs\nto operate in real time and be verifiable. We propose a general architecture\ninvolving a declarative ethical arbiter which draws upon multiple evidential\nreasoners each responsible for a particular ethical feature of the system's\nenvironment. We claim that this architecture enables some separation of\nconcerns among the practical challenges that ethical machine reasoning poses.",
    "published_date": "2018-01-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.01422v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.03533v1",
    "title": "Selection Problems in the Presence of Implicit Bias",
    "authors": [
      "Jon Kleinberg",
      "Manish Raghavan"
    ],
    "author_ids": [],
    "abstract": "Over the past two decades, the notion of implicit bias has come to serve as\nan important component in our understanding of discrimination in activities\nsuch as hiring, promotion, and school admissions. Research on implicit bias\nposits that when people evaluate others -- for example, in a hiring context --\ntheir unconscious biases about membership in particular groups can have an\neffect on their decision-making, even when they have no deliberate intention to\ndiscriminate against members of these groups. A growing body of experimental\nwork has pointed to the effect that implicit bias can have in producing adverse\noutcomes.\n  Here we propose a theoretical model for studying the effects of implicit bias\non selection decisions, and a way of analyzing possible procedural remedies for\nimplicit bias within this model. A canonical situation represented by our model\nis a hiring setting: a recruiting committee is trying to choose a set of\nfinalists to interview among the applicants for a job, evaluating these\napplicants based on their future potential, but their estimates of potential\nare skewed by implicit bias against members of one group. In this model, we\nshow that measures such as the Rooney Rule, a requirement that at least one of\nthe finalists be chosen from the affected group, can not only improve the\nrepresentation of this affected group, but also lead to higher payoffs in\nabsolute terms for the organization performing the recruiting. However,\nidentifying the conditions under which such measures can lead to improved\npayoffs involves subtle trade-offs between the extent of the bias and the\nunderlying distribution of applicant characteristics, leading to novel\ntheoretical questions about order statistics in the presence of probabilistic\nside information.",
    "published_date": "2018-01-04T00:00:00",
    "year": 2018,
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.03533v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1801.00742v1",
    "title": "Large Flocks of Small Birds: On the Minimal Size of Population Protocols",
    "authors": [
      "Michael Blondin",
      "Javier Esparza",
      "Stefan Jaax"
    ],
    "author_ids": [],
    "abstract": "Population protocols are a well established model of distributed computation\nby mobile finite-state agents with very limited storage. A classical result\nestablishes that population protocols compute exactly predicates definable in\nPresburger arithmetic. We initiate the study of the minimal amount of memory\nrequired to compute a given predicate as a function of its size. We present\nresults on the predicates $x \\geq n$ for $n \\in \\mathbb{N}$, and more generally\non the predicates corresponding to systems of linear inequalities. We show that\nthey can be computed by protocols with $O(\\log n)$ states (or, more generally,\nlogarithmic in the coefficients of the predicate), and that, surprisingly, some\nfamilies of predicates can be computed by protocols with $O(\\log\\log n)$\nstates. We give essentially matching lower bounds for the class of 1-aware\nprotocols.",
    "published_date": "2018-01-02T00:00:00",
    "year": 2018,
    "categories": [
      "cs.DC",
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.00742v1",
    "is_ai_related": false
  }
]