[
  {
    "id": "http://arxiv.org/abs/1612.09029v1",
    "title": "Distributed Convex Optimization with Inequality Constraints over Time-varying Unbalanced Digraphs",
    "authors": [
      "Pei Xie",
      "Keyou You",
      "Roberto Tempo",
      "Shiji Song",
      "Cheng Wu"
    ],
    "author_ids": [],
    "abstract": "This paper considers a distributed convex optimization problem with\ninequality constraints over time-varying unbalanced digraphs, where the cost\nfunction is a sum of local objectives, and each node of the graph only knows\nits local objective and inequality constraints. Although there is a vast\nliterature on distributed optimization, most of them require the graph to be\nbalanced, which is quite restrictive and not necessary. Very recently, the\nunbalanced problem has been resolved only for either time-invariant graphs or\nunconstrained optimization. This work addresses the unbalancedness by focusing\non an epigraph form of the constrained optimization. A striking feature is that\nthis novel idea can be easily used to study time-varying unbalanced digraphs.\nUnder local communications, a simple iterative algorithm is then designed for\neach node. We prove that if the graph is uniformly jointly strongly connected,\neach node asymptotically converges to some common optimal solution.",
    "published_date": "2016-12-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.09029v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.08477v1",
    "title": "Effect of white LED DC-bias on modulation speed for visible light communications",
    "authors": [
      "Peng Deng",
      "Mohsen Kavehrad"
    ],
    "author_ids": [],
    "abstract": "The light emitting diode (LED) nonlinearities distortion induced degradation\nin the performance of visible light communication (VLC) systems can be\ncontrolled by optimizing the DC bias point of the LED. In this paper, we\ntheoretically analyze and experimentally demonstrate the effect of white LED DC\nbias on nonlinear modulation bandwidth and dynamic range of the VLC system. The\nlinear dynamic range is enhanced by using series-connected LED chips, and the\nmodulation bandwidth is extended to 40 MHz by post-equalization without using a\nblue filter. The experimental results well match the theoretical model of LED\nnonlinear modulation characteristics. The results show that the modulation\nbandwidth increases and saturates with an increase in LED DC bias current due\nto nonlinear effect of carrier lifetime and junction capacitance. The optimized\nDC-bias current that corresponds to the minimum BER increases with the increase\nof data rate. A 60-Mbps NRZ transmission can be achieved with BER threshold of\n10-3 by properly adjusting LED DC bias point.",
    "published_date": "2016-12-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "physics.optics"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.08477v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.08446v4",
    "title": "Network Slicing Games: Enabling Customization in Multi-Tenant Networks",
    "authors": [
      "Pablo Caballero",
      "Albert Banchs",
      "Gustavo de Veciana",
      "Xavier Costa-Perez"
    ],
    "author_ids": [],
    "abstract": "Network slicing to enable resource sharing among multiple tenants --network\noperators and/or services-- is considered a key functionality for next\ngeneration mobile networks. This paper provides an analysis of a well-known\nmodel for resource sharing, the 'share-constrained proportional allocation'\nmechanism, to realize network slicing. This mechanism enables tenants to reap\nthe performance benefits of sharing, while retaining the ability to customize\ntheir own users' allocation. This results in a network slicing game in which\neach tenant reacts to the user allocations of the other tenants so as to\nmaximize its own utility. We show that, under appropriate conditions, the game\nassociated with such strategic behavior converges to a Nash equilibrium. At the\nNash equilibrium, a tenant always achieves the same, or better, performance\nthan under a static partitioning of resources, hence providing the same level\nof protection as such static partitioning. We further analyze the efficiency\nand fairness of the resulting allocations, providing tight bounds for the price\nof anarchy and envy-freeness. Our analysis and extensive simulation results\nconfirm that the mechanism provides a comprehensive practical solution to\nrealize network slicing. Our theoretical results also fill a gap in the\nliterature regarding the analysis of this resource allocation model under\nstrategic players.",
    "published_date": "2016-12-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.08446v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.08200v1",
    "title": "Neighbor-Neighbor Correlations Explain Measurement Bias in Networks",
    "authors": [
      "Xin-Zeng Wu",
      "Allon G. Percus",
      "Kristina Lerman"
    ],
    "author_ids": [],
    "abstract": "In numerous physical models on networks, dynamics are based on interactions\nthat exclusively involve properties of a node's nearest neighbors. However, a\nnode's local view of its neighbors may systematically bias perceptions of\nnetwork connectivity or the prevalence of certain traits. We investigate the\nstrong friendship paradox, which occurs when the majority of a node's neighbors\nhave more neighbors than does the node itself. We develop a model to predict\nthe magnitude of the paradox, showing that it is enhanced by negative\ncorrelations between degrees of neighboring nodes. We then show that by\nincluding neighbor-neighbor correlations, which are degree correlations one\nstep beyond those of neighboring nodes, we accurately predict the impact of the\nstrong friendship paradox in real-world networks. Understanding how the paradox\nbiases local observations can inform better measurements of network structure\nand our understanding of collective phenomena.",
    "published_date": "2016-12-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cond-mat.stat-mech",
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.08200v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.07454v1",
    "title": "How to Train Your Deep Neural Network with Dictionary Learning",
    "authors": [
      "Vanika Singhal",
      "Shikha Singh",
      "Angshul Majumdar"
    ],
    "author_ids": [],
    "abstract": "Currently there are two predominant ways to train deep neural networks. The\nfirst one uses restricted Boltzmann machine (RBM) and the second one\nautoencoders. RBMs are stacked in layers to form deep belief network (DBN); the\nfinal representation layer is attached to the target to complete the deep\nneural network. Autoencoders are nested one inside the other to form stacked\nautoencoders; once the stcaked autoencoder is learnt the decoder portion is\ndetached and the target attached to the deepest layer of the encoder to form\nthe deep neural network. This work proposes a new approach to train deep neural\nnetworks using dictionary learning as the basic building block; the idea is to\nuse the features from the shallower layer as inputs for training the next\ndeeper layer. One can use any type of dictionary learning (unsupervised,\nsupervised, discriminative etc.) as basic units till the pre-final layer. In\nthe final layer one needs to use the label consistent dictionary learning\nformulation for classification. We compare our proposed framework with existing\nstate-of-the-art deep learning techniques on benchmark problems; we are always\nwithin the top 10 results. In actual problems of age and gender classification,\nwe are better than the best known techniques.",
    "published_date": "2016-12-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.07454v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.06821v2",
    "title": "User Bias Removal in Review Score Prediction",
    "authors": [
      "Rahul Wadbude",
      "Vivek Gupta",
      "Dheeraj Mekala",
      "Harish Karnick"
    ],
    "author_ids": [],
    "abstract": "Review score prediction of text reviews has recently gained a lot of\nattention in recommendation systems. A major problem in models for review score\nprediction is the presence of noise due to user-bias in review scores. We\npropose two simple statistical methods to remove such noise and improve review\nscore prediction. Compared to other methods that use multiple classifiers, one\nfor each user, our model uses a single global classifier to predict review\nscores. We empirically evaluate our methods on two major categories\n(\\textit{Electronics} and \\textit{Movies and TV}) of the SNAP published Amazon\ne-Commerce Reviews data-set and Amazon \\textit{Fine Food} reviews data-set. We\nobtain improved review score prediction for three commonly used text feature\nrepresentations.",
    "published_date": "2016-12-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.06821v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.06112v2",
    "title": "Compact Full Duplex MIMO Radios in D2D Underlaid Cellular Networks: From System Design to Prototype Results",
    "authors": [
      "MinKeun Chung",
      "Min Soo Sim",
      "Dong Ku Kim",
      "Chan-Byoung Chae"
    ],
    "author_ids": [],
    "abstract": "This paper considers the implementation and application possibilities of a\ncompact full duplex multiple-input multiple-output (MIMO) architecture where\ndirect communication exists between users, e.g., device-to-device (D2D) and\ncellular link coexisting on the same spectrum. For the architecture of the\ncompact full duplex radio, we combine an analog self-interference canceler\nbased dual-polarization with high cross-polarization discrimination (XPD) and\nLong Term Evolution (LTE)-based per-subcarrier digital self-interference\ncanceler. While we consider the compactness and power efficiency of an analog\nsolution, we focus on the digital canceler design with robustness to a\nfrequency-selective channel and high compatibility with a conventional LTE\nsystem. For an over-the-air wireless experiment of full duplex testbed with a\ntwo-user-pair, we implement a full duplex MIMO physical layer (PHY), supporting\n20 MHz bandwidth, on an FPGA-based software-defined radio platform. Further, we\npropose a novel timing synchronization method to construct a more viable full\nduplex MIMO link. By having the full duplex link prototype fully operating in\nreal-time, we present the first characterization of the proposed compact full\nduplex MIMO performance depending on the transmit power of the full duplex\nnode. We also show the link quality between nodes. One of the crucial insights\nof this work is that the full duplex operation of a user is capable of\nacquiring the throughput gain if the user has self-interference capability with\nguaranteed performance.",
    "published_date": "2016-12-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.06112v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.05845v2",
    "title": "Dependence Measures Bounding the Exploration Bias for General Measurements",
    "authors": [
      "Jiantao Jiao",
      "Yanjun Han",
      "Tsachy Weissman"
    ],
    "author_ids": [],
    "abstract": "We propose a framework to analyze and quantify the bias in adaptive data\nanalysis. It generalizes that proposed by Russo and Zou'15, applying to\nmeasurements whose moment generating function exists, measurements with a\nfinite $p$-norm, and measurements in general Orlicz spaces. We introduce a new\nclass of dependence measures which retain key properties of mutual information\nwhile more effectively quantifying the exploration bias for heavy tailed\ndistributions. We provide examples of cases where our bounds are nearly tight\nin situations where the original framework of Russo and Zou'15 does not apply.",
    "published_date": "2016-12-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.05845v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.01142v1",
    "title": "The Dem@Care Experiments and Datasets: a Technical Report",
    "authors": [
      "Anastasios Karakostas",
      "Alexia Briassouli",
      "Konstantinos Avgerinakis",
      "Ioannis Kompatsiaris",
      "Magda Tsolaki"
    ],
    "author_ids": [],
    "abstract": "The objective of Dem@Care is the development of a complete system providing\npersonal health services to people with dementia, as well as medical\nprofessionals and caregivers, by using a multitude of sensors, for\ncontext-aware, multi-parametric monitoring of lifestyle, ambient environment,\nand health parameters. Multi-sensor data analysis, combined with intelligent\ndecision making mechanisms, will allow an accurate representation of the\nperson's current status and will provide the appropriate feedback, both to the\nperson and the associated caregivers, enhancing the standard clinical workflow.\nWithin the project framework, several data collection activities have taken\nplace to assist technical development and evaluation tasks. In all these\nactivities, particular attention has been paid to adhere to ethical guidelines\nand preserve the participants' privacy. This technical report describes shorty\nthe (a) the main objectives of the project, (b) the main ethical principles and\n(c) the datasets that have been already created.",
    "published_date": "2016-12-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.01142v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.05299v1",
    "title": "A Survey of Inductive Biases for Factorial Representation-Learning",
    "authors": [
      "Karl Ridgeway"
    ],
    "author_ids": [],
    "abstract": "With the resurgence of interest in neural networks, representation learning\nhas re-emerged as a central focus in artificial intelligence. Representation\nlearning refers to the discovery of useful encodings of data that make\ndomain-relevant information explicit. Factorial representations identify\nunderlying independent causal factors of variation in data. A factorial\nrepresentation is compact and faithful, makes the causal factors explicit, and\nfacilitates human interpretation of data. Factorial representations support a\nvariety of applications, including the generation of novel examples, indexing\nand search, novelty detection, and transfer learning.\n  This article surveys various constraints that encourage a learning algorithm\nto discover factorial representations. I dichotomize the constraints in terms\nof unsupervised and supervised inductive bias. Unsupervised inductive biases\nexploit assumptions about the environment, such as the statistical distribution\nof factor coefficients, assumptions about the perturbations a factor should be\ninvariant to (e.g. a representation of an object can be invariant to rotation,\ntranslation or scaling), and assumptions about how factors are combined to\nsynthesize an observation. Supervised inductive biases are constraints on the\nrepresentations based on additional information connected to observations.\nSupervisory labels come in variety of types, which vary in how strongly they\nconstrain the representation, how many factors are labeled, how many\nobservations are labeled, and whether or not we know the associations between\nthe constraints and the factors they are related to.\n  This survey brings together a wide variety of models that all touch on the\nproblem of learning factorial representations and lays out a framework for\ncomparing these models based on the strengths of the underlying supervised and\nunsupervised inductive biases.",
    "published_date": "2016-12-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.05299v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.04913v1",
    "title": "Distributed Algorithms for Solving a Class of Convex Feasibility Problems",
    "authors": [
      "Kaihong Lu",
      "Gangshan Jing",
      "Long Wang"
    ],
    "author_ids": [],
    "abstract": "In this paper, a class of convex feasibility problems (CFPs) are studied for\nmulti-agent systems through local interactions. The objective is to search a\nfeasible solution to the convex inequalities with some set constraints in a\ndistributed manner. The distributed control algorithms, involving subgradient\nand projection, are proposed for both continuous- and discrete-time systems,\nrespectively. Conditions associated with connectivity of the directed\ncommunication graph are given to ensure convergence of the algorithms. It is\nshown that under mild conditions, the states of all agents reach consensus\nasymptotically and the consensus state is located in the solution set of the\nCFP. Simulation examples are presented to demonstrate the effectiveness of the\ntheoretical results.",
    "published_date": "2016-12-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.04913v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.04902v1",
    "title": "Prerequisites for International Exchanges of Health Information: Comparison of Australian, Austrian, Finnish, Swiss, and US Privacy Policies",
    "authors": [
      "Hanna Suominen",
      "Henning Müller",
      "Lucila Ohno-Machado",
      "Sanna Salanterä",
      "Günter Schreier",
      "Leif Hanlen"
    ],
    "author_ids": [],
    "abstract": "Capabilities to exchange health information are critical to accelerate\ndiscovery and its diffusion to healthcare practice. However, the same ethical\nand legal policies that protect privacy hinder these data exchanges, and the\nissues accumulate if moving data across geographical or organizational borders.\nThis can be seen as one of the reasons why many health technologies and\nresearch findings are limited to very narrow domains. In this paper, we compare\nhow using and disclosing personal data for research purposes is addressed in\nAustralian, Austrian, Finnish, Swiss, and US policies with a focus on text data\nanalytics. Our goal is to identify approaches and issues that enable or hinder\ninternational health information exchanges. As expected, the policies within\neach country are not as diverse as across countries. Most policies apply the\nprinciples of accountability and/or adequacy and are thereby fundamentally\nsimilar. Their following requirements create complications with re-using and\nre-disclosing data and even secondary data: 1) informing data subjects about\nthe purposes of data collection and use, before the dataset is collected; 2)\nassurance that the subjects are no longer identifiable; and 3) destruction of\ndata when the research activities are finished. Using storage and compute cloud\nservices as well as other exchange technologies on the Internet without proper\npermissions is technically not allowed if the data are stored in another\ncountry. Both legislation and technologies are available as vehicles for\novercoming these barriers. The resulting richness in information variety will\ncontribute to the development and evaluation of new clinical hypotheses and\ntechnologies.",
    "published_date": "2016-12-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.04902v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.04580v1",
    "title": "Socioeconomic correlations and stratification in social-communication networks",
    "authors": [
      "Yannick Leo",
      "Eric Fleury",
      "J. Ignacio Alvarez-Hamelin",
      "Carlos Sarraute",
      "Márton Karsai"
    ],
    "author_ids": [],
    "abstract": "The uneven distribution of wealth and individual economic capacities are\namong the main forces which shape modern societies and arguably bias the\nemerging social structures. However, the study of correlations between the\nsocial network and economic status of individuals is difficult due to the lack\nof large-scale multimodal data disclosing both the social ties and economic\nindicators of the same population. Here, we close this gap through the analysis\nof coupled datasets recording the mobile phone communications and bank\ntransaction history of one million anonymised individuals living in a Latin\nAmerican country. We show that wealth and debt are unevenly distributed among\npeople in agreement with the Pareto principle; the observed social structure is\nstrongly stratified, with people being better connected to others of their own\nsocioeconomic class rather than to others of different classes; the social\nnetwork appears with assortative socioeconomic correlations and tightly\nconnected \"rich clubs\"; and that egos from the same class live closer to each\nother but commute further if they are wealthier. These results are based on a\nrepresentative, society-large population, and empirically demonstrate some\nlong-lasting hypotheses on socioeconomic correlations which potentially lay\nbehind social segregation, and induce differences in human mobility.",
    "published_date": "2016-12-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.04580v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.03468v1",
    "title": "Bias reduction of peer influence effects with latent coordinates and community membership",
    "authors": [
      "Daniel Rajchwald",
      "Natasha Markuzon"
    ],
    "author_ids": [],
    "abstract": "The importance of peer influence on consumer actions plays a vital role in\nmarketing efforts. However, peer influence effects are often confounded with\nlatent homophily, which are unobserved commonalities that drive friendship.\nUnderstanding causality has become one of the pressing issues of current\nresearch. We present an approach to explicitly account for various causal\ninfluences. We implement a simulation framework to show the effectiveness of\ntwo latent homophily proxies, latent coordinates and community membership, in\nimproving peer influence effect estimates on game downloads in a Japanese\nsocial network website. We demonstrate that latent homophily proxies have no\nsignificant improvement in peer influence effect bias in the available website\ndata.",
    "published_date": "2016-12-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.03468v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.03164v1",
    "title": "Square Hellinger Subadditivity for Bayesian Networks and its Applications to Identity Testing",
    "authors": [
      "Constantinos Daskalakis",
      "Qinxuan Pan"
    ],
    "author_ids": [],
    "abstract": "We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors.",
    "published_date": "2016-12-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "math.PR",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.03164v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.03161v2",
    "title": "Prophet Inequalities Made Easy: Stochastic Optimization by Pricing Non-Stochastic Inputs",
    "authors": [
      "Paul Dütting",
      "Michal Feldman",
      "Thomas Kesselheim",
      "Brendan Lucier"
    ],
    "author_ids": [],
    "abstract": "We present a general framework for stochastic online maximization problems\nwith combinatorial feasibility constraints. The framework establishes prophet\ninequalities by constructing price-based online approximation algorithms, a\nnatural extension of threshold algorithms for settings beyond binary selection.\nOur analysis takes the form of an extension theorem: we derive sufficient\nconditions on prices when all weights are known in advance, then prove that the\nresulting approximation guarantees extend directly to stochastic settings. Our\nframework unifies and simplifies much of the existing literature on prophet\ninequalities and posted price mechanisms, and is used to derive new and\nimproved results for combinatorial markets (with and without complements),\nmulti-dimensional matroids, and sparse packing problems. Finally, we highlight\na surprising connection between the smoothness framework for bounding the price\nof anarchy of mechanisms and our framework, and show that many smooth\nmechanisms can be recast as posted price mechanisms with comparable performance\nguarantees.",
    "published_date": "2016-12-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.03161v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.02859v1",
    "title": "Exploiting 2D Floorplan for Building-scale Panorama RGBD Alignment",
    "authors": [
      "Erik Wijmans",
      "Yasutaka Furukawa"
    ],
    "author_ids": [],
    "abstract": "This paper presents a novel algorithm that utilizes a 2D floorplan to align\npanorama RGBD scans. While effective panorama RGBD alignment techniques exist,\nsuch a system requires extremely dense RGBD image sampling. Our approach can\nsignificantly reduce the number of necessary scans with the aid of a floorplan\nimage. We formulate a novel Markov Random Field inference problem as a scan\nplacement over the floorplan, as opposed to the conventional scan-to-scan\nalignment. The technical contributions lie in multi-modal image correspondence\ncues (between scans and schematic floorplan) as well as a novel coverage\npotential avoiding an inherent stacking bias. The proposed approach has been\nevaluated on five challenging large indoor spaces. To the best of our\nknowledge, we present the first effective system that utilizes a 2D floorplan\nimage for building-scale 3D pointcloud alignment. The source code and the data\nwill be shared with the community to further enhance indoor mapping research.",
    "published_date": "2016-12-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.02859v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.02686v1",
    "title": "Effects of online group exercises for older adults on physical, psychological and social wellbeing: a pilot trial",
    "authors": [
      "Marcos Baez",
      "Iman Khaghani Far",
      "Francisco Ibarra",
      "Michela Ferron",
      "Daniele Didino",
      "Fabio Casati"
    ],
    "author_ids": [],
    "abstract": "Background. There are many factors that can make of group exercises a\nchallenging setting for older adults. A major one in the elderly population is\nthe difference in the level of skills. In this paper we report on the physical,\npsychological and social wellbeing outcomes of a novel virtual gym that enables\nonline group-exercises in older adults with different levels of skills.\n  Methods. A total of 37 older adults (65-87 years old) followed a personalized\nexercise program based on the OTAGO program for fall prevention, for a period\nof eight weeks. Participants could join online group exercises using a\ntablet-based application. Participants were assigned either to a Control group\n(individual training) or Social group (online group-exercising). Pre- and post-\nmeasurements were taken to analyze the physical, psychological and social\nwellbeing outcomes. The study received ethical approval from the CREATE-NET\nEthics Committee on ICT Research Involving Human Beings (Application N.\n2014-001).\n  Results. There were improvements in both the Social and Control groups in\nterms of physical outcomes. Interestingly though, while in the Control group\nfitter individuals tended to adhere more to the training, this was not the case\nfor the Social group, where the initial level had no effect on adherence. For\npsychological and social wellbeing outcomes there were improvements on both\ngroups, regardless of the application used.\n  Conclusion. Group exercising in a virtual gym can be effective in motivating\nand enabling individuals who are less fit to train as much as fitter\nindividuals. This not only indicates the feasibility of training together\ndespite differences in physical skills but also suggests that online exercise\ncan reduce the effect of skills on adherence in a social context. Longer term\ninterventions with more participants are instead recommended to assess impacts\non wellbeing.",
    "published_date": "2016-12-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.02686v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.02503v5",
    "title": "What do Shannon-type Inequalities, Submodular Width, and Disjunctive Datalog have to do with one another?",
    "authors": [
      "Mahmoud Abo Khamis",
      "Hung Q. Ngo",
      "Dan Suciu"
    ],
    "author_ids": [],
    "abstract": "Recent works on bounding the output size of a conjunctive query with\nfunctional dependencies and degree constraints have shown a deep connection\nbetween fundamental questions in information theory and database theory. We\nprove analogous output bounds for disjunctive datalog rules, and answer several\nopen questions regarding the tightness and looseness of these bounds along the\nway. Our bounds are intimately related to Shannon-type information\ninequalities. We devise the notion of a \"proof sequence\" of a specific class of\nShannon-type information inequalities called \"Shannon flow inequalities\". We\nthen show how such a proof sequence can be interpreted as symbolic instructions\nguiding an algorithm called \"PANDA\", which answers disjunctive datalog rules\nwithin the time that the size bound predicted. We show that PANDA can be used\nas a black-box to devise algorithms matching precisely the fractional hypertree\nwidth and the submodular width runtimes for aggregate and conjunctive queries\nwith functional dependencies and degree constraints.\n  Our results improve upon known results in three ways. First, our bounds and\nalgorithms are for the much more general class of disjunctive datalog rules, of\nwhich conjunctive queries are a special case. Second, the runtime of PANDA\nmatches precisely the submodular width bound, while the previous algorithm by\nMarx has a runtime that is polynomial in this bound. Third, our bounds and\nalgorithms work for queries with input cardinality bounds, functional\ndependencies, and degree constraints.\n  Overall, our results show a deep connection between three seemingly unrelated\nlines of research; and, our results on proof sequences for Shannon flow\ninequalities might be of independent interest.",
    "published_date": "2016-12-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DB",
      "cs.DS",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.02503v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.01641v1",
    "title": "Incremental View Maintenance for Deductive Graph Databases Using Generalized Discrimination Networks",
    "authors": [
      "Thomas Beyhl",
      "Holger Giese"
    ],
    "author_ids": [],
    "abstract": "Nowadays, graph databases are employed when relationships between entities\nare in the scope of database queries to avoid performance-critical join\noperations of relational databases. Graph queries are used to query and modify\ngraphs stored in graph databases. Graph queries employ graph pattern matching\nthat is NP-complete for subgraph isomorphism. Graph database views can be\nemployed that keep ready answers in terms of precalculated graph pattern\nmatches for often stated and complex graph queries to increase query\nperformance. However, such graph database views must be kept consistent with\nthe graphs stored in the graph database.\n  In this paper, we describe how to use incremental graph pattern matching as\ntechnique for maintaining graph database views. We present an incremental\nmaintenance algorithm for graph database views, which works for imperatively\nand declaratively specified graph queries. The evaluation shows that our\nmaintenance algorithm scales when the number of nodes and edges stored in the\ngraph database increases. Furthermore, our evaluation shows that our approach\ncan outperform existing approaches for the incremental maintenance of graph\nquery results.",
    "published_date": "2016-12-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.01641v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.01636v1",
    "title": "A Stochastic Geometry-based Demand Response Management Framework for Cellular Networks Powered by Smart Grid",
    "authors": [
      "Muhammad Junaid Farooq",
      "Hakim Ghazzai",
      "Abdullah Kadri"
    ],
    "author_ids": [],
    "abstract": "In this paper, the production decisions across multiple energy suppliers in\nsmart grid, powering cellular networks are investigated. The suppliers are\ncharacterized by different offered prices and pollutant emissions levels. The\nchallenge is to decide the amount of energy provided by each supplier to each\nof the operators such that their profitability is maximized while respecting\nthe maximum tolerated level of CO2 emissions. The cellular operators are\ncharacterized by their offered quality of service (QoS) to the subscribers and\nthe number of users that determines their energy requirements. Stochastic\ngeometry is used to determine the average power needed to achieve the target\nprobability of coverage for each operator. The total average power requirements\nof all networks are fed to an optimization framework to find the optimal amount\nof energy to be provided from each supplier to the operators. The generalized\n$\\alpha$-fair utility function is used to avoid production bias among the\nsuppliers based on profitability of generation. Results illustrate the\nproduction behavior of the energy suppliers versus QoS level, cost of energy,\ncapacity of generation, and level of fairness.",
    "published_date": "2016-12-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.01636v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.01594v1",
    "title": "Object Classification with Joint Projection and Low-rank Dictionary Learning",
    "authors": [
      "Homa Foroughi",
      "Nilanjan Ray",
      "Hong Zhang"
    ],
    "author_ids": [],
    "abstract": "For an object classification system, the most critical obstacles towards\nreal-world applications are often caused by large intra-class variability,\narising from different lightings, occlusion and corruption, in limited sample\nsets. Most methods in the literature would fail when the training samples are\nheavily occluded, corrupted or have significant illumination or viewpoint\nvariations. Besides, most of the existing methods and especially deep\nlearning-based methods, need large training sets to achieve a satisfactory\nrecognition performance. Although using the pre-trained network on a generic\nlarge-scale dataset and fine-tune it to the small-sized target dataset is a\nwidely used technique, this would not help when the content of base and target\ndatasets are very different. To address these issues, we propose a joint\nprojection and low-rank dictionary learning method using dual graph constraints\n(JP-LRDL). The proposed joint learning method would enable us to learn the\nfeatures on top of which dictionaries can be better learned, from the data with\nlarge intra-class variability. Specifically, a structured class-specific\ndictionary is learned and the discrimination is further improved by imposing a\ngraph constraint on the coding coefficients, that maximizes the intra-class\ncompactness and inter-class separability. We also enforce low-rank and\nstructural incoherence constraints on sub-dictionaries to make them more\ncompact and robust to variations and outliers and reduce the redundancy among\nthem, respectively. To preserve the intrinsic structure of data and penalize\nunfavourable relationship among training samples simultaneously, we introduce a\nprojection graph into the framework, which significantly enhances the\ndiscriminative ability of the projection matrix and makes the method robust to\nsmall-sized and high-dimensional datasets.",
    "published_date": "2016-12-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.01594v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.00985v2",
    "title": "Wikiwhere: An interactive tool for studying the geographical provenance of Wikipedia references",
    "authors": [
      "Martin Körner",
      "Tatiana Sennikova",
      "Florian Windhäuser",
      "Claudia Wagner",
      "Fabian Flöck"
    ],
    "author_ids": [],
    "abstract": "Wikipedia articles about the same topic in different language editions are\nbuilt around different sources of information. For example, one can find very\ndifferent news articles linked as references in the English Wikipedia article\ntitled \"Annexation of Crimea by the Russian Federation\" than in its German\ncounterpart (determined via Wikipedia's language links). Some of this\ndifference can of course be attributed to the different language proficiencies\nof readers and editors in separate language editions, yet, although including\nEnglish-language news sources seems to be no issue in the German edition,\nEnglish references that are listed do not overlap highly with the ones in the\narticle's English version. Such patterns could be an indicator of bias towards\ncertain national contexts when referencing facts and statements in Wikipedia.\nHowever, determining for each reference which national context it can be traced\nback to, and comparing the link distributions to each other is infeasible for\ncasual readers or scientists with non-technical backgrounds. Wikiwhere answers\nthe question where Web references stem from by analyzing and visualizing the\ngeographic location of external reference links that are included in a given\nWikipedia article. Instead of relying solely on the IP location of a given URL\nour machine learning models consider several features.",
    "published_date": "2016-12-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.00985v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1612.00668v2",
    "title": "Estonian Voting Verification Mechanism Revisited",
    "authors": [
      "Koksal Mus",
      "Mehmet Sabir Kiraz",
      "Murat Cenk",
      "Isa Sertkaya"
    ],
    "author_ids": [],
    "abstract": "After the Estonian Parliamentary Elections held in 2011, an additional\nverification mechanism was integrated into the i-voting system in order to\nresist corrupted voting devices, including the so called Student's Attack where\na student practically showed that the voting system is indeed not verifiable by\ndeveloping several versions of malware capable of blocking or even changing the\nvote. This mechanism gives voters the opportunity to verify whether the vote\nthey cast is stored in the central system correctly. However, the verification\nphase ends by displaying the cast vote in plain form on the verification\ndevice. In other words, the device on which the verification is done learns the\nvoter's choice. In this work, our aim is to investigate this verification phase\nin detail and to point out that leaking the voter's choice to the verification\napplication may harm the voter privacy. Additionally, when applied in a wide\nrange, this would even compromise the fairness and the overall secrecy of the\nelections. In this respect, we propose an alternative verification mechanism\nfor the Estonian i-voting system to overcome this vulnerability. Not only is\nthe proposed mechanism secure and resistant against corrupted verification\ndevices, so does it successfully verify whether the vote is correctly stored in\nthe system. We also highlight that our proposed mechanism brings only symmetric\nencryptions and hash functions on the verification device, thereby mitigating\nthese weaknesses in an efficient way with a negligible cost. More concretely,\nit brings only $m$ additional symmetric key decryptions to the verification\ndevice, where $m$ denoting the number of candidates. Finally, we prove the\nsecurity of the proposed verification mechanism and compare the cost complexity\nof the proposed method with that of the current mechanism.",
    "published_date": "2016-12-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CR",
      "94A60"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.00668v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1612.00323v2",
    "title": "The Tyranny of Data? The Bright and Dark Sides of Data-Driven Decision-Making for Social Good",
    "authors": [
      "Bruno Lepri",
      "Jacopo Staiano",
      "David Sangokoya",
      "Emmanuel Letouzé",
      "Nuria Oliver"
    ],
    "author_ids": [],
    "abstract": "The unprecedented availability of large-scale human behavioral data is\nprofoundly changing the world we live in. Researchers, companies, governments,\nfinancial institutions, non-governmental organizations and also citizen groups\nare actively experimenting, innovating and adapting algorithmic decision-making\ntools to understand global patterns of human behavior and provide decision\nsupport to tackle problems of societal importance. In this chapter, we focus\nour attention on social good decision-making algorithms, that is algorithms\nstrongly influencing decision-making and resource optimization of public goods,\nsuch as public health, safety, access to finance and fair employment. Through\nan analysis of specific use cases and approaches, we highlight both the\npositive opportunities that are created through data-driven algorithmic\ndecision-making, and the potential negative consequences that practitioners\nshould be aware of and address in order to truly realize the potential of this\nemergent field. We elaborate on the need for these algorithms to provide\ntransparency and accountability, preserve privacy and be tested and evaluated\nin context, by means of living lab approaches involving citizens. Finally, we\nturn to the requirements which would make it possible to leverage the\npredictive power of data-driven human behavior analysis while ensuring\ntransparency, accountability, and civic participation.",
    "published_date": "2016-12-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1612.00323v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.09960v1",
    "title": "Attend in groups: a weakly-supervised deep learning framework for learning from web data",
    "authors": [
      "Bohan Zhuang",
      "Lingqiao Liu",
      "Yao Li",
      "Chunhua Shen",
      "Ian Reid"
    ],
    "author_ids": [],
    "abstract": "Large-scale datasets have driven the rapid development of deep neural\nnetworks for visual recognition. However, annotating a massive dataset is\nexpensive and time-consuming. Web images and their labels are, in comparison,\nmuch easier to obtain, but direct training on such automatically harvested\nimages can lead to unsatisfactory performance, because the noisy labels of Web\nimages adversely affect the learned recognition models. To address this\ndrawback we propose an end-to-end weakly-supervised deep learning framework\nwhich is robust to the label noise in Web images. The proposed framework relies\non two unified strategies -- random grouping and attention -- to effectively\nreduce the negative impact of noisy web image annotations. Specifically, random\ngrouping stacks multiple images into a single training instance and thus\nincreases the labeling accuracy at the instance level. Attention, on the other\nhand, suppresses the noisy signals from both incorrectly labeled images and\nless discriminative image regions. By conducting intensive experiments on two\nchallenging datasets, including a newly collected fine-grained dataset with Web\nimages of different car models, the superior performance of the proposed\nmethods over competitive baselines is clearly demonstrated.",
    "published_date": "2016-11-30T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.09960v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.09309v2",
    "title": "Gaze Embeddings for Zero-Shot Image Classification",
    "authors": [
      "Nour Karessli",
      "Zeynep Akata",
      "Bernt Schiele",
      "Andreas Bulling"
    ],
    "author_ids": [],
    "abstract": "Zero-shot image classification using auxiliary information, such as\nattributes describing discriminative object properties, requires time-consuming\nannotation by domain experts. We instead propose a method that relies on human\ngaze as auxiliary information, exploiting that even non-expert users have a\nnatural ability to judge class membership. We present a data collection\nparadigm that involves a discrimination task to increase the information\ncontent obtained from gaze data. Our method extracts discriminative descriptors\nfrom the data and learns a compatibility function between image and gaze using\nthree novel gaze embeddings: Gaze Histograms (GH), Gaze Features with Grid\n(GFG) and Gaze Features with Sequence (GFS). We introduce two new\ngaze-annotated datasets for fine-grained image classification and show that\nhuman gaze data is indeed class discriminative, provides a competitive\nalternative to expert-annotated attributes, and outperforms other baselines for\nzero-shot image classification.",
    "published_date": "2016-11-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.09309v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.09030v4",
    "title": "A modelling and computational study of the frustration index in signed networks",
    "authors": [
      "Samin Aref",
      "Andrew J. Mason",
      "Mark C. Wilson"
    ],
    "author_ids": [],
    "abstract": "Computing the frustration index of a signed graph is a key step toward\nsolving problems in many fields including social networks, political science,\nphysics, chemistry, and biology. The frustration index determines the distance\nof a network from a state of total structural balance. Although the definition\nof the frustration index goes back to the 1950's, its exact algorithmic\ncomputation, which is closely related to classic NP-hard graph problems, has\nonly become a focus in recent years. We develop three new binary linear\nprogramming models to compute the frustration index exactly and efficiently as\nthe solution to a global optimisation problem. Solving the models with\nprioritised branching and valid inequalities in Gurobi, we can compute the\nfrustration index of real signed networks with over 15000 edges in less than a\nminute on inexpensive hardware. We provide extensive performance analysis for\nboth random and real signed networks and show that our models outperform all\nexisting approaches by large factors. Based on solve time, algorithm output,\nand effective branching factor we highlight the superiority of our models to\nboth exact and heuristic methods in the literature.",
    "published_date": "2016-11-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "math.OC",
      "90C10, 90C20, 90C35, 90C57, 90C90, 05C15, 11E16, 65K05"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.09030v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.08983v12",
    "title": "Analyzing the group sparsity based on the rank minimization methods",
    "authors": [
      "Zhiyuan Zha",
      "Xin Liu",
      "Xiaohua Huang",
      "Henglin Shi",
      "Yingyue Xu",
      "Qiong Wang",
      "Lan Tang",
      "Xinggan Zhang"
    ],
    "author_ids": [],
    "abstract": "Sparse coding has achieved a great success in various image processing\nstudies. However, there is not any benchmark to measure the sparsity of image\npatch/group because sparse discriminant conditions cannot keep unchanged. This\npaper analyzes the sparsity of group based on the strategy of the rank\nminimization. Firstly, an adaptive dictionary for each group is designed. Then,\nwe prove that group-based sparse coding is equivalent to the rank minimization\nproblem, and thus the sparse coefficient of each group is measured by\nestimating the singular values of each group. Based on that measurement, the\nweighted Schatten $p$-norm minimization (WSNM) has been found to be the closest\nsolution to the real singular values of each group. Thus, WSNM can be\nequivalently transformed into a non-convex $\\ell_p$-norm minimization problem\nin group-based sparse coding. To make the proposed scheme tractable and robust,\nthe alternating direction method of multipliers (ADMM) is used to solve the\n$\\ell_p$-norm minimization problem. Experimental results on two applications:\nimage inpainting and image compressive sensing (CS) recovery have shown that\nthe proposed scheme outperforms many state-of-the-art methods.",
    "published_date": "2016-11-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.08983v12",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.08758v2",
    "title": "Variational inequality approach to enforce the non-negative constraint for advection-diffusion equations",
    "authors": [
      "J. Chang",
      "K. B. Nakshatrala"
    ],
    "author_ids": [],
    "abstract": "Predictive simulations are crucial for the success of many subsurface\napplications, and it is highly desirable to obtain accurate non-negative\nsolutions for transport equations in these numerical simulations. In this\npaper, we propose a computational framework based on the variational inequality\n(VI) which can also be used to enforce important mathematical properties (e.g.,\nmaximum principles) and physical constraints (e.g., the non-negative\nconstraint). We demonstrate that this framework is not only applicable to\ndiffusion equations but also to non-symmetric advection-diffusion equations. An\nattractive feature of the proposed framework is that it works with with any\nweak formulation for the advection-diffusion equations, including single-field\nformulations, which are computationally attractive. A particular emphasis is\nplaced on the parallel and algorithmic performance of the VI approach across\nlarge-scale and heterogeneous problems. It is also shown that QP and VI are\nequivalent under certain conditions. State-of-the-art QP and VI solvers\navailable from the PETSc library are used on a variety of steady-state 2D and\n3D benchmarks, and a comparative study on the scalability between the QP and VI\nsolvers is presented. We then extend the proposed framework to transient\nproblems by simulating the miscible displacement of fluids in a heterogeneous\nporous medium and illustrate the importance of enforcing maximum principles for\nthese types of coupled problems. Our numerical experiments indicate that VIs\nare indeed a viable approach for enforcing the maximum principles and the\nnon-negative constraint in a large-scale computing environment. Also provided\nare Firedrake project files as well as a discussion on the computer\nimplementation to help facilitate readers in understanding the proposed\nframework.",
    "published_date": "2016-11-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CE",
      "cs.NA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.08758v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.08483v1",
    "title": "On the Exponentially Weighted Aggregate with the Laplace Prior",
    "authors": [
      "Arnak S. Dalalyan",
      "Edwin Grappin",
      "Quentin Paris"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study the statistical behaviour of the Exponentially\nWeighted Aggregate (EWA) in the problem of high-dimensional regression with\nfixed design. Under the assumption that the underlying regression vector is\nsparse, it is reasonable to use the Laplace distribution as a prior. The\nresulting estimator and, specifically, a particular instance of it referred to\nas the Bayesian lasso, was already used in the statistical literature because\nof its computational convenience, even though no thorough mathematical analysis\nof its statistical properties was carried out. The present work fills this gap\nby establishing sharp oracle inequalities for the EWA with the Laplace prior.\nThese inequalities show that if the temperature parameter is small, the EWA\nwith the Laplace prior satisfies the same type of oracle inequality as the\nlasso estimator does, as long as the quality of estimation is measured by the\nprediction loss. Extensions of the proposed methodology to the problem of\nprediction with low-rank matrices are considered.",
    "published_date": "2016-11-25T00:00:00",
    "year": 2016,
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.08483v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.08292v2",
    "title": "Identifying Significant Predictive Bias in Classifiers",
    "authors": [
      "Zhe Zhang",
      "Daniel B. Neill"
    ],
    "author_ids": [],
    "abstract": "We present a novel subset scan method to detect if a probabilistic binary\nclassifier has statistically significant bias -- over or under predicting the\nrisk -- for some subgroup, and identify the characteristics of this subgroup.\nThis form of model checking and goodness-of-fit test provides a way to\ninterpretably detect the presence of classifier bias or regions of poor\nclassifier fit. This allows consideration of not just subgroups of a priori\ninterest or small dimensions, but the space of all possible subgroups of\nfeatures. To address the difficulty of considering these exponentially many\npossible subgroups, we use subset scan and parametric bootstrap-based methods.\nExtending this method, we can penalize the complexity of the detected subgroup\nand also identify subgroups with high classification errors. We demonstrate\nthese methods and find interesting results on the COMPAS crime recidivism and\ncredit delinquency data.",
    "published_date": "2016-11-24T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.08292v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.07509v1",
    "title": "A causal framework for discovering and removing direct and indirect discrimination",
    "authors": [
      "Lu Zhang",
      "Yongkai Wu",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Anti-discrimination is an increasingly important task in data science. In\nthis paper, we investigate the problem of discovering both direct and indirect\ndiscrimination from the historical data, and removing the discriminatory\neffects before the data is used for predictive analysis (e.g., building\nclassifiers). We make use of the causal network to capture the causal structure\nof the data. Then we model direct and indirect discrimination as the\npath-specific effects, which explicitly distinguish the two types of\ndiscrimination as the causal effects transmitted along different paths in the\nnetwork. Based on that, we propose an effective algorithm for discovering\ndirect and indirect discrimination, as well as an algorithm for precisely\nremoving both types of discrimination while retaining good data utility.\nDifferent from previous works, our approaches can ensure that the predictive\nmodels built from the modified data will not incur discrimination in decision\nmaking. Experiments using real datasets show the effectiveness of our\napproaches.",
    "published_date": "2016-11-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.07509v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.07438v1",
    "title": "Achieving non-discrimination in data release",
    "authors": [
      "Lu Zhang",
      "Yongkai Wu",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Discrimination discovery and prevention/removal are increasingly important\ntasks in data mining. Discrimination discovery aims to unveil discriminatory\npractices on the protected attribute (e.g., gender) by analyzing the dataset of\nhistorical decision records, and discrimination prevention aims to remove\ndiscrimination by modifying the biased data before conducting predictive\nanalysis. In this paper, we show that the key to discrimination discovery and\nprevention is to find the meaningful partitions that can be used to provide\nquantitative evidences for the judgment of discrimination. With the support of\nthe causal graph, we present a graphical condition for identifying a meaningful\npartition. Based on that, we develop a simple criterion for the claim of\nnon-discrimination, and propose discrimination removal algorithms which\naccurately remove discrimination while retaining good data utility. Experiments\nusing real datasets show the effectiveness of our approaches.",
    "published_date": "2016-11-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.07438v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.07238v1",
    "title": "Time and Space Optimal Counting in Population Protocols",
    "authors": [
      "James Aspnes",
      "Joffroy Beauquier",
      "Janna Burman",
      "Devan Sohier"
    ],
    "author_ids": [],
    "abstract": "This work concerns the general issue of combined optimality in terms of time\nand space complexity. In this context, we study the problem of (exact) counting\nresource-limited and passively mobile nodes in the model of population\nprotocols, in which the space complexity is crucial. The counted nodes are\nmemory-limited anonymous devices (called agents) communicating asynchronously\nin pairs (according to a fairness condition). Moreover, we assume that these\nagents are prone to failures so that they cannot be correctly initialized. This\nstudy considers two classical fairness conditions, and for each we investigate\nthe issue of time optimality of counting given the optimal space per agent. In\nthe case of randomly interacting agents (probabilistic fairness), as usual, the\nconvergence time is measured in terms of parallel time (or parallel\ninteractions), which is defined as the number of pairwise interactions until\nconvergence, divided by n (the number of agents). In case of weak fairness,\nwhere it is only required that every pair of agents interacts infinitely often,\nthe convergence time is defined in terms of non-null transitions, i.e, the\ntransitions that affect the states of the interacting agents.First, assuming\nprobabilistic fairness, we present a \"non-guessing\" time optimal protocol of\nO(n log n) expected time given an optimal space of only one bit, and we prove\nthe time optimality of this protocol. Then, for weak fairness, we show that a\nspace optimal (semi-uniform) solution cannot converge faster than in\n$\\Omega$(2^n) time (non-null transitions). This result, together with the time\ncomplexity analysis of an already known space optimal protocol, shows that it\nis also optimal in time (given the optimal space constrains).",
    "published_date": "2016-11-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.07238v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.06972v6",
    "title": "Measuring Sample Quality with Diffusions",
    "authors": [
      "Jackson Gorham",
      "Andrew B. Duncan",
      "Sebastian J. Vollmer",
      "Lester Mackey"
    ],
    "author_ids": [],
    "abstract": "Stein's method for measuring convergence to a continuous target distribution\nrelies on an operator characterizing the target and Stein factor bounds on the\nsolutions of an associated differential equation. While such operators and\nbounds are readily available for a diversity of univariate targets, few\nmultivariate targets have been analyzed. We introduce a new class of\ncharacterizing operators based on Ito diffusions and develop explicit\nmultivariate Stein factor bounds for any target with a fast-coupling Ito\ndiffusion. As example applications, we develop computable and\nconvergence-determining diffusion Stein discrepancies for log-concave,\nheavy-tailed, and multimodal targets and use these quality measures to select\nthe hyperparameters of biased Markov chain Monte Carlo (MCMC) samplers, compare\nrandom and deterministic quadrature rules, and quantify bias-variance tradeoffs\nin approximate MCMC. Our results establish a near-linear relationship between\ndiffusion Stein discrepancies and Wasserstein distances, improving upon past\nwork even for strongly log-concave targets. The exposed relationship between\nStein factors and Markov process coupling may be of independent interest.",
    "published_date": "2016-11-21T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "60J60, 62-04, 62E17, 60E15, 65C60 (Primary) 62-07, 65C05, 68T05\n  (Secondary)"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.06972v6",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.06589v2",
    "title": "Fair Division via Social Comparison",
    "authors": [
      "Rediet Abebe",
      "Jon Kleinberg",
      "David Parkes"
    ],
    "author_ids": [],
    "abstract": "In the classical cake cutting problem, a resource must be divided among\nagents with different utilities so that each agent believes they have received\na fair share of the resource relative to the other agents. We introduce a\nvariant of the problem in which we model an underlying social network on the\nagents with a graph, and agents only evaluate their shares relative to their\nneighbors' in the network. This formulation captures many situations in which\nit is unrealistic to assume a global view, and also exposes interesting\nphenomena in the original problem.\n  Specifically, we say an allocation is locally envy-free if no agent envies a\nneighbor's allocation and locally proportional if each agent values her own\nallocation as much as the average value of her neighbor's allocations, with the\nformer implying the latter. While global envy-freeness implies local\nenvy-freeness, global proportionality does not imply local proportionality, or\nvice versa. A general result is that for any two distinct graphs on the same\nset of nodes and an allocation, there exists a set of valuation functions such\nthat the allocation is locally proportional on one but not the other.\n  We fully characterize the set of graphs for which an oblivious single-cutter\nprotocol-- a protocol that uses a single agent to cut the cake into pieces\n--admits a bounded protocol with $O(n^2)$ query complexity for locally\nenvy-free allocations in the Robertson-Webb model. We also consider the price\nof envy-freeness, which compares the total utility of an optimal allocation to\nthe best utility of an allocation that is envy-free. We show that a lower bound\nof $\\Omega(\\sqrt{n})$ on the price of envy-freeness for global allocations in\nfact holds for local envy-freeness in any connected undirected graph. Thus,\nsparse graphs surprisingly do not provide more flexibility with respect to the\nquality of envy-free allocations.",
    "published_date": "2016-11-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.GT",
      "math.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.06589v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.06497v1",
    "title": "A Reinforcement Learning Approach to Power Control and Rate Adaptation in Cellular Networks",
    "authors": [
      "Euhanna Ghadimi",
      "Francesco Davide Calabrese",
      "Gunnar Peters",
      "Pablo Soldati"
    ],
    "author_ids": [],
    "abstract": "Optimizing radio transmission power and user data rates in wireless systems\nvia power control requires an accurate and instantaneous knowledge of the\nsystem model. While this problem has been extensively studied in the\nliterature, an efficient solution approaching optimality with the limited\ninformation available in practical systems is still lacking. This paper\npresents a reinforcement learning framework for power control and rate\nadaptation in the downlink of a radio access network that closes this gap. We\npresent a comprehensive design of the learning framework that includes the\ncharacterization of the system state, the design of a general reward function,\nand the method to learn the control policy. System level simulations show that\nour design can quickly learn a power control policy that brings significant\nenergy savings and fairness across users in the system.",
    "published_date": "2016-11-20T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.06497v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.06459v2",
    "title": "Gendered Conversation in a Social Game-Streaming Platform",
    "authors": [
      "Supun Nakandala",
      "Giovanni Luca Ciampaglia",
      "Norman Makoto Su",
      "Yong-Yeol Ahn"
    ],
    "author_ids": [],
    "abstract": "Online social media and games are increasingly replacing offline social\nactivities. Social media is now an indispensable mode of communication; online\ngaming is not only a genuine social activity but also a popular spectator\nsport. With support for anonymity and larger audiences, online interaction\nshrinks social and geographical barriers. Despite such benefits, social\ndisparities such as gender inequality persist in online social media. In\nparticular, online gaming communities have been criticized for persistent\ngender disparities and objectification. As gaming evolves into a social\nplatform, persistence of gender disparity is a pressing question. Yet, there\nare few large-scale, systematic studies of gender inequality and\nobjectification in social gaming platforms. Here we analyze more than one\nbillion chat messages from Twitch, a social game-streaming platform, to study\nhow the gender of streamers is associated with the nature of conversation.\nUsing a combination of computational text analysis methods, we show that\ngendered conversation and objectification is prevalent in chats. Female\nstreamers receive significantly more objectifying comments while male streamers\nreceive more game-related comments. This difference is more pronounced for\npopular streamers. There also exists a large number of users who post only on\nfemale or male streams. Employing a neural vector-space embedding (paragraph\nvector) method, we analyze gendered chat messages and create prediction models\nthat (i) identify the gender of streamers based on messages posted in the\nchannel and (ii) identify the gender a viewer prefers to watch based on their\nchat messages. Our findings suggest that disparities in social game-streaming\nplatforms is a nuanced phenomenon that involves the gender of streamers as well\nas those who produce gendered and game-related conversation.",
    "published_date": "2016-11-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.CL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.06459v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.05915v1",
    "title": "Generative One-Class Models for Text-based Person Retrieval in Forensic Applications",
    "authors": [
      "David Gerónimo",
      "Hedvig Kjellström"
    ],
    "author_ids": [],
    "abstract": "Automatic forensic image analysis assists criminal investigation experts in\nthe search for suspicious persons, abnormal behaviors detection and identity\nmatching in images. In this paper we propose a person retrieval system that\nuses textual queries (e.g., \"black trousers and green shirt\") as descriptions\nand a one-class generative color model with outlier filtering to represent the\nimages both to train the models and to perform the search. The method is\nevaluated in terms of its efficiency in fulfilling the needs of a forensic\nretrieval system: limited annotation, robustness, extensibility, adaptability\nand computational cost. The proposed generative method is compared to a\ncorresponding discriminative approach. Experiments are carried out using a\nrange of queries in three different databases. The experiments show that the\ntwo evaluated algorithms provide average retrieval performance and adaptable to\nnew datasets. The proposed generative algorithm has some advantages over the\ndiscriminative one, specifically its capability to work with very few training\nsamples and its much lower computational requirements when the number of\ntraining examples increases.",
    "published_date": "2016-11-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.05915v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.05080v2",
    "title": "Neural stochastic codes, encoding and decoding",
    "authors": [
      "Hugo Gabriel Eyherabide"
    ],
    "author_ids": [],
    "abstract": "Understanding brain function, constructing computational models and\nengineering neural prosthetics require assessing two problems, namely encoding\nand decoding, but their relation remains controversial. For decades, the\nencoding problem has been shown to provide insight into the decoding problem,\nfor example, by upper bounding the decoded information. However, here we show\nthat this need not be the case when studying response aspects beyond noise\ncorrelations, and trace back the actual causes of this major departure from\ntraditional views. To that end, we reformulate the encoding and decoding\nproblems from the observer or organism perspective. In addition, we study the\nrole of spike-time precision and response discrimination, among other response\naspects, using stochastic transformations of the neural responses, here called\nstochastic codes. Our results show that stochastic codes may cause different\ninformation losses when used to describe neural responses and when employed to\ntrain optimal decoders. Therefore, we conclude that response aspects beyond\nnoise correlations may play different roles in encoding and decoding. In\npractice, our results show for the first time that decoders constructed\nlow-quality descriptions of response aspects may operate optimally on\nhigh-quality descriptions and vice versa, thereby potentially yielding\nexperimental and computational savings, as well as new opportunities for\nsimplifying the design of computational brain models and neural prosthetics.",
    "published_date": "2016-11-15T00:00:00",
    "year": 2016,
    "categories": [
      "q-bio.NC",
      "cs.IT",
      "math.IT",
      "q-bio.QM",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.05080v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.04967v1",
    "title": "Iterative Orthogonal Feature Projection for Diagnosing Bias in Black-Box Models",
    "authors": [
      "Julius Adebayo",
      "Lalana Kagal"
    ],
    "author_ids": [],
    "abstract": "Predictive models are increasingly deployed for the purpose of determining\naccess to services such as credit, insurance, and employment. Despite potential\ngains in productivity and efficiency, several potential problems have yet to be\naddressed, particularly the potential for unintentional discrimination. We\npresent an iterative procedure, based on orthogonal projection of input\nattributes, for enabling interpretability of black-box predictive models.\nThrough our iterative procedure, one can quantify the relative dependence of a\nblack-box model on its input attributes.The relative significance of the inputs\nto a predictive model can then be used to assess the fairness (or\ndiscriminatory extent) of such a model.",
    "published_date": "2016-11-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.04967v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.04921v3",
    "title": "Gaussian mixtures: entropy and geometric inequalities",
    "authors": [
      "Alexandros Eskenazis",
      "Piotr Nayar",
      "Tomasz Tkocz"
    ],
    "author_ids": [],
    "abstract": "A symmetric random variable is called a Gaussian mixture if it has the same\ndistribution as the product of two independent random variables, one being\npositive and the other a standard Gaussian random variable. Examples of\nGaussian mixtures include random variables with densities proportional to\n$e^{-|t|^p}$ and symmetric $p$-stable random variables, where $p\\in(0,2]$. We\nobtain various sharp moment and entropy comparison estimates for weighted sums\nof independent Gaussian mixtures and investigate extensions of the B-inequality\nand the Gaussian correlation inequality in the context of Gaussian mixtures. We\nalso obtain a correlation inequality for symmetric geodesically convex sets in\nthe unit sphere equipped with the normalized surface area measure. We then\napply these results to derive sharp constants in Khintchine inequalities for\nvectors uniformly distributed on the unit balls with respect to $p$-norms and\nprovide short proofs to new and old comparison estimates for geometric\nparameters of sections and projections of such balls.",
    "published_date": "2016-11-15T00:00:00",
    "year": 2016,
    "categories": [
      "math.PR",
      "cs.IT",
      "math.FA",
      "math.IT",
      "math.MG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.04921v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.04278v1",
    "title": "Revisiting 802.11 for User Fairness and Efficient Channel Utilization in Presence of LTE-U",
    "authors": [
      "Anand M. Baswade",
      "Touheed Anwar Atif",
      "Bheemarjuna Reddy Tamma",
      "Antony Franklin A"
    ],
    "author_ids": [],
    "abstract": "A promising solution satisfying the industry's demand to have minimum\nalterations in LTE for its operation in unlicensed spectrum is duty cycled\nLTE-U scheme, which adopts discontinuous transmission to ensure fair\ncoexistence with 802.11 (Wi-Fi) WLANs. Even though the scheme guarantees to\nmaintain Wi-Fi network performance, the fairness among Wi-Fi users still\nremains arcane. In this work, we present a practical scenario where LTE-U,\ndespite being discontinuous (by following an ON-OFF cycle), results in not only\nunfair throughput distribution among Wi-Fi users but also causes degradation in\nWi-Fi APs downlink performance. This is due to the domination of few Wi-Fi\nusers who harness channel in both ON and OFF durations of LTE-U, namely\nnon-victim users over those who get access only in OFF duration, called victim\nusers. In this paper, we studied the performance of victim and non-victim Wi-Fi\nusers, and Wi-Fi AP while varying LTE-U ON duration (i.e., duty cycle). A\npropitious scheme is proposed for WLANs, with regard to ease of implementation,\nemploying Point Coordination Function (PCF) mode of 802.11, promising fairness\namong Wi-Fi users with improvement in the channel utilization of Wi-Fi network.\nAn analytical model is developed to demonstrate guaranteed improvement and\nvalidate the simulation results.",
    "published_date": "2016-11-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.04278v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.04034v2",
    "title": "Fair Public Decision Making",
    "authors": [
      "Vincent Conitzer",
      "Rupert Freeman",
      "Nisarg Shah"
    ],
    "author_ids": [],
    "abstract": "We generalize the classic problem of fairly allocating indivisible goods to\nthe problem of \\emph{fair public decision making}, in which a decision must be\nmade on several social issues simultaneously, and, unlike the classic setting,\na decision can provide positive utility to multiple players. We extend the\npopular fairness notion of proportionality (which is not guaranteeable) to our\nmore general setting, and introduce three novel relaxations ---\n\\emph{proportionality up to one issue, round robin share, and pessimistic\nproportional share} --- that are also interesting in the classic goods\nallocation setting. We show that the Maximum Nash Welfare solution, which is\nknown to satisfy appealing fairness properties in the classic setting,\nsatisfies or approximates all three relaxations in our framework. We also\nprovide polynomial time algorithms and hardness results for finding allocations\nsatisfying these axioms, with or without insisting on Pareto optimality.",
    "published_date": "2016-11-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.04034v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.03852v3",
    "title": "A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models",
    "authors": [
      "Chelsea Finn",
      "Paul Christiano",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "author_ids": [],
    "abstract": "Generative adversarial networks (GANs) are a recently proposed class of\ngenerative models in which a generator is trained to optimize a cost function\nthat is being simultaneously learned by a discriminator. While the idea of\nlearning cost functions is relatively new to the field of generative modeling,\nlearning costs has long been studied in control and reinforcement learning (RL)\ndomains, typically for imitation learning from demonstrations. In these fields,\nlearning cost function underlying observed behavior is known as inverse\nreinforcement learning (IRL) or inverse optimal control. While at first the\nconnection between cost learning in RL and cost learning in generative modeling\nmay appear to be a superficial one, we show in this paper that certain IRL\nmethods are in fact mathematically equivalent to GANs. In particular, we\ndemonstrate an equivalence between a sample-based algorithm for maximum entropy\nIRL and a GAN in which the generator's density can be evaluated and is provided\nas an additional input to the discriminator. Interestingly, maximum entropy IRL\nis a special case of an energy-based model. We discuss the interpretation of\nGANs as an algorithm for training energy-based models, and relate this\ninterpretation to other recent work that seeks to connect GANs and EBMs. By\nformally highlighting the connection between GANs, IRL, and EBMs, we hope that\nresearchers in all three communities can better identify and apply transferable\nideas from one domain to another, particularly for developing more stable and\nscalable algorithms: a major challenge in all three domains.",
    "published_date": "2016-11-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.03852v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.03071v4",
    "title": "Fairness in Reinforcement Learning",
    "authors": [
      "Shahin Jabbari",
      "Matthew Joseph",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "We initiate the study of fairness in reinforcement learning, where the\nactions of a learning algorithm may affect its environment and future rewards.\nOur fairness constraint requires that an algorithm never prefers one action\nover another if the long-term (discounted) reward of choosing the latter action\nis higher. Our first result is negative: despite the fact that fairness is\nconsistent with the optimal policy, any learning algorithm satisfying fairness\nmust take time exponential in the number of states to achieve non-trivial\napproximation to the optimal policy. We then provide a provably fair polynomial\ntime algorithm under an approximate notion of fairness, thus establishing an\nexponential gap between exact and approximate fairness",
    "published_date": "2016-11-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.03071v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.02512v1",
    "title": "Cognitive Discriminative Mappings for Rapid Learning",
    "authors": [
      "Wen-Chieh Fang",
      "Yi-ting Chiang"
    ],
    "author_ids": [],
    "abstract": "Humans can learn concepts or recognize items from just a handful of examples,\nwhile machines require many more samples to perform the same task. In this\npaper, we build a computational model to investigate the possibility of this\nkind of rapid learning. The proposed method aims to improve the learning task\nof input from sensory memory by leveraging the information retrieved from\nlong-term memory. We present a simple and intuitive technique called cognitive\ndiscriminative mappings (CDM) to explore the cognitive problem. First, CDM\nseparates and clusters the data instances retrieved from long-term memory into\ndistinct classes with a discrimination method in working memory when a sensory\ninput triggers the algorithm. CDM then maps each sensory data instance to be as\nclose as possible to the median point of the data group with the same class.\nThe experimental results demonstrate that the CDM approach is effective for\nlearning the discriminative features of supervised classifications with few\ntraining sensory input instances.",
    "published_date": "2016-11-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.02512v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.02401v7",
    "title": "Divide and Conquer Networks",
    "authors": [
      "Alex Nowak-Vila",
      "David Folqué",
      "Joan Bruna"
    ],
    "author_ids": [],
    "abstract": "We consider the learning of algorithmic tasks by mere observation of\ninput-output pairs. Rather than studying this as a black-box discrete\nregression problem with no assumption whatsoever on the input-output mapping,\nwe concentrate on tasks that are amenable to the principle of divide and\nconquer, and study what are its implications in terms of learning. This\nprinciple creates a powerful inductive bias that we leverage with neural\narchitectures that are defined recursively and dynamically, by learning two\nscale-invariant atomic operations: how to split a given input into smaller\nsets, and how to merge two partially solved tasks into a larger partial\nsolution. Our model can be trained in weakly supervised environments, namely by\njust observing input-output pairs, and in even weaker environments, using a\nnon-differentiable reward signal. Moreover, thanks to the dynamic aspect of our\narchitecture, we can incorporate the computational complexity as a\nregularization term that can be optimized by backpropagation. We demonstrate\nthe flexibility and efficiency of the Divide-and-Conquer Network on several\ncombinatorial and geometric tasks: convex hull, clustering, knapsack and\neuclidean TSP. Thanks to the dynamic programming nature of our model, we show\nsignificant improvements in terms of generalization error and computational\ncomplexity.",
    "published_date": "2016-11-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.02401v7",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.01965v1",
    "title": "Relations Between Work and Entropy Production for General Information-Driven, Finite-State Engines",
    "authors": [
      "Neri Merhav"
    ],
    "author_ids": [],
    "abstract": "We consider a system model of a general finite-state machine (ratchet) that\nsimultaneously interacts with three kinds of reservoirs: a heat reservoir, a\nwork reservoir, and an information reservoir, the latter being taken to be a\nrunning digital tape whose symbols interact sequentially with the machine. As\nhas been shown in earlier work, this finite-state machine can act as a demon\n(with memory), which creates a net flow of energy from the heat reservoir into\nthe work reservoir (thus extracting useful work) at the price of increasing the\nentropy of the information reservoir. Under very few assumptions, we propose a\nsimple derivation of a family of inequalities that relate the work extraction\nwith the entropy production. These inequalities can be seen as either upper\nbounds on the extractable work or as lower bounds on the entropy production,\ndepending on the point of view. Many of these bounds are relatively easy to\ncalculate and they are tight in the sense that equality can be approached\narbitrarily closely. In their basic forms, these inequalities are applicable to\nany finite number of cycles (and not only asymptotically), and for a general\ninput information sequence (possibly correlated), which is not necessarily\nassumed even stationary. Several known results are obtained as special cases.",
    "published_date": "2016-11-07T00:00:00",
    "year": 2016,
    "categories": [
      "cond-mat.stat-mech",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.01965v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.01947v3",
    "title": "SPECTRA -- a Maple library for solving linear matrix inequalities in exact arithmetic",
    "authors": [
      "Mohab Safey El Din",
      "Didier Henrion",
      "Simone Naldi",
      "Mohab Safey",
      "El Din"
    ],
    "author_ids": [],
    "abstract": "This document describes our freely distributed Maple library {\\sc spectra},\nfor Semidefinite Programming solved Exactly with Computational Tools of Real\nAlgebra. It solves linear matrix inequalities with symbolic computation in\nexact arithmetic and it is targeted to small-size, possibly degenerate problems\nfor which symbolic infeasibility or feasibility certificates are required.",
    "published_date": "2016-11-07T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SC",
      "math.AG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.01947v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.01817v1",
    "title": "Exploring the Pathways of Adaptation an Avatar 3D Animation Procedures and Virtual Reality Arenas in Research of Human Courtship Behaviour and Sexual Reactivity in Psychological Research",
    "authors": [
      "Jakub Binter",
      "Kateřina Klapilová",
      "Tereza Zikánová",
      "Tommy Nilsson",
      "Klára Bártová",
      "Lucie Krejcová",
      "Renata Androvicová",
      "Jitka Lindová",
      "Denisa Prušová",
      "Timothy Wells",
      "Daniel Riha"
    ],
    "author_ids": [],
    "abstract": "There are many reasons for utilising 3D animation and virtual reality in\nsexuality research. Apart from providing a mean with which to (re)experience\ncertain situations there are four main advantages: a) bespoke animated stimuli\ncan be created and customized, which is especially important when researching\nparaphilia and sexual preferences, b) stimulus production is less expensive and\neasier to produce compared to real world stimuli, c) virtual reality allows us\nto capture data such as physiological reasons to stimuli, that we would not be\nable to otherwise (without resorting to self-report measures which are\nespecially problematic in this research domain), d) ethical, legal, and health\nand safety issues are less complex since neither physical nor psychological\nharm is caused to animated characters allowing for the safe presentation of\nstimuli involving vulnerable targets. The animation sub-group has been\nexploring so far several production quality levels and various animation\nprocedures in a number of available software. The aim is to develop static as\nwell as dynamic, interactive sexual stimuli for sexual diagnostic and\ntherapeutic purposes. We are aware of number of ethical issues related to the\nuse of virtual reality in proposed research are analysed in this chapter.",
    "published_date": "2016-11-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.01817v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.01607v2",
    "title": "Non-Orthogonal Multiple Access in Multi-Cell Networks: Theory, Performance, and Practical Challenges",
    "authors": [
      "Wonjae Shin",
      "Mojtaba Vaezi",
      "Byungju Lee",
      "David J. Love",
      "Jungwoo Lee",
      "H. Vincent Poor"
    ],
    "author_ids": [],
    "abstract": "Non-orthogonal multiple access (NOMA) is a potential enabler for the\ndevelopment of 5G and beyond wireless networks. By allowing multiple users to\nshare the same time and frequency, NOMA can scale up the number of served\nusers, increase the spectral efficiency, and improve user-fairness compared to\nexisting orthogonal multiple access (OMA) techniques. While single-cell NOMA\nhas drawn significant attention recently, much less attention has been given to\nmulti-cell NOMA. This article discusses the opportunities and challenges of\nNOMA in a multi-cell environment. As the density of base stations and devices\nincreases, inter-cell interference becomes a major obstacle in multi-cell\nnetworks. As such, identifying techniques that combine interference management\napproaches with NOMA is of great significance. After discussing the theory\nbehind NOMA, this paper provides an overview of the current literature and\ndiscusses key implementation and research challenges, with an emphasis on\nmulti-cell NOMA.",
    "published_date": "2016-11-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.01607v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.01335v1",
    "title": "Phi-Entropic Measures of Correlation",
    "authors": [
      "Salman Beigi",
      "Amin Gohari"
    ],
    "author_ids": [],
    "abstract": "A measure of correlation is said to have the tensorization property if it is\nunchanged when computed for i.i.d.\\ copies. More precisely, a measure of\ncorrelation between two random variables $(X, Y)$ denoted by $\\rho(X, Y)$, has\nthe tensorization property if $\\rho(X^n, Y^n)=\\rho(X, Y)$ where $(X^n, Y^n)$ is\n$n$ i.i.d.\\ copies of $(X, Y)$.Two well-known examples of such measures are the\nmaximal correlation and the hypercontractivity ribbon (HC~ribbon). We show that\nthe maximal correlation and HC ribbons are special cases of $\\Phi$-ribbon,\ndefined in this paper for any function $\\Phi$ from a class of convex functions\n($\\Phi$-ribbon reduces to HC~ribbon and the maximal correlation for special\nchoices of $\\Phi$). Any $\\Phi$-ribbon is shown to be a measures of correlation\nwith the tensorization property. We show that the $\\Phi$-ribbon also\ncharacterizes the $\\Phi$-strong data processing inequality constant introduced\nby Raginsky. We further study the $\\Phi$-ribbon for the choice of $\\Phi(t)=t^2$\nand introduce an equivalent characterization of this ribbon.",
    "published_date": "2016-11-04T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.01335v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.00962v1",
    "title": "Multitask Protein Function Prediction Through Task Dissimilarity",
    "authors": [
      "Marco Frasca",
      "Nicolò Cesa Bianchi"
    ],
    "author_ids": [],
    "abstract": "Automated protein function prediction is a challenging problem with\ndistinctive features, such as the hierarchical organization of protein\nfunctions and the scarcity of annotated proteins for most biological functions.\nWe propose a multitask learning algorithm addressing both issues. Unlike\nstandard multitask algorithms, which use task (protein functions) similarity\ninformation as a bias to speed up learning, we show that dissimilarity\ninformation enforces separation of rare class labels from frequent class\nlabels, and for this reason is better suited for solving unbalanced protein\nfunction prediction problems. We support our claim by showing that a multitask\nextension of the label propagation algorithm empirically works best when the\ntask relatedness information is represented using a dissimilarity matrix as\nopposed to a similarity matrix. Moreover, the experimental comparison carried\nout on three model organism shows that our method has a more stable performance\nin both \"protein-centric\" and \"function-centric\" evaluation settings.",
    "published_date": "2016-11-03T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-bio.QM",
      "68Q01",
      "I.5; J.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00962v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.00910v2",
    "title": "Task-driven sampling of attributed networks",
    "authors": [
      "Suhansanu Kumar",
      "Hari Sundaram"
    ],
    "author_ids": [],
    "abstract": "This paper introduces new techniques for sampling attributed networks to\nsupport standard Data Mining tasks. The problem is important for two reasons.\nFirst, it is commonplace to perform data mining tasks such as clustering and\nclassification of network attributes (attributes of the nodes, including social\nmedia posts). Furthermore, the extraordinarily large size of real-world\nnetworks necessitates that we work with a smaller graph sample. Second, while\nrandom sampling will provide an unbiased estimate of content, random access is\noften unavailable for many networks. Hence, network samplers such as Snowball\nsampling, Forest Fire, Random Walk, Metropolis-Hastings Random Walk are widely\nused; however, these attribute-agnostic samplers were designed to capture\nsalient properties of network structure, not node content. The latter is\ncritical for clustering and classification tasks. There are three contributions\nof this paper. First, we introduce several attribute-aware samplers based on\nInformation Theoretic principles. Second, we prove that these samplers have a\nbias towards capturing new content, and are equivalent to uniform sampling in\nthe limit. Finally, our experimental results over large real-world datasets and\nsynthetic benchmarks are insightful: attribute-aware samplers outperform both\nrandom sampling and baseline attribute-agnostic samplers by a wide margin in\nclustering and classification tasks.",
    "published_date": "2016-11-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "H.2.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00910v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.00483v2",
    "title": "Detecting Context Dependent Messages in a Conversational Environment",
    "authors": [
      "Chaozhuo Li",
      "Yu Wu",
      "Wei Wu",
      "Chen Xing",
      "Zhoujun Li",
      "Ming Zhou"
    ],
    "author_ids": [],
    "abstract": "While automatic response generation for building chatbot systems has drawn a\nlot of attention recently, there is limited understanding on when we need to\nconsider the linguistic context of an input text in the generation process. The\ntask is challenging, as messages in a conversational environment are short and\ninformal, and evidence that can indicate a message is context dependent is\nscarce. After a study of social conversation data crawled from the web, we\nobserved that some characteristics estimated from the responses of messages are\ndiscriminative for identifying context dependent messages. With the\ncharacteristics as weak supervision, we propose using a Long Short Term Memory\n(LSTM) network to learn a classifier. Our method carries out text\nrepresentation and classifier learning in a unified framework. Experimental\nresults show that the proposed method can significantly outperform baseline\nmethods on accuracy of classification.",
    "published_date": "2016-11-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00483v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.00447v1",
    "title": "Bots as Virtual Confederates: Design and Ethics",
    "authors": [
      "Peter M Krafft",
      "Michael Macy",
      "Alex Pentland"
    ],
    "author_ids": [],
    "abstract": "The use of bots as virtual confederates in online field experiments holds\nextreme promise as a new methodological tool in computational social science.\nHowever, this potential tool comes with inherent ethical challenges. Informed\nconsent can be difficult to obtain in many cases, and the use of confederates\nnecessarily implies the use of deception. In this work we outline a design\nspace for bots as virtual confederates, and we propose a set of guidelines for\nmeeting the status quo for ethical experimentation. We draw upon examples from\nprior work in the CSCW community and the broader social science literature for\nillustration. While a handful of prior researchers have used bots in online\nexperimentation, our work is meant to inspire future work in this area and\nraise awareness of the associated ethical issues.",
    "published_date": "2016-11-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.SI",
      "physics.soc-ph",
      "J.4; K.4.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00447v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1611.00404v2",
    "title": "Per-Server Dominant-Share Fairness (PS-DSF): A Multi-Resource Fair Allocation Mechanism for Heterogeneous Servers",
    "authors": [
      "Jalal Khamse-Ashari",
      "Ioannis Lambadaris",
      "George Kesidis",
      "Bhuvan Urgaonkar",
      "Yiqiang Zhao"
    ],
    "author_ids": [],
    "abstract": "Users of cloud computing platforms pose different types of demands for\nmultiple resources on servers (physical or virtual machines). Besides\ndifferences in their resource capacities, servers may be additionally\nheterogeneous in their ability to service users - certain users' tasks may only\nbe serviced by a subset of the servers. We identify important shortcomings in\nexisting multi-resource fair allocation mechanisms - Dominant Resource Fairness\n(DRF) and its follow up work - when used in such environments. We develop a new\nfair allocation mechanism called Per-Server Dominant-Share Fairness (PS-DSF)\nwhich we show offers all desirable sharing properties that DRF is able to offer\nin the case of a single \"resource pool\" (i.e., if the resources of all servers\nwere pooled together into one hypothetical server). We evaluate the performance\nof PS-DSF through simulations. Our evaluation shows the enhanced efficiency of\nPS-DSF compared to the existing allocation mechanisms. We argue how our\nproposed allocation mechanism is applicable in cloud computing networks and\nespecially large scale data-centers.",
    "published_date": "2016-11-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00404v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.00024v3",
    "title": "Symmetry, Outer Bounds, and Code Constructions: A Computer-Aided Investigation on the Fundamental Limits of Caching",
    "authors": [
      "Chao Tian"
    ],
    "author_ids": [],
    "abstract": "We illustrate how computer-aided methods can be used to investigate the\nfundamental limits of the caching systems, which are significantly different\nfrom the conventional analytical approach usually seen in the information\ntheory literature. The linear programming (LP) outer bound of the entropy space\nserves as the starting point of this approach; however, our effort goes\nsignificantly beyond using it to prove information inequalities. We first\nidentify and formalize the symmetry structure in the problem, which enables us\nto show the existence of optimal symmetric solutions. A symmetry-reduced linear\nprogram is then used to identify the boundary of the memory-transmission-rate\ntradeoff for several small cases, for which we obtain a set of tight outer\nbounds. General hypotheses on the optimal tradeoff region are formed from these\ncomputed data, which are then analytically proven. This leads to a complete\ncharacterization of the optimal tradeoff for systems with only two users, and\ncertain partial characterization for systems with only two files. Next, we show\nthat by carefully analyzing the joint entropy structure of the outer bounds for\ncertain cases, a novel code construction can be reverse-engineered, which\neventually leads to a general class of codes. Finally, we show that outer\nbounds can be computed through strategically relaxing the LP in different ways,\nwhich can be used to explore the problem computationally. This allows us\nfirstly to deduce generic characteristic of the converse proof, and secondly to\ncompute outer bounds for larger problem cases, despite the seemingly impossible\ncomputation scale.",
    "published_date": "2016-10-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.00024v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1611.07824v1",
    "title": "SimAthens: A spatial microsimulation approach to the estimation and analysis of small-area income distributions and poverty rates in Athens, Greece",
    "authors": [
      "Anastasia Panori",
      "Dimitris Ballas",
      "Yannis Psycharis"
    ],
    "author_ids": [],
    "abstract": "Published during a severe economic crisis, this study presents the first\nspatial microsimulation model for the analysis of income inequalities and\npoverty in Greece. First, we present a brief overview of the method and discuss\nits potential for the analysis of multidimensional poverty and income\ninequality in Greece. We then present the SimAthens model, based on a\ncombination of small-area demographic and socioeconomic information available\nfrom the Greek census of population with data from the European Union\nStatistics on Income and Living Conditions (EU-SILC). The model is based on an\niterative proportional fitting (IPF) algorithm, and is used to reweigh EU-SILC\nrecords to fit in small-area descriptions for Athens based on 2001 and 2011\ncensuses. This is achieved by using demographic and socioeconomic\ncharacteristics as constraint variables. Finally, synthesis of the labor market\nand occupations are chosen as the main variables for externally validating our\nresults, in order to verify the integrity of the model. Results of this\nexternal validation process are found to be extremely satisfactory, indicating\na high goodness of fit between simulated and real values. Finally, the study\npresents a number of model outputs, illustrating changes in social and economic\ngeography, during a severe economic crisis, offering a great opportunity for\ndiscussing further potential of this model in policy analysis.",
    "published_date": "2016-10-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.MA",
      "62P25"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.07824v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.09312v1",
    "title": "User Cooperation for Enhanced Throughput Fairness in Wireless Powered Communication Networks",
    "authors": [
      "Mingquan Zhong",
      "Suzhi Bi",
      "Xiaohui Lin"
    ],
    "author_ids": [],
    "abstract": "This paper studies a novel user cooperation method in a wireless powered\ncooperative communication network (WPCN) in which a pair of distributed\nterminal users first harvest wireless energy broadcasted by one energy node\n(EN) and then use the harvested energy to transmit information to a destination\nnode (DN). In particular, the two cooperating users exchange their independent\ninformation with each other so as to form a virtual antenna array and transmit\njointly to the DN. By allowing the users to share their harvested energy to\ntransmit each other's information, the proposed method can effectively mitigate\nthe inherent user unfairness problem in WPCN, where one user may suffer from\nvery low data rate due to poor energy harvesting performance and high data\ntransmission consumptions. Depending on the availability of channel state\ninformation at the transmitters, we consider the two users cooperating using\neither coherent or non-coherent data transmissions. In both cases, we derive\nthe maximum common throughput achieved by the cooperation schemes through\noptimizing the time allocation on wireless energy transfer, user message\nexchange, and joint information transmissions in a fixed-length time slot. We\nalso perform numerical analysis to study the impact of channel conditions on\nthe system performance. By comparing with some existing benchmark schemes, our\nresults demonstrate the effectiveness of the proposed user cooperation in a\nWPCN under different application scenarios.",
    "published_date": "2016-10-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.09312v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.09110v1",
    "title": "$f$-Divergence Inequalities via Functional Domination",
    "authors": [
      "Igal Sason",
      "Sergio Verdú"
    ],
    "author_ids": [],
    "abstract": "This paper considers derivation of $f$-divergence inequalities via the\napproach of functional domination. Bounds on an $f$-divergence based on one or\nseveral other $f$-divergences are introduced, dealing with pairs of probability\nmeasures defined on arbitrary alphabets. In addition, a variety of bounds are\nshown to hold under boundedness assumptions on the relative information. The\njournal paper, which includes more approaches for the derivation of\nf-divergence inequalities and proofs, is available on the arXiv at\nhttps://arxiv.org/abs/1508.00335, and it has been published in the IEEE Trans.\non Information Theory, vol. 62, no. 11, pp. 5973-6006, November 2016.",
    "published_date": "2016-10-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.PR",
      "math.ST",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.09110v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.08984v1",
    "title": "Quantitative Evaluation of Gender Bias in Astronomical Publications from Citation Counts",
    "authors": [
      "Neven Caplar",
      "Sandro Tacchella",
      "Simon Birrer"
    ],
    "author_ids": [],
    "abstract": "We analyze the role of first (leading) author gender on the number of\ncitations that a paper receives, on the publishing frequency and on the\nself-citing tendency. We consider a complete sample of over 200,000\npublications from 1950 to 2015 from five major astronomy journals. We determine\nthe gender of the first author for over 70% of all publications. The fraction\nof papers which have a female first author has increased from less than 5% in\nthe 1960s to about 25% today. We find that the increase of the fraction of\npapers authored by females is slowest in the most prestigious journals such as\nScience and Nature. Furthermore, female authors write 19$\\pm$7% fewer papers in\nseven years following their first paper than their male colleagues. At all\ntimes papers with male first authors receive more citations than papers with\nfemale first authors. This difference has been decreasing with time and amounts\nto $\\sim$6% measured over the last 30 years. To account for the fact that the\nproperties of female and male first author papers differ intrinsically, we use\na random forest algorithm to control for the non-gender specific properties of\nthese papers which include seniority of the first author, number of references,\ntotal number of authors, year of publication, publication journal, field of\nstudy and region of the first author's institution. We show that papers\nauthored by females receive 10.4$\\pm$0.9% fewer citations than what would be\nexpected if the papers with the same non-gender specific properties were\nwritten by the male authors. Finally, we also find that female authors in our\nsample tend to self-cite more, but that this effect disappears when controlled\nfor non-gender specific variables.",
    "published_date": "2016-10-27T00:00:00",
    "year": 2016,
    "categories": [
      "astro-ph.IM",
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08984v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.08629v1",
    "title": "The Promise and Prejudice of Big Data in Intelligence Community",
    "authors": [
      "Karan Jani"
    ],
    "author_ids": [],
    "abstract": "Big data holds critical importance in the current generation of information\ntechnology, with applications ranging from financial, industrial, academic to\ndefense sectors. With the exponential rise of open source data from social\nmedia and increasing government monitoring, big data is now also linked with\nnational security, and subsequently to the intelligence community. In this\nstudy I review the scope of big data sciences in the functioning of\nintelligence community. The major part of my study focuses on the inherent\nlimitations of big data, which affects the intelligence agencies from gathering\nof information to anticipating surprises. The limiting factors range from\ntechnical to ethical issues connected with big data. My study concludes the\nneed of experts with domain knowledge from intelligence community to\nefficiently guide big data analysis for timely filling the knowledge gaps. As a\ncase study on limitations of using big data, I narrate some of the ongoing work\nin nuclear intelligence using simple analytics and argue on why big data\nanalysis in that case would lead to unnecessary complications. For further\ninvestigation, I highlight cases of crowdsource forecasting tournaments and\npredicting unrest from social media.",
    "published_date": "2016-10-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08629v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.08606v3",
    "title": "Fast Low-rank Shared Dictionary Learning for Image Classification",
    "authors": [
      "Tiep Vu",
      "Vishal Monga"
    ],
    "author_ids": [],
    "abstract": "Despite the fact that different objects possess distinct class-specific\nfeatures, they also usually share common patterns. This observation has been\nexploited partially in a recently proposed dictionary learning framework by\nseparating the particularity and the commonality (COPAR). Inspired by this, we\npropose a novel method to explicitly and simultaneously learn a set of common\npatterns as well as class-specific features for classification with more\nintuitive constraints. Our dictionary learning framework is hence characterized\nby both a shared dictionary and particular (class-specific) dictionaries. For\nthe shared dictionary, we enforce a low-rank constraint, i.e. claim that its\nspanning subspace should have low dimension and the coefficients corresponding\nto this dictionary should be similar. For the particular dictionaries, we\nimpose on them the well-known constraints stated in the Fisher discrimination\ndictionary learning (FDDL). Further, we develop new fast and accurate\nalgorithms to solve the subproblems in the learning step, accelerating its\nconvergence. The said algorithms could also be applied to FDDL and its\nextensions. The efficiencies of these algorithms are theoretically and\nexperimentally verified by comparing their complexities and running time with\nthose of other well-known dictionary learning methods. Experimental results on\nwidely used image datasets establish the advantages of our method over\nstate-of-the-art dictionary learning methods.",
    "published_date": "2016-10-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08606v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.08559v1",
    "title": "Measuring Fairness in Ranked Outputs",
    "authors": [
      "Ke Yang",
      "Julia Stoyanovich"
    ],
    "author_ids": [],
    "abstract": "Ranking and scoring are ubiquitous. We consider the setting in which an\ninstitution, called a ranker, evaluates a set of individuals based on\ndemographic, behavioral or other characteristics. The final output is a ranking\nthat represents the relative quality of the individuals. While automatic and\ntherefore seemingly objective, rankers can, and often do, discriminate against\nindividuals and systematically disadvantage members of protected groups. This\nwarrants a careful study of the fairness of a ranking scheme.\n  In this paper we propose fairness measures for ranked outputs. We develop a\ndata generation procedure that allows us to systematically control the degree\nof unfairness in the output, and study the behavior of our measures on these\ndatasets. We then apply our proposed measures to several real datasets, and\ndemonstrate cases of unfairness. Finally, we show preliminary results of\nincorporating our ranked fairness measures into an optimization framework, and\nshow potential for improving fairness of ranked outputs while maintaining\naccuracy.",
    "published_date": "2016-10-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DB"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08559v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.08452v2",
    "title": "Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment",
    "authors": [
      "Muhammad Bilal Zafar",
      "Isabel Valera",
      "Manuel Gomez Rodriguez",
      "Krishna P. Gummadi"
    ],
    "author_ids": [],
    "abstract": "Automated data-driven decision making systems are increasingly being used to\nassist, or even replace humans in many settings. These systems function by\nlearning from historical decisions, often taken by humans. In order to maximize\nthe utility of these systems (or, classifiers), their training involves\nminimizing the errors (or, misclassifications) over the given historical data.\nHowever, it is quite possible that the optimally trained classifier makes\ndecisions for people belonging to different social groups with different\nmisclassification rates (e.g., misclassification rates for females are higher\nthan for males), thereby placing these groups at an unfair disadvantage. To\naccount for and avoid such unfairness, in this paper, we introduce a new notion\nof unfairness, disparate mistreatment, which is defined in terms of\nmisclassification rates. We then propose intuitive measures of disparate\nmistreatment for decision boundary-based classifiers, which can be easily\nincorporated into their formulation as convex-concave constraints. Experiments\non synthetic as well as real world datasets show that our methodology is\neffective at avoiding disparate mistreatment, often at a small cost in terms of\naccuracy.",
    "published_date": "2016-10-26T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08452v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.08293v1",
    "title": "Opportunistic Device-to-Device Communication in Cellular networks: From Theory to Practice",
    "authors": [
      "Arash Asadi"
    ],
    "author_ids": [],
    "abstract": "This dissertation studies different aspects of D2D communications and its\nimpact on the key performance indicators of the network. We design an\narchitecture for the collaboration of cellular users by means of timely\nexploited D2D opportunities. We begin by presenting the analytical study on\nopportunistic outband D2D communications. The study reveals the great potential\nof opportunistic outband D2D communications for enhancing energy efficiency,\nfairness, and capacity of cellular networks when groups of D2D users can be\nform and managed in the cellular network. Then we introduce a protocol that is\ncompatible with the latest release of IEEE and 3GPP standards and allows for\nimplementation of our proposal in a today's cellular network. To validate our\nanalytical findings, we use our experimental Software Defined Radio (SDR)-based\ntestbed to further study our proposal in a real world scenario. The\nexperimental results confirm the outstanding potential of opportunistic outband\nD2D communications. Finally, we investigate the performance merits and\ndisadvantages of different D2D modes. Our investigation reveals, despite the\ncommon belief, that all D2D modes are complementary and their merits are\nscenario based.",
    "published_date": "2016-10-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08293v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.08077v1",
    "title": "A statistical framework for fair predictive algorithms",
    "authors": [
      "Kristian Lum",
      "James Johndrow"
    ],
    "author_ids": [],
    "abstract": "Predictive modeling is increasingly being employed to assist human\ndecision-makers. One purported advantage of replacing human judgment with\ncomputer models in high stakes settings-- such as sentencing, hiring, policing,\ncollege admissions, and parole decisions-- is the perceived \"neutrality\" of\ncomputers. It is argued that because computer models do not hold personal\nprejudice, the predictions they produce will be equally free from prejudice.\nThere is growing recognition that employing algorithms does not remove the\npotential for bias, and can even amplify it, since training data were\ninevitably generated by a process that is itself biased. In this paper, we\nprovide a probabilistic definition of algorithmic bias. We propose a method to\nremove bias from predictive models by removing all information regarding\nprotected variables from the permitted training data. Unlike previous work in\nthis area, our framework is general enough to accommodate arbitrary data types,\ne.g. binary, continuous, etc. Motivated by models currently in use in the\ncriminal justice system that inform decisions on pre-trial release and\nparoling, we apply our proposed method to a dataset on the criminal histories\nof individuals at the time of sentencing to produce \"race-neutral\" predictions\nof re-arrest. In the process, we demonstrate that the most common approach to\ncreating \"race-neutral\" models-- omitting race as a covariate-- still results\nin racially disparate predictions. We then demonstrate that the application of\nour proposed method to these data removes racial disparities from predictions\nwith minimal impact on predictive accuracy.",
    "published_date": "2016-10-25T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.08077v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.07969v1",
    "title": "Wasserstein Stability of the Entropy Power Inequality for Log-Concave Densities",
    "authors": [
      "Thomas A. Courtade",
      "Max Fathi",
      "Ashwin Pananjady"
    ],
    "author_ids": [],
    "abstract": "We establish quantitative stability results for the entropy power inequality\n(EPI). Specifically, we show that if uniformly log-concave densities nearly\nsaturate the EPI, then they must be close to Gaussian densities in the\nquadratic Wasserstein distance. Further, if one of the densities is log-concave\nand the other is Gaussian, then the deficit in the EPI can be controlled in\nterms of the $L^1$-Wasserstein distance. As a counterpoint, an example shows\nthat the EPI can be unstable with respect to the quadratic Wasserstein distance\nwhen densities are uniformly log-concave on sets of measure arbitrarily close\nto one. Our stability results can be extended to non-log-concave densities,\nprovided certain regularity conditions are met. The proofs are based on optimal\ntransportation.",
    "published_date": "2016-10-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.FA",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.07969v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.07718v2",
    "title": "Bias-Aware Sketches",
    "authors": [
      "Jiecao Chen",
      "Qin Zhang"
    ],
    "author_ids": [],
    "abstract": "Linear sketching algorithms have been widely used for processing large-scale\ndistributed and streaming datasets. Their popularity is largely due to the fact\nthat linear sketches can be naturally composed in the distributed model and be\nefficiently updated in the streaming model. The errors of linear sketches are\ntypically expressed in terms of the sum of coordinates of the input vector\nexcluding those largest ones, or, the mass on the tail of the vector. Thus, the\nprecondition for these algorithms to perform well is that the mass on the tail\nis small, which is, however, not always the case -- in many real-world datasets\nthe coordinates of the input vector have a {\\em bias}, which will generate a\nlarge mass on the tail.\n  In this paper we propose linear sketches that are {\\em bias-aware}. We\nrigorously prove that they achieve strictly better error guarantees than the\ncorresponding existing sketches, and demonstrate their practicality and\nsuperiority via an extensive experimental evaluation on both real and synthetic\ndatasets.",
    "published_date": "2016-10-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.07718v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.07644v1",
    "title": "Discrimination power of a quantum detector",
    "authors": [
      "Christoph Hirche",
      "Masahito Hayashi",
      "Emilio Bagan",
      "John Calsamiglia"
    ],
    "author_ids": [],
    "abstract": "We investigate the ability of a quantum measurement device to discriminate\ntwo states or, generically, two hypothesis. In full generality, the measurement\ncan be performed a number $n$ of times, and arbitrary pre-processing of the\nstates and post-processing of the obtained data is allowed. Even if the two\nhypothesis correspond to orthogonal states, perfect discrimination is not\nalways possible. There is thus an intrinsic error associated to the measurement\ndevice, which we aim to quantify, that limits its discrimination power. We\nminimize various error probabilities (averaged or constrained) over all pairs\nof $n$-partite input states. These probabilities, or their exponential rates of\ndecrease in the case of large $n$, give measures of the discrimination power of\nthe device. For the asymptotic rate of the averaged error probability, we\nobtain a Chernoff-type bound, dual to the standard Chernoff bound for which the\nstate pair is fixed and the optimization is over all measurements. The key\npoint in the derivation is that i.i.d. states become optimal in asymptotic\nsettings. Minimum asymptotic rates are also obtained for constrained error\nprobabilities, dual to Stein's Lemma and Hoeffding's bound. We further show\nthat adaptive protocols where the state preparer gets feedback from the\nmeasurer do not improve the asymptotic rates. These rates thus quantify the\nultimate discrimination power of a measurement device.",
    "published_date": "2016-10-24T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math-ph",
      "math.IT",
      "math.MP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.07644v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.07524v1",
    "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments",
    "authors": [
      "Alexandra Chouldechova"
    ],
    "author_ids": [],
    "abstract": "Recidivism prediction instruments provide decision makers with an assessment\nof the likelihood that a criminal defendant will reoffend at a future point in\ntime. While such instruments are gaining increasing popularity across the\ncountry, their use is attracting tremendous controversy. Much of the\ncontroversy concerns potential discriminatory bias in the risk assessments that\nare produced. This paper discusses a fairness criterion originating in the\nfield of educational and psychological testing that has recently been applied\nto assess the fairness of recidivism prediction instruments. We demonstrate how\nadherence to the criterion may lead to considerable disparate impact when\nrecidivism prevalence differs across groups.",
    "published_date": "2016-10-24T00:00:00",
    "year": 2016,
    "categories": [
      "stat.AP",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.07524v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.07183v1",
    "title": "How to be Fair and Diverse?",
    "authors": [
      "L. Elisa Celis",
      "Amit Deshpande",
      "Tarun Kathuria",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Due to the recent cases of algorithmic bias in data-driven decision-making,\nmachine learning methods are being put under the microscope in order to\nunderstand the root cause of these biases and how to correct them. Here, we\nconsider a basic algorithmic task that is central in machine learning:\nsubsampling from a large data set. Subsamples are used both as an end-goal in\ndata summarization (where fairness could either be a legal, political or moral\nrequirement) and to train algorithms (where biases in the samples are often a\nsource of bias in the resulting model). Consequently, there is a growing effort\nto modify either the subsampling methods or the algorithms themselves in order\nto ensure fairness. However, in doing so, a question that seems to be\noverlooked is whether it is possible to produce fair subsamples that are also\nadequately representative of the feature space of the data set - an important\nand classic requirement in machine learning. Can diversity and fairness be\nsimultaneously ensured? We start by noting that, in some applications,\nguaranteeing one does not necessarily guarantee the other, and a new approach\nis required. Subsequently, we present an algorithmic framework which allows us\nto produce both fair and diverse samples. Our experimental results on an image\nsummarization task show marked improvements in fairness without compromising\nfeature diversity by much, giving us the best of both the worlds.",
    "published_date": "2016-10-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.07183v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.06809v1",
    "title": "The Anatomy of Brexit Debate on Facebook",
    "authors": [
      "Michela Del Vicario",
      "Fabiana Zollo",
      "Guido Caldarelli",
      "Antonio Scala",
      "Walter Quattrociocchi"
    ],
    "author_ids": [],
    "abstract": "Nowadays users get informed and shape their opinion through social media.\nHowever, the disintermediated access to contents does not guarantee quality of\ninformation. Selective exposure and confirmation bias, indeed, have been shown\nto play a pivotal role in content consumption and information spreading. Users\ntend to select information adhering (and reinforcing) their worldview and to\nignore dissenting information. This pattern elicits the formation of polarized\ngroups -- i.e., echo chambers -- where the interaction with like-minded people\nmight even reinforce polarization. In this work we address news consumption\naround Brexit in UK on Facebook. In particular, we perform a massive analysis\non more than 1 Million users interacting with Brexit related posts from the\nmain news providers between January and July 2016. We show that consumption\npatterns elicit the emergence of two distinct communities of news outlets.\nFurthermore, to better characterize inner group dynamics, we introduce a new\ntechnique which combines automatic topic extraction and sentiment analysis. We\ncompare how the same topics are presented on posts and the related emotional\nresponse on comments finding significant differences in both echo chambers and\nthat polarization influences the perception of topics. Our results provide\nimportant insights about the determinants of polarization and evolution of core\nnarratives on online debating.",
    "published_date": "2016-10-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.06809v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.06766v2",
    "title": "The societal impact of big data: A research roadmap for Europe",
    "authors": [
      "Martí Cuquet",
      "Anna Fensel"
    ],
    "author_ids": [],
    "abstract": "With its rapid growth and increasing adoption, big data is producing a\nsubstantial impact in society. Its usage is opening both opportunities such as\nnew business models and economic gains and risks such as privacy violations and\ndiscrimination. Europe is in need of a comprehensive strategy to optimise the\nuse of data for a societal benefit and increase the innovation and\ncompetitiveness of its productive activities. In this paper, we contribute to\nthe definition of this strategy with a research roadmap to capture the\neconomic, social and ethical, legal and political benefits associated with the\nuse of big data in Europe. The present roadmap considers the positive and\nnegative externalities associated with big data, maps research and innovation\ntopics in the areas of data management, processing, analytics, protection,\nvisualisation, as well as non-technical topics, to the externalities they can\ntackle, and provides a time frame to address these topics in order to deliver\nsocial impact, skills development and standardisation. Finally, it also\nidentifies what sectors will be most benefited by each of the research efforts.\nThe goal of the roadmap is to guide European research efforts to develop a\nsocially responsible big data economy, and to allow stakeholders to identify\nand meet big data challenges and proceed with a shared understanding of the\nsocietal impact, positive and negative externalities and concrete problems\nworth investigating in future programmes.",
    "published_date": "2016-10-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.06766v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.06700v1",
    "title": "End-to-End Training Approaches for Discriminative Segmental Models",
    "authors": [
      "Hao Tang",
      "Weiran Wang",
      "Kevin Gimpel",
      "Karen Livescu"
    ],
    "author_ids": [],
    "abstract": "Recent work on discriminative segmental models has shown that they can\nachieve competitive speech recognition performance, using features based on\ndeep neural frame classifiers. However, segmental models can be more\nchallenging to train than standard frame-based approaches. While some segmental\nmodels have been successfully trained end to end, there is a lack of\nunderstanding of their training under different settings and with different\nlosses.\n  We investigate a model class based on recent successful approaches,\nconsisting of a linear model that combines segmental features based on an LSTM\nframe classifier. Similarly to hybrid HMM-neural network models, segmental\nmodels of this class can be trained in two stages (frame classifier training\nfollowed by linear segmental model weight training), end to end (joint training\nof both frame classifier and linear weights), or with end-to-end fine-tuning\nafter two-stage training.\n  We study segmental models trained end to end with hinge loss, log loss,\nlatent hinge loss, and marginal log loss. We consider several losses for the\ncase where training alignments are available as well as where they are not.\n  We find that in general, marginal log loss provides the most consistent\nstrong performance without requiring ground-truth alignments. We also find that\ntraining with dropout is very important in obtaining good performance with\nend-to-end training. Finally, the best results are typically obtained by a\ncombination of two-stage training and fine-tuning.",
    "published_date": "2016-10-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.06700v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.06067v1",
    "title": "Fairness as a Program Property",
    "authors": [
      "Aws Albarghouthi",
      "Loris D'Antoni",
      "Samuel Drews",
      "Aditya Nori"
    ],
    "author_ids": [],
    "abstract": "We explore the following question: Is a decision-making program fair, for\nsome useful definition of fairness? First, we describe how several algorithmic\nfairness questions can be phrased as program verification problems. Second, we\ndiscuss an automated verification technique for proving or disproving fairness\nof decision-making programs with respect to a probabilistic model of the\npopulation.",
    "published_date": "2016-10-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.06067v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.06006v3",
    "title": "Early onset of structural inequality in the formation of collaborative knowledge, Wikipedia",
    "authors": [
      "Jinhyuk Yun",
      "Sang Hoon Lee",
      "Hawoong Jeong"
    ],
    "author_ids": [],
    "abstract": "We perform an in-depth analysis on the inequality in 863 Wikimedia projects.\nWe take the complete editing history of 267,304,095 Wikimedia items until 2016,\nwhich not only covers every language edition of Wikipedia, but also embraces\nthe complete versions of Wiktionary, Wikisource, Wikivoyage, etc. Our findings\nof common growth pattern described by the interrelations between four\ncharacteristic growth yardsticks suggest a universal law of communal data\nformation. In this encyclopaedic data set, we observe the interplay between the\nnumber of edits and the degree of inequality. In particular, the rapid increase\nin the Gini coefficient suggests that this entrenched inequality stems from the\nnature of such open-editing communal data sets, namely the abiogenesis of the\nsupereditors' oligopoly. We show that these supereditor groups were created at\nthe early stages of these open-editing media and are still active. Furthermore,\nour model considers both short-term and long-term memories to successfully\nelucidate the underlying mechanism of the establishment of oligarchy in\nWikipedia. Our results anticipate a noticeable prospect of such communal\ndatabases in the future: the disparity will not be resolved spontaneously.",
    "published_date": "2016-10-19T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.06006v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.05937v1",
    "title": "Gender differences in scientific collaborations: Women are more egalitarian than men",
    "authors": [
      "Eduardo B. Araujo",
      "Nuno A. M. Araujo",
      "Andre A. Moreira",
      "Hans J. Herrmann",
      "J. S. Andrade Jr"
    ],
    "author_ids": [],
    "abstract": "By analyzing a unique dataset of more than 270,000 scientists, we discovered\nsubstantial gender differences in scientific collaborations. While men are more\nlikely to collaborate with other men, women are more egalitarian. This is\nconsistently observed over all fields and regardless of the number of\ncollaborators a scientist has. The only exception is observed in the field of\nengineering, where this gender bias disappears with increasing number of\ncollaborators. We also found that the distribution of the number of\ncollaborators follows a truncated power law with a cut-off that is gender\ndependent and related to the gender differences in the number of published\npapers. Considering interdisciplinary research, our analysis shows that men and\nwomen behave similarly across fields, except in the case of natural sciences,\nwhere women with many collaborators are more likely to have collaborators from\nother fields.",
    "published_date": "2016-10-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.05937v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.05075v1",
    "title": "Employing Game theory and Multilevel Analysis to Predict the Factors that affect Collaborative Learning Outcomes: An Empirical Study",
    "authors": [
      "Sara Taraman",
      "Yasmin Hassan",
      "Doaa Shawky",
      "Ashraf H. Badawi"
    ],
    "author_ids": [],
    "abstract": "The purpose of this study is to propose a model that predicts the social and\npsychological factors that affect the individuals collaborative learning\noutcome in group projects. The model is established on the basis of two\ntheories, namely, the multilevel analysis and the cooperative game theory\n(CGT). In CGT, a group of players form a coalition and a set of payoffs for\neach member in the coalition. Shapely values is one of the most important\nsolution concepts in CGT. It represents a fair and efficient distribution of\npayoffs among members of a coalition. The proposed approach was applied on a\nsample that consisted of 78 freshman students, in their first semester, who\nwere studying philosophical thinking course and instructed by the same\nprofessor. Tools for the data collection included self-assessments, peer\nassessments, quizzes and observations. The research concluded that learning\noutcome and contribution are best prophesied by the extent of engagement the\ncontent is purveying. Whereas personality traits, as well as, learning styles\nhave the least impact on contribution. In addition, results show that Shapley\nvalues can be used as good vaticinators for individuals learning outcomes.\nThese results indicate that CGT can be used as a good engine for analyzing\ninteractions that recur in collaborative learning.",
    "published_date": "2016-10-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.GT",
      "62C99"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.05075v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.03995v2",
    "title": "Semi-Supervised Active Learning for Support Vector Machines: A Novel Approach that Exploits Structure Information in Data",
    "authors": [
      "Tobias Reitmaier",
      "Adrian Calma",
      "Bernhard Sick"
    ],
    "author_ids": [],
    "abstract": "In our today's information society more and more data emerges, e.g.~in social\nnetworks, technical applications, or business applications. Companies try to\ncommercialize these data using data mining or machine learning methods. For\nthis purpose, the data are categorized or classified, but often at high\n(monetary or temporal) costs. An effective approach to reduce these costs is to\napply any kind of active learning (AL) methods, as AL controls the training\nprocess of a classifier by specific querying individual data points (samples),\nwhich are then labeled (e.g., provided with class memberships) by a domain\nexpert. However, an analysis of current AL research shows that AL still has\nsome shortcomings. In particular, the structure information given by the\nspatial pattern of the (un)labeled data in the input space of a classification\nmodel (e.g.,~cluster information), is used in an insufficient way. In addition,\nmany existing AL techniques pay too little attention to their practical\napplicability. To meet these challenges, this article presents several\ntechniques that together build a new approach for combining AL and\nsemi-supervised learning (SSL) for support vector machines (SVM) in\nclassification tasks. Structure information is captured by means of\nprobabilistic models that are iteratively improved at runtime when label\ninformation becomes available. The probabilistic models are considered in a\nselection strategy based on distance, density, diversity, and distribution (4DS\nstrategy) information for AL and in a kernel function (Responsibility Weighted\nMahalanobis kernel) for SVM. The approach fuses generative and discriminative\nmodeling techniques. With 20 benchmark data sets and with the MNIST data set it\nis shown that our new solution yields significantly better results than\nstate-of-the-art methods.",
    "published_date": "2016-10-13T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.03995v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.03745v1",
    "title": "Dividing goods and bads under additive utilities",
    "authors": [
      "Anna Bogomolnaia",
      "Herve Moulin",
      "Fedor Sandomirskiy",
      "Elena Yanovskaya"
    ],
    "author_ids": [],
    "abstract": "When utilities are additive, we uncovered in our previous paper (Bogomolnaia\net al. \"Dividing Goods or Bads under Additive Utilities\") many similarities but\nalso surprising differences in the behavior of the familiar Competitive rule\n(with equal incomes), when we divide (private) goods or bads. The rule picks in\nboth cases the critical points of the product of utilities (or disutilities) on\nthe efficiency frontier, but there is only one such point if we share goods,\nwhile there can be exponentially many in the case of bads.\n  We extend this analysis to the fair division of mixed items: each item can be\nviewed by some participants as a good and by others as a bad, with\ncorresponding positive or negative marginal utilities. We find that the\ndivision of mixed items boils down, normatively as well as computationally, to\na variant of an all goods problem, or of an all bads problem: in particular the\ntask of dividing the non disposable items must be either good news for\neveryone, or bad news for everyone.\n  If at least one feasible utility profile is positive, the Competitive rule\npicks the unique maximum of the product of (positive) utilities. If no feasible\nutility profile is positive, this rule picks all critical points of the product\nof disutilities on the efficient frontier.",
    "published_date": "2016-10-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.03745v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.03474v2",
    "title": "The Core of the Participatory Budgeting Problem",
    "authors": [
      "Brandon Fain",
      "Ashish Goel",
      "Kamesh Munagala"
    ],
    "author_ids": [],
    "abstract": "In participatory budgeting, communities collectively decide on the allocation\nof public tax dollars for local public projects. In this work, we consider the\nquestion of fairly aggregating the preferences of community members to\ndetermine an allocation of funds to projects. This problem is different from\nstandard fair resource allocation because of public goods: The allocated goods\nbenefit all users simultaneously. Fairness is crucial in participatory decision\nmaking, since generating equitable outcomes is an important goal of these\nprocesses. We argue that the classic game theoretic notion of core captures\nfairness in the setting. To compute the core, we first develop a novel\ncharacterization of a public goods market equilibrium called the Lindahl\nequilibrium, which is always a core solution. We then provide the first (to our\nknowledge) polynomial time algorithm for computing such an equilibrium for a\nbroad set of utility functions; our algorithm also generalizes (in a\nnon-trivial way) the well-known concept of proportional fairness. We use our\ntheoretical insights to perform experiments on real participatory budgeting\nvoting data. We empirically show that the core can be efficiently computed for\nutility functions that naturally model our practical setting, and examine the\nrelation of the core with the familiar welfare objective. Finally, we address\nconcerns of incentives and mechanism design by developing a randomized\napproximately dominant-strategy truthful mechanism building on the exponential\nmechanism from differential privacy.",
    "published_date": "2016-10-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.CY",
      "cs.DS",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.03474v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.03229v1",
    "title": "In The Wild Residual Data Research and Privacy",
    "authors": [
      "William Bradley Glisson",
      "Tim Storer",
      "Andrew Blyth",
      "George Grispos",
      "Matt Campbell"
    ],
    "author_ids": [],
    "abstract": "As the world becomes increasingly dependent on technology, researchers in\nboth industry and academia endeavor to understand how technology is used, the\nimpact it has on everyday life, the artifact life-cycle and overall\nintegrations of digital information. In doing so, researchers are increasingly\ngathering 'real-world' or 'in-the-wild' residual data, obtained from a variety\nof sources, without the explicit consent of the original owners. This data\ngathering raises significant concerns regarding privacy, ethics and\nlegislation, as well as practical considerations concerning investigator\ntraining, data storage, overall security and data disposal. This research\nsurveys recent studies of residual data gathered in-the-wild and analyzes the\nchallenges that were confronted. Amalgamating these insights, the research\npresents a compendium of practices for addressing the issues that can arise\nin-the-wild when conducting residual data research. The practices identified in\nthis research can be used to critique current projects and assess the\nfeasibility of proposed future research.",
    "published_date": "2016-10-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.03229v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.02991v2",
    "title": "Quantifying moral foundations from various topics on Twitter conversations",
    "authors": [
      "Rishemjit Kaur",
      "Kazutoshi Sasahara"
    ],
    "author_ids": [],
    "abstract": "Moral foundations theory explains variations in moral behavior using innate\nmoral foundations: Care, Fairness, Ingroup, Authority, and Purity, along with\nexperimental supports. However, little is known about the roles of and\nrelationships between those foundations in everyday moral situations. To\naddress these, we quantify moral foundations from a large amount of online\nconversations (tweets) about moral topics on the social media site Twitter. We\nmeasure moral loadings using latent semantic analysis of tweets related to\ntopics on abortion, homosexuality, immigration, religion, and immorality in\ngeneral, showing how the five moral foundations function in spontaneous\nconversations about moral violating situations. The results indicate that\nalthough the five foundations are mutually related, Purity is the most\ndistinctive foundation and Care is the most dominant foundation in everyday\nconversations on immorality. Our study shows a new possibility of natural\nlanguage processing and social big data for moral psychology.",
    "published_date": "2016-10-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.02991v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.02820v1",
    "title": "Redundancies in Linear Systems with two Variables per Inequality",
    "authors": [
      "Komei Fukuda",
      "May Szedlak"
    ],
    "author_ids": [],
    "abstract": "The problem of detecting and removing redundant constraints is fundamental in\noptimization. We focus on the case of linear programs (LPs), given by $d$\nvariables with $n$ inequality constraints. A constraint is called\n\\emph{redundant}, if after its removal, the LP still has the same feasible\nregion. The currently fastest method to detect all redundancies is due to\nClarkson: it solves $n$ linear programs, but each of them has at most $s$\nconstraints, where $s$ is the number of nonredundant constraints.\n  In this paper, we study the special case where every constraint has at most\ntwo variables with nonzero coefficients. This family, denoted by $LI(2)$, has\nsome nice properties. Namely, as shown by Aspvall and Shiloach, given a\nvariable $x_i$ and a value $\\lambda$, we can test in time $O(nd)$ whether there\nis a feasible solution with $x_i = \\lambda$. Hochbaum and Naor present an\n$O(d^2 n \\log n)$ algorithm for solving the feasibility problem in $LI(2)$.\nTheir technique makes use of the Fourier-Motzkin elimination method and the\nearlier mentioned result by Aspvall and Shiloach.\n  We present a strongly polynomial algorithm that solves redundancy detection\nin time $O(n d^2 s \\log s)$. It uses a modification of Clarkson's algorithm,\ntogether with a revised version of Hochbaum and Naor's technique. Finally we\nshow that dimensionality testing can be done with the same running time as\nsolving feasibility.",
    "published_date": "2016-10-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.02820v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.02413v1",
    "title": "Equality of Opportunity in Supervised Learning",
    "authors": [
      "Moritz Hardt",
      "Eric Price",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "We propose a criterion for discrimination against a specified sensitive\nattribute in supervised learning, where the goal is to predict some target\nbased on available features. Assuming data about the predictor, target, and\nmembership in the protected group are available, we show how to optimally\nadjust any learned predictor so as to remove discrimination according to our\ndefinition. Our framework also improves incentives by shifting the cost of poor\nclassification from disadvantaged groups to the decision maker, who can respond\nby improving the classification accuracy.\n  In line with other studies, our notion is oblivious: it depends only on the\njoint statistics of the predictor, the target and the protected attribute, but\nnot on interpretation of individualfeatures. We study the inherent limits of\ndefining and identifying biases based on such oblivious measures, outlining\nwhat can and cannot be inferred from different oblivious tests.\n  We illustrate our notion using a case study of FICO credit scores.",
    "published_date": "2016-10-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.02413v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.02391v4",
    "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization",
    "authors": [
      "Ramprasaath R. Selvaraju",
      "Michael Cogswell",
      "Abhishek Das",
      "Ramakrishna Vedantam",
      "Devi Parikh",
      "Dhruv Batra"
    ],
    "author_ids": [],
    "abstract": "We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting important regions in the image for\npredicting the concept. Grad-CAM is applicable to a wide variety of CNN\nmodel-families: (1) CNNs with fully-connected layers, (2) CNNs used for\nstructured outputs, (3) CNNs used in tasks with multimodal inputs or\nreinforcement learning, without any architectural changes or re-training. We\ncombine Grad-CAM with fine-grained visualizations to create a high-resolution\nclass-discriminative visualization and apply it to off-the-shelf image\nclassification, captioning, and visual question answering (VQA) models,\nincluding ResNet-based architectures. In the context of image classification\nmodels, our visualizations (a) lend insights into their failure modes, (b) are\nrobust to adversarial images, (c) outperform previous methods on localization,\n(d) are more faithful to the underlying model and (e) help achieve\ngeneralization by identifying dataset bias. For captioning and VQA, we show\nthat even non-attention based models can localize inputs. We devise a way to\nidentify important neurons through Grad-CAM and combine it with neuron names to\nprovide textual explanations for model decisions. Finally, we design and\nconduct human studies to measure if Grad-CAM helps users establish appropriate\ntrust in predictions from models and show that Grad-CAM helps untrained users\nsuccessfully discern a 'stronger' nodel from a 'weaker' one even when both make\nidentical predictions. Our code is available at\nhttps://github.com/ramprs/grad-cam/, along with a demo at\nhttp://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E.",
    "published_date": "2016-10-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.02391v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1610.02056v1",
    "title": "Constant Approximation Algorithm for Non-Uniform Capacitated Multi-Item Lot-Sizing via Strong Covering Inequalities",
    "authors": [
      "Shi Li"
    ],
    "author_ids": [],
    "abstract": "We study the non-uniform capacitated multi-item lot-sizing (\\lotsizing)\nproblem. In this problem, there is a set of demands over a planning horizon of\n$T$ time periods and all demands must be satisfied on time. We can place an\norder at the beginning of each period $s$, incurring an ordering cost $K_s$.\nThe total quantity of all products ordered at time $s$ can not exceed a given\ncapacity $C_s$. On the other hand, carrying inventory from time to time incurs\ninventory holding cost. The goal of the problem is to find a feasible solution\nthat minimizes the sum of ordering and holding costs.\n  Levi et al.\\ (Levi, Lodi and Sviridenko, Mathmatics of Operations Research\n33(2), 2008) gave a 2-approximation for the problem when the capacities $C_s$\nare the same. In this paper, we extend their result to the case of non-uniform\ncapacities. That is, we give a constant approximation algorithm for the\ncapacitated multi-item lot-sizing problem with general capacities.\n  The constant approximation is achieved by adding an exponentially large set\nof new covering inequalities to the natural facility-location type linear\nprogramming relaxation for the problem. Along the way of our algorithm, we\nreduce the \\lotsizing problem to two generalizations of the classic knapsack\ncovering problem. We give LP-based constant approximation algorithms for both\ngeneralizations, via the iterative rounding technique.",
    "published_date": "2016-10-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.02056v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.00560v3",
    "title": "Poly-Symmetry in Processor-Sharing Systems",
    "authors": [
      "Thomas Bonald",
      "Céline Comte",
      "Virag Shah",
      "Gustavo de Veciana"
    ],
    "author_ids": [],
    "abstract": "We consider a system of processor-sharing queues with state-dependent service\nrates. These are allocated according to balanced fairness within a polymatroid\ncapacity set. Balanced fairness is known to be both insensitive and\nPareto-efficient in such systems, which ensures that the performance metrics,\nwhen computable, will provide robust insights into the real performance of the\nsystem considered. We first show that these performance metrics can be\nevaluated with a complexity that is polynomial in the system size if the system\nis partitioned into a finite number of parts, so that queues are exchangeable\nwithin each part and asymmetric across different parts. This in turn allows us\nto derive stochastic bounds for a larger class of systems which satisfy less\nrestrictive symmetry assumptions. These results are applied to practical\nexamples of tree data networks, such as backhaul networks of Internet service\nproviders, and computer clusters.",
    "published_date": "2016-10-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.PF",
      "60K25 Queueing theory, 68M20 Performance evaluation, queueing,\n  scheduling, 90B15 Network models, stochastic"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.00560v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.09413v1",
    "title": "Clean up or mess up: the effect of sampling biases on measurements of degree distributions in mobile phone datasets",
    "authors": [
      "Adeline Decuyper",
      "Arnaud Browet",
      "Vincent Traag",
      "Vincent D. Blondel",
      "Jean-Charles Delvenne"
    ],
    "author_ids": [],
    "abstract": "Mobile phone data have been extensively used in the recent years to study\nsocial behavior. However, most of these studies are based on only partial data\nwhose coverage is limited both in space and time. In this paper, we point to an\nobservation that the bias due to the limited coverage in time may have an\nimportant influence on the results of the analyses performed. In particular, we\nobserve significant differences, both qualitatively and quantitatively, in the\ndegree distribution of the network, depending on the way the dataset is\npre-processed and we present a possible explanation for the emergence of Double\nPareto LogNormal (DPLN) degree distributions in temporal data.",
    "published_date": "2016-09-29T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.09413v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.08476v2",
    "title": "Joint Cell Muting and User Scheduling in Multi-Cell Networks with Temporal Fairness",
    "authors": [
      "Shahram Shahsavari",
      "Nail Akar",
      "Babak Hossein Khalaj"
    ],
    "author_ids": [],
    "abstract": "A semi-centralized joint cell muting and user scheduling scheme for\ninterference coordination in a multicell network is proposed under two\ndifferent temporal fairness criteria. The main principle behind the proposed\nscheme is that a central entity selects a cell muting pattern out of a pattern\nset at a decision instant, and subsequently the un-muted base stations\nopportunistically schedule the users in the associated cells, both decisions\nmade on a temporal-fair basis. Although some pattern sets are easily obtainable\nfrom static frequency reuse systems, we propose a more general pattern set\nconstruction algorithm in this paper. As for the first fairness criterion, all\ncells are assigned to receive the same temporal share with the ratio between\nthe temporal share of a cell center section and that of the cell edge section\nis set to a fixed desired value for all cells. The second fairness criterion is\nbased on the max-min temporal fairness for which the temporal share of the\nnetwork-wide worst-case user is maximized. Numerical results are provided to\nvalidate the effectiveness of the proposed scheme for both criteria. The impact\nof choice of the cell muting pattern set is also studied through numerical\nexamples for various cellular topologies.",
    "published_date": "2016-09-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.08476v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.08381v1",
    "title": "Multiplex Modeling of the Society",
    "authors": [
      "Janos Kertesz",
      "Janos Torok",
      "Yohsuke Murase",
      "Hang-Hyun Jo",
      "Kimmo Kaski"
    ],
    "author_ids": [],
    "abstract": "The society has a multi-layered structure, where the layers represent the\ndifferent contexts. To model this structure we begin with a single-layer\nweighted social network (WSN) model showing the Granovetterian structure. We\nfind that when merging such WSN models, a sufficient amount of inter-layer\ncorrelation is needed to maintain the relationship between topology and link\nweights, while these correlations destroy the enhancement in the community\noverlap due to multiple layers. To resolve this, we devise a geographic\nmulti-layer WSN model, where the indirect inter-layer correlations due to the\ngeographic constraints of individuals enhance the overlaps between the\ncommunities and, at the same time, the Granovetterian structure is preserved.\nFurthermore, the network of social interactions can be considered as a\nmultiplex from another point of view too: each layer corresponds to one\ncommunication channel and the aggregate of all them constitutes the entire\nsocial network. However, usually one has information only about one of the\nchannels, which should be considered as a sample of the whole. Here we show by\nsimulations and analytical methods that this sampling may lead to bias. For\nexample, while it is expected that the degree distribution of the whole social\nnetwork has a maximum at a value larger than one, we get with reasonable\nassumptions about the sampling process a monotonously decreasing distribution\nas observed in empirical studies of single channel data. We analyse the\nfar-reaching consequences of our findings.",
    "published_date": "2016-09-27T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.08381v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.08182v2",
    "title": "Availability-Aware Cell Association for Hybrid Power Supply Networks with Adaptive Bias",
    "authors": [
      "Fanny Parzysz",
      "Christos Verikoukis"
    ],
    "author_ids": [],
    "abstract": "New challenges have emerged from the integration of renewable energy sources\nwithin the conventional electrical grid which powers base stations (BS).\nEnergy-aware traffic offloading brings a promising solution to maintain the\nuser performance while reducing the carbon footprint. Focusing on downlink\ncellular networks consisting of on-grid, off-grid and hybrid BSs, we propose a\nnovel power-aware biased cell association where each user independently\npartitions BSs into two sets and applies different association biases for each,\ndepending on the type of power, renewable or not, that can be requested for\nservice. The gain provided by such strategy regarding the probability of power\noutage and the average grid power consumption is investigated. To capture their\ndual nature, the bias applied for association with a hybrid BS is not constant\namong users nor over time, and is dynamically tailored to the fluctuations of\nthe BS battery level, the user power requirement and the estimated power\nconsumed to serve other users potentially associated with the same BS. Such\napproach allows to efficiently share the available energy among BSs and turns\nhigh heterogeneity in the BS powering into advantage.",
    "published_date": "2016-09-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.08182v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.07899v1",
    "title": "Using an innovative assessment approach on a real-world group based software project",
    "authors": [
      "Susan Bergin",
      "Aidan Mooney"
    ],
    "author_ids": [],
    "abstract": "Currently, there is a lack of practical, real-world projects on Computer\nScience (CS) courses at Maynooth University. Generally CS undergraduate modules\nare composed of 24 hours of lectures and 24 hours of labs where students learn\ntheoretical concepts in the lectures and apply their understanding to practical\nlab-based exercises. The problem with this approach is that students do not\ngain any awareness of, or learn how to solve tasks that they are likely to\nencounter in a real-world industrial setting; nor do they gain experience of\nworking as part of a team even though most software development positions\ninvolve team-based work.\n  This paper reports on a web-based development module that incorporated a\nreal-world group based project was re-designed and delivered. The module went\nwell; however, assessing the work fairly was found to be difficult, especially\nwhere team members contributed at considerably varying levels was a challenge.\nOf particular concern was that some hard-working students were penalised by\nother students poor work and lazy students were rewarded because of more\nhard-working students work.\n  This action research project will attempt to re-address how to assess this\ngroup-based work with a cohort of students. The goal of the research is to\nimplement an innovative assessment structure, using peer-, self-, and\nco-assessment, for a group based real-world project, that is deemed fair and\nreasonable and provided a good learning environment.",
    "published_date": "2016-09-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.07899v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.07256v3",
    "title": "Towards Fairness of Cryptocurrency Payments",
    "authors": [
      "Jian Liu",
      "Wenting Li",
      "Ghassan O. Karame",
      "N. Asokan"
    ],
    "author_ids": [],
    "abstract": "Motivated by the great success and adoption of Bitcoin, a number of\ncryptocurrencies such as Litecoin, Dogecoin, and Ethereum are becoming\nincreasingly popular. Although existing blockchain-based cryptocurrency schemes\ncan ensure reasonable security for transactions, they do not consider any\nnotion of fairness. Fair exchange allows two players to exchange digital\n\"items\", such as digital signatures, over insecure networks fairly, so that\neither each player gets the other's item, or neither player does. Given that\nblockchain participants typically do not trust each other, enabling fairness in\nexisting cryptocurrencies is an essential but insufficiently explored problem.\n  In this paper, we explore the solution space for enabling the fair exchange\nof a cryptocurrency payment for a receipt. We identify the timeliness of an\nexchange as an important property especially when one of the parties involved\nin the exchange is resource-constrained. We introduce the notion of strong\ntimeliness for a fair exchange protocol and propose two fair\npayment-for-receipt protocol instantiations that leverage functionality of the\nblockchain to achieve strong timeliness. We implement both and compare their\nsecurity and efficiency.",
    "published_date": "2016-09-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.07256v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.07236v1",
    "title": "On the (im)possibility of fairness",
    "authors": [
      "Sorelle A. Friedler",
      "Carlos Scheidegger",
      "Suresh Venkatasubramanian"
    ],
    "author_ids": [],
    "abstract": "What does it mean for an algorithm to be fair? Different papers use different\nnotions of algorithmic fairness, and although these appear internally\nconsistent, they also seem mutually incompatible. We present a mathematical\nsetting in which the distinctions in previous papers can be made formal. In\naddition to characterizing the spaces of inputs (the \"observed\" space) and\noutputs (the \"decision\" space), we introduce the notion of a construct space: a\nspace that captures unobservable, but meaningful variables for the prediction.\n  We show that in order to prove desirable properties of the entire\ndecision-making process, different mechanisms for fairness require different\nassumptions about the nature of the mapping from construct space to decision\nspace. The results in this paper imply that future treatments of algorithmic\nfairness should more explicitly state assumptions about the relationship\nbetween constructs and observations.",
    "published_date": "2016-09-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.07236v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.06844v1",
    "title": "Posted Pricing sans Discrimination",
    "authors": [
      "Shreyas Sekar"
    ],
    "author_ids": [],
    "abstract": "In the quest for market mechanisms that are easy to implement, yet close to\noptimal, few seem as viable as posted pricing. Despite the growing body of\nimpressive results, the performance of most posted price mechanisms however,\nrely crucially on price discrimination when multiple copies of a good are\navailable. For the more general case with non-linear production costs on each\ngood, hardly anything is known for general multi-good markets. With this in\nmind, we study a Bayesian setting where the seller can produce any number of\ncopies of a good but faces convex production costs for the same, and buyers\narrive sequentially. Our main contribution is a framework for\nnon-discriminatory pricing in the presence of production costs: the framework\nyields posted price mechanisms with O(1)-approximation factors for fractionally\nsubadditive (XoS) buyers, logarithmic approximations for subadditive buyers,\nand also extends to settings where the seller is oblivious to buyer valuations.\nOur work presents the first known results for Bayesian settings with production\ncosts and is among the few posted price mechanisms that do not charge buyers\ndifferently for the same good.",
    "published_date": "2016-09-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.06844v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.06492v1",
    "title": "Document Image Coding and Clustering for Script Discrimination",
    "authors": [
      "Darko Brodic",
      "Alessia Amelio",
      "Zoran N. Milivojevic",
      "Milena Jevtic"
    ],
    "author_ids": [],
    "abstract": "The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.",
    "published_date": "2016-09-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE",
      "97R40, 62H35, 68U15, 68T50,"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.06492v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.06408v2",
    "title": "Control Barrier Function Based Quadratic Programs for Safety Critical Systems",
    "authors": [
      "Aaron D. Ames",
      "Xiangru Xu",
      "Jessy W. Grizzle",
      "Paulo Tabuada"
    ],
    "author_ids": [],
    "abstract": "Safety critical systems involve the tight coupling between potentially\nconflicting control objectives and safety constraints. As a means of creating a\nformal framework for controlling systems of this form, and with a view toward\nautomotive applications, this paper develops a methodology that allows safety\nconditions -- expressed as control barrier functions -- to be unified with\nperformance objectives -- expressed as control Lyapunov functions -- in the\ncontext of real-time optimization-based controllers. Safety conditions are\nspecified in terms of forward invariance of a set, and are verified via two\nnovel generalizations of barrier functions; in each case, the existence of a\nbarrier function satisfying Lyapunov-like conditions implies forward invariance\nof the set, and the relationship between these two classes of barrier functions\nis characterized. In addition, each of these formulations yields a notion of\ncontrol barrier function (CBF), providing inequality constraints in the control\ninput that, when satisfied, again imply forward invariance of the set. Through\nthese constructions, CBFs can naturally be unified with control Lyapunov\nfunctions (CLFs) in the context of a quadratic program (QP); this allows for\nthe achievement of control objectives (represented by CLFs) subject to\nconditions on the admissible states of the system (represented by CBFs). The\nmediation of safety and performance through a QP is demonstrated on adaptive\ncruise control and lane keeping, two automotive control problems that present\nboth safety and performance considerations coupled with actuator bounds.",
    "published_date": "2016-09-21T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.06408v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.05807v2",
    "title": "Inherent Trade-Offs in the Fair Determination of Risk Scores",
    "authors": [
      "Jon Kleinberg",
      "Sendhil Mullainathan",
      "Manish Raghavan"
    ],
    "author_ids": [],
    "abstract": "Recent discussion in the public sphere about algorithmic classification has\ninvolved tension between competing notions of what it means for a probabilistic\nclassification to be fair to different groups. We formalize three fairness\nconditions that lie at the heart of these debates, and we prove that except in\nhighly constrained special cases, there is no method that can satisfy these\nthree conditions simultaneously. Moreover, even satisfying all three conditions\napproximately requires that the data lie in an approximate version of one of\nthe constrained special cases identified by our theorem. These results suggest\nsome of the ways in which key notions of fairness are incompatible with each\nother, and hence provide a framework for thinking about the trade-offs between\nthem.",
    "published_date": "2016-09-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05807v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.05782v1",
    "title": "Toward a Science of Autonomy for Physical Systems: Defense",
    "authors": [
      "Ronald C. Arkin",
      "Gaurav S. Sukhatme"
    ],
    "author_ids": [],
    "abstract": "Militaries around the world have long been cognizant of the potential\nbenefits associated with autonomous systems both in the conduct of warfare and\nin its prevention. This has lead to the declaration by some that this\ntechnology will lead to a fundamental change in the ways in which war is\nconducted, i.e., a revolution in military affairs (RMA) not unlike gunpowder,\nthe long bow, the rifled bullet, the aircraft carrier, etc. Indeed the United\nStates has created roadmaps for robotics with ever-increasing autonomous\ncapability that span almost 40 years. These systems span air, sea, sea surface,\nlittoral, ground and subterranean environments. There are serious societal and\nethical concerns associated with the deployment of this technology that remain\nunaddressed. How can sufficient protection be afforded noncombatants? What\nabout civilian blowback, where this technology may end up being used in\npolicing operations against domestic groups? How can we protect the fundamental\nhuman rights of all involved? Considerable discussion is being conducted at an\ninternational level, including at the United Nations Convention on Certain\nConventional Weapons (CCW) over the past two years, debating if and how such\nsystems, particularly lethal platforms should be banned or regulated.",
    "published_date": "2016-09-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05782v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.05708v1",
    "title": "Reducing energy consumption of network infrastructure using spectral approach",
    "authors": [
      "Mohammad Habibullah Khan",
      "Eric Rondeau",
      "Jean-Philippe Georges"
    ],
    "author_ids": [],
    "abstract": "The energy consumption by ICT (Information and Communication Technology)\nequipment is rapidly increasing which causes a significant economic and\nenvironmental problem. At present, the network infrastructure is becoming a\nlarge portion of the energy footprint in ICT. Thus, the concept of energy\nefficient or green networking has been introduced. Now one of the main concerns\nof network industry is to minimize energy consumption of network infrastructure\nbecause of the potential economic benefits, ethical responsibility, and its\nenvironmental impact. In this paper, the energy management strategies to reduce\nthe energy consumed by network switches in LAN (Local Area Network) have been\ndeveloped. According to the life-cycle assessment of network switches, the\nhighest amount of energy is consumed during usage phase. The study considers\nbandwidth, link load and traffic matrices as input parameters which have the\nhighest contribution to energy footprints of network switches during usage\nphase and energy consumption as output. Then with the objective of reducing\nenergy usage of network infrastructure, the feasibility of putting Ethernet\nswitches hibernate or sleep mode was investigated. After that, the network\ntopology was reorganized using clustering method based on the spectral approach\nfor putting network switches to hibernate or switched off mode considering the\ntime and communications among them. Experimental results show the interest in\nthis approach in terms of energy consumption. .",
    "published_date": "2016-09-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05708v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.05545v1",
    "title": "Patterns of authors contribution in scientific manuscripts",
    "authors": [
      "Edilson A. Corrêa Jr.",
      "Filipi N. Silva",
      "Luciano da F. Costa",
      "Diego R. Amancio"
    ],
    "author_ids": [],
    "abstract": "Science is becoming increasingly more interdisciplinary, giving rise to more\ndiversity in the areas of expertise within research labs and groups. This also\nhave brought changes to the role researchers in scientific works. As a\nconsequence, multi-authored scientific papers have now became a norm for high\nquality research. Unfortunately, such a phenomenon induces bias to existing\nmetrics employed to evaluate the productivity and success of researchers. While\nsome metrics were adapted to account for the rank of authors in a paper, many\njournals are now requiring a description of the specific roles of each author\nin a publication. Surprisingly, the investigation of the relationship between\nthe rank of authors and their contributions has been limited to a few studies.\nBy analyzing such kind of data, here we show, quantitatively, that the\nregularity in the authorship contributions decreases with the number of authors\nin a paper. Furthermore, we found that the rank of authors and their roles in\npapers follows three general patterns according to the nature of their\ncontributions, such as writing, data analysis, and the conduction of\nexperiments. This was accomplished by collecting and analyzing the data\nretrieved from PLoS ONE and by devising an entropy-based measurement to\nquantify the effective number of authors in a paper according to their\ncontributions. The analysis of such patterns confirms that some aspects of the\nauthor ranking are in accordance with the expected convention, such as the fact\nthat the first and last authors are more likely to contribute more in a\nscientific work. Conversely, such analysis also revealed that authors in the\nintermediary positions of the rank contribute more in certain specific roles,\nsuch as the task of collecting data. This indicates that the an unbiased\nevaluation of researchers must take into account the distinct types of\nscientific contributions.",
    "published_date": "2016-09-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05545v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.05528v1",
    "title": "Sequential Ensemble Learning for Outlier Detection: A Bias-Variance Perspective",
    "authors": [
      "Shebuti Rayana",
      "Wen Zhong",
      "Leman Akoglu"
    ],
    "author_ids": [],
    "abstract": "Ensemble methods for classification and clustering have been effectively used\nfor decades, while ensemble learning for outlier detection has only been\nstudied recently. In this work, we design a new ensemble approach for outlier\ndetection in multi-dimensional point data, which provides improved accuracy by\nreducing error through both bias and variance. Although classification and\noutlier detection appear as different problems, their theoretical underpinnings\nare quite similar in terms of the bias-variance trade-off [1], where outlier\ndetection is considered as a binary classification task with unobserved labels\nbut a similar bias-variance decomposition of error.\n  In this paper, we propose a sequential ensemble approach called CARE that\nemploys a two-phase aggregation of the intermediate results in each iteration\nto reach the final outcome. Unlike existing outlier ensembles which solely\nincorporate a parallel framework by aggregating the outcomes of independent\nbase detectors to reduce variance, our ensemble incorporates both the parallel\nand sequential building blocks to reduce bias as well as variance by ($i$)\nsuccessively eliminating outliers from the original dataset to build a better\ndata model on which outlierness is estimated (sequentially), and ($ii$)\ncombining the results from individual base detectors and across iterations\n(parallelly). Through extensive experiments on sixteen real-world datasets\nmainly from the UCI machine learning repository [2], we show that CARE performs\nsignificantly better than or at least similar to the individual baselines. We\nalso compare CARE with the state-of-the-art outlier ensembles where it also\nprovides significant improvement when it is the winner and remains close\notherwise.",
    "published_date": "2016-09-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05528v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.05339v4",
    "title": "Better than Counting Seconds: Identifying Fallers among Healthy Elderly using Fusion of Accelerometer Features and Dual-Task Timed Up and Go",
    "authors": [
      "Moacir Ponti",
      "Patricia Bet",
      "Caroline Oliveira",
      "Paula C. Castro"
    ],
    "author_ids": [],
    "abstract": "Devices and sensors for identification of fallers can be used to implement\nactions to prevent falls and to allow the elderly to live an independent life\nwhile reducing the long-term care costs. In this study we aimed to investigate\nthe accuracy of Timed Up and Go test, for fallers' identification, using fusion\nof features extracted from accelerometer data. Single and dual tasks TUG\n(manual and cognitive) were performed by a final sample (94% power) of 36\ncommunity dwelling healthy older persons (18 fallers paired with 18\nnon-fallers) while they wear a single triaxial accelerometer at waist with\nsampling rate of 200Hz. The segmentation of the TUG different trials and its\ncomparative analysis allows to better discriminate fallers from non-fallers,\nwhile conventional functional tests fail to do so. In addition, we show that\nthe fusion of features improve the discrimination power, achieving AUC of 0.84\n(Sensitivity=Specificity=0.83, 95% CI 0.62-0.91), and demonstrating the\nclinical relevance of the study. We concluded that features extracted from\nsegmented TUG trials acquired with dual tasks has potential to improve\nperformance when identifying fallers via accelerometer sensors, which can\nimprove TUG accuracy for clinical and epidemiological applications.",
    "published_date": "2016-09-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05339v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.05300v1",
    "title": "Detection of Biasing Attacks on Distributed Estimation Networks",
    "authors": [
      "Mohammad Deghat",
      "Valery Ugrinovskii",
      "Iman Shames",
      "Cedric Langbort"
    ],
    "author_ids": [],
    "abstract": "The paper addresses the problem of detecting attacks on distributed estimator\nnetworks that aim to intentionally bias process estimates produced by the\nnetwork. It provides a sufficient condition, in terms of the feasibility of\ncertain linear matrix inequalities, which guarantees distributed input attack\ndetection using an $H_\\infty$ approach.",
    "published_date": "2016-09-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.05300v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.04897v3",
    "title": "Variants of the Entropy Power Inequality",
    "authors": [
      "Sergey Bobkov",
      "Arnaud Marsiglietti"
    ],
    "author_ids": [],
    "abstract": "An extension of the entropy power inequality to the form $N_r^\\alpha(X+Y)\n\\geq N_r^\\alpha(X) + N_r^\\alpha(Y)$ with arbitrary independent summands $X$ and\n$Y$ in $\\mathbb{R}^n$ is obtained for the R\\'enyi entropy and powers $\\alpha\n\\geq (r+1)/2$.",
    "published_date": "2016-09-16T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR",
      "94A17"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.04897v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.07472v3",
    "title": "Gated Neural Networks for Option Pricing: Rationality by Design",
    "authors": [
      "Yongxin Yang",
      "Yu Zheng",
      "Timothy M. Hospedales"
    ],
    "author_ids": [],
    "abstract": "We propose a neural network approach to price EU call options that\nsignificantly outperforms some existing pricing models and comes with\nguarantees that its predictions are economically reasonable. To achieve this,\nwe introduce a class of gated neural networks that automatically learn to\ndivide-and-conquer the problem space for robust and accurate pricing. We then\nderive instantiations of these networks that are 'rational by design' in terms\nof naturally encoding a valid call option surface that enforces no arbitrage\nprinciples. This integration of human insight within data-driven learning\nprovides significantly better generalisation in pricing performance due to the\nencoded inductive bias in the learning, guarantees sanity in the model's\npredictions, and provides econometrically useful byproduct such as risk neutral\ndensity.",
    "published_date": "2016-09-14T00:00:00",
    "year": 2016,
    "categories": [
      "q-fin.CP",
      "cs.LG",
      "q-fin.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.07472v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.04373v1",
    "title": "Consistency of Social Sensing Signatures Across Major US Cities",
    "authors": [
      "Aiman Soliman",
      "Kiumars Soltani",
      "Anand Padmanabhan",
      "Shaowen Wang"
    ],
    "author_ids": [],
    "abstract": "Previous studies have shown that Twitter users have biases to tweet from\ncertain locations, locational bias, and during certain hours, temporal bias. We\nused three years of geolocated Twitter Data to quantify these biases and test\nour central hypothesis that Twitter users biases are consistent across US\ncities. Our results suggest that temporal and locational bias of Twitter users\nare inconsistent between three US metropolitan cities. We derive conclusions\nabout the role of the complexity of the underlying data producing process on\nits consistency and argue for the potential research avenue for Geospatial Data\nScience to test and quantify these inconsistencies in the class of organically\nevolved Big Data.",
    "published_date": "2016-09-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.04373v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.04116v1",
    "title": "Joint Gender Classification and Age Estimation by Nearly Orthogonalizing Their Semantic Spaces",
    "authors": [
      "Qing Tian",
      "Songcan Chen"
    ],
    "author_ids": [],
    "abstract": "In human face-based biometrics, gender classification and age estimation are\ntwo typical learning tasks. Although a variety of approaches have been proposed\nto handle them, just a few of them are solved jointly, even so, these joint\nmethods do not yet specifically concern the semantic difference between human\ngender and age, which is intuitively helpful for joint learning, consequently\nleaving us a room of further improving the performance. To this end, in this\nwork we firstly propose a general learning framework for jointly estimating\nhuman gender and age by specially attempting to formulate such semantic\nrelationships as a form of near-orthogonality regularization and then\nincorporate it into the objective of the joint learning framework. In order to\nevaluate the effectiveness of the proposed framework, we exemplify it by\nrespectively taking the widely used binary-class SVM for gender classification,\nand two threshold-based ordinal regression methods (i.e., the discriminant\nlearning for ordinal regression and support vector ordinal regression) for age\nestimation, and crucially coupling both through the proposed semantic\nformulation. Moreover, we develop its kernelized nonlinear counterpart by\nderiving a representer theorem for the joint learning strategy. Finally,\nthrough extensive experiments on three aging datasets FG-NET, Morph Album I and\nMorph Album II, we demonstrate the effectiveness and superiority of the\nproposed joint learning strategy.",
    "published_date": "2016-09-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.04116v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.03938v2",
    "title": "Envy-Free Division of Land",
    "authors": [
      "Erel Segal-Halevi",
      "Shmuel Nitzan",
      "Avinatan Hassidim",
      "Yonatan Aumann"
    ],
    "author_ids": [],
    "abstract": "Classic cake-cutting algorithms enable people with different preferences to\ndivide among them a heterogeneous resource (``cake''), such that the resulting\ndivision is fair according to each agent's individual preferences. However,\nthese algorithms either ignore the geometry of the resource altogether, or\nassume it is one-dimensional. In practice, it is often required to divide\nmulti-dimensional resources, such as land-estates or advertisement spaces in\nprint or electronic media. In such cases, the geometric shape of the allotted\npiece is of crucial importance. For example, when building houses or designing\nadvertisements, in order to be useful, the allotments should be squares or\nrectangles with bounded aspect-ratio. We thus introduce the problem of fair\nland division --- fair division of a multi-dimensional resource wherein the\nallocated piece must have a pre-specified geometric shape. We present\nconstructive division algorithms that satisfy the two most prominent fairness\ncriteria, namely envy-freeness and proportionality. In settings where\nproportionality cannot be achieved due to the geometric constraints, our\nalgorithms provide a partially-proportional division, guaranteeing that the\nfraction allocated to each agent be at least a certain positive constant. We\nprove that in many natural settings the envy-freeness requirement is compatible\nwith the best attainable partial-proportionality.",
    "published_date": "2016-09-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.CG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.03938v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.03266v1",
    "title": "Recovering the History of Informed Consent for Data Science and Internet Industry Research Ethics",
    "authors": [
      "Elaine Sedenberg",
      "Anna Lauren Hoffmann"
    ],
    "author_ids": [],
    "abstract": "Respect for persons is a cornerstone value for any conception of research\nethics--though how to best realize respect in practice is an ongoing question.\nIn the late 19th and early 20th centuries, \"informed consent\" emerged as a\nparticular way to operationalize respect in medical and behavioral research\ncontexts. Today, informed consent has been challenged by increasingly advanced\nnetworked information and communication technologies (ICTs) and the massive\namounts of data they produce--challenges that have led many researchers and\nprivate companies to abandon informed consent as untenable or infeasible\nonline.\n  Against any easy dismissal, we aim to recover insights from the history of\ninformed consent as it developed from the late 19th century to today. With a\nparticular focus on the United States policy context, we show how informed\nconsent is not a fixed or monolithic concept that should be abandoned in view\nof new data-intensive and technological practices, but rather it is a mechanism\nthat has always been fluid--it has constantly evolved alongside the specific\ncontexts and practices it is intended to regulate. Building on this insight, we\narticulate some specific challenges and lessons from the history of informed\nconsent that stand to benefit current discussions of informed consent and\nresearch ethics in the context of data science and Internet industry research.",
    "published_date": "2016-09-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.03266v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.03161v2",
    "title": "Distributed algorithms for solving convex inequalities",
    "authors": [
      "Kaihong Lu",
      "Gangshan Jing",
      "Long Wang"
    ],
    "author_ids": [],
    "abstract": "In this paper, a distributed subgradient-based algorithm is proposed for\ncontinuous-time multi-agent systems to search a feasible solution to convex\ninequalities. The algorithm involves each agent achieving a state constrained\nby its own inequalities while exchanging local information with other agents\nunder a time-varying directed communication graph. With the validity of a mild\nconnectivity condition associated with the communication graph, it is shown\nthat all agents will reach agreement asymptotically and the consensus state is\nin the solution set of the inequalities. Furthermore, the method is also\nextended to solving the distributed optimization problem of minimizing the sum\nof local objective functions subject to convex inequalities. A simulation\nexample is presented to demonstrate the effectiveness of the theoretical\nresults.",
    "published_date": "2016-09-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.03161v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.02931v1",
    "title": "An architecture for ethical robots",
    "authors": [
      "Dieter Vanderelst",
      "Alan Winfield"
    ],
    "author_ids": [],
    "abstract": "Robots are becoming ever more autonomous. This expanding ability to take\nunsupervised decisions renders it imperative that mechanisms are in place to\nguarantee the safety of behaviours executed by the robot. Moreover, smart\nautonomous robots should be more than safe; they should also be explicitly\nethical -- able to both choose and justify actions that prevent harm. Indeed,\nas the cognitive, perceptual and motor capabilities of robots expand, they will\nbe expected to have an improved capacity for making moral judgements. We\npresent a control architecture that supplements existing robot controllers.\nThis so-called Ethical Layer ensures robots behave according to a predetermined\nset of ethical rules by predicting the outcomes of possible actions and\nevaluating the predicted outcomes against those rules. To validate the proposed\narchitecture, we implement it on a humanoid robot so that it behaves according\nto Asimov's laws of robotics. In a series of four experiments, using a second\nhumanoid robot as a proxy for the human, we demonstrate that the proposed\nEthical Layer enables the robot to prevent the human from coming to harm.",
    "published_date": "2016-09-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.02931v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.02770v2",
    "title": "Image and Video Mining through Online Learning",
    "authors": [
      "Andrew Gilbert",
      "Richard Bowden"
    ],
    "author_ids": [],
    "abstract": "Within the field of image and video recognition, the traditional approach is\na dataset split into fixed training and test partitions. However, the labelling\nof the training set is time-consuming, especially as datasets grow in size and\ncomplexity. Furthermore, this approach is not applicable to the home user, who\nwants to intuitively group their media without tirelessly labelling the\ncontent. Our interactive approach is able to iteratively cluster classes of\nimages and video. Our approach is based around the concept of an image\nsignature which, unlike a standard bag of words model, can express\nco-occurrence statistics as well as symbol frequency. We efficiently compute\nmetric distances between signatures despite their inherent high dimensionality\nand provide discriminative feature selection, to allow common and distinctive\nelements to be identified from a small set of user labelled examples. These\nelements are then accentuated in the image signature to increase similarity\nbetween examples and pull correct classes together. By repeating this process\nin an online learning framework, the accuracy of similarity increases\ndramatically despite labelling only a few training examples. To demonstrate\nthat the approach is agnostic to media type and features used, we evaluate on\nthree image datasets (15 scene, Caltech101 and FG-NET), a mixed text and image\ndataset (ImageTag), a dataset used in active learning (Iris) and on three\naction recognition datasets (UCF11, KTH and Hollywood2). On the UCF11 video\ndataset, the accuracy is 86.7% despite using only 90 labelled examples from a\ndataset of over 1200 videos, instead of the standard 1122 training videos. The\napproach is both scalable and efficient, with a single iteration over the full\nUCF11 dataset of around 1200 videos taking approximately 1 minute on a standard\ndesktop machine.",
    "published_date": "2016-09-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.02770v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.02208v1",
    "title": "Breaking the Bandwidth Barrier: Geometrical Adaptive Entropy Estimation",
    "authors": [
      "Weihao Gao",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "author_ids": [],
    "abstract": "Estimators of information theoretic measures such as entropy and mutual\ninformation are a basic workhorse for many downstream applications in modern\ndata science. State of the art approaches have been either geometric (nearest\nneighbor (NN) based) or kernel based (with a globally chosen bandwidth). In\nthis paper, we combine both these approaches to design new estimators of\nentropy and mutual information that outperform state of the art methods. Our\nestimator uses local bandwidth choices of $k$-NN distances with a finite $k$,\nindependent of the sample size. Such a local and data dependent choice improves\nperformance in practice, but the bandwidth is vanishing at a fast rate, leading\nto a non-vanishing bias. We show that the asymptotic bias of the proposed\nestimator is universal; it is independent of the underlying distribution.\nHence, it can be pre-computed and subtracted from the estimate. As a byproduct,\nwe obtain a unified way of obtaining both kernel and NN estimators. The\ncorresponding theoretical contribution relating the asymptotic geometry of\nnearest neighbors to order statistics is of independent mathematical interest.",
    "published_date": "2016-09-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.02208v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.02107v1",
    "title": "Quadrature Amplitude Modulation Division for Multiuser MISO Broadcast Channels",
    "authors": [
      "Zheng Dong",
      "Yan-Yu Zhang",
      "Jian-Kang Zhang",
      "Xiang-Chuan Gao"
    ],
    "author_ids": [],
    "abstract": "This paper considers a discrete-time multiuser multiple-input single-output\n(MISO) Gaussian broadcast channel~(BC), in which channel state information\n(CSI) is available at both the transmitter and the receivers. The flexible and\nexplicit design of a uniquely decomposable constellation group (UDCG) is\nprovided based on pulse amplitude modulation (PAM) and rectangular quadrature\namplitude modulation (QAM) constellations. With this, a modulation division\n(MD) transmission scheme is developed for the MISO BC. The proposed MD scheme\nenables each receiver to uniquely and efficiently detect their desired signals\nfrom the superposition of mutually interfering cochannel signals in the absence\nof noise. In our design, the optimal transmitter beamforming problem is solved\nin a closed-form for two-user MISO BC using max-min fairness as a design\ncriterion. Then, for a general case with more than two receivers, we develop a\nuser-grouping-based beamforming scheme, where the grouping method, beamforming\nvector design and power allocation problems are addressed by using weighted\nmax-min fairness. It is shown that our proposed approach has a lower\nprobability of error compared with the zero-forcing (ZF) method when the\nHermitian angle between the two channel vectors is small in a two-user case. In\naddition, simulation results also reveal that for the general channel model\nwith more than two users, our user-grouping-based scheme significantly\noutperforms the ZF, time division (TD), minimum mean-square error (MMSE) and\nsignal-to-leakage-and-noise ratio (SLNR) based techniques in moderate and high\nSNR regimes when the number of users approaches to the number of base station\n(BS) antennas and it degrades into the ZF scheme when the number of users is\nfar less than the number of BS antennas in Rayleigh fading channels.",
    "published_date": "2016-09-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.02107v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.01921v2",
    "title": "A Model for Partial Kantian Cooperation",
    "authors": [
      "Ioannis Kordonis"
    ],
    "author_ids": [],
    "abstract": "In several game situations, the behavior of the players may depend not only\non individual interests, but also on what each player considers as the correct\nthing to do. This work presents a game theoretic model, aiming to describe game\nsituations in which the players' behavior is affected by ethical\nconsiderations. Particularly, we assume that they partially follow, Kant's\n`Categorical Imperative'. The model is stated for games with a continuum of\nplayers. The basic assumption made is that the participants perceive that they\nbelong to virtual (imagined) groups, in which they optimize their actions as if\nthey were bound to follow the same strategy. A partially cooperative\nequilibrium, called $r$-Kant-Nash equilibrium is then introduced. We then study\nthe relationship of the $r$-Kant-Nash equilibrium with the Nash, (Bentham-)\nHarsanyi, Rawls difference and Roemer solutions. For the case where the set of\npossible player types is finite, we prove sufficient conditions for the\nexistence and uniqueness of the $r$-Kant-Nash equilibrium and the equilibrium\nis characterized in terms of a variational inequality. For the case of\ncontinuous types, necessary conditions characterizing the partial Kantian\nequilibria are derived using a reduction to a set of optimal control problems.\nFinally, some numerical examples are given.",
    "published_date": "2016-09-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.01921v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1610.01502v2",
    "title": "Template shape estimation: correcting an asymptotic bias",
    "authors": [
      "Nina Miolane",
      "Susan Holmes",
      "Xavier Pennec"
    ],
    "author_ids": [],
    "abstract": "We use tools from geometric statistics to analyze the usual estimation\nprocedure of a template shape. This applies to shapes from landmarks, curves,\nsurfaces, images etc. We demonstrate the asymptotic bias of the template shape\nestimation using the stratified geometry of the shape space. We give a Taylor\nexpansion of the bias with respect to a parameter $\\sigma$ describing the\nmeasurement error on the data. We propose two bootstrap procedures that\nquantify the bias and correct it, if needed. They are applicable for any type\nof shape data. We give a rule of thumb to provide intuition on whether the bias\nhas to be corrected. This exhibits the parameters that control the bias'\nmagnitude. We illustrate our results on simulated and real shape data.",
    "published_date": "2016-09-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "math.DG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1610.01502v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1609.01383v1",
    "title": "Rate-Distortion Analysis of Quantizers with Error Feedback",
    "authors": [
      "Shuichi Ohno",
      "Teruyuki Shiraki",
      "M. Rizwan Tariq",
      "Masaaki Nagahara"
    ],
    "author_ids": [],
    "abstract": "A Delta-Sigma modulator that is often utilized to convert analog signals into\ndigital signals can be modeled as a static uniform quantizer with an error\nfeedback filter. In this paper, we present a rate-distortion analysis of\nquantizers with error feedback including the Delta-Sigma modulators, assuming\nthat the error owing to overloading in the static quantizer is negligible. We\ndemonstrate that the amplitude response of the optimal error feedback filter\nthat minimizes the mean squared quantization error can be parameterized by one\nparameter. This parameterization enables us to determine the optimal error\nfeedback filter numerically. The relationship between the number of bits used\nfor the quantization and the achievable mean squared error can be obtained\nusing the optimal error feedback filter. This clarifies the rate-distortion\nproperty of quantizers with error feedback. Then, ideal optimal error feedback\nfilters are approximated by practical filters using the Yule-Walker method and\nthe linear matrix inequality-based method. Numerical examples are provided for\ndemonstrating our analysis and synthesis.",
    "published_date": "2016-09-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.01383v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.01374v1",
    "title": "Test-Bed based Comparison of Single and Parallel TCP and the Impact Of Parallelism on Throughput and Fairness in Heterogenous Networks",
    "authors": [
      "Mohamed A. Alrshah",
      "Mohamed Othman"
    ],
    "author_ids": [],
    "abstract": "Parallel Transport Control Protocol (TCP) has been used to effectively\nutilize bandwidth for data intensive applications over high Bandwidth-Delay\nProduct (BDP) networks. On the other hand, it has been argued that, a\nsingle-based TCP connection with proper modification such as HSTCP can emulate\nand capture the robustness of parallel TCP and can well replace it. In this\nwork a Comparison between Single-Based and the proposed parallel TCP has been\nconducted to show the differences in their performance measurements such as\nthroughput performance and throughput ratio, as well as the link sharing\nFairness also has been observed to show the impact of using the proposed\nParallel TCP on the existing Single-Based TCP connections. The experiment\nresults show that, single-based TCP cannot overcome Parallel TCP especially in\nheterogeneous networks where the packet losses are common. Furthermore, the\nproposed parallel TCP does not affect TCP fairness which makes parallel TCP\nhighly recommended to effectively utilize bandwidth for data intensive\napplications.",
    "published_date": "2016-09-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.01374v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.01030v2",
    "title": "Device-independent characterizations of a shared quantum state independent of any Bell inequalities",
    "authors": [
      "Zhaohui Wei",
      "Jamie Sikora"
    ],
    "author_ids": [],
    "abstract": "In a Bell experiment two parties share a quantum state and perform local\nmeasurements on their subsystems separately, and the statistics of the\nmeasurement outcomes are recorded as a Bell correlation. For any Bell\ncorrelation, it turns out {that} a quantum state with minimal size that is able\nto produce this correlation can always be pure. In this work, we first exhibit\ntwo device-independent characterizations for the pure state that Alice and Bob\nshare using only the correlation data. Specifically, we give two conditions\nthat the Schmidt coefficients must satisfy, which can be tight, and have\nvarious applications in quantum tasks. First, one of the characterizations\nallows us to bound the entanglement between Alice and Bob using Renyi entropies\nand also to {bound} the underlying Hilbert space dimension. Second, when the\n{Hilbert space dimension bound} is tight, the shared pure quantum state has to\nbe maximally entangled. Third, the second characterization gives a sufficient\ncondition that a Bell correlation cannot be generated by particular quantum\nstates. We also show that our results can be generalized to the case of shared\nmixed states.",
    "published_date": "2016-09-05T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.01030v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.02171v1",
    "title": "The Effect of Class Imbalance and Order on Crowdsourced Relevance Judgments",
    "authors": [
      "Rehab K. Qarout",
      "Alessandro Checco",
      "Gianluca Demartini"
    ],
    "author_ids": [],
    "abstract": "In this paper we study the effect on crowd worker efficiency and\neffectiveness of the dominance of one class in the data they process. We aim at\nunderstanding if there is any positive or negative bias in workers seeing many\nnegative examples in the identification of positive labels. To test our\nhypothesis, we design an experiment where crowd workers are asked to judge the\nrelevance of documents presented in different orders. Our findings indicate\nthat there is a significant improvement in the quality of relevance judgements\nwhen presenting relevant results before the non-relevant ones.",
    "published_date": "2016-09-04T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IR",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.02171v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1609.00302v1",
    "title": "Sampling-based verification of Lyapunov's inequality for piecewise continuous nonlinear systems",
    "authors": [
      "Ruxandra Bobiti",
      "Mircea Lazar"
    ],
    "author_ids": [],
    "abstract": "This paper considers a sampling-based approach to stability verification for\npiecewise continuous nonlinear systems via Lyapunov functions. Depending on the\nsystem dynamics, the candidate Lyapunov function and the set of initial states\nof interest, one generally needs to handle large, possibly non-convex or\nnon-feasible optimization problems. To avoid such problems, we propose a\nconstructive and systematically applicable sampling-based method to Lyapunov's\ninequality verification. This approach proposes verification of the decrease\ncondition for a candidate Lyapunov function on a finite sampling of a bounded\nset of initial conditions and then it extends the validity of the Lyapunov\nfunction to an infinite set of initial conditions by automatically exploiting\ncontinuity properties. This result is based on multi-resolution sampling, to\nperform efficient state- space exploration. Using hyper-rectangles as basic\nsampling blocks, to account for different constraint scales on different\nstates, further reduces the amount of samples to be verified. Moreover, the\nverification is decentralized in the sampling points, which makes the method\nscalable. The proposed methodology is illustrated through examples.",
    "published_date": "2016-09-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1609.00302v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.08761v2",
    "title": "hi-RF: Incremental Learning Random Forest for large-scale multi-class Data Classification",
    "authors": [
      "Tingting Xie",
      "Yuxing Peng",
      "Changjian Wang"
    ],
    "author_ids": [],
    "abstract": "In recent years, dynamically growing data and incrementally growing number of\nclasses pose new challenges to large-scale data classification research. Most\ntraditional methods struggle to balance the precision and computational burden\nwhen data and its number of classes increased. However, some methods are with\nweak precision, and the others are time-consuming. In this paper, we propose an\nincremental learning method, namely, heterogeneous incremental Nearest Class\nMean Random Forest (hi-RF), to handle this issue. It is a heterogeneous method\nthat either replaces trees or updates trees leaves in the random forest\nadaptively, to reduce the computational time in comparable performance, when\ndata of new classes arrive. Specifically, to keep the accuracy, one proportion\nof trees are replaced by new NCM decision trees; to reduce the computational\nload, the rest trees are updated their leaves probabilities only. Most of all,\nout-of-bag estimation and out-of-bag boosting are proposed to balance the\naccuracy and the computational efficiency. Fair experiments were conducted and\ndemonstrated its comparable precision with much less computational time.",
    "published_date": "2016-08-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.08761v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.08738v1",
    "title": "A Dictionary-based Approach to Racism Detection in Dutch Social Media",
    "authors": [
      "Stéphan Tulkens",
      "Lisa Hilte",
      "Elise Lodewyckx",
      "Ben Verhoeven",
      "Walter Daelemans"
    ],
    "author_ids": [],
    "abstract": "We present a dictionary-based approach to racism detection in Dutch social\nmedia comments, which were retrieved from two public Belgian social media sites\nlikely to attract racist reactions. These comments were labeled as racist or\nnon-racist by multiple annotators. For our approach, three discourse\ndictionaries were created: first, we created a dictionary by retrieving\npossibly racist and more neutral terms from the training data, and then\naugmenting these with more general words to remove some bias. A second\ndictionary was created through automatic expansion using a \\texttt{word2vec}\nmodel trained on a large corpus of general Dutch text. Finally, a third\ndictionary was created by manually filtering out incorrect expansions. We\ntrained multiple Support Vector Machines, using the distribution of words over\nthe different categories in the dictionaries as features. The best-performing\nmodel used the manually cleaned dictionary and obtained an F-score of 0.46 for\nthe racist class on a test set consisting of unseen Dutch comments, retrieved\nfrom the same sites used for the training set. The automated expansion of the\ndictionary only slightly boosted the model's performance, and this increase in\nperformance was not statistically significant. The fact that the coverage of\nthe expanded dictionaries did increase indicates that the words that were\nautomatically added did occur in the corpus, but were not able to meaningfully\nimpact performance. The dictionaries, code, and the procedure for requesting\nthe corpus are available at: https://github.com/clips/hades",
    "published_date": "2016-08-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.08738v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.08414v3",
    "title": "Identification of milestone papers through time-balanced network centrality",
    "authors": [
      "Manuel Sebastian Mariani",
      "Matus Medo",
      "Yi-Cheng Zhang"
    ],
    "author_ids": [],
    "abstract": "Citations between scientific papers and related bibliometric indices, such as\nthe $h$-index for authors and the impact factor for journals, are being\nincreasingly used - often in controversial ways - as quantitative tools for\nresearch evaluation. Yet, a fundamental research question remains still open:\nto which extent do quantitative metrics capture the significance of scientific\nworks? We analyze the network of citations among the $449,935$ papers published\nby the American Physical Society (APS) journals between 1893 and 2009, and\nfocus on the comparison of metrics built on the citation count with\nnetwork-based metrics. We contrast five article-level metrics with respect to\nthe rankings that they assign to a set of fundamental papers, called Milestone\nLetters, carefully selected by the APS editors for \"making long-lived\ncontributions to physics, either by announcing significant discoveries, or by\ninitiating new areas of research\". A new metric, which combines PageRank\ncentrality with the explicit requirement that paper score is not biased by\npaper age, is the best-performing metric overall in identifying the Milestone\nLetters. The lack of time bias in the new metric makes it also possible to use\nit to compare papers of different age on the same scale. We find that\nnetwork-based metrics identify the Milestone Letters better than metrics based\non the citation count, which suggests that the structure of the citation\nnetwork contains information that can be used to improve the ranking of\nscientific publications. The methods and results presented here are relevant\nfor all evolving systems where network centrality metrics are applied, for\nexample the World Wide Web and online social networks. An interactive Web\nplatform where it is possible to view the ranking of the APS papers by rescaled\nPageRank is available at the address \\url{http://www.sciencenow.info}.",
    "published_date": "2016-08-30T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.DL",
      "cs.IR",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.08414v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.08469v1",
    "title": "On the Efficiency and Fairness of Multiplayer HTTP-based Adaptive Video Streaming",
    "authors": [
      "Xiaoqi Yin",
      "Mihovil Bartulović",
      "Vyas Sekar",
      "Bruno Sinopoli"
    ],
    "author_ids": [],
    "abstract": "User-perceived quality-of-experience (QoE) is critical in internet video\ndelivery systems. Extensive prior work has studied the design of client-side\nbitrate adaptation algorithms to maximize single-player QoE. However,\nmultiplayer QoE fairness becomes critical as the growth of video traffic makes\nit more likely that multiple players share a bottleneck in the network. Despite\nseveral recent proposals, there is still a series of open questions. In this\npaper, we bring the problem space to light from a control theory perspective by\nformalizing the multiplayer QoE fairness problem and addressing two key\nquestions in the broader problem space. First, we derive the sufficient\nconditions of convergence to steady state QoE fairness under TCP-based\nbandwidth sharing scheme. Based on the insight from this analysis that\nin-network active bandwidth allocation is needed, we propose a non-linear\nMPC-based, router-assisted bandwidth allocation algorithm that regards each\nplayer as closed-loop systems. We use trace-driven simulation to show the\nimprovement over existing approaches. We identify several research directions\nenabled by the control theoretic modeling and envision that control theory can\nplay an important role on guiding real system design in adaptive video\nstreaming.",
    "published_date": "2016-08-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.MM",
      "cs.NI",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.08469v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.07895v1",
    "title": "Human-Algorithm Interaction Biases in the Big Data Cycle: A Markov Chain Iterated Learning Framework",
    "authors": [
      "Olfa Nasraoui",
      "Patrick Shafto"
    ],
    "author_ids": [],
    "abstract": "Early supervised machine learning algorithms have relied on reliable expert\nlabels to build predictive models. However, the gates of data generation have\nrecently been opened to a wider base of users who started participating\nincreasingly with casual labeling, rating, annotating, etc. The increased\nonline presence and participation of humans has led not only to a\ndemocratization of unchecked inputs to algorithms, but also to a wide\ndemocratization of the \"consumption\" of machine learning algorithms' outputs by\ngeneral users. Hence, these algorithms, many of which are becoming essential\nbuilding blocks of recommender systems and other information filters, started\ninteracting with users at unprecedented rates. The result is machine learning\nalgorithms that consume more and more data that is unchecked, or at the very\nleast, not fitting conventional assumptions made by various machine learning\nalgorithms. These include biased samples, biased labels, diverging training and\ntesting sets, and cyclical interaction between algorithms, humans, information\nconsumed by humans, and data consumed by algorithms. Yet, the continuous\ninteraction between humans and algorithms is rarely taken into account in\nmachine learning algorithm design and analysis. In this paper, we present a\npreliminary theoretical model and analysis of the mutual interaction between\nhumans and algorithms, based on an iterated learning framework that is inspired\nfrom the study of human language evolution. We also define the concepts of\nhuman and algorithm blind spots and outline machine learning approaches to mend\niterated bias through two novel notions: antidotes and reactive learning.",
    "published_date": "2016-08-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.HC",
      "I.2.6; K.4.m; H.2.8; H.3.3; H.1.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.07895v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.07187v4",
    "title": "Semantics derived automatically from language corpora contain human-like biases",
    "authors": [
      "Aylin Caliskan",
      "Joanna J. Bryson",
      "Arvind Narayanan"
    ],
    "author_ids": [],
    "abstract": "Artificial intelligence and machine learning are in a period of astounding\ngrowth. However, there are concerns that these technologies may be used, either\nwith or without intention, to perpetuate the prejudice and unfairness that\nunfortunately characterizes many human institutions. Here we show for the first\ntime that human-like semantic biases result from the application of standard\nmachine learning to ordinary language---the same sort of language humans are\nexposed to every day. We replicate a spectrum of standard human biases as\nexposed by the Implicit Association Test and other well-known psychological\nstudies. We replicate these using a widely used, purely statistical\nmachine-learning model---namely, the GloVe word embedding---trained on a corpus\nof text from the Web. Our results indicate that language itself contains\nrecoverable and accurate imprints of our historic biases, whether these are\nmorally neutral as towards insects or flowers, problematic as towards race or\ngender, or even simply veridical, reflecting the {\\em status quo} for the\ndistribution of gender with respect to careers or first names. These\nregularities are captured by machine learning along with the rest of semantics.\nIn addition to our empirical findings concerning language, we also contribute\nnew methods for evaluating bias in text, the Word Embedding Association Test\n(WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results\nhave implications not only for AI and machine learning, but also for the fields\nof psychology, sociology, and human ethics, since they raise the possibility\nthat mere exposure to everyday language can account for the biases we replicate\nhere.",
    "published_date": "2016-08-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.07187v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.06716v1",
    "title": "A Novel Approach for Shot Boundary Detection in Videos",
    "authors": [
      "D. S. Guru",
      "Mahamad Suhil",
      "P. Lolika"
    ],
    "author_ids": [],
    "abstract": "This paper presents a novel approach for video shot boundary detection. The\nproposed approach is based on split and merge concept. A fisher linear\ndiscriminant criterion is used to guide the process of both splitting and\nmerging. For the purpose of capturing the between class and within class\nscatter we employ 2D2 FLD method which works on texture feature of regions in\neach frame of a video. Further to reduce the complexity of the process we\npropose to employ spectral clustering to group related regions together to a\nsingle there by achieving reduction in dimension. The proposed method is\nexperimentally also validated on a cricket video. It is revealed that shots\nobtained by the proposed approach are highly cohesive and loosely coupled",
    "published_date": "2016-08-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.06716v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.05889v1",
    "title": "Online Feature Selection with Group Structure Analysis",
    "authors": [
      "Jing Wang",
      "Meng Wang",
      "Peipei Li",
      "Luoqi Liu",
      "Zhongqiu Zhao",
      "Xuegang Hu",
      "Xindong Wu"
    ],
    "author_ids": [],
    "abstract": "Online selection of dynamic features has attracted intensive interest in\nrecent years. However, existing online feature selection methods evaluate\nfeatures individually and ignore the underlying structure of feature stream.\nFor instance, in image analysis, features are generated in groups which\nrepresent color, texture and other visual information. Simply breaking the\ngroup structure in feature selection may degrade performance. Motivated by this\nfact, we formulate the problem as an online group feature selection. The\nproblem assumes that features are generated individually but there are group\nstructure in the feature stream. To the best of our knowledge, this is the\nfirst time that the correlation among feature stream has been considered in the\nonline feature selection process. To solve this problem, we develop a novel\nonline group feature selection method named OGFS. Our proposed approach\nconsists of two stages: online intra-group selection and online inter-group\nselection. In the intra-group selection, we design a criterion based on\nspectral analysis to select discriminative features in each group. In the\ninter-group selection, we utilize a linear regression model to select an\noptimal subset. This two-stage procedure continues until there are no more\nfeatures arriving or some predefined stopping conditions are met. %Our method\nhas been applied Finally, we apply our method to multiple tasks including image\nclassification %, face verification and face verification. Extensive empirical\nstudies performed on real-world and benchmark data sets demonstrate that our\nmethod outperforms other state-of-the-art online feature selection %method\nmethods.",
    "published_date": "2016-08-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.05889v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.05347v1",
    "title": "Probabilistic Data Analysis with Probabilistic Programming",
    "authors": [
      "Feras Saad",
      "Vikash Mansinghka"
    ],
    "author_ids": [],
    "abstract": "Probabilistic techniques are central to data analysis, but different\napproaches can be difficult to apply, combine, and compare. This paper\nintroduces composable generative population models (CGPMs), a computational\nabstraction that extends directed graphical models and can be used to describe\nand compose a broad class of probabilistic data analysis techniques. Examples\ninclude hierarchical Bayesian models, multivariate kernel methods,\ndiscriminative machine learning, clustering algorithms, dimensionality\nreduction, and arbitrary probabilistic programs. We also demonstrate the\nintegration of CGPMs into BayesDB, a probabilistic programming platform that\ncan express data analysis tasks using a modeling language and a structured\nquery language. The practical value is illustrated in two ways. First, CGPMs\nare used in an analysis that identifies satellite data records which probably\nviolate Kepler's Third Law, by composing causal probabilistic programs with\nnon-parametric Bayes in under 50 lines of probabilistic code. Second, for\nseveral representative data analysis tasks, we report on lines of code and\naccuracy measurements of various CGPMs, plus comparisons with standard baseline\nsolutions from Python and MATLAB libraries.",
    "published_date": "2016-08-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.05347v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.05315v2",
    "title": "A Multi-Dimensional Fairness Combinatorial Double-Sided Auction Model in Cloud Environment",
    "authors": [
      "Reihaneh Hassanzadeh",
      "Ali Movaghar",
      "Hamid Reza Hassanzadeh"
    ],
    "author_ids": [],
    "abstract": "In cloud investment markets, consumers are looking for the lowest cost and a\ndesirable fairness while providers are looking for strategies to achieve the\nhighest possible profit and return. Most existing models for auction-based\nresource allocation in cloud environments only consider the overall profit\nincrease and ignore the profit of each participant individually or the\ndifference between the rich and the poor participants. This paper proposes a\nmulti-dimensional fairness combinatorial double auction (MDFCDA) model which\nstrikes a balance between the revenue and the fairness among participants. We\nsolve a winner determination problem (WDP) through integer programming which\nincorporates the fairness attribute based on the history of participants which\nis stored in a repository. Our evaluation results show that the proposed model\nincreases the willingness of participants to take part in the next auction\nrounds. Moreover, the average percentage of resource utilization is increased.",
    "published_date": "2016-08-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.05315v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.04764v1",
    "title": "Bounded Turing Reductions and Data Processing Inequalities for Sequences",
    "authors": [
      "Adam Case"
    ],
    "author_ids": [],
    "abstract": "A data processing inequality states that the quantity of shared information\nbetween two entities (e.g. signals, strings) cannot be significantly increased\nwhen one of the entities is processed by certain kinds of transformations. In\nthis paper, we prove several data processing inequalities for sequences, where\nthe transformations are bounded Turing functionals and the shared information\nis measured by the lower and upper mutual dimensions between sequences.\n  We show that, for all sequences $X,Y,$ and $Z$, if $Z$ is computable\nLipschitz reducible to $X$, then \\[ mdim(Z:Y) \\leq mdim(X:Y) \\text{ and }\nMdim(Z:Y) \\leq Mdim(X:Y). \\] We also show how to derive different data\nprocessing inequalities by making adjustments to the computable bounds of the\nuse of a Turing functional.\n  The yield of a Turing functional $\\Phi^S$ with access to at most $n$ bits of\nthe oracle $S$ is the smallest input $m \\in \\mathbb{N}$ such that $\\Phi^{S\n\\upharpoonright n}(m)\\uparrow$. We show how to derive reverse data processing\ninequalities (i.e., data processing inequalities where the transformation may\nsignificantly increase the shared information between two entities) for\nsequences by applying computable bounds to the yield of a Turing functional.",
    "published_date": "2016-08-16T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CC",
      "68Q30",
      "F.0"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.04764v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.04363v2",
    "title": "Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification",
    "authors": [
      "Justin Salamon",
      "Juan Pablo Bello"
    ],
    "author_ids": [],
    "abstract": "The ability of deep convolutional neural networks (CNN) to learn\ndiscriminative spectro-temporal patterns makes them well suited to\nenvironmental sound classification. However, the relative scarcity of labeled\ndata has impeded the exploitation of this family of high-capacity models. This\nstudy has two primary contributions: first, we propose a deep convolutional\nneural network architecture for environmental sound classification. Second, we\npropose the use of audio data augmentation for overcoming the problem of data\nscarcity and explore the influence of different augmentations on the\nperformance of the proposed CNN architecture. Combined with data augmentation,\nthe proposed model produces state-of-the-art results for environmental sound\nclassification. We show that the improved performance stems from the\ncombination of a deep, high-capacity model and an augmented training set: this\ncombination outperforms both the proposed CNN without augmentation and a\n\"shallow\" dictionary learning model with augmentation. Finally, we examine the\ninfluence of each augmentation on the model's classification accuracy for each\nclass, and observe that the accuracy for each class is influenced differently\nby each augmentation, suggesting that the performance of the model could be\nimproved further by applying class-conditional data augmentation.",
    "published_date": "2016-08-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.04363v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.04260v2",
    "title": "Location Aware Opportunistic Bandwidth Sharing between Static and Mobile Users with Stochastic Learning in Cellular Networks",
    "authors": [
      "Arpan Chattopadhyay",
      "Bartłomiej Błaszczyszyn",
      "Eitan Altman"
    ],
    "author_ids": [],
    "abstract": "We consider location-dependent opportunistic bandwidth sharing between static\nand mobile downlink users in a cellular network. Each cell has some fixed\nnumber of static users. Mobile users enter the cell, move inside the cell for\nsome time and then leave the cell. In order to provide higher data rate to\nmobile users, we propose to provide higher bandwidth to the mobile users at\nfavourable times and locations, and provide higher bandwidth to the static\nusers in other times. We formulate the problem as a long run average reward\nMarkov decision process (MDP) where the per-step reward is a linear combination\nof instantaneous data volumes received by static and mobile users, and find the\noptimal policy. The transition structure of this MDP is not known in general.\nTo alleviate this issue, we propose a learning algorithm based on single\ntimescale stochastic approximation. Also, noting that the unconstrained MDP can\nbe used to solve a constrained problem, we provide a learning algorithm based\non multi-timescale stochastic approximation. The results are extended to\naddress the issue of fair bandwidth sharing between the two classes of users.\nNumerical results demonstrate performance improvement by our scheme, and also\nthe trade-off between performance gain and fairness.",
    "published_date": "2016-08-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.04260v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.03735v2",
    "title": "Causal Inference for Social Discrimination Reasoning",
    "authors": [
      "Bilal Qureshi",
      "Faisal Kamiran",
      "Asim Karim",
      "Salvatore Ruggieri",
      "Dino Pedreschi"
    ],
    "author_ids": [],
    "abstract": "The discovery of discriminatory bias in human or automated decision making is\na task of increasing importance and difficulty, exacerbated by the pervasive\nuse of machine learning and data mining. Currently, discrimination discovery\nlargely relies upon correlation analysis of decisions records, disregarding the\nimpact of confounding biases. We present a method for causal discrimination\ndiscovery based on propensity score analysis, a statistical tool for filtering\nout the effect of confounding variables. We introduce causal measures of\ndiscrimination which quantify the effect of group membership on the decisions,\nand highlight causal discrimination/favoritism patterns by learning regression\ntrees over the novel measures. We validate our approach on two real world\ndatasets. Our proposed framework for causal discrimination has the potential to\nenhance the transparency of machine learning with tools for detecting\ndiscriminatory bias both in the training data and in the learning algorithms.",
    "published_date": "2016-08-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.03735v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.03380v1",
    "title": "Distributed Association and Relaying with Fairness in Millimeter Wave Networks",
    "authors": [
      "Yuzhe Xu",
      "Hossein Shokri-Ghadikolaei",
      "Carlo Fischione"
    ],
    "author_ids": [],
    "abstract": "Millimeter wave (mmWave) systems are emerging as an essential technology to\nenable extremely high data rate wireless communications. The main limiting\nfactors of mmWave systems are blockage (high penetration loss) and deafness\n(misalignment between the beams of the transmitter and receiver). To alleviate\nthese problems, it is imperative to incorporate efficient association and\nrelaying between terminals and access points. Unfortunately, the existing\nassociation techniques are designed for the traditional interference-limited\nnetworks, and thus are highly suboptimal for mmWave communications due to\nnarrow-beam operations and the resulting non-negligible interference-free\nbehavior. This paper introduces a distributed approach that solves the joint\nassociation and relaying problem in mmWave networks considering the load\nbalancing at access points. The problem is posed as a novel stochastic\noptimization problem, which is solved by distributed auction algorithms where\nthe clients and relays act asynchronously to achieve optimal\nclient-relay-access point association. It is shown that the algorithms provably\nconverge to a solution that maximizes the aggregate logarithmic utility within\na desired bound. Numerical results allow to quantify the performance\nenhancements introduced by the relays, and the substantial improvements of the\nnetwork throughput and fairness among the clients by the proposed association\nmethod as compared to standard approaches. It is concluded that mmWave\ncommunications with proper association and relaying mechanisms can support\nextremely high data rates, connection reliability, and fairness among the\nclients.",
    "published_date": "2016-08-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.03380v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.03217v1",
    "title": "DeepCAMP: Deep Convolutional Action & Attribute Mid-Level Patterns",
    "authors": [
      "Ali Diba",
      "Ali Mohammad Pazandeh",
      "Hamed Pirsiavash",
      "Luc Van Gool"
    ],
    "author_ids": [],
    "abstract": "The recognition of human actions and the determination of human attributes\nare two tasks that call for fine-grained classification. Indeed, often rather\nsmall and inconspicuous objects and features have to be detected to tell their\nclasses apart. In order to deal with this challenge, we propose a novel\nconvolutional neural network that mines mid-level image patches that are\nsufficiently dedicated to resolve the corresponding subtleties. In particular,\nwe train a newly de- signed CNN (DeepPattern) that learns discriminative patch\ngroups. There are two innovative aspects to this. On the one hand we pay\nattention to contextual information in an origi- nal fashion. On the other\nhand, we let an iteration of feature learning and patch clustering purify the\nset of dedicated patches that we use. We validate our method for action clas-\nsification on two challenging datasets: PASCAL VOC 2012 Action and Stanford 40\nActions, and for attribute recogni- tion we use the Berkeley Attributes of\nPeople dataset. Our discriminative mid-level mining CNN obtains state-of-the-\nart results on these datasets, without a need for annotations about parts and\nposes.",
    "published_date": "2016-08-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.03217v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.03073v1",
    "title": "Ranking Competitors Using Degree-Neutralized Random Walks",
    "authors": [
      "Seungkyu Shin",
      "Sebastian E. Ahnert",
      "Juyong Park"
    ],
    "author_ids": [],
    "abstract": "Competition is ubiquitous in many complex biological, social, and\ntechnological systems, playing an integral role in the evolutionary dynamics of\nthe systems. It is often useful to determine the dominance hierarchy or the\nrankings of the components of the system that compete for survival and success\nbased on the outcomes of the competitions between them. Here we propose a\nranking method based on the random walk on the network representing the\ncompetitors as nodes and competitions as directed edges with asymmetric\nweights. We use the edge weights and node degrees to define the gradient on\neach edge that guides the random walker towards the weaker (or the stronger)\nnode, which enables us to interpret the steady-state occupancy as the measure\nof the node's weakness (or strength) that is free of unwarranted degree-induced\nbias. We apply our method to two real-world competition networks and explore\nthe issues of ranking stabilization and prediction accuracy, finding that our\nmethod outperforms other methods including the baseline win--loss differential\nmethod in sparse networks.",
    "published_date": "2016-08-10T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.03073v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.02639v1",
    "title": "GID: Graph-based Intrusion Detection on Massive Process Traces for Enterprise Security Systems",
    "authors": [
      "Boxiang Dong",
      "Zhengzhang Chen",
      "Hui Wang",
      "Lu-An Tang",
      "Kai Zhang",
      "Ying Lin",
      "Haifeng Chen",
      "Guofei Jiang"
    ],
    "author_ids": [],
    "abstract": "Intrusion detection system (IDS) is an important part of enterprise security\nsystem architecture. In particular, anomaly-based IDS has been widely applied\nto detect abnormal process behaviors that deviate from the majority. However,\nsuch abnormal behavior usually consists of a series of low-level heterogeneous\nevents. The gap between the low-level events and the high-level abnormal\nbehaviors makes it hard to infer which single events are related to the real\nabnormal activities, especially considering that there are massive \"noisy\"\nlow-level events happening in between. Hence, the existing work that focus on\ndetecting single entities/events can hardly achieve high detection accuracy.\nDifferent from previous work, we design and implement GID, an efficient\ngraph-based intrusion detection technique that can identify abnormal event\nsequences from a massive heterogeneous process traces with high accuracy. GID\nfirst builds a compact graph structure to capture the interactions between\ndifferent system entities. The suspiciousness or anomaly score of process paths\nis then measured by leveraging random walk technique to the constructed acyclic\ndirected graph. To eliminate the score bias from the path length, the Box-Cox\npower transformation based approach is introduced to normalize the anomaly\nscores so that the scores of paths of different lengths have the same\ndistribution. The efficiency of suspicious path discovery is further improved\nby the proposed optimization scheme. We fully implement our GID algorithm and\ndeploy it into a real enterprise security system, and it greatly helps detect\nthe advanced threats, and optimize the incident response. Executing GID on\nsystem monitoring datasets showing that GID is efficient (about 2 million\nrecords per minute) and accurate (higher than 80% in terms of detection rate).",
    "published_date": "2016-08-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.02639v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.02326v1",
    "title": "Jury-Contestant Bipartite Competition Network: Identifying Biased Scores and Their Impact on Network Structure Inference",
    "authors": [
      "Gyuhyeon Jeon",
      "Juyong Park"
    ],
    "author_ids": [],
    "abstract": "A common form of competition is one where judges grade contestants'\nperformances which are then compiled to determine the final ranking of the\ncontestants. Unlike in another common form of competition where two contestants\nplay a head-to-head match to produce a winner as in football or basketball, the\nobjectivity of judges are prone to be questioned, potentially undermining the\npublic's trust in the fairness of the competition. In this work we show, by\nmodeling the judge--contestant competition as a weighted bipartite network, how\nwe can identify biased scores and measure their impact on our inference of the\nnetwork structure. Analyzing the prestigious International Chopin Piano\nCompetition of 2015 with a well-publicized scoring controversy as an example,\nwe show that even a single statistically uncharacteristic score can be enough\nto gravely distort our inference of the community structure, demonstrating the\nimportance of detecting and eliminating biases. In the process we also find\nthat there does not exist a significant system-wide bias of the judges based on\nthe the race of the contestants.",
    "published_date": "2016-08-08T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.02326v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.02255v1",
    "title": "Spontaneous Facial Micro-Expression Recognition using Discriminative Spatiotemporal Local Binary Pattern with an Improved Integral Projection",
    "authors": [
      "Xiaohua Huang",
      "Sujing Wang",
      "Xin Liu",
      "Guoying Zhao",
      "Xiaoyi Feng",
      "Matti Pietikainen"
    ],
    "author_ids": [],
    "abstract": "Recently, there are increasing interests in inferring mirco-expression from\nfacial image sequences. Due to subtle facial movement of micro-expressions,\nfeature extraction has become an important and critical issue for spontaneous\nfacial micro-expression recognition. Recent works usually used spatiotemporal\nlocal binary pattern for micro-expression analysis. However, the commonly used\nspatiotemporal local binary pattern considers dynamic texture information to\nrepresent face images while misses the shape attribute of face images. On the\nother hand, their works extracted the spatiotemporal features from the global\nface regions, which ignore the discriminative information between two\nmicro-expression classes. The above-mentioned problems seriously limit the\napplication of spatiotemporal local binary pattern on micro-expression\nrecognition. In this paper, we propose a discriminative spatiotemporal local\nbinary pattern based on an improved integral projection to resolve the problems\nof spatiotemporal local binary pattern for micro-expression recognition.\nFirstly, we develop an improved integral projection for preserving the shape\nattribute of micro-expressions. Furthermore, an improved integral projection is\nincorporated with local binary pattern operators across spatial and temporal\ndomains. Specifically, we extract the novel spatiotemporal features\nincorporating shape attributes into spatiotemporal texture features. For\nincreasing the discrimination of micro-expressions, we propose a new feature\nselection based on Laplacian method to extract the discriminative information\nfor facial micro-expression recognition. Intensive experiments are conducted on\nthree availably published micro-expression databases. We compare our method\nwith the state-of-the-art algorithms. Experimental results demonstrate that our\nproposed method achieves promising performance for micro-expression\nrecognition.",
    "published_date": "2016-08-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.02255v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.02195v1",
    "title": "Automating Political Bias Prediction",
    "authors": [
      "Felix Biessmann"
    ],
    "author_ids": [],
    "abstract": "Every day media generate large amounts of text. An unbiased view on media\nreports requires an understanding of the political bias of media content.\nAssistive technology for estimating the political bias of texts can be helpful\nin this context. This study proposes a simple statistical learning approach to\npredict political bias from text. Standard text features extracted from\nspeeches and manifestos of political parties are used to predict political bias\nin terms of political party affiliation and in terms of political views.\nResults indicate that political bias can be predicted with above chance\naccuracy. Mistakes of the model can be interpreted with respect to changes of\npolicies of political actors. Two approaches are presented to make the results\nmore interpretable: a) discriminative text features are related to the\npolitical orientation of a party and b) sentiment features of texts are\ncorrelated with a measure of political power. Political power appears to be\nstrongly correlated with positive sentiment of a text. To highlight some\npotential use cases a web application shows how the model can be used for texts\nfor which the political bias is not clear such as news articles.",
    "published_date": "2016-08-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.02195v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.02132v6",
    "title": "Password Cracking: The Effect of Hash Function Bias on the Average Guesswork",
    "authors": [
      "Yair Yona",
      "Suhas Diggavi"
    ],
    "author_ids": [],
    "abstract": "Modern authentication systems store hashed values of passwords of users using\ncryptographic hash functions. Therefore, to crack a password an attacker needs\nto guess a hash function input that is mapped to the hashed value, as opposed\nto the password itself. We call a hash function that maps the same number of\ninputs to each bin, as \\textbf{unbiased}. However, cryptographic hash functions\nin use have not been proven to be unbiased (i.e., they may have an unequal\nnumber of inputs mapped to different bins). A cryptographic hash function has\nthe property that it is computationally difficult to find an input mapped to a\nbin. In this work we introduce a structured notion of biased hash functions for\nwhich we analyze the average guesswork under certain types of brute force\nattacks. This work shows that the level of security depends on the set of\nhashed values of valid users as well as the statistical profile of a hash\nfunction, resulting from bias. We examine the average guesswork conditioned on\nthe set of hashed values, and model the statistical profile through the\nempirical distribution of the number of inputs that are mapped to a bin. In\nparticular, we focus on a class of statistical profiles (capturing the bias) ,\nwhich we call type-class statistical profiles, that has an empirical\ndistribution related to the probability of the type classes defined in the\nmethod of types. For such profiles, we show that the average guesswork is\nrelated to basic measures in information theory such as entropy and divergence.\nWe use this to show that the effect of bias on the conditional average\nguesswork is limited compared to other system parameters such as the number of\nvalid users who store their hashed passwords in the system.",
    "published_date": "2016-08-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.02132v6",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.01719v2",
    "title": "Online Decorrelation of Humidity and Temperature in Chemical Sensors for Continuous Monitoring",
    "authors": [
      "Ramon Huerta",
      "Thiago S. Mosqueiro",
      "Jordi Fonollosa",
      "Nikolai F Rulkov",
      "Irene Rodriguez-Lujan"
    ],
    "author_ids": [],
    "abstract": "A method for online decorrelation of chemical sensor signals from the effects\nof environmental humidity and temperature variations is proposed. The goal is\nto improve the accuracy of electronic nose measurements for continuous\nmonitoring by processing data from simultaneous readings of environmental\nhumidity and temperature. The electronic nose setup built for this study\nincluded eight metal-oxide sensors, temperature and humidity sensors with a\nwireless communication link to external computer. This wireless electronic nose\nwas used to monitor air for two years in the residence of one of the authors\nand it collected data continuously during 537 days with a sampling rate of 1\nsamples per second. To estimate the effects of variations in air humidity and\ntemperature on the chemical sensors signals, we used a standard energy band\nmodel for an n-type metal-oxide (MOX) gas sensor. The main assumption of the\nmodel is that variations in sensor conductivity can be expressed as a nonlinear\nfunction of changes in the semiconductor energy bands in the presence of\nexternal humidity and temperature variations. Fitting this model to the\ncollected data, we confirmed that the most statistically significant factors\nare humidity changes and correlated changes of temperature and humidity. This\nsimple model achieves excellent accuracy with a coefficient of determination\n$R^2$ close to 1. To show how the humidity-temperature correction model works\nfor gas discrimination, we constructed a model for online discrimination among\nbanana, wine and baseline response. This shows that pattern recognition\nalgorithms improve performance and reliability by including the filtered signal\nof the chemical sensors.",
    "published_date": "2016-08-04T00:00:00",
    "year": 2016,
    "categories": [
      "physics.data-an",
      "cs.CE",
      "physics.ins-det"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.01719v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1608.01017v1",
    "title": "Automated X-ray Image Analysis for Cargo Security: Critical Review and Future Promise",
    "authors": [
      "Thomas W. Rogers",
      "Nicolas Jaccard",
      "Edward J. Morton",
      "Lewis D. Griffin"
    ],
    "author_ids": [],
    "abstract": "We review the relatively immature field of automated image analysis for X-ray\ncargo imagery. There is increasing demand for automated analysis methods that\ncan assist in the inspection and selection of containers, due to the\never-growing volumes of traded cargo and the increasing concerns that customs-\nand security-related threats are being smuggled across borders by organised\ncrime and terrorist networks. We split the field into the classical pipeline of\nimage preprocessing and image understanding. Preprocessing includes: image\nmanipulation; quality improvement; Threat Image Projection (TIP); and material\ndiscrimination and segmentation. Image understanding includes: Automated Threat\nDetection (ATD); and Automated Contents Verification (ACV). We identify several\ngaps in the literature that need to be addressed and propose ideas for future\nresearch. Where the current literature is sparse we borrow from the\nsingle-view, multi-view, and CT X-ray baggage domains, which have some\ncharacteristics in common with X-ray cargo.",
    "published_date": "2016-08-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.01017v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1608.00514v1",
    "title": "Dimensionality reduction based on Distance Preservation to Local Mean (DPLM) for SPD matrices and its application in BCI",
    "authors": [
      "Alireza Davoudi",
      "Saeed Shiry Ghidary",
      "Khadijeh Sadatnejad"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose a nonlinear dimensionality reduction algorithm for\nthe manifold of Symmetric Positive Definite (SPD) matrices that considers the\ngeometry of SPD matrices and provides a low dimensional representation of the\nmanifold with high class discrimination. The proposed algorithm, tries to\npreserve the local structure of the data by preserving distance to local mean\n(DPLM) and also provides an implicit projection matrix. DPLM is linear in terms\nof the number of training samples and may use the label information when they\nare available in order to performance improvement in classification tasks. We\nperformed several experiments on the multi-class dataset IIa from BCI\ncompetition IV. The results show that our approach as dimensionality reduction\ntechnique - leads to superior results in comparison with other competitor in\nthe related literature because of its robustness against outliers. The\nexperiments confirm that the combination of DPLM with FGMDM as the classifier\nleads to the state of the art performance on this dataset.",
    "published_date": "2016-07-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NA",
      "cs.CV",
      "G.1.6; I.5.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1608.00514v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.08289v4",
    "title": "Mammalian Value Systems",
    "authors": [
      "Gopal P. Sarma",
      "Nick J. Hay"
    ],
    "author_ids": [],
    "abstract": "Characterizing human values is a topic deeply interwoven with the sciences,\nhumanities, art, and many other human endeavors. In recent years, a number of\nthinkers have argued that accelerating trends in computer science, cognitive\nscience, and related disciplines foreshadow the creation of intelligent\nmachines which meet and ultimately surpass the cognitive abilities of human\nbeings, thereby entangling an understanding of human values with future\ntechnological development. Contemporary research accomplishments suggest\nsophisticated AI systems becoming widespread and responsible for managing many\naspects of the modern world, from preemptively planning users' travel schedules\nand logistics, to fully autonomous vehicles, to domestic robots assisting in\ndaily living. The extrapolation of these trends has been most forcefully\ndescribed in the context of a hypothetical \"intelligence explosion,\" in which\nthe capabilities of an intelligent software agent would rapidly increase due to\nthe presence of feedback loops unavailable to biological organisms. The\npossibility of superintelligent agents, or simply the widespread deployment of\nsophisticated, autonomous AI systems, highlights an important theoretical\nproblem: the need to separate the cognitive and rational capacities of an agent\nfrom the fundamental goal structure, or value system, which constrains and\nguides the agent's actions. The \"value alignment problem\" is to specify a goal\nstructure for autonomous agents compatible with human values. In this brief\narticle, we suggest that recent ideas from affective neuroscience and related\ndisciplines aimed at characterizing neurological and behavioral universals in\nthe mammalian class provide important conceptual foundations relevant to\ndescribing human values. We argue that the notion of \"mammalian value systems\"\npoints to a potential avenue for fundamental research in AI safety and AI\nethics.",
    "published_date": "2016-07-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.08289v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.07684v1",
    "title": "The Price of Anarchy in Auctions",
    "authors": [
      "Tim Roughgarden",
      "Vasilis Syrgkanis",
      "Eva Tardos"
    ],
    "author_ids": [],
    "abstract": "This survey outlines a general and modular theory for proving approximation\nguarantees for equilibria of auctions in complex settings. This theory\ncomplements traditional economic techniques, which generally focus on exact and\noptimal solutions and are accordingly limited to relatively stylized settings.\n  We highlight three user-friendly analytical tools: smoothness-type\ninequalities, which immediately yield approximation guarantees for many auction\nformats of interest in the special case of complete information and\ndeterministic strategies; extension theorems, which extend such guarantees to\nrandomized strategies, no-regret learning outcomes, and incomplete-information\nsettings; and composition theorems, which extend such guarantees from simpler\nto more complex auctions. Combining these tools yields tight worst-case\napproximation guarantees for the equilibria of many widely-used auction\nformats.",
    "published_date": "2016-07-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.07684v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.07306v2",
    "title": "The Costs and Benefits of Sharing: Sequential Individual Rationality and Sequential Fairness",
    "authors": [
      "Ragavendran Gopalakrishnan",
      "Koyel Mukherjee",
      "Theja Tulabandhula"
    ],
    "author_ids": [],
    "abstract": "In designing dynamic shared service systems that incentivize customers to opt\nfor shared rather than exclusive service, the traditional notion of individual\nrationality may be insufficient, as a customer's estimated utility could\nfluctuate arbitrarily during their time in the shared system, as long as their\nrealized utility at service completion is not worse than that for exclusive\nservice. In this work, within a model that explicitly considers the\n\"inconvenience costs\" incurred by customers due to sharing, we introduce the\nnotion of sequential individual rationality (SIR) that requires that the\ndisutility of existing customers is nonincreasing as the system state changes\ndue to new customer arrivals. Next, under SIR, we observe that cost sharing can\nalso be viewed as benefit sharing, which inspires a natural definition of\nsequential fairness (SF) - the total incremental benefit due to a new customer\nis shared among existing customers in proportion to the incremental\ninconvenience suffered.\n  We demonstrate the effectiveness of these notions by applying them to a\nridesharing system, where unexpected detours to pick up subsequent passengers\ninconvenience the existing passengers. Imposing SIR and SF reveals interesting\nand surprising results, including: (a) natural limits on the incremental\ndetours permissible, (b) exact characterization of \"SIR-feasible\" routes, which\nboast sublinear upper and lower bounds on the fractional detours, (c) exact\ncharacterization of sequentially fair cost sharing schemes, which includes a\nstrong requirement that passengers must compensate each other for the detour\ninconveniences that they cause, and (d) new algorithmic problems related to and\nmotivated by SIR.",
    "published_date": "2016-07-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.CC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.07306v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.07021v1",
    "title": "Analytical Modeling of IEEE 802.11 Type CSMA/CA Networks with Short Term Unfairness",
    "authors": [
      "Abhijit Bhattacharya",
      "Anurag Kumar"
    ],
    "author_ids": [],
    "abstract": "We consider single-hop topologies with saturated transmitting nodes, using\nIEEE~802.11 DCF for medium access. However, unlike the conventional WiFi, we\nstudy systems where one or more of the protocol parameters are different from\nthe standard, and/or where the propagation delays among the nodes are not\nnegligible compared to the duration of a backoff slot. We observe that for\nseveral classes of protocol parameters, and for large propagation delays, such\nsystems exhibit a certain performance anomaly known as short term unfairness,\nwhich may lead to severe performance degradation. The standard fixed point\nanalysis technique (and its simple extensions) do not predict the system\nbehavior well in such cases; a mean field model based asymptotic approach also\nis not adequate to predict the performance for networks of practical sizes in\nsuch cases. We provide a detailed stochastic model that accurately captures the\nsystem evolution. Since an exact analysis of this model is computationally\nintractable, we develop a novel approximate, but accurate, analysis that uses a\nparsimonious state representation for computational tractability. Apart from\nproviding insights into the system behavior, the analytical method is also able\nto quantify the extent of short term unfairness in the system, and can\ntherefore be used for tuning the protocol parameters to achieve desired\nthroughput and fairness objectives.",
    "published_date": "2016-07-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.07021v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.06972v3",
    "title": "Kinematic-Layout-aware Random Forests for Depth-based Action Recognition",
    "authors": [
      "Seungryul Baek",
      "Zhiyuan Shi",
      "Masato Kawade",
      "Tae-Kyun Kim"
    ],
    "author_ids": [],
    "abstract": "In this paper, we tackle the problem of 24 hours-monitoring patient actions\nin a ward such as \"stretching an arm out of the bed\", \"falling out of the bed\",\nwhere temporal movements are subtle or significant. In the concerned scenarios,\nthe relations between scene layouts and body kinematics (skeletons) become\nimportant cues to recognize actions; however they are hard to be secured at a\ntesting stage. To address this problem, we propose a kinematic-layout-aware\nrandom forest which takes into account the kinematic-layout (\\ie layout and\nskeletons), to maximize the discriminative power of depth image appearance. We\nintegrate the kinematic-layout in the split criteria of random forests to guide\nthe learning process by 1) determining the switch to either the depth\nappearance or the kinematic-layout information, and 2) implicitly closing the\ngap between two distributions obtained by the kinematic-layout and the\nappearance, when the kinematic-layout appears useful. The kinematic-layout\ninformation is not required for the test data, thus called \"privileged\ninformation prior\". The proposed method has also been testified in cross-view\nsettings, by the use of view-invariant features and enforcing the consistency\namong synthetic-view data. Experimental evaluations on our new dataset PATIENT,\nCAD-60 and UWA3D (multiview) demonstrate that our method outperforms various\nstate-of-the-arts.",
    "published_date": "2016-07-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.06972v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.06711v4",
    "title": "Algorithmic and optimization aspects of Brascamp-Lieb inequalities, via Operator Scaling",
    "authors": [
      "Ankit Garg",
      "Leonid Gurvits",
      "Rafael Oliveira",
      "Avi Wigderson"
    ],
    "author_ids": [],
    "abstract": "The celebrated Brascamp-Lieb (BL) inequalities (and their extensions) are an\nimportant mathematical tool, unifying and generalizing numerous inequalities in\nanalysis, convex geometry and information theory. While their structural theory\nis very well understood, far less is known about computing their main\nparameters.\n  We give polynomial time algorithms to compute feasibility of BL-datum, the\noptimal BL-constant and a weak separation oracle for the BL-polytope. The same\nresult holds for the so-called Reverse BL inequalities of Barthe. The best\nknown algorithms for any of these tasks required at least exponential time.\n  The algorithms are obtained by a simple efficient reduction of a given\nBL-datum to an instance of the Operator Scaling problem defined by Gurvits, for\nwhich the present authors have provided a polynomial time algorithm. This\nreduction implies algorithmic versions of many of the known structural results,\nand in some cases provide proofs that are different or simpler than existing\nones.\n  Of particular interest is the fact that the operator scaling algorithm is\ncontinuous in its input. Thus as a simple corollary of our reduction we obtain\nexplicit bounds on the magnitude and continuity of the BL-constant in terms of\nthe BL-data. To the best of our knowledge no such bounds were known, as past\narguments relied on compactness. The continuity of BL-constants is important\nfor developing non-linear BL inequalities that have recently found so many\napplications.",
    "published_date": "2016-07-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CC",
      "cs.DS",
      "math.CA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.06711v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.06565v3",
    "title": "Estimating Causal Peer Influence in Homophilous Social Networks by Inferring Latent Locations",
    "authors": [
      "Edward McFowland III",
      "Cosma Rohilla Shalizi"
    ],
    "author_ids": [],
    "abstract": "Social influence cannot be identified from purely observational data on\nsocial networks, because such influence is generically confounded with latent\nhomophily, i.e., with a node's network partners being informative about the\nnode's attributes and therefore its behavior. If the network grows according to\neither a latent community (stochastic block) model, or a continuous latent\nspace model, then latent homophilous attributes can be consistently estimated\nfrom the global pattern of social ties. We show that, for common versions of\nthose two network models, these estimates are so informative that controlling\nfor estimated attributes allows for asymptotically unbiased and consistent\nestimation of social-influence effects in linear models. In particular, the\nbias shrinks at a rate which directly reflects how much information the network\nprovides about the latent attributes. These are the first results on the\nconsistent non-experimental estimation of social-influence effects in the\npresence of latent homophily, and we discuss the prospects for generalizing\nthem.",
    "published_date": "2016-07-22T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ME",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.06565v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.06520v1",
    "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings",
    "authors": [
      "Tolga Bolukbasi",
      "Kai-Wei Chang",
      "James Zou",
      "Venkatesh Saligrama",
      "Adam Kalai"
    ],
    "author_ids": [],
    "abstract": "The blind application of machine learning runs the risk of amplifying biases\npresent in data. Such a danger is facing us with word embedding, a popular\nframework to represent text data as vectors which has been used in many machine\nlearning and natural language processing tasks. We show that even word\nembeddings trained on Google News articles exhibit female/male gender\nstereotypes to a disturbing extent. This raises concerns because their\nwidespread use, as we describe, often tends to amplify these biases.\nGeometrically, gender bias is first shown to be captured by a direction in the\nword embedding. Second, gender neutral words are shown to be linearly separable\nfrom gender definition words in the word embedding. Using these properties, we\nprovide a methodology for modifying an embedding to remove gender stereotypes,\nsuch as the association between between the words receptionist and female,\nwhile maintaining desired associations such as between the words queen and\nfemale. We define metrics to quantify both direct and indirect gender biases in\nembeddings, and develop algorithms to \"debias\" the embedding. Using\ncrowd-worker evaluation as well as standard benchmarks, we empirically\ndemonstrate that our algorithms significantly reduce gender bias in embeddings\nwhile preserving the its useful properties such as the ability to cluster\nrelated concepts and to solve analogy tasks. The resulting embeddings can be\nused in applications without amplifying gender bias.",
    "published_date": "2016-07-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.06520v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.05888v1",
    "title": "Juxtaposition of System Dynamics and Agent-based Simulation for a Case Study in Immunosenescence",
    "authors": [
      "Grazziela P. Figueredo",
      "Peer-Olaf Siebers",
      "Uwe Aickelin",
      "Amanda Whitbrook",
      "Jonathan M. Garibaldi"
    ],
    "author_ids": [],
    "abstract": "Advances in healthcare and in the quality of life significantly increase\nhuman life expectancy. With the ageing of populations, new un-faced challenges\nare brought to science. The human body is naturally selected to be\nwell-functioning until the age of reproduction to keep the species alive.\nHowever, as the lifespan extends, unseen problems due to the body deterioration\nemerge. There are several age-related diseases with no appropriate treatment;\ntherefore, the complex ageing phenomena needs further understanding.\nImmunosenescence, the ageing of the immune system, is highly correlated to the\nnegative effects of ageing, such as the increase of auto-inflammatory diseases\nand decrease in responsiveness to new diseases. Besides clinical and\nmathematical tools, we believe there is opportunity to further exploit\nsimulation tools to understand immunosenescence. Compared to real-world\nexperimentation, benefits include time and cost effectiveness due to the\nlaborious, resource-intensiveness of the biological environment and the\npossibility of conducting experiments without ethic restrictions. Contrasted\nwith mathematical models, simulation modelling is more suitable for\nrepresenting complex systems and emergence. In addition, there is the belief\nthat simulation models are easier to communicate in interdisciplinary contexts.\nOur work investigates the usefulness of simulations to understand\nimmunosenescence by employing two different simulation methods, agent-based and\nsystem dynamics simulation, to a case study of immune cells depletion with age.",
    "published_date": "2016-07-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05888v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.05845v1",
    "title": "Identifying Candidate Risk Factors for Prescription Drug Side Effects using Causal Contrast Set Mining",
    "authors": [
      "Jenna Reps",
      "Zhaoyang Guo",
      "Haoyue Zhu",
      "Uwe Aickelin"
    ],
    "author_ids": [],
    "abstract": "Big longitudinal observational databases present the opportunity to extract\nnew knowledge in a cost effective manner. Unfortunately, the ability of these\ndatabases to be used for causal inference is limited due to the passive way in\nwhich the data are collected resulting in various forms of bias. In this paper\nwe investigate a method that can overcome these limitations and determine\ncausal contrast set rules efficiently from big data. In particular, we present\na new methodology for the purpose of identifying risk factors that increase a\npatients likelihood of experiencing the known rare side effect of renal failure\nafter ingesting aminosalicylates. The results show that the methodology was\nable to identify previously researched risk factors such as being prescribed\ndiuretics and highlighted that patients with a higher than average risk of\nrenal failure may be even more susceptible to experiencing it as a side effect\nafter ingesting aminosalicylates.",
    "published_date": "2016-07-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05845v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.05523v1",
    "title": "Dendritic Spine Shape Analysis: A Clustering Perspective",
    "authors": [
      "Muhammad Usman Ghani",
      "Ertunc Erdil",
      "Sumeyra Demir Kanik",
      "Ali Ozgur Argunsah",
      "Anna Felicity Hobbiss",
      "Inbal Israely",
      "Devrim Unay",
      "Tolga Tasdizen",
      "Mujdat Cetin"
    ],
    "author_ids": [],
    "abstract": "Functional properties of neurons are strongly coupled with their morphology.\nChanges in neuronal activity alter morphological characteristics of dendritic\nspines. First step towards understanding the structure-function relationship is\nto group spines into main spine classes reported in the literature. Shape\nanalysis of dendritic spines can help neuroscientists understand the underlying\nrelationships. Due to unavailability of reliable automated tools, this analysis\nis currently performed manually which is a time-intensive and subjective task.\nSeveral studies on spine shape classification have been reported in the\nliterature, however, there is an on-going debate on whether distinct spine\nshape classes exist or whether spines should be modeled through a continuum of\nshape variations. Another challenge is the subjectivity and bias that is\nintroduced due to the supervised nature of classification approaches. In this\npaper, we aim to address these issues by presenting a clustering perspective.\nIn this context, clustering may serve both confirmation of known patterns and\ndiscovery of new ones. We perform cluster analysis on two-photon microscopic\nimages of spines using morphological, shape, and appearance based features and\ngain insights into the spine shape analysis problem. We use histogram of\noriented gradients (HOG), disjunctive normal shape models (DNSM), morphological\nfeatures, and intensity profile based features for cluster analysis. We use\nx-means to perform cluster analysis that selects the number of clusters\nautomatically using the Bayesian information criterion (BIC). For all features,\nthis analysis produces 4 clusters and we observe the formation of at least one\ncluster consisting of spines which are difficult to be assigned to a known\nclass. This observation supports the argument of intermediate shape types.",
    "published_date": "2016-07-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05523v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.05490v1",
    "title": "Parity Oblivious d-Level Random Access Codes and Class of Noncontextuality Inequalities",
    "authors": [
      "Andris Ambainis",
      "Manik Banik",
      "Anubhav Chaturvedi",
      "Dmitry Kravchenko",
      "Ashutosh Rai"
    ],
    "author_ids": [],
    "abstract": "One of the fundamental results in quantum foundations is the Kochen-Specker\nno-go theorem. For the quantum theory, the no-go theorem excludes the\npossibility of a class of hidden variable models where value attribution is\ncontext independent. Recently, the notion of contextuality has been generalized\nfor different operational procedures and it has been shown that preparation\ncontextuality of mixed quantum states can be a useful resource in an\ninformation-processing task called parity-oblivious multiplexing. Here, we\nintroduce a new class of information processing tasks, namely d-level parity\noblivious random access codes and obtain bounds on the success probabilities of\nperforming such tasks in any preparation noncontextual theory. These bounds\nconstitute noncontextuality inequalities for any value of d. For d=3, using a\nset of mutually asymmetric biased bases we show that the corresponding\nnoncontextual bound is violated by quantum theory. We also show quantum\nviolation of the inequalities for some other higher values of d. This reveals\noperational usefulness of preparation contextuality of higher level quantum\nsystems.",
    "published_date": "2016-07-19T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05490v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.05459v2",
    "title": "Dynamic Joint Uplink and Downlink Optimization for Uplink and Downlink Decoupling-Enabled 5G Heterogeneous Networks",
    "authors": [
      "Qi Liao",
      "Danish Aziz",
      "Slawomir Stanczak"
    ],
    "author_ids": [],
    "abstract": "The concept of user-centric and personalized service in the fifth generation\n(5G) mobile networks encourages technical solutions such as dynamic asymmetric\nuplink/downlink resource allocation and elastic association of cells to users\nwith decoupled uplink and downlink (DeUD) access. In this paper we develop a\njoint uplink and downlink optimization algorithm for DeUD-enabled wireless\nnetworks for adaptive joint uplink and downlink bandwidth allocation and power\ncontrol, under different link association policies. Based on a general model of\ninter-cell interference, we propose a three-step optimization algorithm to\njointly optimize the uplink and downlink bandwidth allocation and power\ncontrol, using the fixed point approach for nonlinear operators with or without\nmonotonicity, to maximize the minimum level of quality of service satisfaction\nper link, subjected to a general class of resource (power and bandwidth)\nconstraints. We present numerical results illustrating the theoretical findings\nfor network simulator in a real-world setting, and show the advantage of our\nsolution compared to the conventional proportional fairness resource allocation\nschemes in both the coupled uplink and downlink (CoUD) access and the novel\nlink association schemes in DeUD.",
    "published_date": "2016-07-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05459v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.05408v1",
    "title": "Discriminating between similar languages in Twitter using label propagation",
    "authors": [
      "Will Radford",
      "Matthias Galle"
    ],
    "author_ids": [],
    "abstract": "Identifying the language of social media messages is an important first step\nin linguistic processing. Existing models for Twitter focus on content\nanalysis, which is successful for dissimilar language pairs. We propose a label\npropagation approach that takes the social graph of tweet authors into account\nas well as content to better tease apart similar languages. This results in\nstate-of-the-art shared task performance of $76.63\\%$, $1.4\\%$ higher than the\ntop system.",
    "published_date": "2016-07-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.05408v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.04747v2",
    "title": "Learning Social Circles in Ego Networks based on Multi-View Social Graphs",
    "authors": [
      "Chao Lan",
      "Yuhao Yang",
      "Xiaoli Li",
      "Bo Luo",
      "Jun Huan"
    ],
    "author_ids": [],
    "abstract": "In social network analysis, automatic social circle detection in ego-networks\nis becoming a fundamental and important task, with many potential applications\nsuch as user privacy protection or interest group recommendation. So far, most\nstudies have focused on addressing two questions, namely, how to detect\noverlapping circles and how to detect circles using a combination of network\nstructure and network node attributes. This paper asks an orthogonal research\nquestion, that is, how to detect circles based on network structures that are\n(usually) described by multiple views? Our investigation begins with crawling\nego-networks from Twitter and employing classic techniques to model their\nstructures by six views, including user relationships, user interactions and\nuser content. We then apply both standard and our modified multi-view spectral\nclustering techniques to detect social circles in these ego-networks. Based on\nextensive automatic and manual experimental evaluations, we deliver two major\nfindings: first, multi-view clustering techniques perform better than common\nsingle-view clustering techniques, which only use one view or naively integrate\nall views for detection, second, the standard multi-view clustering technique\nis less robust than our modified technique, which selectively transfers\ninformation across views based on an assumption that sparse network structures\nare (potentially) incomplete. In particular, the second finding makes us\nbelieve a direct application of standard clustering on potentially incomplete\nnetworks may yield biased results. We lightly examine this issue in theory,\nwhere we derive an upper bound for such bias by integrating theories of\nspectral clustering and matrix perturbation, and discuss how it may be affected\nby several network characteristics.",
    "published_date": "2016-07-16T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.LG",
      "68T01"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.04747v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.03944v2",
    "title": "Formulation and convergence of the finite volume method for conservation laws on spacetimes with boundary",
    "authors": [
      "Jan Giesselmann",
      "Philippe G. LeFloch"
    ],
    "author_ids": [],
    "abstract": "We study nonlinear hyperbolic conservation laws posed on a differential\n(n+1)-manifold with boundary referred to as a spacetime, and defined from a\nprescribed flux field of n-forms depending on a parameter (the unknown\nvariable), a class of equations proposed by LeFloch and Okutmustur in 2008. Our\nmain result is a proof of the convergence of the finite volume method for weak\nsolutions satisfying suitable entropy inequalities. A main difference with\nprevious work is that we allow for slices with a boundary and, in addition,\nintroduce a new formulation of the finite volume method involving the notion of\ntotal flux functions. Under a natural global hyperbolicity condition on the\nflux field and the spacetime and by assuming that the spacetime admits a\nfoliation by compact slices with boundary, we establish an existence and\nuniqueness theory for the initial and boundary value problem, and we prove a\ncontraction property in a geometrically natural L1-type distance.",
    "published_date": "2016-07-13T00:00:00",
    "year": 2016,
    "categories": [
      "math.AP",
      "cs.NA",
      "math.NA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.03944v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.03895v1",
    "title": "Tie-breaker: Using language models to quantify gender bias in sports journalism",
    "authors": [
      "Liye Fu",
      "Cristian Danescu-Niculescu-Mizil",
      "Lillian Lee"
    ],
    "author_ids": [],
    "abstract": "Gender bias is an increasingly important issue in sports journalism. In this\nwork, we propose a language-model-based approach to quantify differences in\nquestions posed to female vs. male athletes, and apply it to tennis post-match\ninterviews. We find that journalists ask male players questions that are\ngenerally more focused on the game when compared with the questions they ask\ntheir female counterparts. We also provide a fine-grained analysis of the\nextent to which the salience of this bias depends on various factors, such as\nquestion type, game outcome or player rank.",
    "published_date": "2016-07-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.03895v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.03547v2",
    "title": "Improved Multi-Class Cost-Sensitive Boosting via Estimation of the Minimum-Risk Class",
    "authors": [
      "Ron Appel",
      "Xavier Burgos-Artizzu",
      "Pietro Perona"
    ],
    "author_ids": [],
    "abstract": "We present a simple unified framework for multi-class cost-sensitive\nboosting. The minimum-risk class is estimated directly, rather than via an\napproximation of the posterior distribution. Our method jointly optimizes\nbinary weak learners and their corresponding output vectors, requiring classes\nto share features at each iteration. By training in a cost-sensitive manner,\nweak learners are invested in separating classes whose discrimination is\nimportant, at the expense of less relevant classification boundaries.\nAdditional contributions are a family of loss functions along with proof that\nour algorithm is Boostable in the theoretical sense, as well as an efficient\nprocedure for growing decision trees for use as weak learners. We evaluate our\nmethod on a variety of datasets: a collection of synthetic planar data, common\nUCI datasets, MNIST digits, SUN scenes, and CUB-200 birds. Results show\nstate-of-the-art performance across all datasets against several strong\nbaselines, including non-boosting multi-class approaches.",
    "published_date": "2016-07-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.03547v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.02864v1",
    "title": "On the Structure of Equilibrium Strategies in Dynamic Gaussian Signaling Games",
    "authors": [
      "Muhammed Sayin",
      "Emrah Akyol",
      "Tamer Basar"
    ],
    "author_ids": [],
    "abstract": "This paper analyzes a finite horizon dynamic signaling game motivated by the\nwell-known strategic information transmission problems in economics. The\nmathematical model involves information transmission between two agents, a\nsender who observes two Gaussian processes, state and bias, and a receiver who\ntakes an action based on the received message from the sender. The players\nincur quadratic instantaneous costs as functions of the state, bias and action\nvariables. Our particular focus is on the Stackelberg equilibrium, which\ncorresponds to information disclosure and Bayesian persuasion problems in\neconomics. Prior work solved the static game, and showed that the Stackelberg\nequilibrium is achieved by pure strategies that are linear functions of the\nstate and the bias variables. The main focus of this work is on the dynamic\n(multi-stage) setting, where we show that the existence of a pure strategy\nStackelberg equilibrium, within the set of linear strategies, depends on the\nproblem parameters. Surprisingly, for most problem parameters, a pure linear\nstrategy does not achieve the Stackelberg equilibrium which implies the\nexistence of a trade-off between exploiting and revealing information, which\nwas also encountered in several other asymmetric information games.",
    "published_date": "2016-07-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY",
      "cs.GT",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.02864v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.02737v3",
    "title": "Transition Forests: Learning Discriminative Temporal Transitions for Action Recognition and Detection",
    "authors": [
      "Guillermo Garcia-Hernando",
      "Tae-Kyun Kim"
    ],
    "author_ids": [],
    "abstract": "A human action can be seen as transitions between one's body poses over time,\nwhere the transition depicts a temporal relation between two poses. Recognizing\nactions thus involves learning a classifier sensitive to these pose transitions\nas well as to static poses. In this paper, we introduce a novel method called\ntransitions forests, an ensemble of decision trees that both learn to\ndiscriminate static poses and transitions between pairs of two independent\nframes. During training, node splitting is driven by alternating two criteria:\nthe standard classification objective that maximizes the discrimination power\nin individual frames, and the proposed one in pairwise frame transitions.\nGrowing the trees tends to group frames that have similar associated\ntransitions and share same action label incorporating temporal information that\nwas not available otherwise. Unlike conventional decision trees where the best\nsplit in a node is determined independently of other nodes, the transition\nforests try to find the best split of nodes jointly (within a layer) for\nincorporating distant node transitions. When inferring the class label of a new\nframe, it is passed down the trees and the prediction is made based on previous\nframe predictions and the current one in an efficient and online manner. We\napply our method on varied skeleton action recognition and online detection\ndatasets showing its suitability over several baselines and state-of-the-art\napproaches.",
    "published_date": "2016-07-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.02737v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.02574v1",
    "title": "The Miracle of Peer Review and Development in Science: An Agent-Based Model",
    "authors": [
      "Simone Righi",
      "Károly Takács"
    ],
    "author_ids": [],
    "abstract": "It is not easy to rationalize how peer review, as the current grassroots of\nscience, can work based on voluntary contributions of reviewers. There is no\nrationale to write impartial and thorough evaluations. Consequently, there is\nno risk in submitting low-quality work by authors. As a result, scientists face\na social dilemma: if everyone acts according to his or her own self-interest,\nlow scientific quality is produced. Still, in practice, reviewers as well as\nauthors invest high effort in reviews and submissions.\n  We examine how the increased relevance of public good benefits (journal\nimpact factor), the editorial policy of handling incoming reviews, and the\nacceptance decisions that take into account reputational information can help\nthe evolution of high-quality contributions from authors. High effort from the\nside of reviewers is problematic even if authors cooperate: reviewers are still\nbest off by producing low-quality reviews, which does not hinder scientific\ndevelopment, just adds random noise and unnecessary costs to it. We show with\nagent-based simulations that tacit agreements between authors that are based on\nreciprocity might decrease these costs, but does not result in superior\nscientific quality. Our study underlines why certain self-emerged current\npractices, such as the increased importance of journal metrics, the\nreputation-based selection of reviewers, and the reputation bias in acceptance\nwork efficiently for scientific development. Our results find no answers,\nhowever, how the system of peer review with impartial and thorough evaluations\ncould be sustainable jointly with rapid scientific development.",
    "published_date": "2016-07-09T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.DL",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.02574v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.01845v2",
    "title": "Urban Social Media Inequality: Definition, Measurements, and Application",
    "authors": [
      "Agustin Indaco",
      "Lev Manovich"
    ],
    "author_ids": [],
    "abstract": "Social media content shared today in cities, such as Instagram images, their\ntags and descriptions, is the key form of contemporary city life. It tells\npeople where activities and locations that interest them are and it allows them\nto share their urban experiences and self-representations. Therefore, any\nanalysis of urban structures and cultures needs to consider social media\nactivity. In our paper, we introduce the novel concept of social media\ninequality. This concept allows us to quantitatively compare patterns in social\nmedia activities between parts of a city, a number of cities, or any other\nspatial areas. We define this concept using an analogy with the concept of\neconomic inequality. Economic inequality indicates how some economic\ncharacteristics or material resources, such as income, wealth or consumption\nare distributed in a city, country or between countries. Accordingly, we can\ndefine social media inequality as the measure of the distribution of\ncharacteristics from social media content shared in a particular geographic\narea or between areas. An example of such characteristics is the number of\nphotos shared by all users of a social network such as Instagram in a given\ncity or city area, or the content of these photos. We propose that the standard\ninequality measures used in other disciplines, such as the Gini coefficient,\ncan also be used to characterize social media inequality. To test our ideas, we\nuse a dataset of 7,442,454 public geo-coded Instagram images shared in\nManhattan during five months (March-July) in 2014, and also selected data for\n287 Census tracts in Manhattan. We compare patterns in Instagram sharing for\nlocals and for visitors for all tracts, and also for hours in a 24-hour cycle.\nWe also look at relations between social media inequality and socio-economic\ninequality using selected indicators for Census tracts.",
    "published_date": "2016-07-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.01845v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.01133v1",
    "title": "Learning when to trust distant supervision: An application to low-resource POS tagging using cross-lingual projection",
    "authors": [
      "Meng Fang",
      "Trevor Cohn"
    ],
    "author_ids": [],
    "abstract": "Cross lingual projection of linguistic annotation suffers from many sources\nof bias and noise, leading to unreliable annotations that cannot be used\ndirectly. In this paper, we introduce a novel approach to sequence tagging that\nlearns to correct the errors from cross-lingual projection using an explicit\ndebiasing layer. This is framed as joint learning over two corpora, one tagged\nwith gold standard and the other with projected tags. We evaluated with only\n1,000 tokens tagged with gold standard tags, along with more plentiful parallel\ndata. Our system equals or exceeds the state-of-the-art on eight simulated\nlow-resource settings, as well as two real low-resource languages, Malagasy and\nKinyarwanda.",
    "published_date": "2016-07-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.01133v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.00647v1",
    "title": "A Survey of Point-of-interest Recommendation in Location-based Social Networks",
    "authors": [
      "Shenglin Zhao",
      "Irwin King",
      "Michael R. Lyu"
    ],
    "author_ids": [],
    "abstract": "Point-of-interest (POI) recommendation that suggests new places for users to\nvisit arises with the popularity of location-based social networks (LBSNs). Due\nto the importance of POI recommendation in LBSNs, it has attracted much\nacademic and industrial interest. In this paper, we offer a systematic review\nof this field, summarizing the contributions of individual efforts and\nexploring their relations. We discuss the new properties and challenges in POI\nrecommendation, compared with traditional recommendation problems, e.g., movie\nrecommendation. Then, we present a comprehensive review in three aspects:\ninfluential factors for POI recommendation, methodologies employed for POI\nrecommendation, and different tasks in POI recommendation. Specifically, we\npropose three taxonomies to classify POI recommendation systems. First, we\ncategorize the systems by the influential factors check-in characteristics,\nincluding the geographical information, social relationship, temporal\ninfluence, and content indications. Second, we categorize the systems by the\nmethodology, including systems modeled by fused methods and joint methods.\nThird, we categorize the systems as general POI recommendation and successive\nPOI recommendation by subtle differences in the recommendation task whether to\nbe bias to the recent check-in. For each category, we summarize the\ncontributions and system features, and highlight the representative work.\nMoreover, we discuss the available data sets and the popular metrics. Finally,\nwe point out the possible future directions in this area and conclude this\nsurvey.",
    "published_date": "2016-07-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IR",
      "H.2.8; H.3.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.00647v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.00485v1",
    "title": "Group Sparse Regularization for Deep Neural Networks",
    "authors": [
      "Simone Scardapane",
      "Danilo Comminiello",
      "Amir Hussain",
      "Aurelio Uncini"
    ],
    "author_ids": [],
    "abstract": "In this paper, we consider the joint task of simultaneously optimizing (i)\nthe weights of a deep neural network, (ii) the number of neurons for each\nhidden layer, and (iii) the subset of active input features (i.e., feature\nselection). While these problems are generally dealt with separately, we\npresent a simple regularized formulation allowing to solve all three of them in\nparallel, using standard optimization routines. Specifically, we extend the\ngroup Lasso penalty (originated in the linear regression literature) in order\nto impose group-level sparsity on the network's connections, where each group\nis defined as the set of outgoing weights from a unit. Depending on the\nspecific case, the weights can be related to an input variable, to a hidden\nneuron, or to a bias unit, thus performing simultaneously all the\naforementioned tasks in order to obtain a compact network. We perform an\nextensive experimental evaluation, by comparing with classical weight decay and\nLasso penalties. We show that a sparse version of the group Lasso penalty is\nable to achieve competitive performances, while at the same time resulting in\nextremely compact networks with a smaller number of input features. We evaluate\nboth on a toy dataset for handwritten digit recognition, and on multiple\nrealistic large-scale classification problems.",
    "published_date": "2016-07-02T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.00485v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1607.00355v1",
    "title": "A note on some inequalities used in channel polarization and polar coding",
    "authors": [
      "T. S. Jayram",
      "Erdal Arikan"
    ],
    "author_ids": [],
    "abstract": "We give a unified treatment of some inequalities that are used in the proofs\nof channel polarization theorems involving a binary-input discrete memoryless\nchannel.",
    "published_date": "2016-07-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.00355v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1607.00022v1",
    "title": "Modeling confirmation bias and polarization",
    "authors": [
      "Michela Del Vicario",
      "Antonio Scala",
      "Guido Caldarelli",
      "H Eugene Stanley",
      "Walter Quattrociocchi"
    ],
    "author_ids": [],
    "abstract": "Online users tend to select claims that adhere to their system of beliefs and\nto ignore dissenting information. Confirmation bias, indeed, plays a pivotal\nrole in viral phenomena. Furthermore, the wide availability of content on the\nweb fosters the aggregation of likeminded people where debates tend to enforce\ngroup polarization. Such a configuration might alter the public debate and thus\nthe formation of the public opinion. In this paper we provide a mathematical\nmodel to study online social debates and the related polarization dynamics. We\nassume the basic updating rule of the Bounded Confidence Model (BCM) and we\ndevelop two variations a) the Rewire with Bounded Confidence Model (RBCM), in\nwhich discordant links are broken until convergence is reached; and b) the\nUnbounded Confidence Model, under which the interaction among discordant pairs\nof users is allowed even with a negative feedback, either with the rewiring\nstep (RUCM) or without it (UCM). From numerical simulations we find that the\nnew models (UCM and RUCM), unlike the BCM, are able to explain the coexistence\nof two stable final opinions, often observed in reality. Lastly, we present a\nmean field approximation of the newly introduced models.",
    "published_date": "2016-06-30T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1607.00022v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.09514v3",
    "title": "Robust Bell inequalities from communication complexity",
    "authors": [
      "Sophie Laplante",
      "Mathieu Laurière",
      "Alexandre Nolin",
      "Jérémie Roland",
      "Gabriel Senno"
    ],
    "author_ids": [],
    "abstract": "The question of how large Bell inequality violations can be, for quantum\ndistributions, has been the object of much work in the past several years. We\nsay that a Bell inequality is normalized if its absolute value does not exceed\n1 for any classical (i.e. local) distribution. Upper and (almost) tight lower\nbounds have been given for the quantum violation of these Bell inequalities in\nterms of number of outputs of the distribution, number of inputs, and the\ndimension of the shared quantum states. In this work, we revisit normalized\nBell inequalities together with another family: inefficiency-resistant Bell\ninequalities. To be inefficiency-resistant, the Bell value must not exceed 1\nfor any local distribution, including those that can abort. This makes the Bell\ninequality resistant to the detection loophole, while a normalized Bell\ninequality is resistant to general local noise. Both these families of Bell\ninequalities are closely related to communication complexity lower bounds. We\nshow how to derive large violations from any gap between classical and quantum\ncommunication complexity, provided the lower bound on classical communication\nis proven using these lower bound techniques. This leads to\ninefficiency-resistant violations that can be exponential in the size of the\ninputs. Finally, we study resistance to noise and inefficiency for these Bell\ninequalities.",
    "published_date": "2016-06-30T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.CC",
      "F.1.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.09514v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.09082v1",
    "title": "Formation of homophily in academic performance: students prefer to change their friends rather than performance",
    "authors": [
      "Ivan Smirnov",
      "Stefan Thurner"
    ],
    "author_ids": [],
    "abstract": "Homophily, the tendency of individuals to associate with others who share\nsimilar traits, has been identified as a major driving force in the formation\nand evolution of social ties. In many cases, it is not clear if homophily is\nthe result of a socialization process, where individuals change their traits\naccording to the dominance of that trait in their local social networks, or if\nit results from a selection process, in which individuals reshape their social\nnetworks so that their traits match those in the new environment. Here we\ndemonstrate the detailed temporal formation of strong homophily in academic\nachievements of high school and university students. We analyze a unique\ndataset that contains information about the detailed time evolution of a\nfriendship network of 6,000 students across 42 months. Combining the evolving\nsocial network data with the time series of the academic performance (GPA) of\nindividual students, we show that academic homophily is a result of selection:\nstudents prefer to gradually reorganize their social networks according to\ntheir performance levels, rather than adapting their performance to the level\nof their local group. We find no signs for a pull effect, where a social\nenvironment of good performers motivates bad students to improve their\nperformance. We are able to understand the underlying dynamics of grades and\nnetworks with a simple model. The lack of a social pull effect in classical\neducational settings could have important implications for the understanding of\nthe observed persistence of segregation, inequality and social immobility in\nsocieties.",
    "published_date": "2016-06-29T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.09082v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.08905v6",
    "title": "knor: A NUMA-Optimized In-Memory, Distributed and Semi-External-Memory k-means Library",
    "authors": [
      "Disa Mhembere",
      "Da Zheng",
      "Carey E. Priebe",
      "Joshua T. Vogelstein",
      "Randal Burns"
    ],
    "author_ids": [],
    "abstract": "k-means is one of the most influential and utilized machine learning\nalgorithms. Its computation limits the performance and scalability of many\nstatistical analysis and machine learning tasks. We rethink and optimize\nk-means in terms of modern NUMA architectures to develop a novel\nparallelization scheme that delays and minimizes synchronization barriers. The\n\\textit{k-means NUMA Optimized Routine} (\\textsf{knor}) library has (i)\nin-memory (\\textsf{knori}), (ii) distributed memory (\\textsf{knord}), and (iii)\nsemi-external memory (\\textsf{knors}) modules that radically improve the\nperformance of k-means for varying memory and hardware budgets. \\textsf{knori}\nboosts performance for single machine datasets by an order of magnitude or\nmore. \\textsf{knors} improves the scalability of k-means on a memory budget\nusing SSDs. \\textsf{knors} scales to billions of points on a single machine,\nusing a fraction of the resources that distributed in-memory systems require.\n\\textsf{knord} retains \\textsf{knori}'s performance characteristics, while\nscaling in-memory through distributed computation in the cloud. \\textsf{knor}\nmodifies Elkan's triangle inequality pruning algorithm such that we utilize it\non billion-point datasets without the significant memory overhead of the\noriginal algorithm. We demonstrate \\textsf{knor} outperforms distributed\ncommercial products like H$_2$O, Turi (formerly Dato, GraphLab) and Spark's\nMLlib by more than an order of magnitude for datasets of $10^7$ to $10^9$\npoints.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08905v6",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.08829v3",
    "title": "Dynamics and Biases of Online Attention: The Case of Aircraft Crashes",
    "authors": [
      "Ruth García-Gavilanes",
      "Milena Tsvetkova",
      "Taha Yasseri"
    ],
    "author_ids": [],
    "abstract": "The Internet not only has changed the dynamics of our collective attention,\nbut also through the transactional log of online activities, provides us with\nthe opportunity to study attention dynamics at scale. In this paper, we\nparticularly study attention to aircraft incidents and accidents using\nWikipedia transactional data in two different language editions, English and\nSpanish. We study both the editorial activities on and the viewership of the\narticles about airline crashes. We analyse how the level of attention is\ninfluenced by different parameters such as number of deaths, airline region,\nand event locale and date. We find evidence that the attention given by\nWikipedia editors to pre-Wikipedia aircraft incidents and accidents depends on\nthe region of the airline for both English and Spanish editions. North American\nairline companies receive more prompt coverage in English Wikipedia. We also\nobserve that the attention given by Wikipedia visitors is influenced by the\nairline region but only for events with high number of deaths. Finally we show\nthat the rate and time span of the decay of attention is independent of the\nnumber of deaths and a fast decay within about a week seems to be universal. We\ndiscuss the implications of these findings in the context of attention bias.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.SI",
      "physics.data-an"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08829v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.08813v3",
    "title": "European Union regulations on algorithmic decision-making and a \"right to explanation\"",
    "authors": [
      "Bryce Goodman",
      "Seth Flaxman"
    ],
    "author_ids": [],
    "abstract": "We summarize the potential impact that the European Union's new General Data\nProtection Regulation will have on the routine use of machine learning\nalgorithms. Slated to take effect as law across the EU in 2018, it will\nrestrict automated individual decision-making (that is, algorithms that make\ndecisions based on user-level predictors) which \"significantly affect\" users.\nThe law will also effectively create a \"right to explanation,\" whereby a user\ncan ask for an explanation of an algorithmic decision that was made about them.\nWe argue that while this law will pose large challenges for industry, it\nhighlights opportunities for computer scientists to take the lead in designing\nalgorithms and evaluation frameworks which avoid discrimination and enable\nexplanation.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08813v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.08808v2",
    "title": "Adaptive Training of Random Mapping for Data Quantization",
    "authors": [
      "Miao Cheng",
      "Ah Chung Tsoi"
    ],
    "author_ids": [],
    "abstract": "Data quantization learns encoding results of data with certain requirements,\nand provides a broad perspective of many real-world applications to data\nhandling. Nevertheless, the results of encoder is usually limited to\nmultivariate inputs with the random mapping, and side information of binary\ncodes are hardly to mostly depict the original data patterns as possible. In\nthe literature, cosine based random quantization has attracted much attentions\ndue to its intrinsic bounded results. Nevertheless, it usually suffers from the\nuncertain outputs, and information of original data fails to be fully preserved\nin the reduced codes. In this work, a novel binary embedding method, termed\nadaptive training quantization (ATQ), is proposed to learn the ideal transform\nof random encoder, where the limitation of cosine random mapping is tackled. As\nan adaptive learning idea, the reduced mapping is adaptively calculated with\nidea of data group, while the bias of random transform is to be improved to\nhold most matching information. Experimental results show that the proposed\nmethod is able to obtain outstanding performance compared with other random\nquantization methods.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08808v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.08572v2",
    "title": "Diversified Visual Attention Networks for Fine-Grained Object Classification",
    "authors": [
      "Bo Zhao",
      "Xiao Wu",
      "Jiashi Feng",
      "Qiang Peng",
      "Shuicheng Yan"
    ],
    "author_ids": [],
    "abstract": "Fine-grained object classification is a challenging task due to the subtle\ninter-class difference and large intra-class variation. Recently, visual\nattention models have been applied to automatically localize the discriminative\nregions of an image for better capturing critical difference and demonstrated\npromising performance. However, without consideration of the diversity in\nattention process, most of existing attention models perform poorly in\nclassifying fine-grained objects. In this paper, we propose a diversified\nvisual attention network (DVAN) to address the problems of fine-grained object\nclassification, which substan- tially relieves the dependency on\nstrongly-supervised information for learning to localize discriminative regions\ncompared with attentionless models. More importantly, DVAN explicitly pursues\nthe diversity of attention and is able to gather discriminative information to\nthe maximal extent. Multiple attention canvases are generated to extract\nconvolutional features for attention. An LSTM recurrent unit is employed to\nlearn the attentiveness and discrimination of attention canvases. The proposed\nDVAN has the ability to attend the object from coarse to fine granularity, and\na dynamic internal representation for classification is built up by\nincrementally combining the information from different locations and scales of\nthe image. Extensive experiments con- ducted on CUB-2011, Stanford Dogs and\nStanford Cars datasets have demonstrated that the proposed diversified visual\nattention networks achieve competitive performance compared to the state-\nof-the-art approaches, without using any prior knowledge, user interaction or\nexternal resource in training or testing.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08572v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.08561v2",
    "title": "Estimating the class prior and posterior from noisy positives and unlabeled data",
    "authors": [
      "Shantanu Jain",
      "Martha White",
      "Predrag Radivojac"
    ],
    "author_ids": [],
    "abstract": "We develop a classification algorithm for estimating posterior distributions\nfrom positive-unlabeled data, that is robust to noise in the positive labels\nand effective for high-dimensional data. In recent years, several algorithms\nhave been proposed to learn from positive-unlabeled data; however, many of\nthese contributions remain theoretical, performing poorly on real\nhigh-dimensional data that is typically contaminated with noise. We build on\nthis previous work to develop two practical classification algorithms that\nexplicitly model the noise in the positive labels and utilize univariate\ntransforms built on discriminative classifiers. We prove that these univariate\ntransforms preserve the class prior, enabling estimation in the univariate\nspace and avoiding kernel density estimation for high-dimensional data. The\ntheoretical development and both parametric and nonparametric algorithms\nproposed here constitutes an important step towards wide-spread use of robust\nclassification algorithms for positive-unlabeled data.",
    "published_date": "2016-06-28T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08561v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.08116v2",
    "title": "Verify LTL with Fairness Assumptions Efficiently",
    "authors": [
      "Yong Li",
      "Lei Song",
      "Yuan Feng",
      "Lijun Zhang"
    ],
    "author_ids": [],
    "abstract": "This paper deals with model checking problems with respect to LTL properties\nunder fairness assumptions. We first present an efficient algorithm to deal\nwith a fragment of fairness assumptions and then extend the algorithm to handle\narbitrary %fairness assumptions ones. Notably, by making use of some syntactic\ntransformations, our algorithm avoids to construct corresponding B\\\"uchi\nautomata for the whole fairness assumptions, which can be very large in\npractice. We implement our algorithm in NuSMV and consider a large selection of\nformulas. Our experiments show that in many cases our approach exceeds the\nautomata-theoretic approach up to several orders of magnitude, in both time and\nmemory.",
    "published_date": "2016-06-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LO",
      "cs.FL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.08116v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.07735v2",
    "title": "Riccati observers for position and velocity bias estimation from either direction or range measurements",
    "authors": [
      "Tarek Hamel",
      "Claude Samson"
    ],
    "author_ids": [],
    "abstract": "This paper revisits the problems of estimating the position of an object\nmoving in $n$ ($\\geq 2$)-dimensional Euclidean space using velocity\nmeasurements and either direction or range measurements of one or multiple\nsource points. The proposed solutions exploit the Continuous Riccati Equation\n(CRE) to calculate observer gains yielding global exponential stability of zero\nestimation errors, even in the case where the measured velocity is biased by an\nunknown constant perturbation. These results are obtained under persistent\nexcitation (p.e.) conditions depending on the number of source points and body\nmotion that ensure both uniform observability and good conditioning of the CRE\nsolutions. With respect to prior contributions on these subjects some of the\nproposed solutions are entirely novel while others are adapted from existing\nones with the preoccupation of stating simpler and more explicit conditions\nunder which uniform exponential stability is achieved. A complementary\ncontribution, related to the delicate tuning of the observers gains, is the\nderivation of a lower-bound of the exponential rate of convergence specified as\na function of the amount of persistent excitation. Simulation results\nillustrate the performance of the proposed observers.",
    "published_date": "2016-06-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.07735v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.07490v1",
    "title": "Enhancing Accountability and Trust in Distributed Ledgers",
    "authors": [
      "Maurice Herlihy",
      "Mark Moir"
    ],
    "author_ids": [],
    "abstract": "Permisionless decentralized ledgers (\"blockchains\") such as the one\nunderlying the cryptocurrency Bitcoin allow anonymous participants to maintain\nthe ledger, while avoiding control or \"censorship\" by any single entity. In\ncontrast, permissioned decentralized ledgers exploit real-world trust and\naccountability, allowing only explicitly authorized parties to maintain the\nledger. Permissioned ledgers support more flexible governance and a wider\nchoice of consensus mechanisms. Both kinds of decentralized ledgers may be\nsusceptible to manipulation by participants who favor some transactions over\nothers. The real-world accountability underlying permissioned ledgers provides\nan opportunity to impose fairness constraints that can be enforced by\npenalizing violators after-the- fact. To date, however, this opportunity has\nnot been fully exploited, unnecessarily leaving participants latitude to\nmanipulate outcomes undetectably. This paper draws attention to this issue, and\nproposes design principles to make such manipulation more difficult, as well as\nspecific mechanisms to make it easier to detect when violations occur.",
    "published_date": "2016-06-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.CY",
      "C.2.4; E.1; K.4.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.07490v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.07239v1",
    "title": "Non Local Spatial and Angular Matching : Enabling higher spatial resolution diffusion MRI datasets through adaptive denoising",
    "authors": [
      "Samuel St-Jean",
      "Pierrick Coupé",
      "Maxime Descoteaux"
    ],
    "author_ids": [],
    "abstract": "Diffusion magnetic resonance imaging datasets suffer from low Signal-to-Noise\nRatio, especially at high b-values. Acquiring data at high b-values contains\nrelevant information and is now of great interest for microstructural and\nconnectomics studies. High noise levels bias the measurements due to the\nnon-Gaussian nature of the noise, which in turn can lead to a false and biased\nestimation of the diffusion parameters. Additionally, the usage of in-plane\nacceleration techniques during the acquisition leads to a spatially varying\nnoise distribution, which depends on the parallel acceleration method\nimplemented on the scanner. This paper proposes a novel diffusion MRI denoising\ntechnique that can be used on all existing data, without adding to the scanning\ntime. We first apply a statistical framework to convert the noise to Gaussian\ndistributed noise, effectively removing the bias. We then introduce a spatially\nand angular adaptive denoising technique, the Non Local Spatial and Angular\nMatching (NLSAM) algorithm. Each volume is first decomposed in small 4D\noverlapping patches to capture the structure of the diffusion data and a\ndictionary of atoms is learned on those patches. A local sparse decomposition\nis then found by bounding the reconstruction error with the local noise\nvariance. We compare against three other state-of-the-art denoising methods and\nshow quantitative local and connectivity results on a synthetic phantom and on\nan in-vivo high resolution dataset. Overall, our method restores perceptual\ninformation, removes the noise bias in common diffusion metrics, restores the\nextracted peaks coherence and improves reproducibility of tractography. Our\nwork paves the way for higher spatial resolution acquisition of diffusion MRI\ndatasets, which could in turn reveal new anatomical details that are not\ndiscernible at the spatial resolution currently used by the diffusion MRI\ncommunity.",
    "published_date": "2016-06-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.07239v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.06975v1",
    "title": "Bias Correction in Saupe Tensor Estimation",
    "authors": [
      "Yuehaw Khoo",
      "Amit Singer",
      "David Cowburn"
    ],
    "author_ids": [],
    "abstract": "Estimation of the Saupe tensor is central to the determination of molecular\nstructures from residual dipolar couplings (RDC) or chemical shift\nanisotropies. Assuming a given template structure, the singular value\ndecomposition (SVD) method proposed in Losonczi et al. 1999 has been used\ntraditionally to estimate the Saupe tensor. Despite its simplicity, whenever\nthe template structure has large structural noise, the eigenvalues of the\nestimated tensor have a magnitude systematically smaller than their actual\nvalues. This leads to systematic error when calculating the eigenvalue\ndependent parameters, magnitude and rhombicity. We propose here a Monte Carlo\nsimulation method to remove such bias. We further demonstrate the effectiveness\nof our method in the setting when the eigenvalue estimates from multiple\ntemplate protein fragments are available and their average is used as an\nimproved eigenvalue estimator. For both synthetic and experimental RDC datasets\nof ubiquitin, when using template fragments corrupted by large noise, the\nmagnitude of our proposed bias-reduced estimator generally reaches at least 90%\nof the actual value, whereas the magnitude of SVD estimator can be shrunk below\n80% of the true value.",
    "published_date": "2016-06-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CE",
      "G.3; J.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.06975v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.06664v3",
    "title": "Inequity Aversion Pricing over Social Networks: Approximation Algorithms and Hardness Results",
    "authors": [
      "Georgios Amanatidis",
      "Peter Fulla",
      "Evangelos Markakis",
      "Krzysztof Sornat"
    ],
    "author_ids": [],
    "abstract": "We study a revenue maximization problem in the context of social networks.\nNamely, we consider a model introduced by Alon, Mansour, and Tennenholtz (EC\n2013) that captures inequity aversion, i.e., prices offered to neighboring\nvertices should not be significantly different. We first provide approximation\nalgorithms for a natural class of instances, referred to as the class of\nsingle-value revenue functions. Our results improve on the current state of the\nart, especially when the number of distinct prices is small. This applies, for\nexample, to settings where the seller will only consider a fixed number of\ndiscount types or special offers. We then resolve one of the open questions\nposed in Alon et al., by establishing APX-hardness for the problem.\nSurprisingly, we further show that the problem is NP-complete even when the\nprice differences are allowed to be large, or even when the number of allowed\ndistinct prices is as small as three. Finally, we provide some extensions of\nthe model, regarding either the allowed set of prices or the demand type of the\nclients.",
    "published_date": "2016-06-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "F.2.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.06664v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.06121v1",
    "title": "Quantifying and Reducing Stereotypes in Word Embeddings",
    "authors": [
      "Tolga Bolukbasi",
      "Kai-Wei Chang",
      "James Zou",
      "Venkatesh Saligrama",
      "Adam Kalai"
    ],
    "author_ids": [],
    "abstract": "Machine learning algorithms are optimized to model statistical properties of\nthe training data. If the input data reflects stereotypes and biases of the\nbroader society, then the output of the learning algorithm also captures these\nstereotypes. In this paper, we initiate the study of gender stereotypes in {\\em\nword embedding}, a popular framework to represent text data. As their use\nbecomes increasingly common, applications can inadvertently amplify unwanted\nstereotypes. We show across multiple datasets that the embeddings contain\nsignificant gender stereotypes, especially with regard to professions. We\ncreated a novel gender analogy task and combined it with crowdsourcing to\nsystematically quantify the gender bias in a given embedding. We developed an\nefficient algorithm that reduces gender stereotype using just a handful of\ntraining examples while preserving the useful geometric properties of the\nembedding. We evaluated our algorithm on several metrics. While we focus on\nmale/female stereotypes, our framework may be applicable to other types of\nembedding biases.",
    "published_date": "2016-06-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.06121v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.06108v2",
    "title": "DualNet: Domain-Invariant Network for Visual Question Answering",
    "authors": [
      "Kuniaki Saito",
      "Andrew Shin",
      "Yoshitaka Ushiku",
      "Tatsuya Harada"
    ],
    "author_ids": [],
    "abstract": "Visual question answering (VQA) task not only bridges the gap between images\nand language, but also requires that specific contents within the image are\nunderstood as indicated by linguistic context of the question, in order to\ngenerate the accurate answers. Thus, it is critical to build an efficient\nembedding of images and texts. We implement DualNet, which fully takes\nadvantage of discriminative power of both image and textual features by\nseparately performing two operations. Building an ensemble of DualNet further\nboosts the performance. Contrary to common belief, our method proved effective\nin both real images and abstract scenes, in spite of significantly different\nproperties of respective domain. Our method was able to outperform previous\nstate-of-the-art methods in real images category even without explicitly\nemploying attention mechanism, and also outperformed our own state-of-the-art\nmethod in abstract scenes category, which recently won the first place in VQA\nChallenge 2016.",
    "published_date": "2016-06-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.06108v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.05969v3",
    "title": "Yet Another Proof of the Entropy Power Inequality",
    "authors": [
      "Olivier Rioul"
    ],
    "author_ids": [],
    "abstract": "Yet another simple proof of the entropy power inequality is given, which\navoids both the integration over a path of Gaussian perturbation and the use of\nYoung's inequality with sharp constant or R\\'enyi entropies. The proof is based\non a simple change of variables, is formally identical in one and several\ndimensions, and easily settles the equality case.",
    "published_date": "2016-06-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "H.1.1; E.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.05969v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.05850v2",
    "title": "Guaranteed bounds on the Kullback-Leibler divergence of univariate mixtures using piecewise log-sum-exp inequalities",
    "authors": [
      "Frank Nielsen",
      "Ke Sun"
    ],
    "author_ids": [],
    "abstract": "Information-theoretic measures such as the entropy, cross-entropy and the\nKullback-Leibler divergence between two mixture models is a core primitive in\nmany signal processing tasks. Since the Kullback-Leibler divergence of mixtures\nprovably does not admit a closed-form formula, it is in practice either\nestimated using costly Monte-Carlo stochastic integration, approximated, or\nbounded using various techniques. We present a fast and generic method that\nbuilds algorithmically closed-form lower and upper bounds on the entropy, the\ncross-entropy and the Kullback-Leibler divergence of mixtures. We illustrate\nthe versatile method by reporting on our experiments for approximating the\nKullback-Leibler divergence between univariate exponential mixtures, Gaussian\nmixtures, Rayleigh mixtures, and Gamma mixtures.",
    "published_date": "2016-06-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.05850v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.05596v1",
    "title": "Ground Truth Bias in External Cluster Validity Indices",
    "authors": [
      "Yang Lei",
      "James C. Bezdek",
      "Simone Romano",
      "Nguyen Xuan Vinh",
      "Jeffrey Chan",
      "James Bailey"
    ],
    "author_ids": [],
    "abstract": "It has been noticed that some external CVIs exhibit a preferential bias\ntowards a larger or smaller number of clusters which is monotonic (directly or\ninversely) in the number of clusters in candidate partitions. This type of bias\nis caused by the functional form of the CVI model. For example, the popular\nRand index (RI) exhibits a monotone increasing (NCinc) bias, while the Jaccard\nIndex (JI) index suffers from a monotone decreasing (NCdec) bias. This type of\nbias has been previously recognized in the literature. In this work, we\nidentify a new type of bias arising from the distribution of the ground truth\n(reference) partition against which candidate partitions are compared. We call\nthis new type of bias ground truth (GT) bias. This type of bias occurs if a\nchange in the reference partition causes a change in the bias status (e.g.,\nNCinc, NCdec) of a CVI. For example, NCinc bias in the RI can be changed to\nNCdec bias by skewing the distribution of clusters in the ground truth\npartition. It is important for users to be aware of this new type of biased\nbehaviour, since it may affect the interpretations of CVI results. The\nobjective of this article is to study the empirical and theoretical\nimplications of GT bias. To the best of our knowledge, this is the first\nextensive study of such a property for external cluster validity indices.",
    "published_date": "2016-06-17T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.05596v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.04220v2",
    "title": "On the Design of MAC Protocol and Transmission Scheduling for Internet of Things",
    "authors": [
      "Tanmay Chaturvedi",
      "Kai Li",
      "Chau Yuen",
      "Abhishek Sharma",
      "Linglong Dai",
      "Meng Zhang"
    ],
    "author_ids": [],
    "abstract": "With the ubiquitous sensing enabled by wireless sensor network technologies,\nInternet of Things (IoT) is developed to many areas of modern day living. The\ninexpensive IoT devices and platforms capable of wireless communications enable\nthe ability to measure, infer and understand environmental indicators, from\ndelicate ecologies and natural resources to urban environments. In this paper,\nwe firstly investigate a scalable multimode-based MAC protocol, IoT-MAC, which\nconsists of a channel contention period and a data transmission period, to\nreduce contention of channel access due to coexist of many IoT devices.\nSecondly, we study a data transmission scheduling algorithm to maximise data\ncollection under the constraints of radio link quality and remaining energy of\nthe IoT node, while ensuring a fair access to the radio channel. To study the\nperformance of data reception rate, packet loss rate and latency, we evaluate\nthe IoT-MAC and scheduling algorithm with varying data rate and different\nnetwork scale.",
    "published_date": "2016-06-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.04220v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.04160v2",
    "title": "The Crossover Process: Learnability and Data Protection from Inference Attacks",
    "authors": [
      "Richard Nock",
      "Giorgio Patrini",
      "Finnian Lattimore",
      "Tiberio Caetano"
    ],
    "author_ids": [],
    "abstract": "It is usual to consider data protection and learnability as conflicting\nobjectives. This is not always the case: we show how to jointly control\ninference --- seen as the attack --- and learnability by a noise-free process\nthat mixes training examples, the Crossover Process (cp). One key point is that\nthe cp~is typically able to alter joint distributions without touching on\nmarginals, nor altering the sufficient statistic for the class. In other words,\nit saves (and sometimes improves) generalization for supervised learning, but\ncan alter the relationship between covariates --- and therefore fool measures\nof nonlinear independence and causal inference into misleading ad-hoc\nconclusions. For example, a cp~can increase / decrease odds ratios, bring\nfairness or break fairness, tamper with disparate impact, strengthen, weaken or\nreverse causal directions, change observed statistical measures of dependence.\nFor each of these, we quantify changes brought by a cp, as well as its\nstatistical impact on generalization abilities via a new complexity measure\nthat we call the Rademacher cp~complexity. Experiments on a dozen readily\navailable domains validate the theory.",
    "published_date": "2016-06-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML",
      "I.2.6; K.4.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.04160v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.04033v2",
    "title": "Designing Commercial Therapeutic Robots for Privacy Preserving Systems and Ethical Research Practices within the Home",
    "authors": [
      "Elaine Sedenberg",
      "John Chuang",
      "Deirdre Mulligan"
    ],
    "author_ids": [],
    "abstract": "The migration of robots from the laboratory into sensitive home settings as\ncommercially available therapeutic agents represents a significant transition\nfor information privacy and ethical imperatives. We present new privacy\nparadigms and apply the Fair Information Practices (FIPs) to investigate\nconcerns unique to the placement of therapeutic robots in private home\ncontexts. We then explore the importance and utility of research ethics as\noperationalized by existing human subjects research frameworks to guide the\nconsideration of therapeutic robotic users -- a step vital to the continued\nresearch and development of these platforms. Together, privacy and research\nethics frameworks provide two complementary approaches to protect users and\nensure responsible yet robust information sharing for technology development.\nWe make recommendations for the implementation of these principles -- paying\nparticular attention to specific principles that apply to vulnerable\nindividuals (i.e., children, disabled, or elderly persons)--to promote the\nadoption and continued improvement of long-term, responsible, and\nresearch-enabled robotics in private settings.",
    "published_date": "2016-06-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.04033v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.03986v2",
    "title": "DDoS Attacks with Randomized Traffic Innovation: Botnet Identification Challenges and Strategies",
    "authors": [
      "Vincenzo Matta",
      "Mario Di Mauro",
      "Maurizio Longo"
    ],
    "author_ids": [],
    "abstract": "Distributed Denial-of-Service (DDoS) attacks are usually launched through the\n$botnet$, an \"army\" of compromised nodes hidden in the network. Inferential\ntools for DDoS mitigation should accordingly enable an early and reliable\ndiscrimination of the normal users from the compromised ones. Unfortunately,\nthe recent emergence of attacks performed at the application layer has\nmultiplied the number of possibilities that a botnet can exploit to conceal its\nmalicious activities. New challenges arise, which cannot be addressed by simply\nborrowing the tools that have been successfully applied so far to earlier DDoS\nparadigms. In this work, we offer basically three contributions: $i)$ we\nintroduce an abstract model for the aforementioned class of attacks, where the\nbotnet emulates normal traffic by continually learning admissible patterns from\nthe environment; $ii)$ we devise an inference algorithm that is shown to\nprovide a consistent (i.e., converging to the true solution as time progresses)\nestimate of the botnet possibly hidden in the network; and $iii)$ we verify the\nvalidity of the proposed inferential strategy over $real$ network traces.",
    "published_date": "2016-06-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.CR",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03986v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.03788v1",
    "title": "Unsupervised Non Linear Dimensionality Reduction Machine Learning methods applied to Multiparametric MRI in cerebral ischemia: Preliminary Results",
    "authors": [
      "Vishwa S. Parekh",
      "Jeremy R. Jacobs",
      "Michael A. Jacobs"
    ],
    "author_ids": [],
    "abstract": "The evaluation and treatment of acute cerebral ischemia requires a technique\nthat can determine the total area of tissue at risk for infarction using\ndiagnostic magnetic resonance imaging (MRI) sequences. Typical MRI data sets\nconsist of T1- and T2-weighted imaging (T1WI, T2WI) along with advanced MRI\nparameters of diffusion-weighted imaging (DWI) and perfusion weighted imaging\n(PWI) methods. Each of these parameters has distinct radiological-pathological\nmeaning. For example, DWI interrogates the movement of water in the tissue and\nPWI gives an estimate of the blood flow, both are critical measures during the\nevolution of stroke. In order to integrate these data and give an estimate of\nthe tissue at risk or damaged, we have developed advanced machine learning\nmethods based on unsupervised non-linear dimensionality reduction (NLDR)\ntechniques. NLDR methods are a class of algorithms that uses mathematically\ndefined manifolds for statistical sampling of multidimensional classes to\ngenerate a discrimination rule of guaranteed statistical accuracy and they can\ngenerate a two- or three-dimensional map, which represents the prominent\nstructures of the data and provides an embedded image of meaningful\nlow-dimensional structures hidden in their high-dimensional observations. In\nthis manuscript, we develop NLDR methods on high dimensional MRI data sets of\npreclinical animals and clinical patients with stroke. On analyzing the\nperformance of these methods, we observed that there was a high of similarity\nbetween multiparametric embedded images from NLDR methods and the ADC map and\nperfusion map. It was also observed that embedded scattergram of abnormal\n(infarcted or at risk) tissue can be visualized and provides a mechanism for\nautomatic methods to delineate potential stroke volumes and early tissue at\nrisk.",
    "published_date": "2016-06-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "H.3.3, I.5.3, I.5.4, J.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03788v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.03736v2",
    "title": "Enhancement of Low-cost GNSS Localization in Connected Vehicle Networks Using Rao-Blackwellized Particle Filters",
    "authors": [
      "Macheng Shen",
      "Ding Zhao",
      "Jing Sun"
    ],
    "author_ids": [],
    "abstract": "An essential function for automated vehicle technologies is accurate\nlocalization. It is difficult, however, to achieve lane-level accuracy with\nlow-cost Global Navigation Satellite System (GNSS) receivers due to the biased\nnoisy pseudo-range measurements. Approaches such as Differential GNSS can\nimprove the accuracy, but usually require an enormous amount of investment in\nbase stations. The emerging connected vehicle technologies provide an\nalternative approach to improving the localization accuracy. It has been shown\nin this paper that localization accuracy can be enhanced by fusing GNSS\ninformation within a group of connected vehicles and matching the configuration\nof the group to a digital map to eliminate the common bias in localization. A\nRao-Blackwellized particle filter (RBPF) was used to jointly estimate the\ncommon biases of the pseudo-ranges and the vehicles positions. Multipath\nbiases, which are non-common to vehicles, were mitigated by a multi-hypothesis\ndetection-rejection approach. The temporal correlation was exploited through\nthe prediction-update process. The proposed approach was compared to the\nexisting static and smoothed static methods in the intersection scenario.\nSimulation results show that the proposed algorithm reduced the estimation\nerror by fifty percent and reduced the estimation variance by two orders of\nmagnitude.",
    "published_date": "2016-06-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.RO",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03736v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.03665v1",
    "title": "Resource Allocation and Fairness in Wireless Powered Cooperative Cognitive Radio Networks",
    "authors": [
      "Sanket S. Kalamkar",
      "Jeya Pradha Jeyaraj",
      "Adrish Banerjee",
      "Ketan Rajawat"
    ],
    "author_ids": [],
    "abstract": "We integrate a wireless powered communication network with a cooperative\ncognitive radio network, where multiple secondary users (SUs) powered\nwirelessly by a hybrid access point (HAP) help a primary user relay the data.\nAs a reward for the cooperation, the secondary network gains the spectrum\naccess where SUs transmit to HAP using time division multiple access. To\nmaximize the sum-throughput of SUs, we present a secondary sum-throughput\noptimal resource allocation (STORA) scheme. Under the constraint of meeting\ntarget primary rate, the STORA scheme chooses the optimal set of relaying SUs\nand jointly performs the time and energy allocation for SUs. Specifically, by\nexploiting the structure of the optimal solution, we find the order in which\nSUs are prioritized to relay primary data. Since the STORA scheme focuses on\nthe sum-throughput, it becomes inconsiderate towards individual SU throughput,\nresulting in low fairness. To enhance fairness, we investigate three resource\nallocation schemes, which are (i) equal time allocation, (ii) minimum\nthroughput maximization, and (iii) proportional time allocation. Simulation\nresults reveal the trade-off between sum-throughput and fairness. The minimum\nthroughput maximization scheme is the fairest one as each SU gets the same\nthroughput, but yields the least SU sum-throughput.",
    "published_date": "2016-06-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03665v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.03506v1",
    "title": "Ethical Implications of IT-enabled Information Flows Conceived as Intermediaries or Mediators",
    "authors": [
      "Dubravka Cecez-Kecmanovic",
      "Olivera Marjanovic"
    ],
    "author_ids": [],
    "abstract": "This paper contributes to a better understanding of ethical concerns\nregarding the deployment of complex public sector IT systems and the\ninformation flows they instigate. The paper aims to reveal how different views\non IT and IT-enabled information flows allow us to see differently their social\nimplications and to construe different ethical questions. This is achieved by\ni) defining two opposing views on IT-enabled information flows as\n'intermediaries' and 'mediators'; ii) by analysing the controversial case of My\nSchool - a web portal that provides performance data of 9,500 Australian\nschools - that introduces new information flows in the education sector; and\niii) by revealing and explaining how some unintended negative social\nimplications emerge and how the articulation of ethical concerns depends on the\nview on My School-enabled information flows. The paper concludes with\ntheoretical and practical implications, with particular emphasis on\nresponsibilities of all involved, setting up foundations for an important area\nof future IS research.",
    "published_date": "2016-06-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03506v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.03402v2",
    "title": "Length bias in Encoder Decoder Models and a Case for Global Conditioning",
    "authors": [
      "Pavel Sountsov",
      "Sunita Sarawagi"
    ],
    "author_ids": [],
    "abstract": "Encoder-decoder networks are popular for modeling sequences probabilistically\nin many applications. These models use the power of the Long Short-Term Memory\n(LSTM) architecture to capture the full dependence among variables, unlike\nearlier models like CRFs that typically assumed conditional independence among\nnon-adjacent variables. However in practice encoder-decoder models exhibit a\nbias towards short sequences that surprisingly gets worse with increasing beam\nsize.\n  In this paper we show that such phenomenon is due to a discrepancy between\nthe full sequence margin and the per-element margin enforced by the locally\nconditioned training objective of a encoder-decoder model. The discrepancy more\nadversely impacts long sequences, explaining the bias towards predicting short\nsequences.\n  For the case where the predicted sequences come from a closed set, we show\nthat a globally conditioned model alleviates the above problems of\nencoder-decoder models. From a practical point of view, our proposed model also\neliminates the need for a beam-search during inference, which reduces to an\nefficient dot-product based search in a vector-space.",
    "published_date": "2016-06-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03402v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.03191v1",
    "title": "Fuzzy-Klassen Model for Development Disparities Analysis based on Gross Regional Domestic Product Sector of a Region",
    "authors": [
      "Tb. Ai Munandar",
      "Retantyo Wardoyo"
    ],
    "author_ids": [],
    "abstract": "Analysis of regional development imbalances quadrant has a very important\nmeaning in order to see the extent of achievement of the development of certain\nareas as well as the difference. Factors that could be used as a tool to\nmeasure the inequality of development is to look at the average growth and\ndevelopment contribution of each sector of Gross Regional Domestic Product\n(GRDP) based on the analyzed region and the reference region. This study\ndiscusses the development of a model to determine the regional development\nimbalances using fuzzy approach system, and the rules of typology Klassen. The\nmodel is then called fuzzy-Klassen. Implications Product Mamdani fuzzy system\nis used in the model as an inference engine to generate output after\ndefuzzyfication process. Application of MATLAB is used as a tool of analysis in\nthis study. The test a result of Kota Cilegon is shows that there are\nsignificant differences between traditional Klassen typology analyses with the\nresults of the model developed. Fuzzy model-Klassen shows GRDP sector\ninequality Cilegon City is dominated by Quadrant I (K4), where status is the\nsector forward and grows exponentially. While the traditional Klassen typology,\nhalf of GRDP sector is dominated by Quadrant IV (K4) with a sector that is\nlagging relative status.",
    "published_date": "2016-06-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03191v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.03062v1",
    "title": "Procrastination with variable present bias",
    "authors": [
      "Nick Gravin",
      "Nicole Immorlica",
      "Brendan Lucier",
      "Emmanouil Pountourakis"
    ],
    "author_ids": [],
    "abstract": "Individuals working towards a goal often exhibit time inconsistent behavior,\nmaking plans and then failing to follow through. One well-known model of such\nbehavioral anomalies is present-bias discounting: individuals over-weight\npresent costs by a bias factor. This model explains many time-inconsistent\nbehaviors, but can make stark predictions in many settings: individuals either\nfollow the most efficient plan for reaching their goal or procrastinate\nindefinitely.\n  We propose a modification in which the present-bias parameter can vary over\ntime, drawn independently each step from a fixed distribution. Following\nKleinberg and Oren (2014), we use a weighted task graph to model task planning,\nand measure the cost of procrastination as the relative expected cost of the\nchosen path versus the optimal path. We use a novel connection to optimal\npricing theory to describe the structure of the worst-case task graph for any\npresent-bias distribution. We then leverage this structure to derive conditions\non the bias distribution under which the worst-case ratio is exponential (in\ntime) or constant. We also examine conditions on the task graph that lead to\nimproved procrastination ratios: graphs with a uniformly bounded distance to\nthe goal, and graphs in which the distance to the goal monotonically decreases\non any path.",
    "published_date": "2016-06-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03062v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.02878v1",
    "title": "What is Learning Analytics about? A Survey of Different Methods Used in 2013-2015",
    "authors": [
      "Mohammad Khalil",
      "Martin Ebner"
    ],
    "author_ids": [],
    "abstract": "The area of Learning Analytics has developed enormously since the first\nInternational Conference on Learning Analytics and Knowledge (LAK) in 2011. It\nis a field that combines different disciplines such as computer science,\nstatistics, psychology and pedagogy to achieve its intended objectives. The\nmain goals illustrate in creating convenient interventions on learning as well\nas its environment and the final optimization about learning domain\nstakeholders. Because the field matures and is now adapted in diverse\neducational settings, we believe there is a pressing need to list its own\nresearch methods and specify its objectives and dilemmas. This paper surveys\npublications from Learning Analytics and Knowledge conference from 2013 to 2015\nand lists the significant research areas in this sphere. We consider the method\nprofile and classify them into seven different categories with a brief\ndescription on each. Furthermore, we show the most cited method categories\nusing Google scholar. Finally, the authors raise the challenges and constraints\nthat affect its ethical approach through the meta-analysis study. It is\nbelieved that this paper will help researchers to identify the common methods\nused in Learning Analytics, and it will assist by establishing a future\nforecast towards new research work taking into account the privacy and ethical\nissues of this strongly emerged field.",
    "published_date": "2016-06-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.02878v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.02597v2",
    "title": "Excess reciprocity distorts reputation in online social networks",
    "authors": [
      "Giacomo Livan",
      "Fabio Caccioli",
      "Tomaso Aste"
    ],
    "author_ids": [],
    "abstract": "The peer-to-peer (P2P) economy relies on establishing trust in distributed\nnetworked systems, where the reliability of a user is assessed through digital\npeer-review processes that aggregate ratings into reputation scores. Here we\npresent evidence of a network effect which biases digital reputation, revealing\nthat P2P networks display exceedingly high levels of reciprocity. In fact,\nthese are much higher than those compatible with a null assumption that\npreserves the empirically observed level of agreement between all pairs of\nnodes, and rather close to the highest levels structurally compatible with the\nnetworks' reputation landscape. This indicates that the crowdsourcing process\nunderpinning digital reputation can be significantly distorted by the attempt\nof users to mutually boost reputation, or to retaliate, through the exchange of\nratings. We uncover that the least active users are predominantly responsible\nfor such reciprocity-induced bias, and that this fact can be exploited to\nobtain more reliable reputation estimates. Our findings are robust across\ndifferent P2P platforms, including both cases where ratings are used to vote on\nthe content produced by users and to vote on user profiles.",
    "published_date": "2016-06-08T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.02597v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.02583v1",
    "title": "The Dark Side of Ethical Robots",
    "authors": [
      "Dieter Vanderelst",
      "Alan Winfield"
    ],
    "author_ids": [],
    "abstract": "Concerns over the risks associated with advances in Artificial Intelligence\nhave prompted calls for greater efforts toward robust and beneficial AI,\nincluding machine ethics. Recently, roboticists have responded by initiating\nthe development of so-called ethical robots. These robots would, ideally,\nevaluate the consequences of their actions and morally justify their choices.\nThis emerging field promises to develop extensively over the next years.\nHowever, in this paper, we point out an inherent limitation of the emerging\nfield of ethical robots. We show that building ethical robots also necessarily\nfacilitates the construction of unethical robots. In three experiments, we show\nthat it is remarkably easy to modify an ethical robot so that it behaves\ncompetitively, or even aggressively. The reason for this is that the specific\nAI, required to make an ethical robot, can always be exploited to make\nunethical robots. Hence, the development of ethical robots will not guarantee\nthe responsible deployment of AI. While advocating for ethical robots, we\nconclude that preventing the misuse of robots is beyond the scope of\nengineering, and requires instead governance frameworks underpinned by\nlegislation. Without this, the development of ethical robots will serve to\nincrease the risks of robotic malpractice instead of diminishing it.",
    "published_date": "2016-06-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.02583v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1606.02497v1",
    "title": "Opportunities and challenges of mobile learning for promoting mathematical literacy",
    "authors": [
      "Zaenal Abidin",
      "Anuradha Mathrani",
      "David Parsons",
      "Suriadi Suriadi"
    ],
    "author_ids": [],
    "abstract": "Mathematical literacy plays an important role in supporting individuals to\nfulfil their professional roles in modern society. The affordances of mobile\ntechnologies as well as the emergence of new theories in mobile learning have\nthe potential to promote mathematical literacy. However, implementation of\nmobile learning in Indonesian society faces challenges related to perceived\nethical and learning issues in curriculum-based educational settings. This\nstudy aims to investigate the preparedness of teachers in integrating\nmathematics subject content with mobile technologies, especially in promoting\nmathematical literacy. An exploratory study has been conducted using mixed\nmethods by performing questionnaire survey and semi-structured interviews to\nunderstand teacher's knowledge towards mathematical literacy and identifying\nopportunities and challenges of mobile learning within instruction. Findings\nindicate that teachers mostly do not know about mathematical literacy,\nindicating that the concept of mathematical literacy needs to be promoted.\nFurther, most schools prohibit the use of mobile devices in classrooms as they\nare wary of inappropriate use of mobile devices which may harm students' mental\nhealth and distract them from learning. Study finds this to be the most common\ncause for teachers' reluctance in using mobile learning.",
    "published_date": "2016-06-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.02497v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.02033v2",
    "title": "User Cooperation for Enhanced Throughput Fairness in Wireless Powered Communication Networks",
    "authors": [
      "Mingquan Zhong",
      "Suzhi Bi",
      "Xiaohui Lin"
    ],
    "author_ids": [],
    "abstract": "This paper studies a novel user cooperation method in a wireless powered\ncommunication network (WPCN), where a pair of distributed terminal users first\nharvest wireless energy broadcasted by one energy node (EN) and then use the\nharvested energy to transmit information cooperatively to a destination node\n(DN). In particular, the two cooperating users exchange their independent\ninformation with each other to form a virtual antenna array and transmit\njointly to the DN. By allowing each user to allocate part of its harvested\nenergy to transmit the other's information, the proposed cooperation can\neffectively mitigate the user unfairness problem in WPCNs, where a user may\nsuffer from very low data rate due to the poor energy harvesting performance\nand high data transmission consumptions. We derive the maximum common\nthroughput achieved by the cooperation scheme through optimizing the time\nallocation on wireless energy transfer, user message exchange, and joint\ninformation transmissions. Through comparing with some representative benchmark\nschemes, our results demonstrate the effectiveness of the proposed user\ncooperation in enhancing the throughput performance under different setups.",
    "published_date": "2016-06-07T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.02033v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.01935v2",
    "title": "A generalized formulation for vehicle routing problems",
    "authors": [
      "Pedro Munari",
      "Twan Dollevoet",
      "Remy Spliet"
    ],
    "author_ids": [],
    "abstract": "Different types of formulations are proposed in the literature to model\nvehicle routing problems. Currently, the most used ones can be fitted into two\nclasses, namely vehicle flow formulations and set partitioning formulations.\nThese types of formulations differ from each other not only due to their\nvariables and constraints but also due to their main features. Vehicle flow\nformulations have the advantage of being compact models, so general-purpose\noptimization packages can be used to straightforwardly solve them. However,\nthey typically show weak linear relaxations and have a large number of\nconstraints. Branch-and-cut methods based on specialized valid inequalities can\nalso be devised to solve these formulations, but they have not shown to be\neffective for large-scale instances. On the other hand, set partitioning\nformulations have stronger linear relaxations, but requires the implementation\nof sophisticate techniques such as column generation and specialized\nbranch-and-price methods. Due to all these reasons, so far it is has been\nrecognized in the vehicle routing community that these two types of\nformulations are rather different. In this paper, we show that they are\nactually strongly related as they correspond to special cases of a generalized\nformulation of vehicle routing problems.",
    "published_date": "2016-06-06T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.01935v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.01800v4",
    "title": "Finite Sample Analysis of Approximate Message Passing Algorithms",
    "authors": [
      "Cynthia Rush",
      "Ramji Venkataramanan"
    ],
    "author_ids": [],
    "abstract": "Approximate message passing (AMP) refers to a class of efficient algorithms\nfor statistical estimation in high-dimensional problems such as compressed\nsensing and low-rank matrix estimation. This paper analyzes the performance of\nAMP in the regime where the problem dimension is large but finite. For\nconcreteness, we consider the setting of high-dimensional regression, where the\ngoal is to estimate a high-dimensional vector $\\beta_0$ from a noisy\nmeasurement $y=A \\beta_0 + w$. AMP is a low-complexity, scalable algorithm for\nthis problem. Under suitable assumptions on the measurement matrix $A$, AMP has\nthe attractive feature that its performance can be accurately characterized in\nthe large system limit by a simple scalar iteration called state evolution.\nPrevious proofs of the validity of state evolution have all been asymptotic\nconvergence results. In this paper, we derive a concentration inequality for\nAMP with i.i.d. Gaussian measurement matrices with finite size $n \\times N$.\nThe result shows that the probability of deviation from the state evolution\nprediction falls exponentially in $n$. This provides theoretical support for\nempirical findings that have demonstrated excellent agreement of AMP\nperformance with state evolution predictions for moderately large dimensions.\nThe concentration inequality also indicates that the number of AMP iterations\n$t$ can grow no faster than order $\\frac{\\log n}{\\log \\log n}$ for the\nperformance to be close to the state evolution predictions with high\nprobability. The analysis can be extended to obtain similar non-asymptotic\nresults for AMP in other settings such as low-rank matrix estimation.",
    "published_date": "2016-06-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.01800v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.00717v1",
    "title": "Biased Contribution Index: A Simpler Mechanism to Maintain Fairness in Peer to Peer Network",
    "authors": [
      "Sateesh Kumar Awasthi",
      "Yatindra Nath Singh"
    ],
    "author_ids": [],
    "abstract": "To maintain fairness, in the terms of resources shared by an individual peer,\na proper incentive policy is required in a peer to peer network. This letter\nproposes, a simpler mechanism to rank the peers based on their resource\ncontributions to the network. This mechanism will suppress the free riders from\ndownloading the resources from the network. Contributions of the peers are\nbiased in such a way that it can balance the download and upload amount of\nresources at each peer. This mechanism can be implemented in a distributed\nsystem and it converges much faster than the other existing approaches.",
    "published_date": "2016-06-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.00717v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1606.00240v1",
    "title": "Using network centrality measures to improve national journal classification lists",
    "authors": [
      "Alesia Zuccala",
      "Nicolas Robinson-Garcia",
      "Rafael Repiso",
      "Daniel Torres-Salinas"
    ],
    "author_ids": [],
    "abstract": "In countries like Denmark and Spain classified journal lists are now being\nproduced and used in the calculation of nationwide performance indicators. As a\nresult, Danish and Spanish scholars are advised to contribute to journals of\nhigh 'authority' (as in the former) or those within a high class (as in the\nlatter). This can create a few problems. The aim of this paper is to analyse\nthe potential use of network centrality measures to identify possible\nmismatches of journal categories. It analysis the Danish National Authority\nList and the Spanish CIRC Classification. Based on a sample of Library and\nInformation Science publications, it analyses centrality measures that can\nassess on the importance of journals to given fields, correcting mismatches in\nthese classifications. We conclude by emphasising the use of these measures to\nbetter calibrate journal classifications as we observe a general bias in these\nlists towards older journals. Centrality measures can allow to identify\nperiphery-to-core journals' transitions.",
    "published_date": "2016-06-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.00240v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.09626v1",
    "title": "Software startuppers took the medias paycheck Medias fightback happens through startup culture and abstraction shifts",
    "authors": [
      "Outi Alapekkala",
      "Juhani Risku"
    ],
    "author_ids": [],
    "abstract": "The collapse of old print media and journalism happened when the Internet,\nits solutions, services and communities became mature and mobile devices\nreached the market. The reader abandoned printed dailies for free and mobile\naccess to information. The business of core industries of the early Internet\nand mobile communication, the mobile network manufacturers and operators are\nalso in stagnation and decline. Therefore these industries may have similar\ninterests to improve or even restructure their own businesses as well as to\nestablish totally new business models by going into media and journalism.\n  This paper analyses, first, the production flows and business models of the\nold and present media species. Second, it analyses the current market\npositioning of the network manufacturers and operators. Third, the paper\nsuggests two avenues for media and journalism and the network manufacturers and\noperators, the Trio, to join their forces to update journalism and make all\nthree stagnating industries great again. Last, we propose further research,\ndevelopment and discussion on the topic and envision possible futures for\njournalism, if the three would engage in cooperation. We see that the\ndiscussion should consist of ethical, societal and philosophical subjects\nbecause the development of the Internet solutions are based on 'technology\nfirst' actions.\n  We find and outline a tremendous opportunity to create a new industry with\nnew actors through combining the interests of the network manufacturers,\nnetwork operators and journalism in a systemic solution through a strategic\nalliance and collaboration Fig. 1. Software startuppers with their applications\nand communities will be the drivers for this abstraction shift in media and\njournalism.",
    "published_date": "2016-05-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.09626v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.09582v1",
    "title": "Model-driven Simulations for Deep Convolutional Neural Networks",
    "authors": [
      "V S R Veeravasarapu",
      "Constantin Rothkopf",
      "Visvanathan Ramesh"
    ],
    "author_ids": [],
    "abstract": "The use of simulated virtual environments to train deep convolutional neural\nnetworks (CNN) is a currently active practice to reduce the\n(real)data-hungriness of the deep CNN models, especially in application domains\nin which large scale real data and/or groundtruth acquisition is difficult or\nlaborious. Recent approaches have attempted to harness the capabilities of\nexisting video games, animated movies to provide training data with high\nprecision groundtruth. However, a stumbling block is in how one can certify\ngeneralization of the learned models and their usefulness in real world data\nsets. This opens up fundamental questions such as: What is the role of\nphotorealism of graphics simulations in training CNN models? Are the trained\nmodels valid in reality? What are possible ways to reduce the performance bias?\nIn this work, we begin to address theses issues systematically in the context\nof urban semantic understanding with CNNs. Towards this end, we (a) propose a\nsimple probabilistic urban scene model, (b) develop a parametric rendering tool\nto synthesize the data with groundtruth, followed by (c) a systematic\nexploration of the impact of level-of-realism on the generality of the trained\nCNN model to real world; and domain adaptation concepts to minimize the\nperformance bias.",
    "published_date": "2016-05-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.09582v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.09184v1",
    "title": "Census Tract License Areas: Disincentive for Sharing the 3.5GHz band?",
    "authors": [
      "Elma Avdic",
      "Irene Macaluso",
      "Nicola Marchetti",
      "Linda Doyle"
    ],
    "author_ids": [],
    "abstract": "Flexible licensing model is a necessary enabler of the technical and\nprocedural complexities of Spectrum Access System (SAS)-based sharing\nframework. The purpose of this study is to explore the effectiveness of 3.5GHz\nLicensing Framework - based on census tracts as area units, areas whose main\ncharacteristic is population. As such, the boundary of census tract does not\nfollow the edge of wireless network coverage. We demonstrate why census tracts\nare not suitable for small cell networks licensing, by (1) gathering and\nanalysing the official census data, (2) exploring the boundaries of census\ntracts which are in the shape of nonconvex polygons and (3) giving a measure of\neffectiveness of the licensing scheme through metrics of area loss and the\nnumber of people per census tract with access to spectrum. Results show that\ncensus tracts severely impact the effectiveness of the licensing framework\nsince almost entire strategically important cities in the U.S. will not avail\nfrom spectrum use in 3.5GHz band. Our paper does not seek to challenge the core\nnotion of geographic licensing concept, but seeks a corrective that addresses\nthe way the license is issued for a certain area of operation. The effects that\ninappropriate size of the license has on spectrum assignments lead to spectrum\nbeing simply wasted in geography, time and frequency or not being assigned in a\nfair manner. The corrective is necessary since the main goal of promoting\ninnovative sharing in 3.5 GHz band is to put spectrum to more efficient use.",
    "published_date": "2016-05-30T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.09184v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.09013v2",
    "title": "Flexible constrained de Finetti reductions and applications",
    "authors": [
      "Cécilia Lancien",
      "Andreas Winter"
    ],
    "author_ids": [],
    "abstract": "De Finetti theorems show how sufficiently exchangeable states are\nwell-approximated by convex combinations of i.i.d. states. Recently, it was\nshown that in many quantum information applications a more relaxed de Finetti\nreduction (i.e. only a matrix inequality between the symmetric state and one of\nde Finetti form) is enough, and that it leads to more concise and elegant\narguments. Here we show several uses and general flexible applicability of a\nconstrained de Finetti reduction in quantum information theory, which was\nrecently discovered by Duan, Severini and Winter. In particular we show that\nthe technique can accommodate other symmetries commuting with the permutation\naction, and permutation-invariant linear constraints. We then demonstrate that,\nin some cases, it is also fruitful with convex constraints, in particular\nseparability in a bipartite setting. This is a constraint particularly\ninteresting in the context of the complexity class $\\mathrm{QMA}(2)$ of\ninteractive quantum Merlin-Arthur games with unentangled provers, and our\nresults relate to the soundness gap amplification of $\\mathrm{QMA}(2)$\nprotocols by parallel repetition. It is also relevant for the regularization of\ncertain entropic channel parameters. Finally, we explore an extension to\ninfinite-dimensional systems, which usually pose inherent problems to de\nFinetti techniques in the quantum case.",
    "published_date": "2016-05-29T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.09013v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.07896v4",
    "title": "Belief-Invariant and Quantum Equilibria in Games of Incomplete Information",
    "authors": [
      "Vincenzo Auletta",
      "Diodato Ferraioli",
      "Ashutosh Rai",
      "Giannicola Scarpa",
      "Andreas Winter"
    ],
    "author_ids": [],
    "abstract": "Drawing on ideas from game theory and quantum physics, we investigate\nnonlocal correlations from the point of view of equilibria in games of\nincomplete information. These equilibria can be classified in decreasing power\nas communication equilibria, belief-invariant equilibria, and correlated\nequilibria, all of which contain the familiar Nash equilibria. The notion of\nbelief-invariant equilibrium appeared in game theory in the 90s. However, the\nclass of non-signalling correlations associated to belief-invariance arose\nnaturally already in the 80s in the foundations of quantum mechanics. In the\npresent work, we explain and unify these two origins of the idea and study the\nabove classes of equilibria, together with quantum correlated equilibria, using\ntools from quantum information but the language of (algorithmic) game theory.\nWe present a general framework of belief-invariant communication equilibria,\nwhich contains correlated equilibria and quantum correlated equilibria as\nspecial cases. Our framework also contains the theory of Bell inequalities and\ntheir violations due to non-locality, which is a question of intense interest\nin the foundations of quantum mechanics, and it was indeed the original\nmotivation for the aforementioned studies. Moreover, in our framework we can\nalso model quantum games where players have conflicting interests, a recent\ndeveloping topic in physics. We then use our framework to show new results\nrelated to the social welfare of equilibria. Namely, we exhibit a game where\nbelief-invariance is socially better than any correlated equilibrium, and a\ngame where all non-belief-invariant communication equilibria have a suboptimal\nsocial welfare. We also show that optimal social welfare can sometimes be\nachieved by quantum mechanical correlations, which do not need an informed\nmediator to be implemented, and go beyond the classical shared randomness\napproach.",
    "published_date": "2016-05-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.07896v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.07853v1",
    "title": "Thinning, photonic beamsplitting, and a general discrete entropy power inequality",
    "authors": [
      "Saikat Guha",
      "Jeffrey H. Shapiro",
      "Raul Garcia-Patron Sanchez"
    ],
    "author_ids": [],
    "abstract": "Many partially-successful attempts have been made to find the most natural\ndiscrete-variable version of Shannon's entropy power inequality (EPI). We\ndevelop an axiomatic framework from which we deduce the natural form of a\ndiscrete-variable EPI and an associated entropic monotonicity in a\ndiscrete-variable central limit theorem. In this discrete EPI, the geometric\ndistribution, which has the maximum entropy among all discrete distributions\nwith a given mean, assumes a role analogous to the Gaussian distribution in\nShannon's EPI. The entropy power of $X$ is defined as the mean of a geometric\nrandom variable with entropy $H(X)$. The crux of our construction is a\ndiscrete-variable version of Lieb's scaled addition $X \\boxplus_\\eta Y$ of two\ndiscrete random variables $X$ and $Y$ with $\\eta \\in (0, 1)$. We discuss the\nrelationship of our discrete EPI with recent work of Yu and Johnson who\ndeveloped an EPI for a restricted class of random variables that have\nultra-log-concave (ULC) distributions. Even though we leave open the proof of\nthe aforesaid natural form of the discrete EPI, we show that this discrete EPI\nholds true for variables with arbitrary discrete distributions when the entropy\npower is redefined as $e^{H(X)}$ in analogy with the continuous version.\nFinally, we show that our conjectured discrete EPI is a special case of the\nyet-unproven Entropy Photon-number Inequality (EPnI), which assumes a role\nanalogous to Shannon's EPI in capacity proofs for Gaussian bosonic (quantum)\nchannels.",
    "published_date": "2016-05-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.07853v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.07139v2",
    "title": "Fairness in Learning: Classic and Contextual Bandits",
    "authors": [
      "Matthew Joseph",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "We introduce the study of fairness in multi-armed bandit problems. Our\nfairness definition can be interpreted as demanding that given a pool of\napplicants (say, for college admission or mortgages), a worse applicant is\nnever favored over a better one, despite a learning algorithm's uncertainty\nover the true payoffs. We prove results of two types.\n  First, in the important special case of the classic stochastic bandits\nproblem (i.e., in which there are no contexts), we provide a provably fair\nalgorithm based on \"chained\" confidence intervals, and provide a cumulative\nregret bound with a cubic dependence on the number of arms. We further show\nthat any fair algorithm must have such a dependence. When combined with regret\nbounds for standard non-fair algorithms such as UCB, this proves a strong\nseparation between fair and unfair learning, which extends to the general\ncontextual case.\n  In the general contextual case, we prove a tight connection between fairness\nand the KWIK (Knows What It Knows) learning model: a KWIK algorithm for a class\nof functions can be transformed into a provably fair contextual bandit\nalgorithm, and conversely any fair contextual bandit algorithm can be\ntransformed into a KWIK learning algorithm. This tight connection allows us to\nprovide a provably fair algorithm for the linear contextual bandit problem with\na polynomial dependence on the dimension, and to show (for a different class of\nfunctions) a worst-case exponential gap in regret between fair and non-fair\nlearning algorithms",
    "published_date": "2016-05-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.07139v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.06743v4",
    "title": "Inductive Bias of Deep Convolutional Networks through Pooling Geometry",
    "authors": [
      "Nadav Cohen",
      "Amnon Shashua"
    ],
    "author_ids": [],
    "abstract": "Our formal understanding of the inductive bias that drives the success of\nconvolutional networks on computer vision tasks is limited. In particular, it\nis unclear what makes hypotheses spaces born from convolution and pooling\noperations so suitable for natural images. In this paper we study the ability\nof convolutional networks to model correlations among regions of their input.\nWe theoretically analyze convolutional arithmetic circuits, and empirically\nvalidate our findings on other types of convolutional networks as well.\nCorrelations are formalized through the notion of separation rank, which for a\ngiven partition of the input, measures how far a function is from being\nseparable. We show that a polynomially sized deep network supports\nexponentially high separation ranks for certain input partitions, while being\nlimited to polynomial separation ranks for others. The network's pooling\ngeometry effectively determines which input partitions are favored, thus serves\nas a means for controlling the inductive bias. Contiguous pooling windows as\ncommonly employed in practice favor interleaved partitions over coarse ones,\norienting the inductive bias towards the statistics of natural images. Other\npooling schemes lead to different preferences, and this allows tailoring the\nnetwork to data that departs from the usual domain of natural imagery. In\naddition to analyzing deep networks, we show that shallow ones support only\nlinear separation ranks, and by this gain insight into the benefit of functions\nbrought forth by depth - they are able to efficiently model strong correlation\nunder favored partitions of the input.",
    "published_date": "2016-05-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06743v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.06659v1",
    "title": "Information and Communications Technologies (ICT) and Pre-Service Education Professionals: A Case Study of Motivation and Knowledge",
    "authors": [
      "Maria Isabel Ponce-Escudero",
      "Jose Gomez-Galan"
    ],
    "author_ids": [],
    "abstract": "The importance of knowing ICT training and motivation -so relevant in today's\nsociety- which currently offers the first year college students, mostly in\ndegrees in Education, focuses the object of interest in this study. The\nfollowing targets have been proposed: [1] knowing what basic skills regarding\ninitial instrumental knowledge presents the prospective teacher (aptitudes) and\n[2] knowing their motivation for the educational use of ICT in the classroom\n(attitudes). For this purpose a non-experimental descriptive quantitative\nmethodology has been used, with a sample of subjects (N=282) of the Autonomous\nRegion of Extremadura (Spain). The results show that new degree college\nstudents possess a basic knowledge of ICT alongside a highly positive\nmotivation towards the use of these. However, it is worrying that they only\nshow an instrumental and technical knowledge of computing and telematic tools\nimplied in social environments, but not pedagogical ones. Also they are\nunfamiliar with the true power of social, economic, political, ethical,\ninfluence as well as the effects and problems that their misuse can generate in\ntheir future students (addictions, manipulation, consumerism, etc.). Dimensions\ntherefore for which they are urged to be trained at University for a proper\nperformance as future professionals in education.",
    "published_date": "2016-05-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06659v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.06486v1",
    "title": "Using Read-$k$ Inequalities to Analyze a Distributed MIS Algorithm",
    "authors": [
      "Sriram Pemmaraju",
      "Talal Riaz"
    ],
    "author_ids": [],
    "abstract": "Until recently, the fastest distributed MIS algorithm, even for simple\ngraphs, e.g., unoriented trees has been the simple randomized algorithm\ndiscovered the 80s. This algorithm (commonly called Luby's algorithm) computes\nan MIS in $O(\\log n)$ rounds (with high probability). This situation changed\nwhen Lenzen and Wattenhofer (PODC 2011) presented a randomized $O(\\sqrt{\\log\nn}\\cdot \\log\\log n)$-round MIS algorithm for unoriented trees. This algorithm\nwas improved by Barenboim et al. (FOCS 2012), resulting in an $O(\\sqrt{\\log n\n\\cdot \\log\\log n})$-round MIS algorithm.\n  The analyses of these tree MIS algorithms depends on \"near independence\" of\nprobabilistic events, a feature of the tree structure of the network. In their\npaper, Lenzen and Wattenhofer hope that their algorithm and analysis could be\nextended to graphs with bounded arboricity. We show how to do this. By using a\nnew tail inequality for read-k families of random variables due to Gavinsky et\nal. (Random Struct Algorithms, 2015), we show how to deal with dependencies\ninduced by the recent tree MIS algorithms when they are executed on bounded\narboricity graphs. Specifically, we analyze a version of the tree MIS algorithm\nof Barenboim et al. and show that it runs in $O(\\mbox{poly}(\\alpha) \\cdot\n\\sqrt{\\log n \\cdot \\log\\log n})$ rounds in the $\\mathcal{CONGEST}$ model for\ngraphs with arboricity $\\alpha$.\n  While the main thrust of this paper is the new probabilistic analysis via\nread-$k$ inequalities, for small values of $\\alpha$, this algorithm is faster\nthan the bounded arboricity MIS algorithm of Barenboim et al. We also note that\nrecently (SODA 2016), Gaffari presented a novel MIS algorithm for general\ngraphs that runs in $O(\\log \\Delta) + 2^{O(\\sqrt{\\log\\log n})}$ rounds; a\ncorollary of this algorithm is an $O(\\log \\alpha + \\sqrt{\\log n})$-round MIS\nalgorithm on arboricity-$\\alpha$ graphs.",
    "published_date": "2016-05-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06486v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.06398v2",
    "title": "Stochastic Variance Reduction Methods for Saddle-Point Problems",
    "authors": [
      "P Balamurugan",
      "Francis Bach"
    ],
    "author_ids": [],
    "abstract": "We consider convex-concave saddle-point problems where the objective\nfunctions may be split in many components, and extend recent stochastic\nvariance reduction methods (such as SVRG or SAGA) to provide the first\nlarge-scale linearly convergent algorithms for this class of problems which is\ncommon in machine learning. While the algorithmic extension is straightforward,\nit comes with challenges and opportunities: (a) the convex minimization\nanalysis does not apply and we use the notion of monotone operators to prove\nconvergence, showing in particular that the same algorithm applies to a larger\nclass of problems, such as variational inequalities, (b) there are two notions\nof splits, in terms of functions, or in terms of partial derivatives, (c) the\nsplit does need to be done with convex-concave terms, (d) non-uniform sampling\nis key to an efficient algorithm, both in theory and practice, and (e) these\nincremental algorithms can be easily accelerated using a simple extension of\nthe \"catalyst\" framework, leading to an algorithm which is always superior to\naccelerated batch algorithms.",
    "published_date": "2016-05-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06398v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.06167v1",
    "title": "Combining Density and Overlap (CoDO): A New Method for Assessing the Significance of Overlap Among Subgraphs",
    "authors": [
      "Abram Magner",
      "Shahin Mohammadi",
      "Ananth Grama"
    ],
    "author_ids": [],
    "abstract": "Algorithms for detecting clusters (including overlapping clusters) in graphs\nhave received significant attention in the research community. A closely\nrelated important aspect of the problem -- quantification of statistical\nsignificance of overlap of clusters, remains relatively unexplored. This paper\npresents the first theoretical and practical results on quantifying\nstatistically significant interactions between clusters in networks. Such\nproblems commonly arise in diverse applications, ranging from social network\nanalysis to systems biology. The paper addresses the problem of quantifying the\nstatistical significance of the observed overlap of the two clusters in an\nErd\\H{o}s-R\\'enyi graph model. The analytical framework presented in the paper\nassigns a $p$-value to overlapping subgraphs by combining information about\nboth the sizes of the subgraphs and their edge densities in comparison to the\ncorresponding values for their overlapping component. This $p$-value is\ndemonstrated to have excellent discrimination properties in real applications\nand is shown to be robust across broad parameter ranges.\n  Our results are comprehensively validated on synthetic, social, and\nbiological networks. We show that our framework: (i) derives insight from both\nthe density and the size of overlap among communities (circles/pathways), (ii)\nconsistently outperforms state-of-the-art methods over all tested datasets, and\n(iii) when compared to other measures, has much broader application scope. In\nthe context of social networks, we identify highly interdependent (social)\ncircles and show that our predictions are highly co-enriched with known user\nfeatures. In networks of biomolecular interactions, we show that our method\nidentifies novel cross-talk between pathways, sheds light on their mechanisms\nof interaction, and provides new opportunities for investigations of\nbiomolecular interactions.",
    "published_date": "2016-05-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06167v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.06083v1",
    "title": "Stereotyping and Bias in the Flickr30K Dataset",
    "authors": [
      "Emiel van Miltenburg"
    ],
    "author_ids": [],
    "abstract": "An untested assumption behind the crowdsourced descriptions of the images in\nthe Flickr30K dataset (Young et al., 2014) is that they \"focus only on the\ninformation that can be obtained from the image alone\" (Hodosh et al., 2013, p.\n859). This paper presents some evidence against this assumption, and provides a\nlist of biases and unwarranted inferences that can be found in the Flickr30K\ndataset. Finally, it considers methods to find examples of these, and discusses\nhow we should deal with stereotype-driven descriptions in future applications.",
    "published_date": "2016-05-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06083v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.04693v1",
    "title": "Overcoming the language barrier in mobile user interface design: A case study on a mobile health app",
    "authors": [
      "Jason Ross",
      "Jing Gao"
    ],
    "author_ids": [],
    "abstract": "This research report proposes a structured solution to address the need for\nawareness of cultural and language in user design. It will include evaluated\nresearch on established methods that already exist. Discussed ideas about how\nto address this situation include: what others have found to take into\nconsideration when using design principles to develop an interface, detailed\ntroubles and critical issues that have been previously identified and also ways\nthat have been found already to overcome such issues. This will also involve\ndesigning a prototype application catering to resolving these issues.\nOvercoming the language barrier plays an important role in the process of\nimplementing a user design interface that will satisfy users. This issue must\nbe researched and examined to identify the issues and concerns associated in\norder to provide a solution in an ethical manner.",
    "published_date": "2016-05-16T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.04693v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.04379v1",
    "title": "Frequency Assignment Problem with Net Filter Discrimination Constraints",
    "authors": [
      "H. Birkan Yilmaz",
      "Bon-Hong Koo",
      "Sung-Ho Park",
      "Hwi-Sung Park",
      "Jae-Hyun Ham",
      "Chan-Byoung Chae"
    ],
    "author_ids": [],
    "abstract": "Managing radio spectrum resources is a crucial issue. The frequency\nassignment problem (FAP) basically aims to allocate, in an efficient manner,\nlimited number of frequencies to communication links. Geographically close\nlinks, however, cause interference, which complicates the assignment, imposing\nfrequency separation constraints. The FAP is closely related to the\ngraph-coloring problem and it is an NP-hard problem. In this paper, we propose\nto incorporate the randomization into greedy and fast heuristics. As far as\nbeing implemented, the proposed algorithms are very straight forward and are\nwithout system parameters that need tuned. The proposed algorithms\nsignificantly improve, quickly and effectively, the solutions obtained by\ngreedy algorithms in terms of the number of assigned frequencies and the range.\nThe enhanced versions of proposed algorithms perform close to the lower bounds\nwhile running for a reasonable duration. Another novelty of our study is its\nconsideration of the net filter discrimination effects in the communication\nmodel. Performance analysis is done by synthetic and measured data, where the\nmeasurement data includes the effect of the real 3-dimensional (3D)\ngeographical features in the Daejeon region in Korea. In both cases, we observe\na significant improvement by employing randomized heuristics.",
    "published_date": "2016-05-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.04379v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.04374v1",
    "title": "Online learning for Social Spammer Detection on Twitter",
    "authors": [
      "Phuc Tri Nguyen",
      "Hideaki Takeda"
    ],
    "author_ids": [],
    "abstract": "Social networking services like Twitter have been playing an import role in\npeople's daily life since it supports new ways of communicating effectively and\nsharing information. The advantages of these social network services enable\nthem rapidly growing. However, the rise of social network services is leading\nto the increase of unwanted, disruptive information from spammers, malware\ndiscriminators, and other content polluters. Negative effects of social\nspammers do not only annoy users, but also lead to financial loss and privacy\nissues. There are two main challenges of spammer detection on Twitter. Firstly,\nthe data of social network scale with a huge volume of streaming social data.\nSecondly, spammers continually change their spamming strategy such as changing\ncontent patterns or trying to gain social influence, disguise themselves as far\nas possible. With those challenges, it is hard to directly apply traditional\nbatch learning methods to quickly adapt newly spamming pattern in the\nhigh-volume and real-time social media data. We need an anti-spammer system to\nbe able to adjust the learning model when getting a label feedback. Moreover,\nthe data on social media may be unbounded. Then, the system must allow update\nefficiency model in both computation and memory requirements. Online learning\nis an ideal solution for this problem. These methods incrementally adapt the\nlearning model with every single feedback and adjust to the changing patterns\nof spammers overtime. Our experiments demonstrate that an anti-spam system\nbased on online learning approach is efficient in fast changing of spammers\ncomparing with batch learning methods. We also attempt to find the optimal\nonline learning method and study the effectiveness of various feature sets on\nthese online learning methods.",
    "published_date": "2016-05-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.04374v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.04184v1",
    "title": "Scalable Information Inequalities for Uncertainty Quantification",
    "authors": [
      "Markos A. Katsoulakis",
      "Luc Rey-Bellet",
      "Jie Wang"
    ],
    "author_ids": [],
    "abstract": "In this paper we demonstrate the only available scalable information bounds\nfor quantities of interest of high dimensional probabilistic models.\nScalability of inequalities allows us to (a) obtain uncertainty quantification\nbounds for quantities of interest in the large degree of freedom limit and/or\nat long time regimes; (b) assess the impact of large model perturbations as in\nnonlinear response regimes in statistical mechanics; (c) address model-form\nuncertainty, i.e. compare different extended models and corresponding\nquantities of interest. We demonstrate some of these properties by deriving\nrobust uncertainty quantification bounds for phase diagrams in statistical\nmechanics models.",
    "published_date": "2016-05-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.04184v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.02693v2",
    "title": "Inference of High-dimensional Autoregressive Generalized Linear Models",
    "authors": [
      "Eric C. Hall",
      "Garvesh Raskutti",
      "Rebecca Willett"
    ],
    "author_ids": [],
    "abstract": "Vector autoregressive models characterize a variety of time series in which\nlinear combinations of current and past observations can be used to accurately\npredict future observations. For instance, each element of an observation\nvector could correspond to a different node in a network, and the parameters of\nan autoregressive model would correspond to the impact of the network structure\non the time series evolution. Often these models are used successfully in\npractice to learn the structure of social, epidemiological, financial, or\nbiological neural networks. However, little is known about statistical\nguarantees on estimates of such models in non-Gaussian settings. This paper\naddresses the inference of the autoregressive parameters and associated network\nstructure within a generalized linear model framework that includes Poisson and\nBernoulli autoregressive processes. At the heart of this analysis is a\nsparsity-regularized maximum likelihood estimator. While\nsparsity-regularization is well-studied in the statistics and machine learning\ncommunities, those analysis methods cannot be applied to autoregressive\ngeneralized linear models because of the correlations and potential\nheteroscedasticity inherent in the observations. Sample complexity bounds are\nderived using a combination of martingale concentration inequalities and modern\nempirical process techniques for dependent random variables. These bounds,\nwhich are supported by several simulation studies, characterize the impact of\nvarious network parameters on estimator performance.",
    "published_date": "2016-05-09T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.IT",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.02693v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.02424v1",
    "title": "Learning Discriminative Features with Class Encoder",
    "authors": [
      "Hailin Shi",
      "Xiangyu Zhu",
      "Zhen Lei",
      "Shengcai Liao",
      "Stan Z. Li"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks usually benefit from unsupervised pre-training, e.g.\nauto-encoders. However, the classifier further needs supervised fine-tuning\nmethods for good discrimination. Besides, due to the limits of full-connection,\nthe application of auto-encoders is usually limited to small, well aligned\nimages. In this paper, we incorporate the supervised information to propose a\nnovel formulation, namely class-encoder, whose training objective is to\nreconstruct a sample from another one of which the labels are identical.\nClass-encoder aims to minimize the intra-class variations in the feature space,\nand to learn a good discriminative manifolds on a class scale. We impose the\nclass-encoder as a constraint into the softmax for better supervised training,\nand extend the reconstruction on feature-level to tackle the parameter size\nissue and translation issue. The experiments show that the class-encoder helps\nto improve the performance on benchmarks of classification and face\nrecognition. This could also be a promising direction for fast training of face\nrecognition models.",
    "published_date": "2016-05-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.02424v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.02077v2",
    "title": "Function-Specific Mixing Times and Concentration Away from Equilibrium",
    "authors": [
      "Maxim Rabinovich",
      "Aaditya Ramdas",
      "Michael I. Jordan",
      "Martin J. Wainwright"
    ],
    "author_ids": [],
    "abstract": "Slow mixing is the central hurdle when working with Markov chains, especially\nthose used for Monte Carlo approximations (MCMC). In many applications, it is\nonly of interest to estimate the stationary expectations of a small set of\nfunctions, and so the usual definition of mixing based on total variation\nconvergence may be too conservative. Accordingly, we introduce\nfunction-specific analogs of mixing times and spectral gaps, and use them to\nprove Hoeffding-like function-specific concentration inequalities. These\nresults show that it is possible for empirical expectations of functions to\nconcentrate long before the underlying chain has mixed in the classical sense,\nand we show that the concentration rates we achieve are optimal up to\nconstants. We use our techniques to derive confidence intervals that are\nsharper than those implied by both classical Markov chain Hoeffding bounds and\nBerry-Esseen-corrected CLT bounds. For applications that require testing,\nrather than point estimation, we show similar improvements over recent\nsequential testing results for MCMC. We conclude by applying our framework to\nreal data examples of MCMC, providing evidence that our theory is both accurate\nand relevant to practice.",
    "published_date": "2016-05-06T00:00:00",
    "year": 2016,
    "categories": [
      "math.ST",
      "cs.LG",
      "math.PR",
      "stat.TH",
      "Markov chains (60J10), Markov processes: estimation (62M05), Markov\n  processes: hypothesis testing (62M02)"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.02077v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1605.01627v2",
    "title": "A Sensing Contribution-based Two-layer Game for Channel Selection and Spectrum Access in Cognitive Radio Ad-hoc Networks",
    "authors": [
      "Yuan Lu",
      "Alexandra Duel-Hallen"
    ],
    "author_ids": [],
    "abstract": "In cognitive radio (CR) networks, the secondary users (SUs) sense the\nspectrum licensed to the primary users (PUs) to identify and possibly transmit\nover temporarily unoccupied channels. Cooperative sensing was proposed to\nimprove the sensing accuracy, but in heterogeneous scenarios SUs do not\ncontribute equally to the cooperative sensing result because they experience\ndifferent received PU signal quality at their sensors. In this paper, a\ntwo-layer coalitional game is developed for distributed sensing and access in\nmultichannel CR ad hoc networks where the SUs' transmission opportunities are\ncommensurate with their sensing contributions, thus fostering cooperation and\neliminating free-riders. Numerical results show that the proposed two-layer\ngame is computationally efficient and outperforms previously investigated\ncollaborative sensing and spectrum access approaches for heterogeneous\nmultichannel CR networks in terms of energy efficiency, throughput, SU\nfairness, and complexity. Moreover, it is demonstrated that this game is robust\nto changes in the network topology and the number of SUs in low-mobility\nscenarios. Finally, we propose a new physical-layer approach to distributing\nthe network-level miss-detection (MD) constraints fairly among the interfering\nSUs for guaranteed PU protection and demonstrate the performance advantages of\nthe AND-rule combining of spectrum sensing results for heterogeneous SUs.",
    "published_date": "2016-05-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.01627v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.01557v1",
    "title": "On the Aloha throughput-fairness tradeoff",
    "authors": [
      "Nan Xie",
      "Steven Weber"
    ],
    "author_ids": [],
    "abstract": "A well-known inner bound of the stability region of the slotted Aloha\nprotocol on the collision channel with n users assumes worst-case service rates\n(all user queues non-empty). Using this inner bound as a feasible set of\nachievable rates, a characterization of the throughput--fairness tradeoff over\nthis set is obtained, where throughput is defined as the sum of the individual\nuser rates, and two definitions of fairness are considered: the Jain-Chiu-Hawe\nfunction and the sum-user alpha-fair (isoelastic) utility function. This\ncharacterization is obtained using both an equality constraint and an\ninequality constraint on the throughput, and properties of the optimal\ncontrols, the optimal rates, and the fairness as a function of the target\nthroughput are established. A key fact used in all theorems is the observation\nthat all contention probability vectors that extremize the fairness functions\ntake at most two non-zero values.",
    "published_date": "2016-05-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.NI",
      "cs.PF",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.01557v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.01003v1",
    "title": "Monadic second order logic as the model companion of temporal logic",
    "authors": [
      "Silvio Ghilardi",
      "Samuel J. van Gool"
    ],
    "author_ids": [],
    "abstract": "The main focus of this paper is on bisimulation-invariant MSO, and more\nparticularly on giving a novel model-theoretic approach to it. In model theory,\na model companion of a theory is a first-order description of the class of\nmodels in which all potentially solvable systems of equations and non-equations\nhave solutions. We show that bisimulation-invariant MSO on trees gives the\nmodel companion for a new temporal logic, \"fair CTL\", an enrichment of CTL with\nlocal fairness constraints. To achieve this, we give a completeness proof for\nthe logic fair CTL which combines tableaux and Stone duality, and a fair CTL\nencoding of the automata for the modal {\\mu}-calculus. Moreover, we also show\nthat MSO on binary trees is the model companion of binary deterministic fair\nCTL.",
    "published_date": "2016-05-03T00:00:00",
    "year": 2016,
    "categories": [
      "math.LO",
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.01003v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.00962v2",
    "title": "Does disaggregated electricity feedback reduce domestic electricity consumption? A systematic review of the literature",
    "authors": [
      "Jack Kelly",
      "William Knottenbelt"
    ],
    "author_ids": [],
    "abstract": "We examine 12 studies on the efficacy of disaggregated energy feedback. The\naverage electricity reduction across these studies is 4.5%. However, 4.5% may\nbe a positively-biased estimate of the savings achievable across the entire\npopulation because all 12 studies are likely to be prone to opt-in bias hence\nnone test the effect of disaggregated feedback on the general population.\nDisaggregation may not be required to achieve these savings: Aggregate feedback\nalone drives 3% reductions; and the 4 studies which directly compared aggregate\nfeedback against disaggregated feedback found that aggregate feedback is at\nleast as effective as disaggregated feedback, possibly because web apps are\nviewed less often than in-home-displays (in the short-term, at least) and\nbecause some users do not trust fine-grained disaggregation (although this may\nbe an issue with the specific user interface studied). Disaggregated\nelectricity feedback may help a motivated sub-group of the population to save\nmore energy but fine-grained disaggregation may not be necessary to achieve\nthese energy savings. Disaggregation has many uses beyond those discussed in\nthis paper but, on the specific question of promoting energy reduction in the\ngeneral population, there is no robust evidence that current forms of\ndisaggregated energy feedback are more effective than aggregate energy\nfeedback. The effectiveness of disaggregated feedback may increase if the\ngeneral population become more energy-conscious (e.g. if energy prices rise or\nconcern about climate change deepens); or if users' trust in fine-grained\ndisaggregation improves; or if innovative new approaches or alternative\ndisaggregation strategies (e.g. disaggregating by behaviour rather than by\nappliance) out-perform existing feedback. We also discuss opportunities for new\nresearch into the effectiveness of disaggregated feedback.",
    "published_date": "2016-05-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.00962v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.00620v3",
    "title": "Game-Theoretic Multi-Agent Control and Network Cost Allocation under Communication Constraints",
    "authors": [
      "Feier Lian",
      "Aranya Chakrabortty",
      "Alexandra Duel-Hallen"
    ],
    "author_ids": [],
    "abstract": "Multi-agent networked linear dynamic systems have attracted attention of\nresearchers in power systems, intelligent transportation, and industrial\nautomation. The agents might cooperatively optimize a global performance\nobjective, resulting in social optimization, or try to satisfy their own\nselfish objectives using a noncooperative differential game. However, in these\nsolutions, large volumes of data must be sent from system states to possibly\ndistant control inputs, thus resulting in high cost of the underlying\ncommunication network. To enable economically-viable communication, a\ngame-theoretic framework is proposed under the \\textit{communication cost}, or\n\\textit{sparsity}, constraint, given by the number of communicating\nstate/control input pairs. As this constraint tightens, the system transitions\nfrom dense to sparse communication, providing the trade-off between dynamic\nsystem performance and information exchange. Moreover, using the proposed\nsparsity-constrained distributed social optimization and noncooperative game\nalgorithms, we develop a method to allocate the costs of the communication\ninfrastructure fairly and according to the agents' diverse needs for feedback\nand cooperation. Numerical results illustrate utilization of the proposed\nalgorithms to enable and ensure economic fairness of wide-area control among\npower companies.",
    "published_date": "2016-05-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.00620v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1605.00251v1",
    "title": "A vector-contraction inequality for Rademacher complexities",
    "authors": [
      "Andreas Maurer"
    ],
    "author_ids": [],
    "abstract": "The contraction inequality for Rademacher averages is extended to Lipschitz\nfunctions with vector-valued domains, and it is also shown that in the bounding\nexpression the Rademacher variables can be replaced by arbitrary iid symmetric\nand sub-gaussian variables. Example applications are given for multi-category\nlearning, K-means clustering and learning-to-learn.",
    "published_date": "2016-05-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.00251v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.08620v2",
    "title": "Computer keyboard interaction as an indicator of early Parkinson's disease",
    "authors": [
      "L. Giancardo",
      "A. Sánchez-Ferro",
      "T. Arroyo-Gallego",
      "I. Butterworth",
      "C. S. Mendoza",
      "P. Montero",
      "M. Matarazzo",
      "A. Obeso",
      "M. L. Gray",
      "San José Estépar"
    ],
    "author_ids": [],
    "abstract": "Parkinson's disease (PD) is a slowly progressing neurodegenerative disease\nwith early manifestation of motor signs. Objective measurements of motor signs\nare of vital importance for diagnosing, monitoring and developing disease\nmodifying therapies, particularly for the early stages of the disease when\nputative neuroprotective treatments could stop neurodegeneration. Current\nmedical practice has limited tools to routinely monitor PD motor signs with\nenough frequency and without undue burden for patients and the healthcare\nsystem. In this paper, we present data indicating that the routine interaction\nwith computer keyboards can be used to detect motor signs in the early stages\nof PD. We explore a solution that measures the key hold times (the time\nrequired to press and release a key) during the normal use of a computer\nwithout any change in hardware and converts it to a PD motor index. This is\nachieved by the automatic discovery of patterns in the time series of key hold\ntimes using an ensemble regression algorithm. This new approach discriminated\nearly PD groups from controls with an AUC = 0.81 (n = 42/43; mean age =\n59.0/60.1; women = 43%/60%;PD/controls). The performance was comparable or\nbetter than two other quantitative motor performance tests used clinically:\nalternating finger tapping (AUC = 0.75) and single key tapping (AUC = 0.61).",
    "published_date": "2016-04-28T00:00:00",
    "year": 2016,
    "categories": [
      "cs.HC",
      "J.3; I.2.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.08620v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.08394v2",
    "title": "Crowdsourcing the Robin Hood effect in cities",
    "authors": [
      "Thomas Louail",
      "Maxime Lenormand",
      "Juan Murillo Arias",
      "José J. Ramasco"
    ],
    "author_ids": [],
    "abstract": "Socioeconomic inequalities in cities are embedded in space and result in\nneighborhood effects, whose harmful consequences have proved very hard to\ncounterbalance efficiently by planning policies alone. Considering\nredistribution of money flows as a first step toward improved spatial equity,\nwe study a bottom-up approach that would rely on a slight evolution of shopping\nmobility practices. Building on a database of anonymized credit card\ntransactions in Madrid and Barcelona, we quantify the mobility effort required\nto reach a reference situation where commercial income is evenly shared among\nneighborhoods. The redirections of shopping trips preserve key properties of\nhuman mobility, including travel distances. Surprisingly, for both cities only\na small fraction ($\\sim 5 \\%$) of trips need to be altered to reach equity\nsituations, improving even other sustainability indicators. The method could be\nimplemented in mobile applications that would assist individuals in reshaping\ntheir shopping practices, to promote the spatial redistribution of\nopportunities in the city.",
    "published_date": "2016-04-28T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.08394v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.08079v2",
    "title": "UBL: an R package for Utility-based Learning",
    "authors": [
      "Paula Branco",
      "Rita P. Ribeiro",
      "Luis Torgo"
    ],
    "author_ids": [],
    "abstract": "This document describes the R package UBL that allows the use of several\nmethods for handling utility-based learning problems. Classification and\nregression problems that assume non-uniform costs and/or benefits pose serious\nchallenges to predictive analytic tasks. In the context of meteorology,\nfinance, medicine, ecology, among many other, specific domain information\nconcerning the preference bias of the users must be taken into account to\nenhance the models predictive performance. To deal with this problem, a large\nnumber of techniques was proposed by the research community for both\nclassification and regression tasks. The main goal of UBL package is to\nfacilitate the utility-based predictive analytic task by providing a set of\nmethods to deal with this type of problems in the R environment. It is a\nversatile tool that provides mechanisms to handle both regression and\nclassification (binary and multiclass) tasks. Moreover, UBL package allows the\nuser to specify his domain preferences, but it also provides some automatic\nmethods that try to infer those preference bias from the domain, considering\nsome common known settings.",
    "published_date": "2016-04-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.MS",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.08079v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.07180v1",
    "title": "Observing and Recommending from a Social Web with Biases",
    "authors": [
      "Steffen Staab",
      "Sophie Stalla-Bourdillon",
      "Laura Carmichael"
    ],
    "author_ids": [],
    "abstract": "The research question this report addresses is: how, and to what extent,\nthose directly involved with the design, development and employment of a\nspecific black box algorithm can be certain that it is not unlawfully\ndiscriminating (directly and/or indirectly) against particular persons with\nprotected characteristics (e.g. gender, race and ethnicity)?",
    "published_date": "2016-04-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DB",
      "cs.LG",
      "K.5.0; H.2.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.07180v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.07096v1",
    "title": "Understanding Illicit Drug Use Behaviors by Mining Social Media",
    "authors": [
      "Yiheng Zhou",
      "Numair Sani",
      "Chia-Kuei Lee",
      "Jiebo Luo"
    ],
    "author_ids": [],
    "abstract": "Drug use by people is on the rise and is of great interest to public health\nagencies and law enforcement agencies. As found by the National Survey on Drug\nUse and Health, 20 million Americans aged 12 years or older consumed illicit\ndrugs in the past few 30 days. Given their ubiquity in everyday life, drug\nabuse related studies have received much and constant attention. However, most\nof the existing studies rely on surveys. Surveys present a fair number of\nproblems because of their nature. Surveys on sensitive topics such as illicit\ndrug use may not be answered truthfully by the people taking them. Selecting a\nrepresentative sample to survey is another major challenge. In this paper, we\nexplore the possibility of using big data from social media in order to\nunderstand illicit drug use behaviors. Instagram posts are collected using drug\nrelated terms by analyzing the hashtags supplied with each post. A large and\ndynamic dictionary of frequent illicit drug related slang is used to find these\nposts. These posts are studied to find common drug consumption behaviors with\nregard to time of day and week. Furthermore, by studying the accounts followed\nby the users of drug related posts, we hope to discover common interests shared\nby drug users.",
    "published_date": "2016-04-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.07096v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.06242v2",
    "title": "Novelty Detection in MultiClass Scenarios with Incomplete Set of Class Labels",
    "authors": [
      "Nomi Vinokurov",
      "Daphna Weinshall"
    ],
    "author_ids": [],
    "abstract": "We address the problem of novelty detection in multiclass scenarios where\nsome class labels are missing from the training set. Our method is based on the\ninitial assignment of confidence values, which measure the affinity between a\nnew test point and each known class. We first compare the values of the two top\nelements in this vector of confidence values. In the heart of our method lies\nthe training of an ensemble of classifiers, each trained to discriminate known\nfrom novel classes based on some partition of the training data into\npresumed-known and presumednovel classes. Our final novelty score is derived\nfrom the output of this ensemble of classifiers. We evaluated our method on two\ndatasets of images containing a relatively large number of classes - the\nCaltech-256 and Cifar-100 datasets. We compared our method to 3 alternative\nmethods which represent commonly used approaches, including the one-class SVM,\nnovelty based on k-NN, novelty based on maximal confidence, and the recent\nKNFST method. The results show a very clear and marked advantage for our method\nover all alternative methods, in an experimental setup where class labels are\nmissing during training.",
    "published_date": "2016-04-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.06242v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.05848v1",
    "title": "Scene Parsing with Integration of Parametric and Non-parametric Models",
    "authors": [
      "Bing Shuai",
      "Zhen Zuo",
      "Gang Wang",
      "Bing Wang"
    ],
    "author_ids": [],
    "abstract": "We adopt Convolutional Neural Networks (CNNs) to be our parametric model to\nlearn discriminative features and classifiers for local patch classification.\nBased on the occurrence frequency distribution of classes, an ensemble of CNNs\n(CNN-Ensemble) are learned, in which each CNN component focuses on learning\ndifferent and complementary visual patterns. The local beliefs of pixels are\noutput by CNN-Ensemble. Considering that visually similar pixels are\nindistinguishable under local context, we leverage the global scene semantics\nto alleviate the local ambiguity. The global scene constraint is mathematically\nachieved by adding a global energy term to the labeling energy function, and it\nis practically estimated in a non-parametric framework. A large margin based\nCNN metric learning method is also proposed for better global belief\nestimation. In the end, the integration of local and global beliefs gives rise\nto the class likelihood of pixels, based on which maximum marginal inference is\nperformed to generate the label prediction maps. Even without any\npost-processing, we achieve state-of-the-art results on the challenging\nSiftFlow and Barcelona benchmarks.",
    "published_date": "2016-04-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.05848v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.05663v6",
    "title": "Three-input Majority Function as the Unique Optimal Function for the Bias Amplification using Nonlocal Boxes",
    "authors": [
      "Ryuhei Mori"
    ],
    "author_ids": [],
    "abstract": "Brassard et al. [Phys. Rev. Lett. 96, 250401 (2006)] showed that shared\nnonlocal boxes with the CHSH probability greater than $\\frac{3+\\sqrt{6}}6$\nyields trivial communication complexity. There still exists the gap with the\nmaximum CHSH probability $\\frac{2+\\sqrt{2}}4$ achievable by quantum mechanics.\nIt is an interesting open question to determine the exact threshold for the\ntrivial communication complexity. Brassard et al.'s idea is based on the\nrecursive bias amplification by the 3-input majority function. It was not\nobvious if other choice of function exhibits stronger bias amplification. We\nshow that the 3-input majority function is the unique optimal, so that one\ncannot improve the threshold $\\frac{3+\\sqrt{6}}6$ by Brassard et al.'s bias\namplification. In this work, protocols for computing the function used for the\nbias amplification are restricted to be non-adaptive protocols or particular\nadaptive protocol inspired by Paw{\\l}owski et al.'s protocol for information\ncausality [Nature 461, 1101 (2009)]. We first show a new adaptive protocol\ninspired by Paw{\\l}owski et al.'s protocol, and then show that the new adaptive\nprotocol is better than any non-adaptive protocol. Finally, we show that the\n3-input majority function is the unique optimal for the bias amplification if\nwe apply the new adaptive protocol to each step of the bias amplification.",
    "published_date": "2016-04-18T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.05663v6",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.05027v2",
    "title": "Most Likely Separation of Intensity and Warping Effects in Image Registration",
    "authors": [
      "Line Kühnel",
      "Stefan Sommer",
      "Akshay Pai",
      "Lars Lau Raket"
    ],
    "author_ids": [],
    "abstract": "This paper introduces a class of mixed-effects models for joint modeling of\nspatially correlated intensity variation and warping variation in 2D images.\nSpatially correlated intensity variation and warp variation are modeled as\nrandom effects, resulting in a nonlinear mixed-effects model that enables\nsimultaneous estimation of template and model parameters by optimization of the\nlikelihood function. We propose an algorithm for fitting the model which\nalternates estimation of variance parameters and image registration. This\napproach avoids the potential estimation bias in the template estimate that\narises when treating registration as a preprocessing step. We apply the model\nto datasets of facial images and 2D brain magnetic resonance images to\nillustrate the simultaneous estimation and prediction of intensity and warp\neffects.",
    "published_date": "2016-04-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.05027v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.04711v1",
    "title": "Transdisciplinarity seen through Information, Communication, Computation, (Inter-)Action and Cognition",
    "authors": [
      "Gordana Dodig-Crnkovic",
      "Daniel Kade",
      "Markus Wallmyr",
      "Tobias Holstein",
      "Alexander Almér"
    ],
    "author_ids": [],
    "abstract": "Similar to oil that acted as a basic raw material and key driving force of\nindustrial society, information acts as a raw material and principal mover of\nknowledge society in the knowledge production, propagation and application. New\ndevelopments in information processing and information communication\ntechnologies allow increasingly complex and accurate descriptions,\nrepresentations and models, which are often multi-parameter, multi-perspective,\nmulti-level and multidimensional. This leads to the necessity of collaborative\nwork between different domains with corresponding specialist competences,\nsciences and research traditions. We present several major transdisciplinary\nunification projects for information and knowledge, which proceed on the\ndescriptive, logical and the level of generative mechanisms. Parallel process\nof boundary crossing and transdisciplinary activity is going on in the applied\ndomains. Technological artifacts are becoming increasingly complex and their\ndesign is strongly user-centered, which brings in not only the function and\nvarious technological qualities but also other aspects including esthetic, user\nexperience, ethics and sustainability with social and environmental dimensions.\nWhen integrating knowledge from a variety of fields, with contributions from\ndifferent groups of stakeholders, numerous challenges are met in establishing\ncommon view and common course of action. In this context, information is our\nenvironment, and informational ecology determines both epistemology and spaces\nfor action. We present some insights into the current state of the art of\ntransdisciplinary theory and practice of information studies and informatics.\nWe depict different facets of transdisciplinarity as we see it from our\ndifferent research fields that include information studies, computability,\nhuman-computer interaction, multi-operating-systems environments and\nphilosophy.",
    "published_date": "2016-04-16T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.04711v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.04413v1",
    "title": "A Generalized Erasure Channel in the Sense of Polarization for Binary Erasure Channels",
    "authors": [
      "Yuta Sakai",
      "Ken-ichi Iwata"
    ],
    "author_ids": [],
    "abstract": "The polar transformation of a binary erasure channel (BEC) can be exactly\napproximated by other BECs. Ar{\\i}kan proposed that polar codes for a BEC can\nbe efficiently constructed by using its useful property. This study proposes a\nnew class of arbitrary input generalized erasure channels, which can be exactly\napproximated the polar transformation by other same channel models, as with the\nBEC. One of the main results is the recursive formulas of the polar\ntransformation of the proposed channel. In the study, we evaluate the polar\ntransformation by using the $\\alpha$-mutual information. Particularly, when the\ninput alphabet size is a prime power, we examines the following: (i)\ninequalities for the average of the $\\alpha$-mutual information of the proposed\nchannel after the one-step polar transformation, and (ii) the exact proportion\nof polarizations of the $\\alpha$-mutual information of proposed channels in\ninfinite number of polar transformations.",
    "published_date": "2016-04-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.04413v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.04348v3",
    "title": "Positive Definite Estimation of Large Covariance Matrix Using Generalized Nonconvex Penalties",
    "authors": [
      "Fei Wen",
      "Yuan Yang",
      "Peilin Liu",
      "Robert C. Qiu"
    ],
    "author_ids": [],
    "abstract": "This work addresses the issue of large covariance matrix estimation in\nhigh-dimensional statistical analysis. Recently, improved iterative algorithms\nwith positive-definite guarantee have been developed. However, these algorithms\ncannot be directly extended to use a nonconvex penalty for sparsity inducing.\nGenerally, a nonconvex penalty has the capability of ameliorating the bias\nproblem of the popular convex lasso penalty, and thus is more advantageous. In\nthis work, we propose a class of positive-definite covariance estimators using\ngeneralized nonconvex penalties. We develop a first-order algorithm based on\nthe alternating direction method framework to solve the nonconvex optimization\nproblem efficiently. The convergence of this algorithm has been proved.\nFurther, the statistical properties of the new estimators have been analyzed\nfor generalized nonconvex penalties. Moreover, extension of this algorithm to\ncovariance estimation from sketched measurements has been considered. The\nperformances of the new estimators have been demonstrated by both a simulation\nstudy and a gene clustering example for tumor tissues. Code for the proposed\nestimators is available at https://github.com/FWen/Nonconvex-PDLCE.git.",
    "published_date": "2016-04-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.04348v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.04334v1",
    "title": "Recognition of facial expressions based on salient geometric features and support vector machines",
    "authors": [
      "Deepak Ghimire",
      "Joonwhoan Lee",
      "Ze-Nian Li",
      "Sunghwan Jeong"
    ],
    "author_ids": [],
    "abstract": "Facial expressions convey nonverbal cues which play an important role in\ninterpersonal relations, and are widely used in behavior interpretation of\nemotions, cognitive science, and social interactions. In this paper we analyze\ndifferent ways of representing geometric feature and present a fully automatic\nfacial expression recognition (FER) system using salient geometric features. In\ngeometric feature-based FER approach, the first important step is to initialize\nand track dense set of facial points as the expression evolves over time in\nconsecutive frames. In the proposed system, facial points are initialized using\nelastic bunch graph matching (EBGM) algorithm and tracking is performed using\nKanade-Lucas-Tomaci (KLT) tracker. We extract geometric features from point,\nline and triangle composed of tracking results of facial points. The most\ndiscriminative line and triangle features are extracted using feature selective\nmulti-class AdaBoost with the help of extreme learning machine (ELM)\nclassification. Finally the geometric features for FER are extracted from the\nboosted line, and triangles composed of facial points. The recognition accuracy\nusing features from point, line and triangle are analyzed independently. The\nperformance of the proposed FER system is evaluated on three different data\nsets: namely CK+, MMI and MUG facial expression data sets.",
    "published_date": "2016-04-15T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.04334v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.04225v2",
    "title": "Forward and Reverse Entropy Power Inequalities in Convex Geometry",
    "authors": [
      "Mokshay Madiman",
      "James Melbourne",
      "Peng Xu"
    ],
    "author_ids": [],
    "abstract": "The entropy power inequality, which plays a fundamental role in information\ntheory and probability, may be seen as an analogue of the Brunn-Minkowski\ninequality. Motivated by this connection to Convex Geometry, we survey various\nrecent developments on forward and reverse entropy power inequalities not just\nfor the Shannon-Boltzmann entropy but also more generally for R\\'enyi entropy.\nIn the process, we discuss connections between the so-called functional (or\nintegral) and probabilistic (or entropic) analogues of some classical\ninequalities in geometric functional analysis",
    "published_date": "2016-04-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.FA",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.04225v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.03225v1",
    "title": "Geometric Feature-Based Facial Expression Recognition in Image Sequences Using Multi-Class AdaBoost and Support Vector Machines",
    "authors": [
      "Deepak Ghimire",
      "Joonwhoan Lee"
    ],
    "author_ids": [],
    "abstract": "Facial expressions are widely used in the behavioral interpretation of\nemotions, cognitive science, and social interactions. In this paper, we present\na novel method for fully automatic facial expression recognition in facial\nimage sequences. As the facial expression evolves over time facial landmarks\nare automatically tracked in consecutive video frames, using displacements\nbased on elastic bunch graph matching displacement estimation. Feature vectors\nfrom individual landmarks, as well as pairs of landmarks tracking results are\nextracted, and normalized, with respect to the first frame in the sequence. The\nprototypical expression sequence for each class of facial expression is formed,\nby taking the median of the landmark tracking results from the training facial\nexpression sequences. Multi-class AdaBoost with dynamic time warping similarity\ndistance between the feature vector of input facial expression and prototypical\nfacial expression, is used as a weak classifier to select the subset of\ndiscriminative feature vectors. Finally, two methods for facial expression\nrecognition are presented, either by using multi-class AdaBoost with dynamic\ntime warping, or by using support vector machine on the boosted feature\nvectors. The results on the Cohn-Kanade (CK+) facial expression database show a\nrecognition accuracy of 95.17% and 97.35% using multi-class AdaBoost and\nsupport vector machines, respectively.",
    "published_date": "2016-04-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "68T01",
      "I.4; I.5"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.03225v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.03023v3",
    "title": "Multivariate Trace Inequalities",
    "authors": [
      "David Sutter",
      "Mario Berta",
      "Marco Tomamichel"
    ],
    "author_ids": [],
    "abstract": "We prove several trace inequalities that extend the Golden-Thompson and the\nAraki-Lieb-Thirring inequality to arbitrarily many matrices. In particular, we\nstrengthen Lieb's triple matrix inequality. As an example application of our\nfour matrix extension of the Golden-Thompson inequality, we prove remainder\nterms for the monotonicity of the quantum relative entropy and strong\nsub-additivity of the von Neumann entropy in terms of recoverability. We find\nthe first explicit remainder terms that are tight in the commutative case. Our\nproofs rely on complex interpolation theory as well as asymptotic spectral\npinching, providing a transparent approach to treat generic multivariate trace\ninequalities.",
    "published_date": "2016-04-11T00:00:00",
    "year": 2016,
    "categories": [
      "math-ph",
      "cs.IT",
      "math.IT",
      "math.MP",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.03023v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.02737v2",
    "title": "Correlated Equilibria for Approximate Variational Inference in MRFs",
    "authors": [
      "Luis E. Ortiz",
      "Boshen Wang",
      "Ze Gong"
    ],
    "author_ids": [],
    "abstract": "Almost all of the work in graphical models for game theory has mirrored\nprevious work in probabilistic graphical models. Our work considers the\nopposite direction: Taking advantage of recent advances in equilibrium\ncomputation for probabilistic inference. We present formulations of inference\nproblems in Markov random fields (MRFs) as computation of equilibria in a\ncertain class of game-theoretic graphical models. We concretely establishes the\nprecise connection between variational probabilistic inference in MRFs and\ncorrelated equilibria. No previous work exploits recent theoretical and\nempirical results from the literature on algorithmic and computational game\ntheory on the tractable, polynomial-time computation of exact or approximate\ncorrelated equilibria in graphical games with arbitrary, loopy graph structure.\nWe discuss how to design new algorithms with equally tractable guarantees for\nthe computation of approximate variational inference in MRFs. Also, inspired by\na previously stated game-theoretic view of state-of-the-art tree-reweighed\n(TRW) message-passing techniques for belief inference as zero-sum game, we\npropose a different, general-sum potential game to design approximate\nfictitious-play techniques. We perform synthetic experiments evaluating our\nproposed approximation algorithms with standard methods and TRW on several\nclasses of classical Ising models (i.e., with binary random variables). We also\nevaluate the algorithms using Ising models learned from the MNIST dataset. Our\nexperiments show that our global approach is competitive, particularly shinning\nin a class of Ising models with constant, \"highly attractive\" edge-weights, in\nwhich it is often better than all other alternatives we evaluated. With a\nnotable exception, our more local approach was not as effective. Yet, in\nfairness, almost all of the alternatives are often no better than a simple\nbaseline: estimate 0.5.",
    "published_date": "2016-04-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.02737v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.02123v1",
    "title": "Multilevel Weighted Support Vector Machine for Classification on Healthcare Data with Missing Values",
    "authors": [
      "Talayeh Razzaghi",
      "Oleg Roderick",
      "Ilya Safro",
      "Nicholas Marko"
    ],
    "author_ids": [],
    "abstract": "This work is motivated by the needs of predictive analytics on healthcare\ndata as represented by Electronic Medical Records. Such data is invariably\nproblematic: noisy, with missing entries, with imbalance in classes of\ninterests, leading to serious bias in predictive modeling. Since standard data\nmining methods often produce poor performance measures, we argue for\ndevelopment of specialized techniques of data-preprocessing and classification.\nIn this paper, we propose a new method to simultaneously classify large\ndatasets and reduce the effects of missing values. It is based on a multilevel\nframework of the cost-sensitive SVM and the expected maximization imputation\nmethod for missing values, which relies on iterated regression analyses. We\ncompare classification results of multilevel SVM-based algorithms on public\nbenchmark datasets with imbalanced classes and missing values as well as real\ndata in health applications, and show that our multilevel SVM-based method\nproduces fast, and more accurate and robust classification results.",
    "published_date": "2016-04-07T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.02123v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.01734v1",
    "title": "Efficiency and Sequenceability in Fair Division of Indivisible Goods with Additive Preferences",
    "authors": [
      "Sylvain Bouveret",
      "Michel Lemaître"
    ],
    "author_ids": [],
    "abstract": "In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is the\nfollowing: at each stage, a designated agent picks one object among those that\nremain. This paper, restricted to the case where the agents have numerical\nadditive preferences over objects, revisits to some extent the seminal paper by\nBrams and King [9] which was specific to ordinal and linear order preferences\nover items. We point out similarities and differences with this latter context.\nIn particular, we show that any Pareto-optimal allocation (under additive\npreferences) is sequenceable, but that the converse is not true anymore. This\nasymmetry leads naturally to the definition of a \"scale of efficiency\" having\nthree steps: Pareto-optimality, sequenceability without Pareto-optimality, and\nnon-sequenceability. Finally, we investigate the links between these efficiency\nproperties and the \"scale of fairness\" we have described in an earlier work\n[7]: we first show that an allocation can be envy-free and non-sequenceable,\nbut that every competitive equilibrium with equal incomes is sequenceable. Then\nwe experimentally explore the links between the scales of efficiency and\nfairness.",
    "published_date": "2016-04-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.01734v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.01088v2",
    "title": "Optimal Parameter Settings for the $(1+(λ, λ))$ Genetic Algorithm",
    "authors": [
      "Benjamin Doerr"
    ],
    "author_ids": [],
    "abstract": "The $(1+(\\lambda,\\lambda))$ genetic algorithm is one of the few algorithms\nfor which a super-constant speed-up through the use of crossover could be\nproven. So far, this algorithm has been used with parameters based also on\nintuitive considerations. In this work, we rigorously regard the whole\nparameter space and show that the asymptotic time complexity proven by Doerr\nand Doerr (GECCO 2015) for the intuitive choice is best possible among all\nsettings for population size, mutation probability, and crossover bias.",
    "published_date": "2016-04-04T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NE",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.01088v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.00863v1",
    "title": "Stability analysis of Model Predictive Controllers using Mixed Integer Linear Programming",
    "authors": [
      "Daniel Simon",
      "Johan Löfberg"
    ],
    "author_ids": [],
    "abstract": "It is a well known fact that finite time optimal controllers, such as MPC\ndoes not necessarily result in closed loop stable systems. Within the MPC\ncommunity it is common practice to add a final state constraint and/or a final\nstate penalty in order to obtain guaranteed stability. However, for more\nadvanced controller structures it can be difficult to show stability using\nthese techniques. Additionally in some cases the final state constraint set\nconsists of so many inequalities that the complexity of the MPC problem is too\nbig for use in certain fast and time critical applications. In this paper we\ninstead focus on deriving a tool for a-postiori analysis of the closed loop\nstability for linear systems controlled with MPC controllers. We formulate an\noptimisation problem that gives a sufficient condition for stability of the\nclosed loop system and we show that the problem can be written as a Mixed\nInteger Linear Programming Problem (MILP)",
    "published_date": "2016-04-04T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.00863v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.00676v1",
    "title": "Multi-Bias Non-linear Activation in Deep Neural Networks",
    "authors": [
      "Hongyang Li",
      "Wanli Ouyang",
      "Xiaogang Wang"
    ],
    "author_ids": [],
    "abstract": "As a widely used non-linear activation, Rectified Linear Unit (ReLU)\nseparates noise and signal in a feature map by learning a threshold or bias.\nHowever, we argue that the classification of noise and signal not only depends\non the magnitude of responses, but also the context of how the feature\nresponses would be used to detect more abstract patterns in higher layers. In\norder to output multiple response maps with magnitude in different ranges for a\nparticular visual pattern, existing networks employing ReLU and its variants\nhave to learn a large number of redundant filters. In this paper, we propose a\nmulti-bias non-linear activation (MBA) layer to explore the information hidden\nin the magnitudes of responses. It is placed after the convolution layer to\ndecouple the responses to a convolution kernel into multiple maps by\nmulti-thresholding magnitudes, thus generating more patterns in the feature\nspace at a low computational cost. It provides great flexibility of selecting\nresponses to different visual patterns in different magnitude ranges to form\nrich representations in higher layers. Such a simple and yet effective scheme\nachieves the state-of-the-art performance on several benchmarks.",
    "published_date": "2016-04-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.00676v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.00457v1",
    "title": "Stability of Analytic Neural Networks with Event-triggered Synaptic Feedbacks",
    "authors": [
      "Ren Zheng",
      "Xinlei Yi",
      "Wenlian Lu",
      "Tianping Chen"
    ],
    "author_ids": [],
    "abstract": "In this paper, we investigate stability of a class of analytic neural\nnetworks with the synaptic feedback via event-triggered rules. This model is\ngeneral and include Hopfield neural network as a special case. These\nevent-trigger rules can efficiently reduces loads of computation and\ninformation transmission at synapses of the neurons. The synaptic feedback of\neach neuron keeps a constant value based on the outputs of the other neurons at\nits latest triggering time but changes at its next triggering time, which is\ndetermined by certain criterion. It is proved that every trajectory of the\nanalytic neural network converges to certain equilibrium under this\nevent-triggered rule for all initial values except a set of zero measure. The\nmain technique of the proof is the Lojasiewicz inequality to prove the\nfiniteness of trajectory length. The realization of this event-triggered rule\nis verified by the exclusion of Zeno behaviors. Numerical examples are provided\nto illustrate the efficiency of the theoretical results.",
    "published_date": "2016-04-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NE",
      "math.DS",
      "nlin.AO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.00457v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1604.00357v2",
    "title": "Beyond matroids: Secretary Problem and Prophet Inequality with general constraints",
    "authors": [
      "Aviad Rubinstein"
    ],
    "author_ids": [],
    "abstract": "We study generalizations of the \"Prophet Inequality\" and \"Secretary Problem\",\nwhere the algorithm is restricted to an arbitrary downward-closed set system.\nFor {0,1}-values, we give O(log n)-competitive algorithms for both problems.\nThis is close to the \\Omega(log n / loglog n) lower bound due to Babaioff,\nImmorlica, and Kleinberg. For general values, our results translate to O(log n\nlog r)-competitive algorithms, where r is the cardinality of the largest\nfeasible set. This resolves (up to the O(log r loglog n) factors) an open\nquestion posed to us by Bobby Kleinberg.",
    "published_date": "2016-04-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.00357v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1604.00033v1",
    "title": "EMBERS at 4 years: Experiences operating an Open Source Indicators Forecasting System",
    "authors": [
      "Sathappan Muthiah",
      "Patrick Butler",
      "Rupinder Paul Khandpur",
      "Parang Saraf",
      "Nathan Self",
      "Alla Rozovskaya",
      "Liang Zhao",
      "Jose Cadena",
      "Chang-Tien Lu",
      "Anil Vullikanti",
      "Achla Marathe",
      "Kristen Summers",
      "Graham Katz",
      "Andy Doyle",
      "Jaime Arredondo",
      "Dipak K. Gupta",
      "David Mares",
      "Naren Ramakrishnan"
    ],
    "author_ids": [],
    "abstract": "EMBERS is an anticipatory intelligence system forecasting population-level\nevents in multiple countries of Latin America. A deployed system from 2012,\nEMBERS has been generating alerts 24x7 by ingesting a broad range of data\nsources including news, blogs, tweets, machine coded events, currency rates,\nand food prices. In this paper, we describe our experiences operating EMBERS\ncontinuously for nearly 4 years, with specific attention to the discoveries it\nhas enabled, correct as well as missed forecasts, and lessons learnt from\nparticipating in a forecasting tournament including our perspectives on the\nlimits of forecasting and ethical considerations.",
    "published_date": "2016-03-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1604.00033v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.09701v3",
    "title": "Paired Threshold Graphs",
    "authors": [
      "Vida Ravanmehr",
      "Gregory J. Puleo",
      "Sadegh Bolouki",
      "Olgica Milenkovic"
    ],
    "author_ids": [],
    "abstract": "Threshold graphs are recursive deterministic network models that have been\nproposed for describing certain economic and social interactions. One drawback\nof this graph family is that it has limited generative attachment rules. To\nmitigate this problem, we introduce a new class of graphs termed Paired\nThreshold (PT) graphs described through vertex weights that govern the\nexistence of edges via two inequalities. One inequality imposes the constraint\nthat the sum of weights of adjacent vertices has to exceed a specified\nthreshold. The second inequality ensures that adjacent vertices have a weight\ndifference upper bounded by another threshold. We provide a conceptually simple\ncharacterization and decomposition of PT graphs, analyze their forbidden\ninduced subgraphs and present a method for performing vertex weight assignments\non PT graphs that satisfy the defining constraints. Furthermore, we describe a\npolynomial-time algorithm for recognizing PT graphs. We conclude our exposition\nwith an analysis of the intersection number, diameter and clustering\ncoefficient of PT graphs.",
    "published_date": "2016-03-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.09701v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.08832v1",
    "title": "Shirtless and Dangerous: Quantifying Linguistic Signals of Gender Bias in an Online Fiction Writing Community",
    "authors": [
      "Ethan Fast",
      "Tina Vachovsky",
      "Michael S. Bernstein"
    ],
    "author_ids": [],
    "abstract": "Imagine a princess asleep in a castle, waiting for her prince to slay the\ndragon and rescue her. Tales like the famous Sleeping Beauty clearly divide up\ngender roles. But what about more modern stories, borne of a generation\nincreasingly aware of social constructs like sexism and racism? Do these\nstories tend to reinforce gender stereotypes, or counter them? In this paper,\nwe present a technique that combines natural language processing with a\ncrowdsourced lexicon of stereotypes to capture gender biases in fiction. We\napply this technique across 1.8 billion words of fiction from the Wattpad\nonline writing community, investigating gender representation in stories, how\nmale and female characters behave and are described, and how authors' use of\ngender stereotypes is associated with the community's ratings. We find that\nmale over-representation and traditional gender stereotypes (e.g., dominant men\nand submissive women) are common throughout nearly every genre in our corpus.\nHowever, only some of these stereotypes, like sexual or violent men, are\nassociated with highly rated stories. Finally, despite women often being the\ntarget of negative stereotypes, female authors are equally likely to write such\nstereotypes as men.",
    "published_date": "2016-03-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.08832v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.08702v1",
    "title": "Nine Features in a Random Forest to Learn Taxonomical Semantic Relations",
    "authors": [
      "Enrico Santus",
      "Alessandro Lenci",
      "Tin-Shing Chiu",
      "Qin Lu",
      "Chu-Ren Huang"
    ],
    "author_ids": [],
    "abstract": "ROOT9 is a supervised system for the classification of hypernyms, co-hyponyms\nand random words that is derived from the already introduced ROOT13 (Santus et\nal., 2016). It relies on a Random Forest algorithm and nine unsupervised\ncorpus-based features. We evaluate it with a 10-fold cross validation on 9,600\npairs, equally distributed among the three classes and involving several\nParts-Of-Speech (i.e. adjectives, nouns and verbs). When all the classes are\npresent, ROOT9 achieves an F1 score of 90.7%, against a baseline of 57.2%\n(vector cosine). When the classification is binary, ROOT9 achieves the\nfollowing results against the baseline: hypernyms-co-hyponyms 95.7% vs. 69.8%,\nhypernyms-random 91.8% vs. 64.1% and co-hyponyms-random 97.8% vs. 79.4%. In\norder to compare the performance with the state-of-the-art, we have also\nevaluated ROOT9 in subsets of the Weeds et al. (2014) datasets, proving that it\nis in fact competitive. Finally, we investigated whether the system learns the\nsemantic relation or it simply learns the prototypical hypernyms, as claimed by\nLevy et al. (2015). The second possibility seems to be the most likely, even\nthough ROOT9 can be trained on negative examples (i.e., switched hypernyms) to\ndrastically reduce this bias.",
    "published_date": "2016-03-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.08702v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.08177v1",
    "title": "Planning Problems for Sophisticated Agents with Present Bias",
    "authors": [
      "Jon Kleinberg",
      "Sigal Oren",
      "Manish Raghavan"
    ],
    "author_ids": [],
    "abstract": "Present bias, the tendency to weigh costs and benefits incurred in the\npresent too heavily, is one of the most widespread human behavioral biases. It\nhas also been the subject of extensive study in the behavioral economics\nliterature. While the simplest models assume that the agents are naive,\nreasoning about the future without taking their bias into account, there is\nconsiderable evidence that people often behave in ways that are sophisticated\nwith respect to present bias, making plans based on the belief that they will\nbe present-biased in the future. For example, committing to a course of action\nto reduce future opportunities for procrastination or overconsumption are\ninstances of sophisticated behavior in everyday life.\n  Models of sophisticated behavior have lacked an underlying formalism that\nallows one to reason over the full space of multi-step tasks that a\nsophisticated agent might face. This has made it correspondingly difficult to\nmake comparative or worst-case statements about the performance of\nsophisticated agents in arbitrary scenarios. In this paper, we incorporate the\nnotion of sophistication into a graph-theoretic model that we used in recent\nwork for modeling naive agents. This new synthesis of two formalisms -\nsophistication and graph-theoretic planning - uncovers a rich structure that\nwasn't apparent in the earlier behavioral economics work on this problem.\n  In particular, our graph-theoretic model makes two kinds of new results\npossible. First, we give tight worst-case bounds on the performance of\nsophisticated agents in arbitrary multi-step tasks relative to the optimal\nplan. Second, the flexibility of our formalism makes it possible to identify\nnew phenomena that had not been seen in prior literature: these include a\nsurprising non-monotonic property in the use of rewards to motivate\nsophisticated agents and a framework for reasoning about commitment devices.",
    "published_date": "2016-03-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.MA",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.08177v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.07783v1",
    "title": "A Convex Approach for Stability Analysis of Coupled PDEs with Spatially Dependent Coefficients",
    "authors": [
      "Evgeny Meyer",
      "Matthew M. Peet"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a methodology for stability analysis of a general\nclass of systems defined by coupled Partial Differential Equations (PDEs) with\nspatially dependent coefficients and a general class of boundary conditions.\nThis class includes PDEs of the parabolic, elliptic and hyperbolic type as well\nas coupled systems without boundary feedback. Our approach uses positive\nmatrices to parameterize a new class of SOS Lyapunov functionals and combines\nthese with a parametrization of projection operators which allow us to enforce\npositivity and negativity on subspaces of L_2. The result allows us to express\nLyapunov stability conditions as a set of Linear Matrix Inequality (LMI)\nconstraints which can be constructed using SOSTOOLS and tested using\nSemi-Definite Programming (SDP) solvers such as SeDuMi or Mosek. The\nmethodology is tested using several simple numerical examples and compared with\nresults obtained from simulation using a standard form of numerical\ndiscretization.",
    "published_date": "2016-03-25T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.07783v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.07697v2",
    "title": "Joint Projection and Dictionary Learning using Low-rank Regularization and Graph Constraints",
    "authors": [
      "Homa Foroughi",
      "Nilanjan Ray",
      "Hong Zhang"
    ],
    "author_ids": [],
    "abstract": "In this paper, we aim at learning simultaneously a discriminative dictionary\nand a robust projection matrix from noisy data. The joint learning, makes the\nlearned projection and dictionary a better fit for each other, so a more\naccurate classification can be obtained. However, current prevailing joint\ndimensionality reduction and dictionary learning methods, would fail when the\ntraining samples are noisy or heavily corrupted. To address this issue, we\npropose a joint projection and dictionary learning using low-rank\nregularization and graph constraints (JPDL-LR). Specifically, the\ndiscrimination of the dictionary is achieved by imposing Fisher criterion on\nthe coding coefficients. In addition, our method explicitly encodes the local\nstructure of data by incorporating a graph regularization term, that further\nimproves the discriminative ability of the projection matrix. Inspired by\nrecent advances of low-rank representation for removing outliers and noise, we\nenforce a low-rank constraint on sub-dictionaries of all classes to make them\nmore compact and robust to noise. Experimental results on several benchmark\ndatasets verify the effectiveness and robustness of our method for both\ndimensionality reduction and image classification, especially when the data\ncontains considerable noise or variations.",
    "published_date": "2016-03-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.07697v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.07686v1",
    "title": "On Existence of Solutions to Structured Lyapunov Inequalities",
    "authors": [
      "Aviar Sootla",
      "James Anderson"
    ],
    "author_ids": [],
    "abstract": "In this paper, we derive sufficient conditions on drift matrices under which\nblock-diagonal solutions to Lyapunov inequalities exist. The motivation for the\nproblem comes from a recently proposed basis pursuit algorithm. In particular,\nthis algorithm can provide approximate solutions to optimisation programmes\nwith constraints involving Lyapunov inequalities using linear or second order\ncone programming. This algorithm requires an initial feasible point, which we\naim to provide in this paper. Our existence conditions are based on the\nso-called $\\mathcal{H}$ matrices. We also establish a link between\n$\\mathcal{H}$ matrices and an application of a small gain theorem to the drift\nmatrix. We finally show how to construct these solutions in some cases without\nsolving the full Lyapunov inequality.",
    "published_date": "2016-03-24T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.07686v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.06995v4",
    "title": "Multi-Scale Convolutional Neural Networks for Time Series Classification",
    "authors": [
      "Zhicheng Cui",
      "Wenlin Chen",
      "Yixin Chen"
    ],
    "author_ids": [],
    "abstract": "Time series classification (TSC), the problem of predicting class labels of\ntime series, has been around for decades within the community of data mining\nand machine learning, and found many important applications such as biomedical\nengineering and clinical prediction. However, it still remains challenging and\nfalls short of classification accuracy and efficiency. Traditional approaches\ntypically involve extracting discriminative features from the original time\nseries using dynamic time warping (DTW) or shapelet transformation, based on\nwhich an off-the-shelf classifier can be applied. These methods are ad-hoc and\nseparate the feature extraction part with the classification part, which limits\ntheir accuracy performance. Plus, most existing methods fail to take into\naccount the fact that time series often have features at different time scales.\nTo address these problems, we propose a novel end-to-end neural network model,\nMulti-Scale Convolutional Neural Networks (MCNN), which incorporates feature\nextraction and classification in a single framework. Leveraging a novel\nmulti-branch layer and learnable convolutional layers, MCNN automatically\nextracts features at different scales and frequencies, leading to superior\nfeature representation. MCNN is also computationally efficient, as it naturally\nleverages GPU computing. We conduct comprehensive empirical evaluation with\nvarious existing methods on a large number of benchmark datasets, and show that\nMCNN advances the state-of-the-art by achieving superior accuracy performance\nthan other leading methods.",
    "published_date": "2016-03-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.06995v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.06113v1",
    "title": "Improved Protocols and Hardness Results for the Two-Player Cryptogenography Problem",
    "authors": [
      "Benjamin Doerr",
      "Marvin Künnemann"
    ],
    "author_ids": [],
    "abstract": "The cryptogenography problem, introduced by Brody, Jakobsen, Scheder, and\nWinkler (ITCS 2014), is to collaboratively leak a piece of information known to\nonly one member of a group (i)~without revealing who was the origin of this\ninformation and (ii)~without any private communication, neither during the\nprocess nor before. Despite several deep structural results, even the smallest\ncase of leaking one bit of information present at one of two players is not\nwell understood. Brody et al.\\ gave a 2-round protocol enabling the two players\nto succeed with probability $1/3$ and showed the hardness result that no\nprotocol can give a success probability of more than~$3/8$.\n  In this work, we show that neither bound is tight. Our new hardness result,\nobtained by a different application of the concavity method used also in the\nprevious work, states that a success probability better than 0.3672 is not\npossible. Using both theoretical and numerical approaches, we improve the lower\nbound to $0.3384$, that is, give a protocol leading to this success\nprobability. To ease the design of new protocols, we prove an equivalent\nformulation of the cryptogenography problem as solitaire vector splitting game.\nVia an automated game tree search, we find good strategies for this game. We\nthen translate the splits that occurred in this strategy into inequalities\nrelating position values and use an LP solver to find an optimal solution for\nthese inequalities. This gives slightly better game values, but more\nimportantly, it gives a more compact representation of the protocol and a way\nto easily verify the claimed quality of the protocol.\n  These improved bounds, as well as the large sizes and depths of the improved\nprotocols we find, suggests that finding good protocols for the\ncryptogenography problem as well as understanding their structure are harder\nthan what the simple problem formulation suggests.",
    "published_date": "2016-03-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CR",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.06113v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.05850v1",
    "title": "N-ary Error Correcting Coding Scheme",
    "authors": [
      "Joey Tianyi Zhou",
      "Ivor W. Tsang",
      "Shen-Shyang Ho",
      "Klaus-Robert Muller"
    ],
    "author_ids": [],
    "abstract": "The coding matrix design plays a fundamental role in the prediction\nperformance of the error correcting output codes (ECOC)-based multi-class task.\n{In many-class classification problems, e.g., fine-grained categorization, it\nis difficult to distinguish subtle between-class differences under existing\ncoding schemes due to a limited choices of coding values.} In this paper, we\ninvestigate whether one can relax existing binary and ternary code design to\n$N$-ary code design to achieve better classification performance. {In\nparticular, we present a novel $N$-ary coding scheme that decomposes the\noriginal multi-class problem into simpler multi-class subproblems, which is\nsimilar to applying a divide-and-conquer method.} The two main advantages of\nsuch a coding scheme are as follows: (i) the ability to construct more\ndiscriminative codes and (ii) the flexibility for the user to select the best\n$N$ for ECOC-based classification. We show empirically that the optimal $N$\n(based on classification performance) lies in $[3, 10]$ with some trade-off in\ncomputational cost. Moreover, we provide theoretical insights on the dependency\nof the generalization error bound of an $N$-ary ECOC on the average base\nclassifier generalization error and the minimum distance between any two codes\nconstructed. Extensive experimental results on benchmark multi-class datasets\nshow that the proposed coding scheme achieves superior prediction performance\nover the state-of-the-art coding methods.",
    "published_date": "2016-03-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.05850v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.05828v1",
    "title": "Online Networks, Social Interaction and Segregation: An Evolutionary Approach",
    "authors": [
      "Angelo Antoci",
      "Fabio Sabatini",
      "Francesco Sarracino"
    ],
    "author_ids": [],
    "abstract": "We have developed an evolutionary game model, where agents can choose between\ntwo forms of social participation: interaction via online social networks and\ninteraction by exclusive means of face-to-face encounters. We illustrate the\nsocietal dynamics that the model predicts, in light of the empirical evidence\nprovided by previous literature. We then assess their welfare implications. We\nshow that dynamics, starting from a world in which online social interaction is\nless gratifying than offline encounters, will lead to the extinction of the\nsub-population of online networks users, thereby making Facebook and alike\ndisappear in the long run. Furthermore, we show that the higher the propensity\nfor discrimination between the two sub-populations of socially active\nindividuals, the greater the probability that individuals will ultimately\nsegregate themselves, making society fall into a social poverty trap.",
    "published_date": "2016-03-18T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.GT",
      "math.DS",
      "q-fin.EC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.05828v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.05579v2",
    "title": "Convergence of a Newton algorithm for semi-discrete optimal transport",
    "authors": [
      "Jun Kitagawa",
      "Quentin Mérigot",
      "Boris Thibert"
    ],
    "author_ids": [],
    "abstract": "Many problems in geometric optics or convex geometry can be recast as optimal\ntransport problems: this includes the far-field reflector problem, Alexandrov's\ncurvature prescription problem, etc. A popular way to solve these problems\nnumerically is to assume that the source probability measure is absolutely\ncontinuous while the target measure is finitely supported. We refer to this\nsetting as semi-discrete optimal transport. Among the several algorithms\nproposed to solve semi-discrete optimal transport problems, one currently needs\nto choose between algorithms that are slow but come with a convergence speed\nanalysis (e.g. Oliker-Prussner) or algorithms that are much faster in practice\nbut which come with no convergence guarantees Algorithms of the first kind rely\non coordinate-wise increments and the number of iterations required to reach\nthe solution up to an error of $\\epsilon$ is of order $N^3/\\epsilon$, where $N$\nis the number of Dirac masses in the target measure. On the other hand,\nalgorithms of the second kind typically rely on the formulation of the\nsemi-discrete optimal transport problem as an unconstrained convex optimization\nproblem which is solved using a Newton or quasi-Newton method.\n  The purpose of this article is to bridge this gap between theory and practice\nby introducing a damped Newton's algorithm which is experimentally efficient\nand by proving the global convergence of this algorithm with optimal rates. The\nmain assumptions is that the cost function satisfies a condition that appears\nin the regularity theory for optimal transport (the Ma-Trudinger-Wang\ncondition) and that the support of the source density is connected in a\nquantitative way (it must satisfy a weighted Poincar\\'e-Wirtinger inequality).",
    "published_date": "2016-03-17T00:00:00",
    "year": 2016,
    "categories": [
      "math.NA",
      "cs.CG",
      "math.AP",
      "49M25, 65K10"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.05579v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.05544v3",
    "title": "Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent",
    "authors": [
      "Linnan Wang",
      "Yi Yang",
      "Martin Renqiang Min",
      "Srimat Chakradhar"
    ],
    "author_ids": [],
    "abstract": "SGD is the widely adopted method to train CNN. Conceptually it approximates\nthe population with a randomly sampled batch; then it evenly trains batches by\nconducting a gradient update on every batch in an epoch. In this paper, we\ndemonstrate Sampling Bias, Intrinsic Image Difference and Fixed Cycle Pseudo\nRandom Sampling differentiate batches in training, which then affect learning\nspeeds on them. Because of this, the unbiased treatment of batches involved in\nSGD creates improper load balancing. To address this issue, we present\nInconsistent Stochastic Gradient Descent (ISGD) to dynamically vary training\neffort according to learning statuses on batches. Specifically ISGD leverages\ntechniques in Statistical Process Control to identify a undertrained batch.\nOnce a batch is undertrained, ISGD solves a new subproblem, a chasing logic\nplus a conservative constraint, to accelerate the training on the batch while\navoid drastic parameter changes. Extensive experiments on a variety of datasets\ndemonstrate ISGD converges faster than SGD. In training AlexNet, ISGD is\n21.05\\% faster than SGD to reach 56\\% top1 accuracy under the exactly same\nexperiment setup. We also extend ISGD to work on multiGPU or heterogeneous\ndistributed system based on data parallelism, enabling the batch size to be the\nkey to scalability. Then we present the study of ISGD batch size to the\nlearning rate, parallelism, synchronization cost, system saturation and\nscalability. We conclude the optimal ISGD batch size is machine dependent.\nVarious experiments on a multiGPU system validate our claim. In particular,\nISGD trains AlexNet to 56.3% top1 and 80.1% top5 accuracy in 11.5 hours with 4\nNVIDIA TITAN X at the batch size of 1536.",
    "published_date": "2016-03-17T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.05544v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.04882v1",
    "title": "Bias Correction for Regularized Regression and its Application in Learning with Streaming Data",
    "authors": [
      "Qiang Wu"
    ],
    "author_ids": [],
    "abstract": "We propose an approach to reduce the bias of ridge regression and\nregularization kernel network. When applied to a single data set the new\nalgorithms have comparable learning performance with the original ones. When\napplied to incremental learning with block wise streaming data the new\nalgorithms are more efficient due to bias reduction. Both theoretical\ncharacterizations and simulation studies are used to verify the effectiveness\nof these new algorithms.",
    "published_date": "2016-03-15T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.04882v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.04789v1",
    "title": "Emergence of metapopulations and echo chambers in mobile agents",
    "authors": [
      "Michele Starnini",
      "Mattia Frasca",
      "Andrea Baronchelli"
    ],
    "author_ids": [],
    "abstract": "Multi-agent models often describe populations segregated either in the\nphysical space, i.e. subdivided in metapopulations, or in the ecology of\nopinions, i.e. partitioned in echo chambers. Here we show how the interplay\nbetween homophily and social influence controls the emergence of both kinds of\nsegregation in a simple model of mobile agents, endowed with a continuous\nopinion variable. In the model, physical proximity determines a progressive\nconvergence of opinions but differing opinions result in agents moving away\nfrom each others. This feedback between mobility and social dynamics determines\nto the onset of a stable dynamical metapopulation scenario where physically\nseparated groups of like-minded individuals interact with each other through\nthe exchange of agents. The further introduction of confirmation bias in social\ninteractions, defined as the tendency of an individual to favor opinions that\nmatch his own, leads to the emergence of echo chambers where different opinions\ncan coexist also within the same group. We believe that the model may be of\ninterest to researchers investigating the origin of segregation in the offline\nand online world.",
    "published_date": "2016-03-15T00:00:00",
    "year": 2016,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.04789v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.04327v1",
    "title": "Automatic Discrimination of Color Retinal Images using the Bag of Words Approach",
    "authors": [
      "Ibrahim Sadek"
    ],
    "author_ids": [],
    "abstract": "Diabetic retinopathy (DR) and age related macular degeneration (ARMD) are\namong the major causes of visual impairment worldwide. DR is mainly\ncharacterized by red spots, namely microaneurysms and bright lesions,\nspecifically exudates whereas ARMD is mainly identified by tiny yellow or white\ndeposits called drusen. Since exudates might be the only manifestation of the\nearly diabetic retinopathy, there is an increase demand for automatic\nretinopathy diagnosis. Exudates and drusen may share similar appearances, thus\ndiscriminating between them is of interest to enhance screening performance. In\nthis research, we investigative the role of bag of words approach in the\nautomatic diagnosis of retinopathy diabetes. We proposed to use a single based\nand multiple based methods for the construction of the visual dictionary by\ncombining the histogram of word occurrences from each dictionary and building a\nsingle histogram. The introduced approach is evaluated for automatic diagnosis\nof normal and abnormal color fundus images with bright lesions. This approach\nhas been implemented on 430 fundus images, including six publicly available\ndatasets, in addition to one local dataset. The mean accuracies reported are\n97.2% and 99.77% for single based and multiple based dictionaries respectively.",
    "published_date": "2016-03-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.04327v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.04015v3",
    "title": "Learning zeroth class dictionary for human action recognition",
    "authors": [
      "Jia-xin Cai",
      "Xin Tang",
      "Lifang Zhang",
      "Guocan Feng"
    ],
    "author_ids": [],
    "abstract": "In this paper, a discriminative two-phase dictionary learning framework is\nproposed for classifying human action by sparse shape representations, in which\nthe first-phase dictionary is learned on the selected discriminative frames and\nthe second-phase dictionary is built for recognition using reconstruction\nerrors of the first-phase dictionary as input features. We propose a \"zeroth\nclass\" trick for detecting undiscriminating frames of the test video and\neliminating them before voting on the action categories. Experimental results\non benchmarks demonstrate the effectiveness of our method.",
    "published_date": "2016-03-13T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.04015v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.03725v1",
    "title": "A Multi-Channel Spectrum Sensing Fusion Mechanism for Cognitive Radio Networks: Design and Application to IEEE 802.22 WRANs",
    "authors": [
      "Navid Tadayon",
      "Sonia Aissa"
    ],
    "author_ids": [],
    "abstract": "The IEEE 802.22 is a new cognitive radio standard that is aimed at extending\nwireless outreach to rural areas. Known as wireless regional area networks, and\ndesigned based on the not-to-interfere spectrum sharing model, WRANs are\nchannelized and centrally-controlled networks working on the under-utilized\nUHF/VHF TV bands to establish communication with remote users, so-called\ncustomer premises equipment (CPEs). Despite the importance of reliable and\ninterference-free operation in these frequencies, spectrum sensing fusion\nmechanisms suggested in IEEE 802.22 are rudimentary and fail to satisfy the\nstringent mandated sensing requirements. Other deep-rooted shortcomings are\nperformance non-uniformity over different signal-to-noise-ratio regimes,\nunbalanced performance, instability and lack of flexibility. Inspired by these\nobservations, in this paper we propose a distributed spectrum sensing technique\nfor WRANs, named multi-channel learning-based distributed sensing fusion\nmechanism (MC-LDS). MC-LDS is demonstrated to be self-trained, stable and to\ncompensate for fault reports through its inherent reward-penalty approach.\nMoreover, MC-LDS exhibits a better uniform performance in all traffic regimes,\nis fair (reduces the false-alarm/misdetection gap), adjustable (works with\nseveral degrees of freedom) and bandwidth efficient (opens transmission\nopportunities for more CPEs). Simulation results and comparisons unanimously\ncorroborate that MC-LDS outperforms IEEE 802.22 recommended algorithms, i.e.,\nthe AND, OR and VOTING rules.",
    "published_date": "2016-03-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.03725v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.03645v1",
    "title": "Mobile-service based Max-Min Fairness Resource Scheduling for Heterogeneous Vehicular Networks",
    "authors": [
      "Yu Zhang",
      "Ke Xiong",
      "Fengping An",
      "Xiaofei DI",
      "Jingtao SU"
    ],
    "author_ids": [],
    "abstract": "This paper investigates the resource scheduling for heterogeneous vehicular\nnetworks, where some moving vehicles are selected and scheduled as helping\nrelays to assist information transmission between the roadside infrastructure\nand other moving vehicles. For such a system, we propose a mobile-service based\nmax-min fairness resource scheduling scheme, where service amount which is more\nsuitable for high mobility scenarios is adopted to characterize the information\ntransmission capacity of the links and the max-min criteria is adopted to meet\nthe fairness requirement of the moving vehicles. Simulation results demonstrate\nthe effectiveness of our proposed scheme. It is shown that our proposed scheme\narchives higher throughput and better fairness compared with random scheduling\nscheme and non relaying scheme.",
    "published_date": "2016-03-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.03645v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.02476v1",
    "title": "Fair Scheduling for Data Collection in Mobile Sensor Networks with Energy Harvesting",
    "authors": [
      "Kai Li",
      "Chau Yuen",
      "Branislav Kusy",
      "Raja Jurdak",
      "Aleksandar Ignjatovic",
      "Salil S. Kanhere",
      "Sanjay Jha"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of data collection from a continental-scale network\nof energy harvesting sensors, applied to tracking mobile assets in rural\nenvironments. Our application constraints favour a highly asymmetric solution,\nwith heavily duty-cycled sensor nodes communicating with powered base stations.\nWe study a novel scheduling optimisation problem for energy harvesting mobile\nsensor network, that maximises the amount of collected data under the\nconstraints of radio link quality and energy harvesting efficiency, while\nensuring a fair data reception. We show that the problem is NP-complete and\npropose a heuristic algorithm to approximate the optimal scheduling solution in\npolynomial time. Moreover, our algorithm is flexible in handling progressive\nenergy harvesting events, such as with solar panels, or opportunistic and\nbursty events, such as with Wireless Power Transfer. We use empirical link\nquality data, solar energy, and WPT efficiency to evaluate the proposed\nalgorithm in extensive simulations and compare its performance to\nstate-of-the-art. We show that our algorithm achieves high data reception\nrates, under different fairness and node lifetime constraints.",
    "published_date": "2016-03-08T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.02476v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.02209v1",
    "title": "Quantum Hashing for Finite Abelian Groups",
    "authors": [
      "Alexander Vasiliev"
    ],
    "author_ids": [],
    "abstract": "We propose a generalization of the quantum hashing technique based on the\nnotion of the small-bias sets. These sets have proved useful in different areas\nof computer science, and here their properties give an optimal construction for\nsuccinct quantum presentation of elements of any finite abelian group, which\ncan be used in various computational and cryptographic scenarios. The known\nquantum fingerprinting schemas turn out to be the special cases of the proposed\nquantum hashing for the corresponding abelian group.",
    "published_date": "2016-03-07T00:00:00",
    "year": 2016,
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.02209v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.01751v4",
    "title": "Stability analysis and stabilization of stochastic linear impulsive, switched and sampled-data systems under dwell-time constraints",
    "authors": [
      "Corentin Briat"
    ],
    "author_ids": [],
    "abstract": "Impulsive systems are a very flexible class of systems that can be used to\nrepresent switched and sampled-data systems. We propose to extend here the\npreviously obtained results on deterministic impulsive systems to the\nstochastic setting. The concepts of mean-square stability and dwell-times are\nutilized in order to formulate relevant stability conditions for such systems.\nThese conditions are formulated as convex clock-dependent linear matrix\ninequality conditions that are applicable to robust analysis and control\ndesign, and are verifiable using discretization or sum of squares techniques.\nStability conditions under various dwell-time conditions are obtained and\nnon-conservatively turned into state-feedback stabilization conditions. The\nresults are finally applied to the analysis and control of stochastic\nsampled-data systems. Several comparative examples demonstrate the accuracy and\nthe tractability of the approach.",
    "published_date": "2016-03-05T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY",
      "math.CA",
      "math.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.01751v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.01696v1",
    "title": "A Feature Learning and Object Recognition Framework for Underwater Fish Images",
    "authors": [
      "Meng-Che Chuang",
      "Jenq-Neng Hwang",
      "Kresimir Williams"
    ],
    "author_ids": [],
    "abstract": "Live fish recognition is one of the most crucial elements of fisheries survey\napplications where vast amount of data are rapidly acquired. Different from\ngeneral scenarios, challenges to underwater image recognition are posted by\npoor image quality, uncontrolled objects and environment, as well as difficulty\nin acquiring representative samples. Also, most existing feature extraction\ntechniques are hindered from automation due to involving human supervision.\nToward this end, we propose an underwater fish recognition framework that\nconsists of a fully unsupervised feature learning technique and an\nerror-resilient classifier. Object parts are initialized based on saliency and\nrelaxation labeling to match object parts correctly. A non-rigid part model is\nthen learned based on fitness, separation and discrimination criteria. For the\nclassifier, an unsupervised clustering approach generates a binary class\nhierarchy, where each node is a classifier. To exploit information from\nambiguous images, the notion of partial classification is introduced to assign\ncoarse labels by optimizing the \"benefit\" of indecision made by the classifier.\nExperiments show that the proposed framework achieves high accuracy on both\npublic and self-collected underwater fish images with high uncertainty and\nclass imbalance.",
    "published_date": "2016-03-05T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.01696v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1603.01607v1",
    "title": "Computing Shortest Paths Using A*, Landmarks, and Polygon Inequalities (Abstract)",
    "authors": [
      "Newton Campbell Jr"
    ],
    "author_ids": [],
    "abstract": "We introduce a new heuristic for the A* algorithm that references a data\nstructure much smaller than the one required by the ALT heuristic. This\nheuristic's benefits are permitted by a new approach for computing lower bounds\nusing generalized polygon inequalities, leveraging distance information from\ntwo landmarks as opposed to the common single landmark paradigm. In this paper,\nwe demonstrate that this heuristic stores a reduced amount of preprocessing\ninformation in comparison to previous landmark algorithms while performing\nfaster search queries.",
    "published_date": "2016-03-04T00:00:00",
    "year": 2016,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.01607v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.01338v1",
    "title": "Finding best possible constant for a polynomial inequality",
    "authors": [
      "Lu Yang",
      "Ju Zhang"
    ],
    "author_ids": [],
    "abstract": "Given a multi-variant polynomial inequality with a parameter, how to find the\nbest possible value of this parameter that satisfies the inequality? For\ninstance, find the greatest number $k$ that satisfies $ a^3+b^3+c^3+\nk(a^2b+b^2c+c^2a)-(k+1)(ab^2+bc^2+ca^2)\\geq 0 $ for all nonnegative real\nnumbers $ a,b,c $. Analogues problems often appeared in studies of inequalities\nand were dealt with by various methods. In this paper, a general algorithm is\nproposed for finding the required best possible constant. The algorithm can be\neasily implemented by computer algebra tools such as Maple.",
    "published_date": "2016-03-04T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.01338v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.00936v2",
    "title": "A size-sensitive inequality for cross-intersecting families",
    "authors": [
      "Peter Frankl",
      "Andrey Kupavskii"
    ],
    "author_ids": [],
    "abstract": "Two families $\\mathcal A$ and $\\mathcal B$ of $k$-subsets of an $n$-set are\ncalled cross-intersecting if $A\\cap B\\ne\\emptyset$ for all $A\\in \\mathcal A,\nB\\in \\mathcal B $. Strengthening the classical Erd\\H os-Ko-Rado theorem, Pyber\nproved that $|\\mathcal A||\\mathcal B|\\le {n-1\\choose k-1}^2$ holds for $n\\ge\n2k$. In the present paper we sharpen this inequality. We prove that assuming\n$|\\mathcal B|\\ge {n-1\\choose k-1}+{n-i\\choose k-i+1}$ for some $3\\le i\\le k+1$\nthe stronger inequality $$|\\mathcal A||\\mathcal B|\\le \\Bigl({n-1\\choose\nk-1}+{n-i\\choose k-i+1}\\Bigr)\\Bigl({n-1\\choose k-1}-{n-i\\choose k-1}\\Bigr)$$\nholds. These inequalities are best possible.",
    "published_date": "2016-03-03T00:00:00",
    "year": 2016,
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.00936v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1603.00286v5",
    "title": "Redividing the Cake",
    "authors": [
      "Erel Segal-Halevi"
    ],
    "author_ids": [],
    "abstract": "The paper considers fair allocation of resources that are already allocated\nin an unfair way. This setting requires a careful balance between the fairness\nconsiderations and the rights of the present owners.\n  The paper presents re-division algorithms that attain various trade-off\npoints between fairness and ownership rights, in various settings differing in\nthe geometric constraints on the allotments: (a) no geometric constraints; (b)\nconnectivity -- the cake is a one-dimensional interval and each piece must be a\ncontiguous interval; (c) rectangularity -- the cake is a two-dimensional\nrectangle or rectilinear polygon and the pieces should be rectangles; (d)\nconvexity -- the cake is a two-dimensional convex polygon and the pieces should\nbe convex.\n  These re-division algorithms have implications on another problem: the\nprice-of-fairness -- the loss of social welfare caused by fairness\nrequirements. Each algorithm implies an upper bound on the price-of-fairness\nwith the respective geometric constraints.",
    "published_date": "2016-03-01T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1603.00286v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.09088v2",
    "title": "To Give or Not to Give: Fair Division for Single Minded Valuations",
    "authors": [
      "Simina Brânzei",
      "Yuezhou Lv",
      "Ruta Mehta"
    ],
    "author_ids": [],
    "abstract": "Single minded agents have strict preferences, in which a bundle is acceptable\nonly if it meets a certain demand. Such preferences arise naturally in\nscenarios such as allocating computational resources among users, where the\ngoal is to fairly serve as many requests as possible. In this paper we study\nthe fair division problem for such agents, which is harder to handle due to\ndiscontinuity and complementarities of the preferences.\n  Our solution concept---the competitive allocation from equal incomes\n(CAEI)---is inspired from market equilibria and implements fair outcomes\nthrough a pricing mechanism. We study the existence and computation of CAEI for\nmultiple divisible goods, cake cutting, and multiple discrete goods. For the\nfirst two scenarios we show that existence of CAEI solutions is guaranteed,\nwhile for the third we give a succinct characterization of instances that admit\nthis solution; then we give an efficient algorithm to find one in all three\ncases. Maximizing social welfare turns out to be NP-hard in general, however we\nobtain efficient algorithms for (i) divisible and discrete goods when the\nnumber of different \\emph{types} of players is a constant, (ii) cake cutting\nwith contiguous demands, for which we establish an interesting connection with\ninterval scheduling, and (iii) cake cutting with a constant number of players\nwith arbitrary demands.\n  Our solution is useful more generally, when the players have a target set of\ndesired goods, and very small positive values for any bundle not containing\ntheir target set.",
    "published_date": "2016-02-29T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.09088v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.08977v1",
    "title": "Clustering Based Feature Learning on Variable Stars",
    "authors": [
      "Cristóbal Mackenzie",
      "Karim Pichara",
      "Pavlos Protopapas"
    ],
    "author_ids": [],
    "abstract": "The success of automatic classification of variable stars strongly depends on\nthe lightcurve representation. Usually, lightcurves are represented as a vector\nof many statistical descriptors designed by astronomers called features. These\ndescriptors commonly demand significant computational power to calculate,\nrequire substantial research effort to develop and do not guarantee good\nperformance on the final classification task. Today, lightcurve representation\nis not entirely automatic; algorithms that extract lightcurve features are\ndesigned by humans and must be manually tuned up for every survey. The vast\namounts of data that will be generated in future surveys like LSST mean\nastronomers must develop analysis pipelines that are both scalable and\nautomated. Recently, substantial efforts have been made in the machine learning\ncommunity to develop methods that prescind from expert-designed and manually\ntuned features for features that are automatically learned from data. In this\nwork we present what is, to our knowledge, the first unsupervised feature\nlearning algorithm designed for variable stars. Our method first extracts a\nlarge number of lightcurve subsequences from a given set of photometric data,\nwhich are then clustered to find common local patterns in the time series.\nRepresentatives of these patterns, called exemplars, are then used to transform\nlightcurves of a labeled set into a new representation that can then be used to\ntrain an automatic classifier. The proposed algorithm learns the features from\nboth labeled and unlabeled lightcurves, overcoming the bias generated when the\nlearning process is done only with labeled data. We test our method on MACHO\nand OGLE datasets; the results show that the classification performance we\nachieve is as good and in some cases better than the performance achieved using\ntraditional features, while the computational cost is significantly lower.",
    "published_date": "2016-02-29T00:00:00",
    "year": 2016,
    "categories": [
      "astro-ph.SR",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.08977v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.08161v1",
    "title": "Robust Max-Min Fairness Energy Harvesting in Secure MISO Cognitive Radio With SWIPT",
    "authors": [
      "Fuhui Zhou",
      "Zan Li",
      "Julian Cheng",
      "Qunwei Li",
      "Jiangbo Si"
    ],
    "author_ids": [],
    "abstract": "A multiple-input single-output cognitive radio downlink network is studied\nwith simultaneous wireless information and power transfer. In this network, a\nsecondary user coexists with multiple primary users and multiple energy\nharvesting receivers. In order to guarantee secure communication and energy\nharvesting, the problem of robust secure artificial noise-aided beamforming and\npower splitting design is investigated under imperfect channel state\ninformation. Specifically, the max-min fairness energy harvesting problem is\nformulated under the bounded channel state information error model. A\none-dimensional search algorithm based on ${\\cal S}\\text{-Procedure} $ is\nproposed to solve the problem. It is shown that the optimal robust secure\nbeamforming can be achieved. A tradeoff is elucidated between the secrecy rate\nof the secondary user receiver and the energy harvested by the energy\nharvesting receivers under a max-min fairness criterion.",
    "published_date": "2016-02-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.08161v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.07507v1",
    "title": "A Bayesian Approach to the Data Description Problem",
    "authors": [
      "Alireza Ghasemi",
      "Hamid R. Rabiee",
      "Mohammad T. Manzuri",
      "M. H. Rohban"
    ],
    "author_ids": [],
    "abstract": "In this paper, we address the problem of data description using a Bayesian\nframework. The goal of data description is to draw a boundary around objects of\na certain class of interest to discriminate that class from the rest of the\nfeature space. Data description is also known as one-class learning and has a\nwide range of applications.\n  The proposed approach uses a Bayesian framework to precisely compute the\nclass boundary and therefore can utilize domain information in form of prior\nknowledge in the framework. It can also operate in the kernel space and\ntherefore recognize arbitrary boundary shapes. Moreover, the proposed method\ncan utilize unlabeled data in order to improve accuracy of discrimination.\n  We evaluate our method using various real-world datasets and compare it with\nother state of the art approaches of data description. Experiments show\npromising results and improved performance over other data description and\none-class learning algorithms.",
    "published_date": "2016-02-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.07507v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.07415v3",
    "title": "Ensuring Rapid Mixing and Low Bias for Asynchronous Gibbs Sampling",
    "authors": [
      "Christopher De Sa",
      "Kunle Olukotun",
      "Christopher Ré"
    ],
    "author_ids": [],
    "abstract": "Gibbs sampling is a Markov chain Monte Carlo technique commonly used for\nestimating marginal distributions. To speed up Gibbs sampling, there has\nrecently been interest in parallelizing it by executing asynchronously. While\nempirical results suggest that many models can be efficiently sampled\nasynchronously, traditional Markov chain analysis does not apply to the\nasynchronous case, and thus asynchronous Gibbs sampling is poorly understood.\nIn this paper, we derive a better understanding of the two main challenges of\nasynchronous Gibbs: bias and mixing time. We show experimentally that our\ntheoretical results match practical outcomes.",
    "published_date": "2016-02-24T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.07415v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.07104v3",
    "title": "Resource Management for OFDMA based Next Generation 802.11ax WLANs",
    "authors": [
      "Mehmet Karaca",
      "Saeed Bastani",
      "Basuki Endah Priyanto",
      "Mohammadhassan Safavi",
      "Björn Landfeldt"
    ],
    "author_ids": [],
    "abstract": "Recently, IEEE 802.11ax Task Group has adapted OFDMA as a new technique for\nenabling multi-user transmission. It has been also decided that the scheduling\nduration should be same for all the users in a multi-user OFDMA so that the\ntransmission of the users should end at the same time. In order to realize that\ncondition, the users with insufficient data should transmit null data (i.e.\npadding) to fill the duration. While this scheme offers strong features such as\nresilience to Overlapping Basic Service Set (OBSS) interference and ease of\nsynchronization, it also poses major side issues of degraded throughput\nperformance and waste of devices' energy. In this work, for OFDMA based 802.11\nWLANs we first propose practical algorithm in which the scheduling duration is\nfixed and does not change from time to time. In the second algorithm the\nscheduling duration is dynamically determined in a resource allocation\nframework by taking into account the padding overhead, airtime fairness and\nenergy consumption of the users. We analytically investigate our resource\nallocation problems through Lyapunov optimization techniques and show that our\nalgorithms are arbitrarily close to the optimal performance at the price of\nreduced convergence rate. We also calculate the overhead of our algorithms in a\nrealistic set-up and propose solutions for the implementation issues.",
    "published_date": "2016-02-23T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI",
      "cs.IT",
      "cs.PF",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.07104v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.06929v2",
    "title": "Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm",
    "authors": [
      "Prateek Jain",
      "Chi Jin",
      "Sham M. Kakade",
      "Praneeth Netrapalli",
      "Aaron Sidford"
    ],
    "author_ids": [],
    "abstract": "This work provides improved guarantees for streaming principle component\nanalysis (PCA). Given $A_1, \\ldots, A_n\\in \\mathbb{R}^{d\\times d}$ sampled\nindependently from distributions satisfying $\\mathbb{E}[A_i] = \\Sigma$ for\n$\\Sigma \\succeq \\mathbf{0}$, this work provides an $O(d)$-space linear-time\nsingle-pass streaming algorithm for estimating the top eigenvector of $\\Sigma$.\nThe algorithm nearly matches (and in certain cases improves upon) the accuracy\nobtained by the standard batch method that computes top eigenvector of the\nempirical covariance $\\frac{1}{n} \\sum_{i \\in [n]} A_i$ as analyzed by the\nmatrix Bernstein inequality. Moreover, to achieve constant accuracy, our\nalgorithm improves upon the best previous known sample complexities of\nstreaming algorithms by either a multiplicative factor of $O(d)$ or\n$1/\\mathrm{gap}$ where $\\mathrm{gap}$ is the relative distance between the top\ntwo eigenvalues of $\\Sigma$.\n  These results are achieved through a novel analysis of the classic Oja's\nalgorithm, one of the oldest and most popular algorithms for streaming PCA. In\nparticular, this work shows that simply picking a random initial point $w_0$\nand applying the update rule $w_{i + 1} = w_i + \\eta_i A_i w_i$ suffices to\naccurately estimate the top eigenvector, with a suitable choice of $\\eta_i$. We\nbelieve our result sheds light on how to efficiently perform streaming PCA both\nin theory and in practice and we hope that our analysis may serve as the basis\nfor analyzing many variants and extensions of streaming PCA.",
    "published_date": "2016-02-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.NE",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.06929v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.06913v1",
    "title": "Robust AN-Aided Beamforming and Power Splitting Design for Secure MISO Cognitive Radio With SWIPT",
    "authors": [
      "Fuhui Zhou",
      "Zan Li",
      "Julian Cheng",
      "Qunwei Li",
      "Jiangbo Si"
    ],
    "author_ids": [],
    "abstract": "A multiple-input single-output cognitive radio downlink network is studied\nwith simultaneous wireless information and power transfer. In this network, a\nsecondary user coexists with multiple primary users and multiple energy\nharvesting receivers. In order to guarantee secure communication and energy\nharvesting, the problem of robust secure artificial noise-aided beamforming and\npower splitting design is investigated under imperfect channel state\ninformation (CSI). Specifically, the transmit power minimization problem and\nthe max-min fairness energy harvesting problem are formulated for both the\nbounded CSI error model and the probabilistic CSI error model. These problems\nare non-convex and challenging to solve. A one-dimensional search algorithm is\nproposed to solve these problems based on ${\\cal S}\\text{-Procedure} $ under\nthe bounded CSI error model and based on Bernstein-type inequalities under the\nprobabilistic CSI error model. It is shown that the optimal robust secure\nbeamforming can be achieved under the bounded CSI error model, whereas a\nsuboptimal beamforming solution can be obtained under the probabilistic CSI\nerror model. A tradeoff is elucidated between the secrecy rate of the secondary\nuser receiver and the energy harvested by the energy harvesting receivers under\na max-min fairness criterion.",
    "published_date": "2016-02-22T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.06913v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.05112v3",
    "title": "Patient Flow Prediction via Discriminative Learning of Mutually-Correcting Processes",
    "authors": [
      "Hongteng Xu",
      "Weichang Wu",
      "Shamim Nemati",
      "Hongyuan Zha"
    ],
    "author_ids": [],
    "abstract": "Over the past decade the rate of care unit (CU) use in the United States has\nbeen increasing. With an aging population and ever-growing demand for medical\ncare, effective management of patients' transitions among different care\nfacilities will prove indispensible for shortening the length of hospital\nstays, improving patient outcomes, allocating critical care resources, and\nreducing preventable re-admissions. In this paper, we focus on an important\nproblem of predicting the so-called \"patient flow\" from longitudinal electronic\nhealth records (EHRs), which has not been explored via existing machine\nlearning techniques. By treating a sequence of transition events as a point\nprocess, we develop a novel framework for modeling patient flow through various\nCUs and jointly predicting patients' destination CUs and duration days. Instead\nof learning a generative point process model via maximum likelihood estimation,\nwe propose a novel discriminative learning algorithm aiming at improving the\nprediction of transition events in the case of sparse data. By parameterizing\nthe proposed model as a mutually-correcting process, we formulate the\nestimation problem via generalized linear models, which lends itself to\nefficient learning based on alternating direction method of multipliers (ADMM).\nFurthermore, we achieve simultaneous feature selection and learning by adding a\ngroup-lasso regularizer to the ADMM algorithm. Additionally, for suppressing\nthe negative influence of data imbalance on the learning of model, we\nsynthesize auxiliary training data for the classes with extremely few samples,\nand improve the robustness of our learning method accordingly. Testing on\nreal-world data, we show that our method obtains superior performance in terms\nof accuracy of predicting the destination CU transition and duration of each CU\noccupancy.",
    "published_date": "2016-02-14T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.05112v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.04286v1",
    "title": "Geometric Adaptive Control of Attitude Dynamics on SO(3) with State Inequality Constraints",
    "authors": [
      "Shankar Kulumani",
      "Christopher Poole",
      "Taeyoung Lee"
    ],
    "author_ids": [],
    "abstract": "This paper presents a new geometric adaptive control system with state\ninequality constraints for the attitude dynamics of a rigid body. The control\nsystem is designed such that the desired attitude is asymptotically stabilized,\nwhile the controlled attitude trajectory avoids undesired regions defined by an\ninequality constraint. In addition, we develop an adaptive update law that\nenables attitude stabilization in the presence of unknown disturbances. The\nattitude dynamics and the proposed control systems are developed on the special\northogonal group such that singularities and ambiguities of other attitude\nparameterizations, such as Euler angles and quaternions are completely avoided.\nThe effectiveness of the proposed control system is demonstrated through\nnumerical simulations and experimental results.",
    "published_date": "2016-02-13T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.04286v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.04265v4",
    "title": "Lasso Guarantees for Time Series Estimation Under Subgaussian Tails and $ β$-Mixing",
    "authors": [
      "Kam Chung Wong",
      "Zifan Li",
      "Ambuj Tewari"
    ],
    "author_ids": [],
    "abstract": "Many theoretical results on estimation of high dimensional time series\nrequire specifying an underlying data generating model (DGM). Instead, along\nthe footsteps of~\\cite{wong2017lasso}, this paper relies only on (strict)\nstationarity and $ \\beta $-mixing condition to establish consistency of lasso\nwhen data comes from a $\\beta$-mixing process with marginals having subgaussian\ntails. Because of the general assumptions, the data can come from DGMs\ndifferent than standard time series models such as VAR or ARCH. When the true\nDGM is not VAR, the lasso estimates correspond to those of the best linear\npredictors using the past observations. We establish non-asymptotic\ninequalities for estimation and prediction errors of the lasso estimates.\nTogether with~\\cite{wong2017lasso}, we provide lasso guarantees that cover full\nspectrum of the parameters in specifications of $ \\beta $-mixing subgaussian\ntime series. Applications of these results potentially extend to non-Gaussian,\nnon-Markovian and non-linear times series models as the examples we provide\ndemonstrate. In order to prove our results, we derive a novel Hanson-Wright\ntype concentration inequality for $\\beta$-mixing subgaussian random vectors\nthat may be of independent interest.",
    "published_date": "2016-02-12T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.04265v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.03903v2",
    "title": "Wavelet-Based Semantic Features for Hyperspectral Signature Discrimination",
    "authors": [
      "Siwei Feng",
      "Yuki Itoh",
      "Mario Parente",
      "Marco F. Duarte"
    ],
    "author_ids": [],
    "abstract": "Hyperspectral signature classification is a quantitative analysis approach\nfor hyperspectral imagery which performs detection and classification of the\nconstituent materials at the pixel level in the scene. The classification\nprocedure can be operated directly on hyperspectral data or performed by using\nsome features extracted from the corresponding hyperspectral signatures\ncontaining information like the signature's energy or shape. In this paper, we\ndescribe a technique that applies non-homogeneous hidden Markov chain (NHMC)\nmodels to hyperspectral signature classification. The basic idea is to use\nstatistical models (such as NHMC) to characterize wavelet coefficients which\ncapture the spectrum semantics (i.e., structural information) at multiple\nlevels. Experimental results show that the approach based on NHMC models can\noutperform existing approaches relevant in classification tasks.",
    "published_date": "2016-02-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.03903v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.03739v1",
    "title": "Qualities and Inequalities in Online Social Networks through the Lens of the Generalized Friendship Paradox",
    "authors": [
      "Naghmeh Momeni",
      "Michael Rabbat"
    ],
    "author_ids": [],
    "abstract": "The friendship paradox is the phenomenon that in social networks, people on\naverage have fewer friends than their friends do. The generalized friendship\nparadox is an extension to attributes other than the number of friends. The\nfriendship paradox and its generalized version have gathered recent attention\ndue to the information they provide about network structure and local\ninequalities. In this paper, we propose several measures of nodal qualities\nwhich capture different aspects of their activities and influence in online\nsocial networks. Using these measures we analyse the prevalence of the\ngeneralized friendship paradox over Twitter and we report high levels of\nprevalence (up to over 90\\% of nodes). We contend that this prevalence of the\nfriendship paradox and its generalized version arise because of the\nhierarchical nature of the connections in the network. This hierarchy is nested\nas opposed to being star-like. We conclude that these paradoxes are collective\nphenomena not created merely by a minority of well-connected or high-attribute\nnodes. Moreover, our results show that a large fraction of individuals can\nexperience the generalized friendship paradox even in the absence of a\nsignificant correlation between degrees and attributes.",
    "published_date": "2016-02-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.03739v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.03647v2",
    "title": "On the Difficulty of Selecting Ising Models with Approximate Recovery",
    "authors": [
      "Jonathan Scarlett",
      "Volkan Cevher"
    ],
    "author_ids": [],
    "abstract": "In this paper, we consider the problem of estimating the underlying graph\nassociated with an Ising model given a number of independent and identically\ndistributed samples. We adopt an \\emph{approximate recovery} criterion that\nallows for a number of missed edges or incorrectly-included edges, in contrast\nwith the widely-studied exact recovery problem. Our main results provide\ninformation-theoretic lower bounds on the sample complexity for graph classes\nimposing constraints on the number of edges, maximal degree, and other\nproperties. We identify a broad range of scenarios where, either up to constant\nfactors or logarithmic factors, our lower bounds match the best known lower\nbounds for the exact recovery criterion, several of which are known to be tight\nor near-tight. Hence, in these cases, approximate recovery has a similar\ndifficulty to exact recovery in the minimax sense.\n  Our bounds are obtained via a modification of Fano's inequality for handling\nthe approximate recovery criterion, along with suitably-designed ensembles of\ngraphs that can broadly be classed into two categories: (i) Those containing\ngraphs that contain several isolated edges or cliques and are thus difficult to\ndistinguish from the empty graph; (ii) Those containing graphs for which\ncertain groups of nodes are highly correlated, thus making it difficult to\ndetermine precisely which edges connect them. We support our theoretical\nresults on these ensembles with numerical experiments.",
    "published_date": "2016-02-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.03647v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.03275v3",
    "title": "Infinite Horizon Average Optimality of the N-network Queueing Model in the Halfin-Whitt Regime",
    "authors": [
      "Ari Arapostathis",
      "Guodong Pang"
    ],
    "author_ids": [],
    "abstract": "We study the infinite horizon optimal control problem for N-network queueing\nsystems, which consist of two customer classes and two server pools, under\naverage (ergodic) criteria in the Halfin-Whitt regime. We consider three\ncontrol objectives: 1) minimizing the queueing (and idleness) cost, 2)\nminimizing the queueing cost while imposing a constraint on idleness at each\nserver pool, and 3) minimizing the queueing cost while requiring fairness on\nidleness. The running costs can be any nonnegative convex functions having at\nmost polynomial growth.\n  For all three problems we establish asymptotic optimality, namely, the\nconvergence of the value functions of the diffusion-scaled state process to the\ncorresponding values of the controlled diffusion limit. We also present a\nsimple state-dependent priority scheduling policy under which the\ndiffusion-scaled state process is geometrically ergodic in the Halfin-Whitt\nregime, and some results on convergence of mean empirical measures which\nfacilitate the proofs.",
    "published_date": "2016-02-10T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY",
      "math.PR",
      "60K25, 68M20, 90B22, 90B36"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.03275v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.03256v1",
    "title": "Improved Eigenfeature Regularization for Face Identification",
    "authors": [
      "Bappaditya Mandal"
    ],
    "author_ids": [],
    "abstract": "In this work, we propose to divide each class (a person) into subclasses\nusing spatial partition trees which helps in better capturing the\nintra-personal variances arising from the appearances of the same individual.\nWe perform a comprehensive analysis on within-class and within-subclass\neigenspectrums of face images and propose a novel method of eigenspectrum\nmodeling which extracts discriminative features of faces from both\nwithin-subclass and total or between-subclass scatter matrices. Effective\nlow-dimensional face discriminative features are extracted for face recognition\n(FR) after performing discriminant evaluation in the entire eigenspace.\nExperimental results on popular face databases (AR, FERET) and the challenging\nunconstrained YouTube Face database show the superiority of our proposed\napproach on all three databases.",
    "published_date": "2016-02-10T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.03256v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.02850v1",
    "title": "Toward Optimal Feature Selection in Naive Bayes for Text Categorization",
    "authors": [
      "Bo Tang",
      "Steven Kay",
      "Haibo He"
    ],
    "author_ids": [],
    "abstract": "Automated feature selection is important for text categorization to reduce\nthe feature size and to speed up the learning process of classifiers. In this\npaper, we present a novel and efficient feature selection framework based on\nthe Information Theory, which aims to rank the features with their\ndiscriminative capacity for classification. We first revisit two information\nmeasures: Kullback-Leibler divergence and Jeffreys divergence for binary\nhypothesis testing, and analyze their asymptotic properties relating to type I\nand type II errors of a Bayesian classifier. We then introduce a new divergence\nmeasure, called Jeffreys-Multi-Hypothesis (JMH) divergence, to measure\nmulti-distribution divergence for multi-class classification. Based on the\nJMH-divergence, we develop two efficient feature selection methods, termed\nmaximum discrimination ($MD$) and $MD-\\chi^2$ methods, for text categorization.\nThe promising results of extensive experiments demonstrate the effectiveness of\nthe proposed approaches.",
    "published_date": "2016-02-09T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.02850v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.02800v1",
    "title": "Primary frequency regulation with load-side participation: stability and optimality",
    "authors": [
      "Andreas Kasis",
      "Eoin Devane",
      "Ioannis Lestas"
    ],
    "author_ids": [],
    "abstract": "We present a method to design distributed generation and demand control\nschemes for primary frequency regulation in power networks that guarantee\nasymptotic stability and ensure fairness of allocation. We impose a passivity\ncondition on net power supply variables and provide explicit steady state\nconditions on a general class of generation and demand control dynamics that\nensure convergence of solutions to equilibria that solve an appropriately\nconstructed network optimization problem. We also show that the inclusion of\ncontrollable demand results in a drop in steady state frequency deviations. We\ndiscuss how various classes of dynamics used in recent studies fit within our\nframework and show that this allows for less conservative stability and\noptimality conditions. We illustrate our results with simulations on the IEEE\n68 bus system and observe that both static and dynamic demand response schemes\nthat fit within our framework offer improved transient and steady state\nbehavior compared with control of generation alone. The dynamic scheme is also\nseen to enhance the robustness of the system to time-delays.",
    "published_date": "2016-02-08T00:00:00",
    "year": 2016,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.02800v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.01237v2",
    "title": "How Far are We from Solving Pedestrian Detection?",
    "authors": [
      "Shanshan Zhang",
      "Rodrigo Benenson",
      "Mohamed Omran",
      "Jan Hosang",
      "Bernt Schiele"
    ],
    "author_ids": [],
    "abstract": "Encouraged by the recent progress in pedestrian detection, we investigate the\ngap between current state-of-the-art methods and the \"perfect single frame\ndetector\". We enable our analysis by creating a human baseline for pedestrian\ndetection (over the Caltech dataset), and by manually clustering the recurrent\nerrors of a top detector. Our results characterize both localization and\nbackground-versus-foreground errors. To address localization errors we study\nthe impact of training annotation noise on the detector performance, and show\nthat we can improve even with a small portion of sanitized training data. To\naddress background/foreground discrimination, we study convnets for pedestrian\ndetection, and discuss which factors affect their performance. Other than our\nin-depth analysis, we report top performance on the Caltech dataset, and\nprovide a new sanitized set of training and test annotations.",
    "published_date": "2016-02-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.01237v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.01197v1",
    "title": "Discriminative Sparse Neighbor Approximation for Imbalanced Learning",
    "authors": [
      "Chen Huang",
      "Chen Change Loy",
      "Xiaoou Tang"
    ],
    "author_ids": [],
    "abstract": "Data imbalance is common in many vision tasks where one or more classes are\nrare. Without addressing this issue conventional methods tend to be biased\ntoward the majority class with poor predictive accuracy for the minority class.\nThese methods further deteriorate on small, imbalanced data that has a large\ndegree of class overlap. In this study, we propose a novel discriminative\nsparse neighbor approximation (DSNA) method to ameliorate the effect of\nclass-imbalance during prediction. Specifically, given a test sample, we first\ntraverse it through a cost-sensitive decision forest to collect a good subset\nof training examples in its local neighborhood. Then we generate from this\nsubset several class-discriminating but overlapping clusters and model each as\nan affine subspace. From these subspaces, the proposed DSNA iteratively seeks\nan optimal approximation of the test sample and outputs an unbiased prediction.\nWe show that our method not only effectively mitigates the imbalance issue, but\nalso allows the prediction to extrapolate to unseen data. The latter capability\nis crucial for achieving accurate prediction on small dataset with limited\nsamples. The proposed imbalanced learning method can be applied to both\nclassification and regression tasks at a wide range of imbalance levels. It\nsignificantly outperforms the state-of-the-art methods that do not possess an\nimbalance handling mechanism, and is found to perform comparably or even better\nthan recent deep learning methods by using hand-crafted features only.",
    "published_date": "2016-02-03T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.01197v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.00795v1",
    "title": "Gender, Productivity, and Prestige in Computer Science Faculty Hiring Networks",
    "authors": [
      "Samuel F. Way",
      "Daniel B. Larremore",
      "Aaron Clauset"
    ],
    "author_ids": [],
    "abstract": "Women are dramatically underrepresented in computer science at all levels in\nacademia and account for just 15% of tenure-track faculty. Understanding the\ncauses of this gender imbalance would inform both policies intended to rectify\nit and employment decisions by departments and individuals. Progress in this\ndirection, however, is complicated by the complexity and decentralized nature\nof faculty hiring and the non-independence of hires. Using comprehensive data\non both hiring outcomes and scholarly productivity for 2659 tenure-track\nfaculty across 205 Ph.D.-granting departments in North America, we investigate\nthe multi-dimensional nature of gender inequality in computer science faculty\nhiring through a network model of the hiring process. Overall, we find that\nhiring outcomes are most directly affected by (i) the relative prestige between\nhiring and placing institutions and (ii) the scholarly productivity of the\ncandidates. After including these, and other features, the addition of gender\ndid not significantly reduce modeling error. However, gender differences do\nexist, e.g., in scholarly productivity, postdoctoral training rates, and in\ncareer movements up the rankings of universities, suggesting that the effects\nof gender are indirectly incorporated into hiring decisions through gender's\ncovariates. Furthermore, we find evidence that more highly ranked departments\nrecruit female faculty at higher than expected rates, which appears to inhibit\nsimilar efforts by lower ranked departments. These findings illustrate the\nsubtle nature of gender inequality in faculty hiring networks and provide new\ninsights to the underrepresentation of women in computer science.",
    "published_date": "2016-02-02T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.CY",
      "physics.soc-ph",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.00795v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.00310v2",
    "title": "Learning a low-rank shared dictionary for object classification",
    "authors": [
      "Tiep H. Vu",
      "Vishal Monga"
    ],
    "author_ids": [],
    "abstract": "Despite the fact that different objects possess distinct class-specific\nfeatures, they also usually share common patterns. Inspired by this\nobservation, we propose a novel method to explicitly and simultaneously learn a\nset of common patterns as well as class-specific features for classification.\nOur dictionary learning framework is hence characterized by both a shared\ndictionary and particular (class-specific) dictionaries. For the shared\ndictionary, we enforce a low-rank constraint, i.e. claim that its spanning\nsubspace should have low dimension and the coefficients corresponding to this\ndictionary should be similar. For the particular dictionaries, we impose on\nthem the well-known constraints stated in the Fisher discrimination dictionary\nlearning (FDDL). Further, we propose a new fast and accurate algorithm to solve\nthe sparse coding problems in the learning step, accelerating its convergence.\nThe said algorithm could also be applied to FDDL and its extensions.\nExperimental results on widely used image databases establish the advantages of\nour method over state-of-the-art dictionary learning methods.",
    "published_date": "2016-01-31T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.00310v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1602.00296v1",
    "title": "A Factorization Algorithm for G-Algebras and Applications",
    "authors": [
      "Albert Heinle",
      "Viktor Levandovskyy"
    ],
    "author_ids": [],
    "abstract": "It has been recently discovered by Bell, Heinle and Levandovskyy that a large\nclass of algebras, including the ubiquitous $G$-algebras, are finite\nfactorization domains (FFD for short).\n  Utilizing this result, we contribute an algorithm to find all distinct\nfactorizations of a given element $f \\in \\mathcal{G}$, where $\\mathcal{G}$ is\nany $G$-algebra, with minor assumptions on the underlying field.\n  Moreover, the property of being an FFD, in combination with the factorization\nalgorithm, enables us to propose an analogous description of the factorized\nGr\\\"obner basis algorithm for $G$-algebras. This algorithm is useful for\nvarious applications, e.g. in analysis of solution spaces of systems of linear\npartial functional equations with polynomial coefficients, coming from\n$\\mathcal{G}$. Additionally, it is possible to include inequality constraints\nfor ideals in the input.",
    "published_date": "2016-01-31T00:00:00",
    "year": 2016,
    "categories": [
      "math.RA",
      "cs.SC",
      "math.OA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.00296v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.00233v1",
    "title": "Characterisations of Matrix and Operator-Valued $Φ$-Entropies, and Operator Efron-Stein Inequalities",
    "authors": [
      "Hao-Chung Cheng",
      "Min-Hsiu Hsieh"
    ],
    "author_ids": [],
    "abstract": "We derive new characterisations of the matrix $\\mathrm{\\Phi}$-entropy\nfunctionals introduced in [Electron.~J.~Probab., 19(20): 1--30, 2014]. Notably,\nall known equivalent characterisations of the classical $\\Phi$-entropies have\ntheir matrix correspondences. Next, we propose an operator-valued\ngeneralisation of the matrix $\\Phi$-entropy functionals, and prove their\nsubadditivity under L\\\"owner partial ordering. Our results demonstrate that the\nsubadditivity of operator-valued $\\Phi$-entropies is equivalent to the\nconvexity of various related functions. This result can be used to demonstrate\nan interesting result in quantum information theory: the matrix $\\Phi$-entropy\nof a quantum ensemble is monotone under unital quantum channels. Finally, we\nderive the operator Efron-Stein inequality to bound the operator-valued\nvariance of a random matrix.",
    "published_date": "2016-01-31T00:00:00",
    "year": 2016,
    "categories": [
      "math-ph",
      "cs.IT",
      "math.IT",
      "math.MP",
      "math.PR",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.00233v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1602.00110v1",
    "title": "DNA-inspired online behavioral modeling and its application to spambot detection",
    "authors": [
      "Stefano Cresci",
      "Roberto Di Pietro",
      "Marinella Petrocchi",
      "Angelo Spognardi",
      "Maurizio Tesconi"
    ],
    "author_ids": [],
    "abstract": "We propose a strikingly novel, simple, and effective approach to model online\nuser behavior: we extract and analyze digital DNA sequences from user online\nactions and we use Twitter as a benchmark to test our proposal. We obtain an\nincisive and compact DNA-inspired characterization of user actions. Then, we\napply standard DNA analysis techniques to discriminate between genuine and\nspambot accounts on Twitter. An experimental campaign supports our proposal,\nshowing its effectiveness and viability. To the best of our knowledge, we are\nthe first ones to identify and adapt DNA-inspired techniques to online user\nbehavioral modeling. While Twitter spambot detection is a specific use case on\na specific social media, our proposed methodology is platform and technology\nagnostic, hence paving the way for diverse behavioral characterization tasks.",
    "published_date": "2016-01-30T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI",
      "cs.CR",
      "cs.LG",
      "H.2.8.d; I.2.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.00110v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.08237v2",
    "title": "The omega-inequality problem for concatenation hierarchies of star-free languages",
    "authors": [
      "J. Almeida",
      "O. Klíma",
      "M. Kunc"
    ],
    "author_ids": [],
    "abstract": "The problem considered in this paper is whether an inequality of omega-terms\nis valid in a given level of a concatenation hierarchy of star-free languages.\nThe main result shows that this problem is decidable for all (integer and half)\nlevels of the Straubing-Th\\'erien hierarchy.",
    "published_date": "2016-01-29T00:00:00",
    "year": 2016,
    "categories": [
      "math.GR",
      "cs.FL",
      "Primary 20M05, 20M07, Secondary 20M35, 68Q70"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.08237v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.07498v2",
    "title": "Equivalence of additive-combinatorial linear inequalities for Shannon entropy and differential entropy",
    "authors": [
      "Ashok Vardhan Makkuva",
      "Yihong Wu"
    ],
    "author_ids": [],
    "abstract": "This paper addresses the correspondence between linear inequalities of\nShannon entropy and differential entropy for sums of independent group-valued\nrandom variables. We show that any balanced (with the sum of coefficients being\nzero) linear inequality of Shannon entropy holds if and only if its\ndifferential entropy counterpart also holds; moreover, any linear inequality\nfor differential entropy must be balanced. In particular, our result shows that\nrecently proved differential entropy inequalities by Kontoyiannis and Madiman\n\\cite{KM14} can be deduced from their discrete counterparts due to Tao\n\\cite{Tao10} in a unified manner. Generalizations to certain abelian groups are\nalso obtained.\n  Our proof of extending inequalities of Shannon entropy to differential\nentropy relies on a result of R\\'enyi \\cite{Renyi59} which relates the Shannon\nentropy of a finely discretized random variable to its differential entropy and\nalso helps in establishing the entropy of the sum of quantized random variables\nis asymptotically equal to that of the quantized sum; the converse uses the\nasymptotics of the differential entropy of convolutions with weak additive\nnoise.",
    "published_date": "2016-01-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.07498v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.07341v1",
    "title": "Providing Probabilistic Robustness Guarantee for Crowdsensing",
    "authors": [
      "Yuben Qu",
      "Shaojie Tang",
      "Chao Dong",
      "Peng Li",
      "Song Guo",
      "Chang Tian"
    ],
    "author_ids": [],
    "abstract": "Due to its flexible and pervasive sensing ability, crowdsensing has been\nextensively studied recently in research communities. However, the fundamental\nissue of how to meet the requirement of sensing robustness in crowdsensing\nremains largely unsolved. Specifically, from the task owner's perspective, how\nto minimize the total payment in crowdsensing while guaranteeing the sensing\ndata quality is a critical issue to be resolved. We elegantly model the\nrobustness requirement over sensing data quality as chance constraints, and\ninvestigate both hard and soft chance constraints for different crowdsensing\napplications. For the former, we reformulate the problem through Boole's\nInequality, and explore the optimal value gap between the original problem and\nthe reformulated problem. For the latter, we study a serial of a general\npayment minimization problem, and propose a binary search algorithm that\nachieves both feasibility and low payment. The performance gap between our\nsolution and the optimal solution is also theoretically analyzed. Extensive\nsimulations validate our theoretical analysis.",
    "published_date": "2016-01-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.GT",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.07341v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.07325v1",
    "title": "DoF Analysis of the MIMO Broadcast Channel with Alternating/Hybrid CSIT",
    "authors": [
      "Borzoo Rassouli",
      "Chenxi Hao",
      "Bruno Clerckx"
    ],
    "author_ids": [],
    "abstract": "We consider a $K$-user multiple-input single-output (MISO) broadcast channel\n(BC) where the channel state information (CSI) of user $i(i=1,2,\\ldots,K)$ may\nbe instantaneously perfect (P), delayed (D) or not known (N) at the transmitter\nwith probabilities $\\lambda_P^i$, $\\lambda_D^i$ and $\\lambda_N^i$,\nrespectively. In this setting, according to the three possible CSIT for each\nuser, knowledge of the joint CSIT of the $K$ users could have at most $3^K$\nstates. In this paper, given the marginal probabilities of CSIT (i.e.,\n$\\lambda_P^i$, $\\lambda_D^i$ and $\\lambda_N^i$), we derive an outer bound for\nthe DoF region of the $K$-user MISO BC. Subsequently, we tighten this outer\nbound by taking into account a set of inequalities that capture some of the\n$3^K$ states of the joint CSIT. One of the consequences of this set of\ninequalities is that for $K\\geq3$, it is shown that the DoF region is not\ncompletely characterized by the marginal probabilities in contrast to the\ntwo-user case. Afterwards, the tightness of these bounds are investigated\nthrough the discussion on the achievability. Finally, a two user MIMO BC having\nCSIT among P and N is considered in which an outer bound for the DoF region is\nprovided and it is shown that in some scenarios it is tight.",
    "published_date": "2016-01-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.07325v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.07285v1",
    "title": "Fairness in Communication for Omniscience",
    "authors": [
      "Ni Ding",
      "Chung Chan",
      "Qiaoqiao Zhou",
      "Rodney A. Kennedy",
      "Parastoo Sadeghi"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of how to fairly distribute the minimum sum-rate\namong the users in communication for omniscience (CO). We formulate a problem\nof minimizing a weighted quadratic function over a submodular base polyhedron\nwhich contains all achievable rate vectors, or transmission strategies, for CO\nthat have the same sum-rate. By solving it, we can determine the rate vector\nthat optimizes the Jain's fairness measure, a more commonly used fairness index\nthan the Shapley value in communications engineering. We show that the\noptimizer is a lexicographically optimal (lex-optimal) base and can be\ndetermined by a decomposition algorithm (DA) that is based on submodular\nfunction minimization (SFM) algorithm and completes in strongly polynomial\ntime. We prove that the lex-optimal minimum sum-rate strategy for CO can be\ndetermined by finding the lex-optimal base in each user subset in the\nfundamental partition and the complexity can be reduced accordingly.",
    "published_date": "2016-01-27T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.07285v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.07200v1",
    "title": "Attention Inequality in Social Media",
    "authors": [
      "Linhong Zhu",
      "Kristina Lerman"
    ],
    "author_ids": [],
    "abstract": "Social media can be viewed as a social system where the currency is\nattention. People post content and interact with others to attract attention\nand gain new followers. In this paper, we examine the distribution of attention\nacross a large sample of users of a popular social media site Twitter. Through\nempirical analysis of these data we conclude that attention is very unequally\ndistributed: the top 20\\% of Twitter users own more than 96\\% of all followers,\n93\\% of the retweets, and 93\\% of the mentions. We investigate the mechanisms\nthat lead to attention inequality and find that it results from the\n\"rich-get-richer\" and \"poor-get-poorer\" dynamics of attention diffusion.\nNamely, users who are \"rich\" in attention, because they are often mentioned and\nretweeted, are more likely to gain new followers, while those who are \"poor\" in\nattention are likely to lose followers. We develop a phenomenological model\nthat quantifies attention diffusion and network dynamics, and solve it to study\nhow attention inequality grows over time in a dynamic environment of social\nmedia.",
    "published_date": "2016-01-26T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.07200v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.06555v3",
    "title": "On Renyi Entropy Power Inequalities",
    "authors": [
      "Eshed Ram",
      "Igal Sason"
    ],
    "author_ids": [],
    "abstract": "This paper gives improved R\\'{e}nyi entropy power inequalities (R-EPIs).\nConsider a sum $S_n = \\sum_{k=1}^n X_k$ of $n$ independent continuous random\nvectors taking values on $\\mathbb{R}^d$, and let $\\alpha \\in [1, \\infty]$. An\nR-EPI provides a lower bound on the order-$\\alpha$ R\\'enyi entropy power of\n$S_n$ that, up to a multiplicative constant (which may depend in general on $n,\n\\alpha, d$), is equal to the sum of the order-$\\alpha$ R\\'enyi entropy powers\nof the $n$ random vectors $\\{X_k\\}_{k=1}^n$. For $\\alpha=1$, the R-EPI\ncoincides with the well-known entropy power inequality by Shannon. The first\nimproved R-EPI is obtained by tightening the recent R-EPI by Bobkov and\nChistyakov which relies on the sharpened Young's inequality. A further\nimprovement of the R-EPI also relies on convex optimization and results on\nrank-one modification of a real-valued diagonal matrix.",
    "published_date": "2016-01-25T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.06555v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.05764v1",
    "title": "A Confidence-Based Approach for Balancing Fairness and Accuracy",
    "authors": [
      "Benjamin Fish",
      "Jeremy Kun",
      "Ádám D. Lelkes"
    ],
    "author_ids": [],
    "abstract": "We study three classical machine learning algorithms in the context of\nalgorithmic fairness: adaptive boosting, support vector machines, and logistic\nregression. Our goal is to maintain the high accuracy of these learning\nalgorithms while reducing the degree to which they discriminate against\nindividuals because of their membership in a protected group.\n  Our first contribution is a method for achieving fairness by shifting the\ndecision boundary for the protected group. The method is based on the theory of\nmargins for boosting. Our method performs comparably to or outperforms previous\nalgorithms in the fairness literature in terms of accuracy and low\ndiscrimination, while simultaneously allowing for a fast and transparent\nquantification of the trade-off between bias and error.\n  Our second contribution addresses the shortcomings of the bias-error\ntrade-off studied in most of the algorithmic fairness literature. We\ndemonstrate that even hopelessly naive modifications of a biased algorithm,\nwhich cannot be reasonably said to be fair, can still achieve low bias and high\naccuracy. To help to distinguish between these naive algorithms and more\nsensible algorithms we propose a new measure of fairness, called resilience to\nrandom bias (RRB). We demonstrate that RRB distinguishes well between our naive\nand sensible fairness algorithms. RRB together with bias and accuracy provides\na more complete picture of the fairness of an algorithm.",
    "published_date": "2016-01-21T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.05764v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.06439v1",
    "title": "Who Ordered This?: Exploiting Implicit User Tag Order Preferences for Personalized Image Tagging",
    "authors": [
      "Amandianeze O. Nwana",
      "Tsuhan Chen"
    ],
    "author_ids": [],
    "abstract": "What makes a person pick certain tags over others when tagging an image? Does\nthe order that a person presents tags for a given image follow an implicit bias\nthat is personal? Can these biases be used to improve existing automated image\ntagging systems? We show that tag ordering, which has been largely overlooked\nby the image tagging community, is an important cue in understanding user\ntagging behavior and can be used to improve auto-tagging systems. Inspired by\nthe assumption that people order their tags, we propose a new way of measuring\ntag preferences, and also propose a new personalized tagging objective function\nthat explicitly considers a user's preferred tag orderings. We also provide a\n(partially) greedy algorithm that produces good solutions to our new objective\nand under certain conditions produces an optimal solution. We validate our\nmethod on a subset of Flickr images that spans 5000 users, over 5200 tags, and\nover 90,000 images. Our experiments show that exploiting personalized tag\norders improves the average performance of state-of-art approaches both on\nper-image and per-user bases.",
    "published_date": "2016-01-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.IR",
      "cs.HC",
      "cs.MM",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.06439v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.05150v2",
    "title": "Factors in Finetuning Deep Model for object detection",
    "authors": [
      "Wanli Ouyang",
      "Xiaogang Wang",
      "Cong Zhang",
      "Xiaokang Yang"
    ],
    "author_ids": [],
    "abstract": "Finetuning from a pretrained deep model is found to yield state-of-the-art\nperformance for many vision tasks. This paper investigates many factors that\ninfluence the performance in finetuning for object detection. There is a\nlong-tailed distribution of sample numbers for classes in object detection. Our\nanalysis and empirical results show that classes with more samples have higher\nimpact on the feature learning. And it is better to make the sample number more\nuniform across classes. Generic object detection can be considered as multiple\nequally important tasks. Detection of each class is a task. These classes/tasks\nhave their individuality in discriminative visual appearance representation.\nTaking this individuality into account, we cluster objects into visually\nsimilar class groups and learn deep representations for these groups\nseparately. A hierarchical feature learning scheme is proposed. In this scheme,\nthe knowledge from the group with large number of classes is transferred for\nlearning features in its sub-groups. Finetuned on the GoogLeNet model,\nexperimental results show 4.7% absolute mAP improvement of our approach on the\nImageNet object detection dataset without increasing much computational cost at\nthe testing stage.",
    "published_date": "2016-01-20T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.05150v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.04890v2",
    "title": "Women Through the Glass Ceiling: Gender Asymmetries in Wikipedia",
    "authors": [
      "Claudia Wagner",
      "Eduardo Graells-Garrido",
      "David Garcia",
      "Filippo Menczer"
    ],
    "author_ids": [],
    "abstract": "Contributing to the writing of history has never been as easy as it is today\nthanks to Wikipedia, a community-created encyclopedia that aims to document the\nworld's knowledge from a neutral point of view. Though everyone can participate\nit is well known that the editor community has a narrow diversity, with a\nmajority of white male editors. While this participatory \\emph{gender gap} has\nbeen studied extensively in the literature, this work sets out to \\emph{assess\npotential gender inequalities in Wikipedia articles} along different\ndimensions: notability, topical focus, linguistic bias, structural properties,\nand meta-data presentation.\n  We find that (i) women in Wikipedia are more notable than men, which we\ninterpret as the outcome of a subtle glass ceiling effect; (ii) family-,\ngender-, and relationship-related topics are more present in biographies about\nwomen; (iii) linguistic bias manifests in Wikipedia since abstract terms tend\nto be used to describe positive aspects in the biographies of men and negative\naspects in the biographies of women; and (iv) there are structural differences\nin terms of meta-data and hyperlinks, which have consequences for\ninformation-seeking activities. While some differences are expected, due to\nhistorical and social contexts, other differences are attributable to Wikipedia\neditors. The implications of such differences are discussed having Wikipedia\ncontribution policies in mind. We hope that the present work will contribute to\nincreased awareness about, first, gender issues in the content of Wikipedia,\nand second, the different levels on which gender biases can manifest on the\nWeb.",
    "published_date": "2016-01-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.04890v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.04802v3",
    "title": "Interpolation synthesis for quadratic polynomial inequalities and combination with EUF",
    "authors": [
      "Ting Gan",
      "Liyun Dai",
      "Bican Xia",
      "Naijun Zhan",
      "Deepak Kapur",
      "Mingshuai Chen"
    ],
    "author_ids": [],
    "abstract": "An algorithm for generating interpolants for formulas which are conjunctions\nof quadratic polynomial inequalities (both strict and nonstrict) is proposed.\nThe algorithm is based on a key observation that quadratic polynomial\ninequalities can be linearized if they are concave. A generalization of\nMotzkin's transposition theorem is proved, which is used to generate an\ninterpolant between two mutually contradictory conjunctions of polynomial\ninequalities, using semi-definite programming in time complexity\n$\\mathcal{O}(n^3+nm))$, where $n$ is the number of variables and $m$ is the\nnumber of inequalities. Using the framework proposed by \\cite{SSLMCS2008} for\ncombining interpolants for a combination of quantifier-free theories which have\ntheir own interpolation algorithms, a combination algorithm is given for the\ncombined theory of concave quadratic polynomial inequalities and the equality\ntheory over uninterpreted functions symbols (\\textit{EUF}). The proposed\napproach is applicable to all existing abstract domains like \\emph{octagon},\n\\emph{polyhedra}, \\emph{ellipsoid} and so on, therefore it can be used to\nimprove the scalability of existing verification techniques for programs and\nhybrid systems. In addition, we also discuss how to extend our approach to\nformulas beyond concave quadratic polynomials using Gr\\\"{o}bner basis.",
    "published_date": "2016-01-19T00:00:00",
    "year": 2016,
    "categories": [
      "cs.LO",
      "D.2.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.04802v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.03061v2",
    "title": "A Delay Efficient Multiclass Packet Scheduler for Heterogeneous M2M Uplink",
    "authors": [
      "Akshay Kumar",
      "Ahmed Abdelhadi",
      "Charles Clancy"
    ],
    "author_ids": [],
    "abstract": "The sensory traffic in Machine-to-Machine (M2M) communications has fairly\nheterogeneous service delay requirements. Therefore, we study the\ndelay-performance of a heterogeneous M2M uplink from the sensors to a M2M\napplication server (AS) via M2M aggregators (MA). We classify the heterogeneous\nM2M traffic aggregated at AS into multiple Periodic Update (PU) and Event\nDriven (ED) classes. The PU arrivals are periodic and need to be processed by a\nprespecified firm service deadline whereas the ED arrivals are random with firm\nor soft real-time or non real-time service requirements. We use step and\nsigmoidal functions to represent the service utility for PU and ED packets\nrespectively. We propose a delay efficient multiclass packet scheduling\nheuristic that aims to maximize a proportionally fair system utility metric.\nSpecifically, the proposed scheduler prioritizes service to ED data while\nensuring that the PU packets meet their service deadline. It also minimizes\nsuccessive PU failures for critical applications by penalizing their\noccurrences. Furthermore, the failed PU packets are immediately cleared from\nthe system so as to reduce network congestion. Using extensive simulations, we\nshow that the proposed scheduler outperforms popular packet schedulers and the\nperformance gap increases with heterogeneity in latency requirements and with\ngreater penalty for PU failures in critical applications.",
    "published_date": "2016-01-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.NI",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.03061v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.03022v2",
    "title": "Riemannian geometry applied to detection of respiratory states from EEG signals: the basis for a brain-ventilator interface",
    "authors": [
      "X Navarro-Sune",
      "A. L. Hudson",
      "F. De Vico Fallani",
      "J. Martinerie",
      "A. Witon",
      "P. Pouget",
      "M. Raux",
      "T. Similowski",
      "M. Chavez"
    ],
    "author_ids": [],
    "abstract": "During mechanical ventilation, patient-ventilator disharmony is frequently\nobserved and may result in increased breathing effort, compromising the\npatient's comfort and recovery. This circumstance requires clinical\nintervention and becomes challenging when verbal communication is difficult. In\nthis work, we propose a brain computer interface (BCI) to automatically and\nnon-invasively detect patient-ventilator disharmony from\nelectroencephalographic (EEG) signals: a brain-ventilator interface (BVI). Our\nframework exploits the cortical activation provoked by the inspiratory\ncompensation when the subject and the ventilator are desynchronized. Use of a\none-class approach and Riemannian geometry of EEG covariance matrices allows\neffective classification of respiratory states. The BVI is validated on nine\nhealthy subjects that performed different respiratory tasks that mimic a\npatient-ventilator disharmony. Classification performances, in terms of areas\nunder ROC curves, are significantly improved using EEG signals compared to\ndetection based on air flow. Reduction in the number of electrodes that can\nachieve discrimination can often be desirable (e.g. for portable BCI systems).\nBy using an iterative channel selection technique, the Common Highest Order\nRanking (CHOrRa), we find that a reduced set of electrodes (n=6) can slightly\nimprove for an intra-subject configuration, and it still provides fairly good\nperformances for a general inter-subject setting. Results support the\ndiscriminant capacity of our approach to identify anomalous respiratory states,\nby learning from a training set containing only normal respiratory epochs. The\nproposed framework opens the door to brain-ventilator interfaces for monitoring\npatient's breathing comfort and adapting ventilator parameters to patient\nrespiratory needs.",
    "published_date": "2016-01-12T00:00:00",
    "year": 2016,
    "categories": [
      "cs.HC",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.03022v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1601.02553v2",
    "title": "Environmental Noise Embeddings for Robust Speech Recognition",
    "authors": [
      "Suyoun Kim",
      "Bhiksha Raj",
      "Ian Lane"
    ],
    "author_ids": [],
    "abstract": "We propose a novel deep neural network architecture for speech recognition\nthat explicitly employs knowledge of the background environmental noise within\na deep neural network acoustic model. A deep neural network is used to predict\nthe acoustic environment in which the system in being used. The discriminative\nembedding generated at the bottleneck layer of this network is then\nconcatenated with traditional acoustic features as input to a deep neural\nnetwork acoustic model. Through a series of experiments on Resource Management,\nCHiME-3 task, and Aurora4, we show that the proposed approach significantly\nimproves speech recognition accuracy in noisy and highly reverberant\nenvironments, outperforming multi-condition training, noise-aware training,\ni-vector framework, and multi-task learning on both in-domain noise and unseen\nnoise.",
    "published_date": "2016-01-11T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.02553v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.02093v2",
    "title": "Group Invariant Deep Representations for Image Instance Retrieval",
    "authors": [
      "Olivier Morère",
      "Antoine Veillard",
      "Jie Lin",
      "Julie Petta",
      "Vijay Chandrasekhar",
      "Tomaso Poggio"
    ],
    "author_ids": [],
    "abstract": "Most image instance retrieval pipelines are based on comparison of vectors\nknown as global image descriptors between a query image and the database\nimages. Due to their success in large scale image classification,\nrepresentations extracted from Convolutional Neural Networks (CNN) are quickly\ngaining ground on Fisher Vectors (FVs) as state-of-the-art global descriptors\nfor image instance retrieval. While CNN-based descriptors are generally\nremarked for good retrieval performance at lower bitrates, they nevertheless\npresent a number of drawbacks including the lack of robustness to common object\ntransformations such as rotations compared with their interest point based FV\ncounterparts.\n  In this paper, we propose a method for computing invariant global descriptors\nfrom CNNs. Our method implements a recently proposed mathematical theory for\ninvariance in a sensory cortex modeled as a feedforward neural network. The\nresulting global descriptors can be made invariant to multiple arbitrary\ntransformation groups while retaining good discriminativeness.\n  Based on a thorough empirical evaluation using several publicly available\ndatasets, we show that our method is able to significantly and consistently\nimprove retrieval results every time a new type of invariance is incorporated.\nWe also show that our method which has few parameters is not prone to\noverfitting: improvements generalize well across datasets with different\nproperties with regard to invariances. Finally, we show that our descriptors\nare able to compare favourably to other state-of-the-art compact descriptors in\nsimilar bitranges, exceeding the highest retrieval results reported in the\nliterature on some datasets. A dedicated dimensionality reduction step\n--quantization or hashing-- may be able to further improve the competitiveness\nof the descriptors.",
    "published_date": "2016-01-09T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.02093v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.01944v1",
    "title": "Nonparametric semi-supervised learning of class proportions",
    "authors": [
      "Shantanu Jain",
      "Martha White",
      "Michael W. Trosset",
      "Predrag Radivojac"
    ],
    "author_ids": [],
    "abstract": "The problem of developing binary classifiers from positive and unlabeled data\nis often encountered in machine learning. A common requirement in this setting\nis to approximate posterior probabilities of positive and negative classes for\na previously unseen data point. This problem can be decomposed into two steps:\n(i) the development of accurate predictors that discriminate between positive\nand unlabeled data, and (ii) the accurate estimation of the prior probabilities\nof positive and negative examples. In this work we primarily focus on the\nlatter subproblem. We study nonparametric class prior estimation and formulate\nthis problem as an estimation of mixing proportions in two-component mixture\nmodels, given a sample from one of the components and another sample from the\nmixture itself. We show that estimation of mixing proportions is generally\nill-defined and propose a canonical form to obtain identifiability while\nmaintaining the flexibility to model any distribution. We use insights from\nthis theory to elucidate the optimization surface of the class priors and\npropose an algorithm for estimating them. To address the problems of\nhigh-dimensional density estimation, we provide practical transformations to\nlow-dimensional spaces that preserve class priors. Finally, we demonstrate the\nefficacy of our method on univariate and multivariate data.",
    "published_date": "2016-01-08T00:00:00",
    "year": 2016,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.01944v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1601.01085v1",
    "title": "Incorporating Structural Alignment Biases into an Attentional Neural Translation Model",
    "authors": [
      "Trevor Cohn",
      "Cong Duy Vu Hoang",
      "Ekaterina Vymolova",
      "Kaisheng Yao",
      "Chris Dyer",
      "Gholamreza Haffari"
    ],
    "author_ids": [],
    "abstract": "Neural encoder-decoder models of machine translation have achieved impressive\nresults, rivalling traditional translation models. However their modelling\nformulation is overly simplistic, and omits several key inductive biases built\ninto traditional models. In this paper we extend the attentional neural\ntranslation model to include structural biases from word based alignment\nmodels, including positional bias, Markov conditioning, fertility and agreement\nover translation directions. We show improvements over a baseline attentional\nmodel and standard phrase-based model over several language pairs, evaluating\non difficult languages in a low resource setting.",
    "published_date": "2016-01-06T00:00:00",
    "year": 2016,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1601.01085v1",
    "is_ai_related": true
  }
]