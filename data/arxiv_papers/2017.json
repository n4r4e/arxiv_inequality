[
  {
    "id": "http://arxiv.org/abs/1801.00070v1",
    "title": "Sum of squares certificates for stability of planar, homogeneous, and switched systems",
    "authors": [
      "Amir Ali Ahmadi",
      "Pablo A. Parrilo"
    ],
    "author_ids": [],
    "abstract": "We show that existence of a global polynomial Lyapunov function for a\nhomogeneous polynomial vector field or a planar polynomial vector field (under\na mild condition) implies existence of a polynomial Lyapunov function that is a\nsum of squares (sos) and that the negative of its derivative is also a sum of\nsquares. This result is extended to show that such sos-based certificates of\nstability are guaranteed to exist for all stable switched linear systems. For\nthis class of systems, we further show that if the derivative inequality of the\nLyapunov function has an sos certificate, then the Lyapunov function itself is\nautomatically a sum of squares. These converse results establish cases where\nsemidefinite programming is guaranteed to succeed in finding proofs of Lyapunov\ninequalities. Finally, we demonstrate some merits of replacing the sos\nrequirement on a polynomial Lyapunov function with an sos requirement on its\ntop homogeneous component. In particular, we show that this is a weaker\nalgebraic requirement in addition to being cheaper to impose computationally.",
    "published_date": "2017-12-30T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY",
      "math.AG",
      "math.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1801.00070v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.10114v1",
    "title": "An Efficient and Fair Multi-Resource Allocation Mechanism for Heterogeneous Servers",
    "authors": [
      "Jalal Khamse-Ashari",
      "Ioannis Lambadaris",
      "George Kesidis",
      "Bhuvan Urgaonkar",
      "Yiqiang Zhao"
    ],
    "author_ids": [],
    "abstract": "Efficient and fair allocation of multiple types of resources is a crucial\nobjective in a cloud/distributed computing cluster. Users may have diverse\nresource needs. Furthermore, diversity in server properties/ capabilities may\nmean that only a subset of servers may be usable by a given user. In platforms\nwith such heterogeneity, we identify important limitations in existing\nmulti-resource fair allocation mechanisms, notably Dominant Resource Fairness\n(DRF) and its follow-up work. To overcome such limitations, we propose a new\nserver-based approach; each server allocates resources by maximizing a\nper-server utility function. We propose a specific class of utility functions\nwhich, when appropriately parameterized, adjusts the trade-off between\nefficiency and fairness, and captures a variety of fairness measures (such as\nour recently proposed Per-Server Dominant Share Fairness). We establish\nconditions for the proposed mechanism to satisfy certain properties that are\ngenerally deemed desirable, e.g., envy-freeness, sharing incentive, bottleneck\nfairness, and Pareto optimality. To implement our resource allocation\nmechanism, we develop an iterative algorithm which is shown to be globally\nconvergent. Finally, we show how the proposed mechanism could be implemented in\na distributed fashion. We carry out extensive trace-driven simulations to show\nthe enhanced performance of our proposed mechanism over the existing ones.",
    "published_date": "2017-12-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.10114v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.10050v1",
    "title": "Kernel Robust Bias-Aware Prediction under Covariate Shift",
    "authors": [
      "Anqi Liu",
      "Rizal Fathony",
      "Brian D. Ziebart"
    ],
    "author_ids": [],
    "abstract": "Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift.",
    "published_date": "2017-12-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.10050v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.09480v2",
    "title": "Robust and discriminative zero-watermark scheme based on invariant feature and similarity-based retrieval for protecting large-scale DIBR 3D videos",
    "authors": [
      "Xiyao Liu",
      "Yifang Wang",
      "Ziqiang Sun",
      "Lei Wang",
      "Rongchang Zhao",
      "Yuesheng Zhu",
      "Beiji Zou"
    ],
    "author_ids": [],
    "abstract": "Digital rights management (DRM) of depth-image-based rendering (DIBR) 3D\nvideo is an emerging area of research. Existing schemes for DIBR 3D video cause\nvideo distortions, are vulnerable to severe signal and geometric attacks,\ncannot protect 2D frame and depth map independently or can hardly deal with\nlarge-scale videos. To address these issues, a novel zero-watermark scheme\nbased on invariant feature and similarity-based retrieval for protecting DIBR\n3D video (RZW-SR3D) is proposed in this study. In RZW-SR3D, invariant features\nare extracted to generate master and ownership shares for providing\ndistortion-free, robust and discriminative copyright identification under\nvarious attacks. Different from traditional zero-watermark schemes, features\nand ownership shares are stored correlatively, and a similarity-based retrieval\nphase is designed to provide effective solutions for large-scale videos. In\naddition, flexible mechanisms based on attention-based fusion are designed to\nprotect 2D frame and depth map independently and simultaneously. Experimental\nresults demonstrate that RZW-SR3D have superior DRM performances than existing\nschemes. First, RZW-SR3D can extracted the ownership shares relevant to a\nparticular 3D video precisely and reliably for effective copyright\nidentification of large-scale videos. Second, RZW-SR3D ensures lossless,\nprecise, reliable and flexible copyright identification for 2D frame and depth\nmap of 3D videos.",
    "published_date": "2017-12-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.09480v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.09124v2",
    "title": "Demographics and discussion influence views on algorithmic fairness",
    "authors": [
      "Emma Pierson"
    ],
    "author_ids": [],
    "abstract": "The field of algorithmic fairness has highlighted ethical questions which may\nnot have purely technical answers. For example, different algorithmic fairness\nconstraints are often impossible to satisfy simultaneously, and choosing\nbetween them requires value judgments about which people may disagree.\nAchieving consensus on algorithmic fairness will be difficult unless we\nunderstand why people disagree in the first place. Here we use a series of\nsurveys to investigate how two factors affect disagreement: demographics and\ndiscussion. First, we study whether disagreement on algorithmic fairness\nquestions is caused partially by differences in demographic backgrounds. This\nis a question of interest because computer science is demographically\nnon-representative. If beliefs about algorithmic fairness correlate with\ndemographics, and algorithm designers are demographically non-representative,\ndecisions made about algorithmic fairness may not reflect the will of the\npopulation as a whole. We show, using surveys of three separate populations,\nthat there are gender differences in beliefs about algorithmic fairness. For\nexample, women are less likely to favor including gender as a feature in an\nalgorithm which recommends courses to students if doing so would make female\nstudents less likely to be recommended science courses. Second, we investigate\nwhether people's views on algorithmic fairness can be changed by discussion and\nshow, using longitudinal surveys of students in two computer science classes,\nthat they can.",
    "published_date": "2017-12-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.09124v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.08914v2",
    "title": "Bayesian Nonparametric Causal Inference: Information Rates and Learning Algorithms",
    "authors": [
      "Ahmed M. Alaa",
      "Mihaela van der Schaar"
    ],
    "author_ids": [],
    "abstract": "We investigate the problem of estimating the causal effect of a treatment on\nindividual subjects from observational data, this is a central problem in\nvarious application domains, including healthcare, social sciences, and online\nadvertising. Within the Neyman Rubin potential outcomes model, we use the\nKullback Leibler (KL) divergence between the estimated and true distributions\nas a measure of accuracy of the estimate, and we define the information rate of\nthe Bayesian causal inference procedure as the (asymptotic equivalence class of\nthe) expected value of the KL divergence between the estimated and true\ndistributions as a function of the number of samples. Using Fano method, we\nestablish a fundamental limit on the information rate that can be achieved by\nany Bayesian estimator, and show that this fundamental limit is independent of\nthe selection bias in the observational data. We characterize the Bayesian\npriors on the potential (factual and counterfactual) outcomes that achieve the\noptimal information rate. As a consequence, we show that a particular class of\npriors that have been widely used in the causal inference literature cannot\nachieve the optimal information rate. On the other hand, a broader class of\npriors can achieve the optimal information rate. We go on to propose a prior\nadaptation procedure (which we call the information based empirical Bayes\nprocedure) that optimizes the Bayesian prior by maximizing an information\ntheoretic criterion on the recovered causal effects rather than maximizing the\nmarginal likelihood of the observed (factual) data. Building on our analysis,\nwe construct an information optimal Bayesian causal inference algorithm.",
    "published_date": "2017-12-24T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08914v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.08910v3",
    "title": "Walrasian Dynamics in Multi-unit Markets",
    "authors": [
      "Simina Brânzei",
      "Aris Filos-Ratsikas"
    ],
    "author_ids": [],
    "abstract": "In a multi-unit market, a seller brings multiple units of a good and tries to\nsell them to a set of buyers that have monetary endowments. While a Walrasian\nequilibrium does not always exist in this model, natural relaxations of the\nconcept that retain its desirable fairness properties do exist.\n  We study the dynamics of (Walrasian) envy-free pricing mechanisms in this\nenvironment, showing that for any such pricing mechanism, the best response\ndynamic starting from truth-telling converges to a pure Nash equilibrium with\nsmall loss in revenue and welfare. Moreover, we generalize these bounds to\ncapture all the Nash equilibria for a large class of (monotone) pricing\nmechanisms. We also identify a natural mechanism, which selects the minimum\nWalrasian envy-free price, in which for $n=2$ buyers the best response dynamic\nconverges from any starting profile, and for which we conjecture convergence\nfor any number of buyers.",
    "published_date": "2017-12-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08910v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.08493v1",
    "title": "Diversifying Support Vector Machines for Boosting using Kernel Perturbation: Applications to Class Imbalance and Small Disjuncts",
    "authors": [
      "Shounak Datta",
      "Sayak Nag",
      "Sankha Subhra Mullick",
      "Swagatam Das"
    ],
    "author_ids": [],
    "abstract": "The diversification (generating slightly varying separating discriminators)\nof Support Vector Machines (SVMs) for boosting has proven to be a challenge due\nto the strong learning nature of SVMs. Based on the insight that perturbing the\nSVM kernel may help in diversifying SVMs, we propose two kernel perturbation\nbased boosting schemes where the kernel is modified in each round so as to\nincrease the resolution of the kernel-induced Reimannian metric in the vicinity\nof the datapoints misclassified in the previous round. We propose a method for\nidentifying the disjuncts in a dataset, dispelling the dependence on rule-based\nlearning methods for identifying the disjuncts. We also present a new\nperformance measure called Geometric Small Disjunct Index (GSDI) to quantify\nthe performance on small disjuncts for balanced as well as class imbalanced\ndatasets. Experimental comparison with a variety of state-of-the-art algorithms\nis carried out using the best classifiers of each type selected by a new\napproach inspired by multi-criteria decision making. The proposed method is\nfound to outperform the contending state-of-the-art methods on different\ndatasets (ranging from mildly imbalanced to highly imbalanced and characterized\nby varying number of disjuncts) in terms of three different performance indices\n(including the proposed GSDI).",
    "published_date": "2017-12-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08493v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.08238v2",
    "title": "Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment",
    "authors": [
      "Chelsea Barabas",
      "Karthik Dinakar",
      "Joichi Ito",
      "Madars Virza",
      "Jonathan Zittrain"
    ],
    "author_ids": [],
    "abstract": "Actuarial risk assessments might be unduly perceived as a neutral way to\ncounteract implicit bias and increase the fairness of decisions made at almost\nevery juncture of the criminal justice system, from pretrial release to\nsentencing, parole and probation. In recent times these assessments have come\nunder increased scrutiny, as critics claim that the statistical techniques\nunderlying them might reproduce existing patterns of discrimination and\nhistorical biases that are reflected in the data. Much of this debate is\ncentered around competing notions of fairness and predictive accuracy, resting\non the contested use of variables that act as \"proxies\" for characteristics\nlegally protected against discrimination, such as race and gender. We argue\nthat a core ethical debate surrounding the use of regression in risk\nassessments is not simply one of bias or accuracy. Rather, it's one of purpose.\nIf machine learning is operationalized merely in the service of predicting\nindividual future crime, then it becomes difficult to break cycles of\ncriminalization that are driven by the iatrogenic effects of the criminal\njustice system itself. We posit that machine learning should not be used for\nprediction, but rather to surface covariates that are fed into a causal model\nfor understanding the social, structural and psychological drivers of crime. We\npropose an alternative application of machine learning and causal inference\naway from predicting risk scores to risk mitigation.",
    "published_date": "2017-12-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08238v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.08205v1",
    "title": "Practically-Self-Stabilizing Vector Clocks in the Absence of Execution Fairness",
    "authors": [
      "Iosif Salem",
      "Elad Michael Schiller"
    ],
    "author_ids": [],
    "abstract": "Vector clock algorithms are basic wait-free building blocks that facilitate\ncausal ordering of events. As wait-free algorithms, they are guaranteed to\ncomplete their operations within a finite number of steps. Stabilizing\nalgorithms allow the system to recover after the occurrence of transient\nfaults, such as soft errors and arbitrary violations of the assumptions\naccording to which the system was designed to behave. We present the first, to\nthe best of our knowledge, stabilizing vector clock algorithm for asynchronous\ncrash-prone message-passing systems that can recover in a wait-free manner\nafter the occurrence of transient faults. In these settings, it is challenging\nto demonstrate a finite and wait-free recovery from (communication and crash\nfailures as well as) transient faults, bound the message and storage sizes,\ndeal with the removal of all stale information without blocking, and deal with\ncounter overflow events (which occur at different network nodes concurrently).\n  We present an algorithm that never violates safety in the absence of\ntransient faults and provides bounded time recovery during fair executions that\nfollow the last transient fault. The novelty is that in the absence of\nexecution fairness, the algorithm guarantees a bound on the number of times in\nwhich the system might violate safety (while existing algorithms might block\nforever due to the presence of both transient faults and crash failures).\n  Since vector clocks facilitate a number of elementary synchronization\nbuilding blocks (without requiring remote replica synchronization) in\nasynchronous systems, we believe that our analytical insights are useful for\nthe design of other systems that cannot guarantee execution fairness.",
    "published_date": "2017-12-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08205v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.08197v1",
    "title": "Fair Forests: Regularized Tree Induction to Minimize Model Bias",
    "authors": [
      "Edward Raff",
      "Jared Sylvester",
      "Steven Mills"
    ],
    "author_ids": [],
    "abstract": "The potential lack of fairness in the outputs of machine learning algorithms\nhas recently gained attention both within the research community as well as in\nsociety more broadly. Surprisingly, there is no prior work developing\ntree-induction algorithms for building fair decision trees or fair random\nforests. These methods have widespread popularity as they are one of the few to\nbe simultaneously interpretable, non-linear, and easy-to-use. In this paper we\ndevelop, to our knowledge, the first technique for the induction of fair\ndecision trees. We show that our \"Fair Forest\" retains the benefits of the\ntree-based approach, while providing both greater accuracy and fairness than\nother alternatives, for both \"group fairness\" and \"individual fairness.'\" We\nalso introduce new measures for fairness which are able to handle multinomial\nand continues attributes as well as regression problems, as opposed to binary\nattributes and labels only. Finally, we demonstrate a new, more robust\nevaluation procedure for algorithms that considers the dataset in its entirety\nrather than only a specific protected attribute.",
    "published_date": "2017-12-21T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.08197v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.07924v2",
    "title": "Matching Code and Law: Achieving Algorithmic Fairness with Optimal Transport",
    "authors": [
      "Meike Zehlike",
      "Philipp Hacker",
      "Emil Wiedemann"
    ],
    "author_ids": [],
    "abstract": "Increasingly, discrimination by algorithms is perceived as a societal and\nlegal problem. As a response, a number of criteria for implementing algorithmic\nfairness in machine learning have been developed in the literature. This paper\nproposes the Continuous Fairness Algorithm (CFA$\\theta$) which enables a\ncontinuous interpolation between different fairness definitions. More\nspecifically, we make three main contributions to the existing literature.\nFirst, our approach allows the decision maker to continuously vary between\nspecific concepts of individual and group fairness. As a consequence, the\nalgorithm enables the decision maker to adopt intermediate ``worldviews'' on\nthe degree of discrimination encoded in algorithmic processes, adding nuance to\nthe extreme cases of ``we're all equal'' (WAE) and ``what you see is what you\nget'' (WYSIWYG) proposed so far in the literature. Second, we use optimal\ntransport theory, and specifically the concept of the barycenter, to maximize\ndecision maker utility under the chosen fairness constraints. Third, the\nalgorithm is able to handle cases of intersectionality, i.e., of\nmulti-dimensional discrimination of certain groups on grounds of several\ncriteria. We discuss three main examples (credit applications; college\nadmissions; insurance contracts) and map out the legal and policy implications\nof our approach. The explicit formalization of the trade-off between individual\nand group fairness allows this post-processing approach to be tailored to\ndifferent situational contexts in which one or the other fairness criterion may\ntake precedence. Finally, we evaluate our model experimentally.",
    "published_date": "2017-12-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.07924v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.07793v1",
    "title": "From Dissipativity Theory to Compositional Construction of Finite Markov Decision Processes",
    "authors": [
      "Abolfazl Lavaei",
      "Sadegh Soudjani",
      "Majid Zamani"
    ],
    "author_ids": [],
    "abstract": "This paper is concerned with a compositional approach for constructing finite\nMarkov decision processes of interconnected discrete-time stochastic control\nsystems. The proposed approach leverages the interconnection topology and a\nnotion of so-called stochastic storage functions describing joint\ndissipativity-type properties of subsystems and their abstractions. In the\nfirst part of the paper, we derive dissipativity-type compositional conditions\nfor quantifying the error between the interconnection of stochastic control\nsubsystems and that of their abstractions. In the second part of the paper, we\npropose an approach to construct finite Markov decision processes together with\ntheir corresponding stochastic storage functions for classes of discrete-time\ncontrol systems satisfying some incremental passivablity property. Under this\nproperty, one can construct finite Markov decision processes by a suitable\ndiscretization of the input and state sets. Moreover, we show that for linear\nstochastic control systems, the aforementioned property can be readily checked\nby some matrix inequality. We apply our proposed results to the temperature\nregulation in a circular building by constructing compositionally a finite\nMarkov decision process of a network containing 200 rooms in which the\ncompositionality condition does not require any constraint on the number or\ngains of the subsystems. We employ the constructed finite Markov decision\nprocess as a substitute to synthesize policies regulating the temperature in\neach room for a bounded time horizon.",
    "published_date": "2017-12-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.07793v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.07610v2",
    "title": "MATE robots simplifying my work: benefits and socio-ethical implications",
    "authors": [
      "Valeria Villani",
      "Lorenzo Sabattini",
      "Julia N. Czerniak",
      "Alexander Mertens",
      "Cesare Fantuzzi"
    ],
    "author_ids": [],
    "abstract": "With the increasing complexity of modern industrial automatic and robotic\nsystems, an increasing burden is put on the operators, who are requested to\nsupervise and interact with very complex systems, typically under challenging\nand stressful conditions. To overcome this issue, it is necessary to adopt a\nresponsible approach based on the anthropocentric design methodology, such that\nmachines adapt to the humans capabilities, and not vice versa. Moving along\nthese lines, in this paper we consider an integrated methodological design\napproach, which we call MATE, consisting in devising complex automatic or\nrobotic solutions that measure current operator's status, adapting the\ninteraction accordingly, and providing her/him with proper training to improve\nthe interaction and learn lacking skills and expertise. Accordingly, a MATE\nsystem is intended to be easily usable for all users, thus meeting the\nprinciples of inclusive design. Using such a MATE system gives rise to several\nethical and social implications, which are discussed in this paper.\nAdditionally, a discussion about which factors in the organization of companies\nare critical with respect to the introduction of a MATE system is presented.",
    "published_date": "2017-12-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.07610v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.07512v1",
    "title": "Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics",
    "authors": [
      "Anil Kumar Singh",
      "Akhilesh Sudhakar"
    ],
    "author_ids": [],
    "abstract": "Ideas from forensic linguistics are now being used frequently in Natural\nLanguage Processing (NLP), using machine learning techniques. While the role of\nforensic linguistics was more benign earlier, it is now being used for purposes\nwhich are questionable. Certain methods from forensic linguistics are employed,\nwithout considering their scientific limitations and ethical concerns. While we\ntake the specific case of forensic linguistics as an example of such trends in\nNLP and machine learning, the issue is a larger one and present in many other\nscientific and data-driven domains. We suggest that such trends indicate that\nsome of the applied sciences are exceeding their legal and scientific briefs.\nWe highlight how carelessly implemented practices are serving to short-circuit\nthe due processes of law as well breach ethical codes.",
    "published_date": "2017-12-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.07512v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.06427v2",
    "title": "Detecting Hate Speech in Social Media",
    "authors": [
      "Shervin Malmasi",
      "Marcos Zampieri"
    ],
    "author_ids": [],
    "abstract": "In this paper we examine methods to detect hate speech in social media, while\ndistinguishing this from general profanity. We aim to establish lexical\nbaselines for this task by applying supervised classification methods using a\nrecently released dataset annotated for this purpose. As features, our system\nuses character n-grams, word n-grams and word skip-grams. We obtain results of\n78% accuracy in identifying posts across three classes. Results demonstrate\nthat the main challenge lies in discriminating profanity and hate speech from\neach other. A number of directions for future work are discussed.",
    "published_date": "2017-12-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.06427v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.06405v2",
    "title": "Automatic Classification of Functional Gait Disorders",
    "authors": [
      "Djordje Slijepcevic",
      "Matthias Zeppelzauer",
      "Anna-Maria Gorgas",
      "Caterine Schwab",
      "Michael Schüller",
      "Arnold Baca",
      "Christian Breiteneder",
      "Brian Horsak"
    ],
    "author_ids": [],
    "abstract": "This article proposes a comprehensive investigation of the automatic\nclassification of functional gait disorders based solely on ground reaction\nforce (GRF) measurements. The aim of the study is twofold: (1) to investigate\nthe suitability of stateof-the-art GRF parameterization techniques\n(representations) for the discrimination of functional gait disorders; and (2)\nto provide a first performance baseline for the automated classification of\nfunctional gait disorders for a large-scale dataset. The utilized database\ncomprises GRF measurements from 279 patients with gait disorders (GDs) and data\nfrom 161 healthy controls (N). Patients were manually classified into four\nclasses with different functional impairments associated with the \"hip\",\n\"knee\", \"ankle\", and \"calcaneus\". Different parameterizations are investigated:\nGRF parameters, global principal component analysis (PCA)-based representations\nand a combined representation applying PCA on GRF parameters. The\ndiscriminative power of each parameterization for different classes is\ninvestigated by linear discriminant analysis (LDA). Based on this analysis, two\nclassification experiments are pursued: (1) distinction between healthy and\nimpaired gait (N vs. GD) and (2) multi-class classification between healthy\ngait and all four GD classes. Experiments show promising results and reveal\namong others that several factors, such as imbalanced class cardinalities and\nvarying numbers of measurement sessions per patient have a strong impact on the\nclassification accuracy and therefore need to be taken into account. The\nresults represent a promising first step towards the automated classification\nof gait disorders and a first performance baseline for future developments in\nthis direction.",
    "published_date": "2017-12-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.06405v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.06299v3",
    "title": "Measurement-based Efficient Resource Allocation with Demand-Side Adjustments",
    "authors": [
      "Georgios Chasparis"
    ],
    "author_ids": [],
    "abstract": "The problem of efficient resource allocation has drawn significant attention\nin many scientific disciplines due to its direct societal benefits, such as\nenergy savings. Traditional approaches in addressing online resource allocation\nproblems neglect the potential benefit of feedback information available from\nthe running tasks/loads as well as the potential flexibility of a task to\nadjust its operation/service-level in order to increase efficiency. The present\npaper builds upon recent developments in the area of bandwidth allocation in\ncomputing systems and proposes a generalized design approach for resource\nallocation when only performance measurements of the running tasks are\navailable, possibly corrupted by noise. We demonstrate through analysis and\nsimulations the potential of the proposed scheme in providing fair and\nefficient allocation of resources in a large class of resource allocation\nproblems.",
    "published_date": "2017-12-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.06299v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.06587v1",
    "title": "Solving satisfiability using inclusion-exclusion",
    "authors": [
      "Anthony Zaleski"
    ],
    "author_ids": [],
    "abstract": "Using Maple, we implement a SAT solver based on the principle of\ninclusion-exclusion and the Bonferroni inequalities. Using randomly generated\ninput, we investigate the performance of our solver as a function of the number\nof variables and number of clauses. We also test it against Maple's built-in\ntautology procedure. Finally, we implement the Lov\\'asz local lemma with Maple\nand discuss its applicability to SAT.",
    "published_date": "2017-12-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "math.CO",
      "68W40, 68R01"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.06587v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.05608v1",
    "title": "A Novel Approach for Effective Learning in Low Resourced Scenarios",
    "authors": [
      "Sri Harsha Dumpala",
      "Rupayan Chakraborty",
      "Sunil Kumar Kopparapu"
    ],
    "author_ids": [],
    "abstract": "Deep learning based discriminative methods, being the state-of-the-art\nmachine learning techniques, are ill-suited for learning from lower amounts of\ndata. In this paper, we propose a novel framework, called simultaneous two\nsample learning (s2sL), to effectively learn the class discriminative\ncharacteristics, even from very low amount of data. In s2sL, more than one\nsample (here, two samples) are simultaneously considered to both, train and\ntest the classifier. We demonstrate our approach for speech/music\ndiscrimination and emotion classification through experiments. Further, we also\nshow the effectiveness of s2sL approach for classification in low-resource\nscenario, and for imbalanced data.",
    "published_date": "2017-12-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.05608v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.05112v1",
    "title": "Inequalities, Preferences and Rankings in US Sports Coach Hiring Networks",
    "authors": [
      "Huanshen Wei",
      "Jason",
      "Zhang",
      "Dongwon Lee"
    ],
    "author_ids": [],
    "abstract": "Hiring a head coach of a college sports team is vital which will definitely\nhave a great influence on the later development of the team. However, a lot of\nattention has been focused on each coach's individual features. A systematic\nand quantitative analysis of the whole coach hiring market is lacking. In a\ncoach hiring network, the coaches are actually voting with their feet. It is\ninteresting to analyze what factors are affecting the \"footprint\" left by those\nhead coaches. In this paper, we collect more than 12,000 head coach hiring\nrecords in two different popular sports from the NCAA. Using network-based\nmethods, we build the coach hiring network in the NCAA men's basketball and\nfootball. We find that: (1).the coach hiring network is of great inequality in\ncoach production with a Gini coefficient close to 0.60. (2).coaches prefer to\nwork within the same geographical region and the same division to their alma\nmaters'. (3).the coach production rankings we calculated using network-based\nmethods are generally correlated to the authoritative rankings, but also show\ndisaccord in specific time period. The results provide us a novel view and\nbetter understanding of the coach hiring market in the NCAA and shed new light\non the coach hiring system.",
    "published_date": "2017-12-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.05112v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.04323v4",
    "title": "Deep Echo State Network (DeepESN): A Brief Survey",
    "authors": [
      "Claudio Gallicchio",
      "Alessio Micheli"
    ],
    "author_ids": [],
    "abstract": "The study of deep recurrent neural networks (RNNs) and, in particular, of\ndeep Reservoir Computing (RC) is gaining an increasing research attention in\nthe neural networks community. The recently introduced Deep Echo State Network\n(DeepESN) model opened the way to an extremely efficient approach for designing\ndeep neural networks for temporal data. At the same time, the study of DeepESNs\nallowed to shed light on the intrinsic properties of state dynamics developed\nby hierarchical compositions of recurrent layers, i.e. on the bias of depth in\nRNNs architectural design. In this paper, we summarize the advancements in the\ndevelopment, analysis and applications of DeepESNs.",
    "published_date": "2017-12-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.04323v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.04172v2",
    "title": "A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents",
    "authors": [
      "Yueh-Hua Wu",
      "Shou-De Lin"
    ],
    "author_ids": [],
    "abstract": "This paper proposes a low-cost, easily realizable strategy to equip a\nreinforcement learning (RL) agent the capability of behaving ethically. Our\nmodel allows the designers of RL agents to solely focus on the task to achieve,\nwithout having to worry about the implementation of multiple trivial ethical\npatterns to follow. Based on the assumption that the majority of human\nbehavior, regardless which goals they are achieving, is ethical, our design\nintegrates human policy with the RL policy to achieve the target objective with\nless chance of violating the ethical code that human beings normally obey.",
    "published_date": "2017-12-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.04172v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.04762v3",
    "title": "Social Media Writing Style Fingerprint",
    "authors": [
      "Himank Yadav",
      "Juliang Li"
    ],
    "author_ids": [],
    "abstract": "We present our approach for computer-aided social media text authorship\nattribution based on recent advances in short text authorship verification. We\nuse various natural language techniques to create word-level and\ncharacter-level models that act as hidden layers to simulate a simple neural\nnetwork. The choice of word-level and character-level models in each layer was\ninformed through validation performance. The output layer of our system uses an\nunweighted majority vote vector to arrive at a conclusion. We also considered\nwriting bias in social media posts while collecting our training dataset to\nincrease system robustness. Our system achieved a precision, recall, and\nF-measure of 0.82, 0.926 and 0.869 respectively.",
    "published_date": "2017-12-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.04762v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.03878v5",
    "title": "Generalized Zero-Shot Learning via Synthesized Examples",
    "authors": [
      "Vinay Kumar Verma",
      "Gundeep Arora",
      "Ashish Mishra",
      "Piyush Rai"
    ],
    "author_ids": [],
    "abstract": "We present a generative framework for generalized zero-shot learning where\nthe training and test classes are not necessarily disjoint. Built upon a\nvariational autoencoder based architecture, consisting of a probabilistic\nencoder and a probabilistic conditional decoder, our model can generate novel\nexemplars from seen/unseen classes, given their respective class attributes.\nThese exemplars can subsequently be used to train any off-the-shelf\nclassification model. One of the key aspects of our encoder-decoder\narchitecture is a feedback-driven mechanism in which a discriminator (a\nmultivariate regressor) learns to map the generated exemplars to the\ncorresponding class attribute vectors, leading to an improved generator. Our\nmodel's ability to generate and leverage examples from unseen classes to train\nthe classification model naturally helps to mitigate the bias towards\npredicting seen classes in generalized zero-shot learning settings. Through a\ncomprehensive set of experiments, we show that our model outperforms several\nstate-of-the-art methods, on several benchmark datasets, for both standard as\nwell as generalized zero-shot learning.",
    "published_date": "2017-12-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.03878v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.03724v1",
    "title": "Cogniculture: Towards a Better Human-Machine Co-evolution",
    "authors": [
      "Rakesh R Pimplikar",
      "Kushal Mukherjee",
      "Gyana Parija",
      "Harit Vishwakarma",
      "Ramasuri Narayanam",
      "Sarthak Ahuja",
      "Rohith D Vallam",
      "Ritwik Chaudhuri",
      "Joydeep Mondal"
    ],
    "author_ids": [],
    "abstract": "Research in Artificial Intelligence is breaking technology barriers every\nday. New algorithms and high performance computing are making things possible\nwhich we could only have imagined earlier. Though the enhancements in AI are\nmaking life easier for human beings day by day, there is constant fear that AI\nbased systems will pose a threat to humanity. People in AI community have\ndiverse set of opinions regarding the pros and cons of AI mimicking human\nbehavior. Instead of worrying about AI advancements, we propose a novel idea of\ncognitive agents, including both human and machines, living together in a\ncomplex adaptive ecosystem, collaborating on human computation for producing\nessential social goods while promoting sustenance, survival and evolution of\nthe agents' life cycle. We highlight several research challenges and technology\nbarriers in achieving this goal. We propose a governance mechanism around this\necosystem to ensure ethical behaviors of all cognitive agents. Along with a\nnovel set of use-cases of Cogniculture, we discuss the road map ahead for this\njourney.",
    "published_date": "2017-12-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.03724v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.03586v3",
    "title": "Fairness in Machine Learning: Lessons from Political Philosophy",
    "authors": [
      "Reuben Binns"
    ],
    "author_ids": [],
    "abstract": "What does it mean for a machine learning model to be `fair', in terms which\ncan be operationalised? Should fairness consist of ensuring everyone has an\nequal probability of obtaining some benefit, or should we aim instead to\nminimise the harms to the least advantaged? Can the relevant ideal be\ndetermined by reference to some alternative state of affairs in which a\nparticular social pattern of discrimination does not exist? Various definitions\nproposed in recent literature make different assumptions about what terms like\ndiscrimination and fairness mean and how they can be defined in mathematical\nterms. Questions of discrimination, egalitarianism and justice are of\nsignificant interest to moral and political philosophers, who have expended\nsignificant efforts in formalising and defending these central concepts. It is\ntherefore unsurprising that attempts to formalise `fairness' in machine\nlearning contain echoes of these old philosophical debates. This paper draws on\nexisting work in moral and political philosophy in order to elucidate emerging\ndebates about fair machine learning.",
    "published_date": "2017-12-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.03586v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.03022v1",
    "title": "Graph Theory Based Approach to Users Grouping and Downlink Scheduling in FDD Massive MIMO",
    "authors": [
      "Ali Maatouk",
      "Salah Eddine Hajri",
      "Mohamad Assaad",
      "Hikmet Sari",
      "Serdar Sezginer"
    ],
    "author_ids": [],
    "abstract": "Massive MIMO is considered as one of the key enablers of the next generation\n5G networks.With a high number of antennas at the BS, both spectral and energy\nefficiencies can be improved. Unfortunately, the downlink channel estimation\noverhead scales linearly with the number of antenna. This does not create\ncomplications in Time Division Duplex (TDD) systems since the channel estimate\nof the uplink direction can be directly utilized for link adaptation in the\ndownlink direction. However, this channel reciprocity is unfeasible for the\nFrequency Division Duplex (FDD) systems where different physical transmission\nchannels are existent for the uplink and downlink. In the aim of reducing the\namount of Channel State Information (CSI) feedback for FDD systems, the\npromising method of two stage beamforming transmission was introduced. The\nperformance of this transmission scheme is however highly influenced by the\nusers grouping and selection mechanisms. In this paper, we first introduce a\nnew similarity measure coupled with a novel clustering technique to achieve the\nappropriate users partitioning. We also use graph theory to develop a low\ncomplexity groups scheduling scheme that outperforms currently existing methods\nin both sum-rate and throughput fairness. This performance gain is demonstrated\nthrough computer simulations.",
    "published_date": "2017-12-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.03022v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.02898v1",
    "title": "Representations of Sound in Deep Learning of Audio Features from Music",
    "authors": [
      "Sergey Shuvaev",
      "Hamza Giaffar",
      "Alexei A. Koulakov"
    ],
    "author_ids": [],
    "abstract": "The work of a single musician, group or composer can vary widely in terms of\nmusical style. Indeed, different stylistic elements, from performance medium\nand rhythm to harmony and texture, are typically exploited and developed across\nan artist's lifetime. Yet, there is often a discernable character to the work\nof, for instance, individual composers at the perceptual level - an experienced\nlistener can often pick up on subtle clues in the music to identify the\ncomposer or performer. Here we suggest that a convolutional network may learn\nthese subtle clues or features given an appropriate representation of the\nmusic. In this paper, we apply a deep convolutional neural network to a large\naudio dataset and empirically evaluate its performance on audio classification\ntasks. Our trained network demonstrates accurate performance on such\nclassification tasks when presented with 5 s examples of music obtained by\nsimple transformations of the raw audio waveform. A particularly interesting\nexample is the spectral representation of music obtained by application of a\nlogarithmically spaced filter bank, mirroring the early stages of auditory\nsignal transduction in mammals. The most successful representation of music to\nfacilitate discrimination was obtained via a random matrix transform (RMT).\nNetworks based on logarithmic filter banks and RMT were able to correctly guess\nthe one composer out of 31 possibilities in 68 and 84 percent of cases\nrespectively.",
    "published_date": "2017-12-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SD",
      "cs.CV",
      "eess.AS",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.02898v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.02485v3",
    "title": "The Approximate Duality Gap Technique: A Unified Theory of First-Order Methods",
    "authors": [
      "Jelena Diakonikolas",
      "Lorenzo Orecchia"
    ],
    "author_ids": [],
    "abstract": "We present a general technique for the analysis of first-order methods. The\ntechnique relies on the construction of a duality gap for an appropriate\napproximation of the objective function, where the function approximation\nimproves as the algorithm converges. We show that in continuous time\nenforcement of an invariant that this approximate duality gap decreases at a\ncertain rate exactly recovers a wide range of first-order continuous-time\nmethods. We characterize the discretization errors incurred by different\ndiscretization methods, and show how iteration-complexity-optimal methods for\nvarious classes of problems cancel out the discretization error. The techniques\nare illustrated on various classes of problems -- including convex minimization\nfor Lipschitz-continuous objectives, smooth convex minimization, composite\nminimization, smooth and strongly convex minimization, solving variational\ninequalities with monotone operators, and convex-concave saddle-point\noptimization -- and naturally extend to other settings.",
    "published_date": "2017-12-07T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.02485v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.02449v1",
    "title": "Quantifying how much sensory information in a neural code is relevant for behavior",
    "authors": [
      "Giuseppe Pica",
      "Eugenio Piasini",
      "Houman Safaai",
      "Caroline A. Runyan",
      "Mathew E. Diamond",
      "Tommaso Fellin",
      "Christoph Kayser",
      "Christopher D. Harvey",
      "Stefano Panzeri"
    ],
    "author_ids": [],
    "abstract": "Determining how much of the sensory information carried by a neural code\ncontributes to behavioral performance is key to understand sensory function and\nneural information flow. However, there are as yet no analytical tools to\ncompute this information that lies at the intersection between sensory coding\nand behavioral readout. Here we develop a novel measure, termed the\ninformation-theoretic intersection information $I_{II}(S;R;C)$, that quantifies\nhow much of the sensory information carried by a neural response R is used for\nbehavior during perceptual discrimination tasks. Building on the Partial\nInformation Decomposition framework, we define $I_{II}(S;R;C)$ as the part of\nthe mutual information between the stimulus S and the response R that also\ninforms the consequent behavioral choice C. We compute $I_{II}(S;R;C)$ in the\nanalysis of two experimental cortical datasets, to show how this measure can be\nused to compare quantitatively the contributions of spike timing and spike\nrates to task performance, and to identify brain areas or neural populations\nthat specifically transform sensory information into choice.",
    "published_date": "2017-12-06T00:00:00",
    "year": 2017,
    "categories": [
      "q-bio.NC",
      "cs.IT",
      "math.IT",
      "physics.data-an"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.02449v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.01661v1",
    "title": "Recognizing Gender from Human Facial Regions using Genetic Algorithm",
    "authors": [
      "Avirup Bhattacharyya",
      "Rajkumar Saini",
      "Partha Pratim Roy",
      "Debi Prosad Dogra",
      "Samarjit Kar"
    ],
    "author_ids": [],
    "abstract": "Recently, recognition of gender from facial images has gained a lot of\nimportance. There exist a handful of research work that focus on feature\nextraction to obtain gender specific information from facial images. However,\nanalyzing different facial regions and their fusion help in deciding the gender\nof a person from facial images. In this paper, we propose a new approach to\nidentify gender from frontal facial images that is robust to background,\nillumination, intensity, and facial expression. In our framework, first the\nfrontal face image is divided into a number of distinct regions based on facial\nlandmark points that are obtained by the Chehra model proposed by Asthana et\nal. The model provides 49 facial landmark points covering different regions of\nthe face, e.g. forehead, left eye, right eye, lips. Next, a face image is\nsegmented into facial regions using landmark points and features are extracted\nfrom each region. The Compass LBP feature, a variant of LBP feature, has been\nused in our framework to obtain discriminative gender-specific information.\nFollowing this, a Support Vector Machine based classifier has been used to\ncompute the probability scores from each facial region. Finally, the\nclassification scores obtained from individual regions are combined with a\ngenetic algorithm based learning to improve the overall classification\naccuracy. The experiments have been performed on popular face image datasets\nsuch as Adience, cFERET (color FERET), LFW and two sketch datasets, namely CUFS\nand CUFSF. Through experiments, we have observed that, the proposed method\noutperforms existing approaches.",
    "published_date": "2017-12-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.01661v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.01619v4",
    "title": "Empirically Analyzing the Effect of Dataset Biases on Deep Face Recognition Systems",
    "authors": [
      "Adam Kortylewski",
      "Bernhard Egger",
      "Andreas Schneider",
      "Thomas Gerig",
      "Andreas Morel-Forster",
      "Thomas Vetter"
    ],
    "author_ids": [],
    "abstract": "It is unknown what kind of biases modern in the wild face datasets have\nbecause of their lack of annotation. A direct consequence of this is that total\nrecognition rates alone only provide limited insight about the generalization\nability of a Deep Convolutional Neural Networks (DCNNs). We propose to\nempirically study the effect of different types of dataset biases on the\ngeneralization ability of DCNNs. Using synthetically generated face images, we\nstudy the face recognition rate as a function of interpretable parameters such\nas face pose and light. The proposed method allows valuable details about the\ngeneralization performance of different DCNN architectures to be observed and\ncompared. In our experiments, we find that: 1) Indeed, dataset bias has a\nsignificant influence on the generalization performance of DCNNs. 2) DCNNs can\ngeneralize surprisingly well to unseen illumination conditions and large\nsampling gaps in the pose variation. 3) Using the presented methodology we\nreveal that the VGG-16 architecture outperforms the AlexNet architecture at\nface recognition tasks because it can much better generalize to unseen face\nposes, although it has significantly more parameters. 4) We uncover a main\nlimitation of current DCNN architectures, which is the difficulty to generalize\nwhen different identities to not share the same pose variation. 5) We\ndemonstrate that our findings on synthetic data also apply when learning from\nreal-world data. Our face image generator is publicly available to enable the\ncommunity to benchmark other DCNN architectures.",
    "published_date": "2017-12-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.01619v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.01381v3",
    "title": "A Generative Adversarial Approach for Zero-Shot Learning from Noisy Texts",
    "authors": [
      "Yizhe Zhu",
      "Mohamed Elhoseiny",
      "Bingchen Liu",
      "Xi Peng",
      "Ahmed Elgammal"
    ],
    "author_ids": [],
    "abstract": "Most existing zero-shot learning methods consider the problem as a visual\nsemantic embedding one. Given the demonstrated capability of Generative\nAdversarial Networks(GANs) to generate images, we instead leverage GANs to\nimagine unseen categories from text descriptions and hence recognize novel\nclasses with no examples being seen. Specifically, we propose a simple yet\neffective generative model that takes as input noisy text descriptions about an\nunseen class (e.g.Wikipedia articles) and generates synthesized visual features\nfor this class. With added pseudo data, zero-shot learning is naturally\nconverted to a traditional classification problem. Additionally, to preserve\nthe inter-class discrimination of the generated features, a visual pivot\nregularization is proposed as an explicit supervision. Unlike previous methods\nusing complex engineered regularizers, our approach can suppress the noise well\nwithout additional regularization. Empirically, we show that our method\nconsistently outperforms the state of the art on the largest available\nbenchmarks on Text-based Zero-shot Learning.",
    "published_date": "2017-12-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.01381v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.03079v3",
    "title": "Replication Ethics",
    "authors": [
      "Adrian Kent"
    ],
    "author_ids": [],
    "abstract": "Suppose some future technology enables the same consciously experienced human\nlife to be repeated, identically or nearly so, N times, in series or in\nparallel. Is this roughly N times as valuable as enabling the same life once,\nbecause each life has value and values are additive? Or is it of roughly equal\nvalue as enabling the life once, because only one life is enabled, albeit in a\nphysically unusual way? Does it matter whether the lives are contemporaneous or\nsuccessive? We argue that these questions highlight a hitherto neglected facet\nof population ethics that may become relevant in the not necessarily far\ndistant future.",
    "published_date": "2017-12-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "physics.hist-ph",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.03079v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1712.00846v1",
    "title": "Always Lurking: Understanding and Mitigating Bias in Online Human Trafficking Detection",
    "authors": [
      "Kyle Hundman",
      "Thamme Gowda",
      "Mayank Kejriwal",
      "Benedikt Boecking"
    ],
    "author_ids": [],
    "abstract": "Web-based human trafficking activity has increased in recent years but it\nremains sparsely dispersed among escort advertisements and difficult to\nidentify due to its often-latent nature. The use of intelligent systems to\ndetect trafficking can thus have a direct impact on investigative resource\nallocation and decision-making, and, more broadly, help curb a widespread\nsocial problem. Trafficking detection involves assigning a normalized score to\na set of escort advertisements crawled from the Web -- a higher score indicates\na greater risk of trafficking-related (involuntary) activities. In this paper,\nwe define and study the problem of trafficking detection and present a\ntrafficking detection pipeline architecture developed over three years of\nresearch within the DARPA Memex program. Drawing on multi-institutional data,\nsystems, and experiences collected during this time, we also conduct post hoc\nbias analyses and present a bias mitigation plan. Our findings show that, while\nautomatic trafficking detection is an important application of AI for social\ngood, it also provides cautionary lessons for deploying predictive machine\nlearning algorithms without appropriate de-biasing. This ultimately led to\nintegration of an interpretable solution into a search system that contains\nover 100 million advertisements and is used by over 200 law enforcement\nagencies to investigate leads.",
    "published_date": "2017-12-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.00846v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.00640v1",
    "title": "Learning Sparse Adversarial Dictionaries For Multi-Class Audio Classification",
    "authors": [
      "Vaisakh Shaj",
      "Puranjoy Bhattacharya"
    ],
    "author_ids": [],
    "abstract": "Audio events are quite often overlapping in nature, and more prone to noise\nthan visual signals. There has been increasing evidence for the superior\nperformance of representations learned using sparse dictionaries for\napplications like audio denoising and speech enhancement. This paper\nconcentrates on modifying the traditional reconstructive dictionary learning\nalgorithms, by incorporating a discriminative term into the objective function\nin order to learn class-specific adversarial dictionaries that are good at\nrepresenting samples of their own class at the same time poor at representing\nsamples belonging to any other class. We quantitatively demonstrate the\neffectiveness of our learned dictionaries as a stand-alone solution for both\nbinary as well as multi-class audio classification problems.",
    "published_date": "2017-12-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.00640v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.00527v2",
    "title": "Adaptive Sampled Softmax with Kernel Based Sampling",
    "authors": [
      "Guy Blanc",
      "Steffen Rendle"
    ],
    "author_ids": [],
    "abstract": "Softmax is the most commonly used output function for multiclass problems and\nis widely used in areas such as vision, natural language processing, and\nrecommendation. A softmax model has linear costs in the number of classes which\nmakes it too expensive for many real-world problems. A common approach to speed\nup training involves sampling only some of the classes at each training step.\nIt is known that this method is biased and that the bias increases the more the\nsampling distribution deviates from the output distribution. Nevertheless,\nalmost any recent work uses simple sampling distributions that require a large\nsample size to mitigate the bias. In this work, we propose a new class of\nkernel based sampling methods and develop an efficient sampling algorithm.\nKernel based sampling adapts to the model as it is trained, thus resulting in\nlow bias. Kernel based sampling can be easily applied to many models because it\nrelies only on the model's last hidden layer. We empirically study the\ntrade-off of bias, sampling distribution and sample size and show that kernel\nbased sampling results in low bias with few samples.",
    "published_date": "2017-12-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.00527v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1712.00064v2",
    "title": "A Short-term Intervention for Long-term Fairness in the Labor Market",
    "authors": [
      "Lily Hu",
      "Yiling Chen"
    ],
    "author_ids": [],
    "abstract": "The persistence of racial inequality in the U.S. labor market against a\ngeneral backdrop of formal equality of opportunity is a troubling phenomenon\nthat has significant ramifications on the design of hiring policies. In this\npaper, we show that current group disparate outcomes may be immovable even when\nhiring decisions are bound by an input-output notion of \"individual fairness.\"\nInstead, we construct a dynamic reputational model of the labor market that\nillustrates the reinforcing nature of asymmetric outcomes resulting from\ngroups' divergent accesses to resources and as a result, investment choices. To\naddress these disparities, we adopt a dual labor market composed of a Temporary\nLabor Market (TLM), in which firms' hiring strategies are constrained to ensure\nstatistical parity of workers granted entry into the pipeline, and a Permanent\nLabor Market (PLM), in which firms hire top performers as desired. Individual\nworker reputations produce externalities for their group; the corresponding\nfeedback loop raises the collective reputation of the initially disadvantaged\ngroup via a TLM fairness intervention that need not be permanent. We show that\nsuch a restriction on hiring practices induces an equilibrium that, under\nparticular market conditions, Pareto-dominates those arising from strategies\nthat statistically discriminate or employ a \"group-blind\" criterion. The\nenduring nature of equilibria that are both inequitable and Pareto suboptimal\nsuggests that fairness interventions beyond procedural checks of hiring\ndecisions will be of critical importance in a world where machines play a\ngreater role in the employment process.",
    "published_date": "2017-11-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "q-fin.GN"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.00064v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.11485v3",
    "title": "On density of subgraphs of Cartesian products",
    "authors": [
      "Victor Chepoi",
      "Arnaud Labourel",
      "Sébastien Ratel"
    ],
    "author_ids": [],
    "abstract": "In this paper, we extend two classical results about the density of subgraphs\nof hypercubes to subgraphs $G$ of Cartesian products $G_1\\times\\cdots\\times\nG_m$ of arbitrary connected graphs. Namely, we show that\n$\\frac{|E(G)|}{|V(G)|}\\le \\lceil 2\\max\\{\n\\text{dens}(G_1),\\ldots,\\text{dens}(G_m)\\} \\rceil\\log|V(G)|$, where\n$\\text{dens}(H)$ is the maximum ratio $\\frac{|E(H')|}{|V(H')|}$ over all\nsubgraphs $H'$ of $H$. We introduce the notions of VC-dimension\n$\\text{VC-dim}(G)$ and VC-density $\\text{VC-dens}(G)$ of a subgraph $G$ of a\nCartesian product $G_1\\times\\cdots\\times G_m$, generalizing the classical\nVapnik-Chervonenkis dimension of set-families (viewed as subgraphs of\nhypercubes). We prove that if $G_1,\\ldots,G_m$ belong to the class ${\\mathcal\nG}(H)$ of all finite connected graphs not containing a given graph $H$ as a\nminor, then for any subgraph $G$ of $G_1\\times\\cdots\\times G_m$ a sharper\ninequality $\\frac{|E(G)|}{|V(G)|}\\le \\text{VC-dim}(G)\\alpha(H)$ holds, where\n$\\alpha(H)$ is the density of the graphs from ${\\mathcal G}(H)$. We refine and\nsharpen those two results to several specific graph classes. We also derive\nupper bounds (some of them polylogarithmic) for the size of adjacency labeling\nschemes of subgraphs of Cartesian products.",
    "published_date": "2017-11-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM",
      "math.CO",
      "G.2.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.11485v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.11414v2",
    "title": "On density of subgraphs of halved cubes",
    "authors": [
      "Victor Chepoi",
      "Arnaud Labourel",
      "Sébastien Ratel"
    ],
    "author_ids": [],
    "abstract": "Let $\\mathcal S$ be a family of subsets of a set $X$ of cardinality $m$ and\n$\\text{VC-dim}(\\mathcal S)$ be the Vapnik-Chervonenkis dimension of $\\mathcal\nS$. Haussler, Littlestone, and Warmuth (Inf. Comput., 1994) proved that if\n$G_1(\\mathcal S)=(V,E)$ is the subgraph of the hypercube $Q_m$ induced by\n$\\mathcal S$ (called the 1-inclusion graph of $\\mathcal S$), then\n$\\frac{|E|}{|V|}\\le \\text{VC-dim}({\\mathcal S})$. Haussler (J. Combin. Th. A,\n1995) presented an elegant proof of this inequality using the shifting\noperation.\n  In this note, we adapt the shifting technique to prove that if $\\mathcal S$\nis an arbitrary set family and $G_{1,2}(\\mathcal S)=(V,E)$ is the 1,2-inclusion\ngraph of $\\mathcal S$ (i.e., the subgraph of the square $Q^2_m$ of the\nhypercube $Q_m$ induced by $\\mathcal S$), then $\\frac{|E|}{|V|}\\le\n\\binom{d}{2}$, where $d:=\\text{cVC-dim}^*(\\mathcal S)$ is the\nclique-VC-dimension of $\\mathcal S$ (which we introduce in this paper). The\n1,2-inclusion graphs are exactly the subgraphs of halved cubes and comprise\nsubgraphs of Johnson graphs as a subclass.",
    "published_date": "2017-11-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM",
      "math.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.11414v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.11129v1",
    "title": "Demand Side Management in the Smart Grid: an Efficiency and Fairness Tradeoff",
    "authors": [
      "Paulin Jacquot",
      "Olivier Beaude",
      "Stéphane Gaubert",
      "Nadia Oudjane"
    ],
    "author_ids": [],
    "abstract": "We compare two Demand Side Management (DSM) mechanisms, introduced\nrespectively by Mohsenian-Rad et al (2010) and Baharlouei et al (2012), in\nterms of efficiency and fairness. Each mechanism defines a game where the\nconsumers optimize their flexible consumption to reduce their electricity\nbills. Mohsenian-Rad et al propose a daily mechanism for which they prove the\nsocial optimality. Baharlouei et al propose a hourly billing mechanism for\nwhich we give theoretical results: we prove the uniqueness of an equilibrium in\nthe associated game and give an upper bound on its price of anarchy. We\nevaluate numerically the two mechanisms, using real consumption data from Pecan\nStreet Inc. The simulations show that the equilibrium reached with the hourly\nmechanism is socially optimal up to 0.1%, and that it achieves an important\nfairness property according to a quantitative indicator we define. We observe\nthat the two DSM mechanisms avoid the synchronization effect induced by non-\ngame theoretic mechanisms, e.g. Peak/OffPeak hours contracts.",
    "published_date": "2017-11-29T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.11129v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.11066v2",
    "title": "Paradoxes in Fair Computer-Aided Decision Making",
    "authors": [
      "Andrew Morgan",
      "Rafael Pass"
    ],
    "author_ids": [],
    "abstract": "Computer-aided decision making--where a human decision-maker is aided by a\ncomputational classifier in making a decision--is becoming increasingly\nprevalent. For instance, judges in at least nine states make use of algorithmic\ntools meant to determine \"recidivism risk scores\" for criminal defendants in\nsentencing, parole, or bail decisions. A subject of much recent debate is\nwhether such algorithmic tools are \"fair\" in the sense that they do not\ndiscriminate against certain groups (e.g., races) of people.\n  Our main result shows that for \"non-trivial\" computer-aided decision making,\neither the classifier must be discriminatory, or a rational decision-maker\nusing the output of the classifier is forced to be discriminatory. We further\nprovide a complete characterization of situations where fair computer-aided\ndecision making is possible.",
    "published_date": "2017-11-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.11066v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.10925v4",
    "title": "Deep Image Prior",
    "authors": [
      "Dmitry Ulyanov",
      "Andrea Vedaldi",
      "Victor Lempitsky"
    ],
    "author_ids": [],
    "abstract": "Deep convolutional networks have become a popular tool for image generation\nand restoration. Generally, their excellent performance is imputed to their\nability to learn realistic image priors from a large number of example images.\nIn this paper, we show that, on the contrary, the structure of a generator\nnetwork is sufficient to capture a great deal of low-level image statistics\nprior to any learning. In order to do so, we show that a randomly-initialized\nneural network can be used as a handcrafted prior with excellent results in\nstandard inverse problems such as denoising, super-resolution, and inpainting.\nFurthermore, the same prior can be used to invert deep neural representations\nto diagnose them, and to restore images based on flash-no flash input pairs.\n  Apart from its diverse applications, our approach highlights the inductive\nbias captured by standard generator network architectures. It also bridges the\ngap between two very popular families of image restoration methods:\nlearning-based methods using deep convolutional networks and learning-free\nmethods based on handcrafted image priors such as self-similarity. Code and\nsupplementary material are available at\nhttps://dmitryulyanov.github.io/deep_image_prior .",
    "published_date": "2017-11-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.10925v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.10708v1",
    "title": "Proceedings 10th Interaction and Concurrency Experience",
    "authors": [
      "Massimo Bartoletti",
      "Laura Bocchi",
      "Ludovic Henrio",
      "Sophia Knight"
    ],
    "author_ids": [],
    "abstract": "This volume contains the proceedings of ICE 2017, the 10th Interaction and\nConcurrency Experience, which was held in Neuch\\^atel, Switzerland on the 21st\nand 22nd of June 2017 as a satellite event of DisCoTec'17.\n  The ICE procedure for paper selection allows PC members to interact,\nanonymously, with authors. During the review phase, each submitted paper is\npublished on a discussion forum whose access is restricted to the authors and\nto all the PC members not declaring a conflict of interest. The PC members post\ncomments and questions that the authors reply to. For the first time, the 2017\nedition of ICE included a double blind reviewing of original research papers,\nin order to increase fairness and avoid bias in reviewing. The gender balance\nof accepted papers was also more even than in past years.\n  Each paper was reviewed by three PC members, and altogether five papers were\naccepted for publication (the workshop also featured five brief announcements\nwhich are not part of this volume). We were proud to host three invited talks,\nby Christian Cachin, Marieke Huismann, and Pawe{\\l} Sobocinski. The abstracts\nof these talks are included in this volume together with the regular papers.",
    "published_date": "2017-11-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO",
      "cs.PL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.10708v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.10352v4",
    "title": "Learning Face Age Progression: A Pyramid Architecture of GANs",
    "authors": [
      "Hongyu Yang",
      "Di Huang",
      "Yunhong Wang",
      "Anil K. Jain"
    ],
    "author_ids": [],
    "abstract": "The two underlying requirements of face age progression, i.e. aging accuracy\nand identity permanence, are not well studied in the literature. In this paper,\nwe present a novel generative adversarial network based approach. It separately\nmodels the constraints for the intrinsic subject-specific characteristics and\nthe age-specific facial changes with respect to the elapsed time, ensuring that\nthe generated faces present desired aging effects while simultaneously keeping\npersonalized properties stable. Further, to generate more lifelike facial\ndetails, high-level age-specific features conveyed by the synthesized face are\nestimated by a pyramidal adversarial discriminator at multiple scales, which\nsimulates the aging effects in a finer manner. The proposed method is\napplicable to diverse face samples in the presence of variations in pose,\nexpression, makeup, etc., and remarkably vivid aging effects are achieved. Both\nvisual fidelity and quantitative evaluations show that the approach advances\nthe state-of-the-art.",
    "published_date": "2017-11-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.10352v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.10282v2",
    "title": "Learning from Between-class Examples for Deep Sound Recognition",
    "authors": [
      "Yuji Tokozume",
      "Yoshitaka Ushiku",
      "Tatsuya Harada"
    ],
    "author_ids": [],
    "abstract": "Deep learning methods have achieved high performance in sound recognition\ntasks. Deciding how to feed the training data is important for further\nperformance improvement. We propose a novel learning method for deep sound\nrecognition: Between-Class learning (BC learning). Our strategy is to learn a\ndiscriminative feature space by recognizing the between-class sounds as\nbetween-class sounds. We generate between-class sounds by mixing two sounds\nbelonging to different classes with a random ratio. We then input the mixed\nsound to the model and train the model to output the mixing ratio. The\nadvantages of BC learning are not limited only to the increase in variation of\nthe training data; BC learning leads to an enlargement of Fisher's criterion in\nthe feature space and a regularization of the positional relationship among the\nfeature distributions of the classes. The experimental results show that BC\nlearning improves the performance on various sound recognition networks,\ndatasets, and data augmentation schemes, in which BC learning proves to be\nalways beneficial. Furthermore, we construct a new deep sound recognition\nnetwork (EnvNet-v2) and train it with BC learning. As a result, we achieved a\nperformance surpasses the human level.",
    "published_date": "2017-11-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.10282v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.09535v3",
    "title": "Learning with Biased Complementary Labels",
    "authors": [
      "Xiyu Yu",
      "Tongliang Liu",
      "Mingming Gong",
      "Dacheng Tao"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study the classification problem in which we have access to\neasily obtainable surrogate for true labels, namely complementary labels, which\nspecify classes that observations do \\textbf{not} belong to. Let $Y$ and\n$\\bar{Y}$ be the true and complementary labels, respectively. We first model\nthe annotation of complementary labels via transition probabilities\n$P(\\bar{Y}=i|Y=j), i\\neq j\\in\\{1,\\cdots,c\\}$, where $c$ is the number of\nclasses. Previous methods implicitly assume that $P(\\bar{Y}=i|Y=j), \\forall\ni\\neq j$, are identical, which is not true in practice because humans are\nbiased toward their own experience. For example, as shown in Figure 1, if an\nannotator is more familiar with monkeys than prairie dogs when providing\ncomplementary labels for meerkats, she is more likely to employ \"monkey\" as a\ncomplementary label. We therefore reason that the transition probabilities will\nbe different. In this paper, we propose a framework that contributes three main\ninnovations to learning with \\textbf{biased} complementary labels: (1) It\nestimates transition probabilities with no bias. (2) It provides a general\nmethod to modify traditional loss functions and extends standard deep neural\nnetwork classifiers to learn with biased complementary labels. (3) It\ntheoretically ensures that the classifier learned with complementary labels\nconverges to the optimal one learned with true labels. Comprehensive\nexperiments on several benchmark datasets validate the superiority of our\nmethod to current state-of-the-art methods.",
    "published_date": "2017-11-27T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.09535v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.09472v1",
    "title": "Community detection algorithm evaluation with ground-truth data",
    "authors": [
      "Jebabli Malek",
      "Cherifi Hocine",
      "Cherifi Chantal",
      "Hamouda Atef"
    ],
    "author_ids": [],
    "abstract": "Community structure is of paramount importance for the understanding of\ncomplex networks. Consequently, there is a tremendous effort in order to\ndevelop efficient community detection algorithms. Unfortunately, the issue of a\nfair assessment of these algorithms is a thriving open question. If the\nground-truth community structure is available, various clustering-based metrics\nare used in order to compare it versus the one discovered by these algorithms.\nHowever, these metrics defined at the node level are fairly insensitive to the\nvariation of the overall community structure. To overcome these limitations, we\npropose to exploit the topological features of the 'community graphs' (where\nthe nodes are the communities and the links represent their interactions) in\norder to evaluate the algorithms. To illustrate our methodology, we conduct a\ncomprehensive analysis of overlapping community detection algorithms using a\nset of real-world networks with known a priori community structure. Results\nprovide a better perception of their relative performance as compared to\nclassical metrics. Moreover, they show that more emphasis should be put on the\ntopology of the community structure. We also investigate the relationship\nbetween the topological properties of the community structure and the\nalternative evaluation measures (quality metrics and clustering metrics). It\nappears clearly that they present different views of the community structure\nand that they must be combined in order to evaluate the effectiveness of\ncommunity detection algorithms.",
    "published_date": "2017-11-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.09472v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.09050v1",
    "title": "Ethical Challenges in Data-Driven Dialogue Systems",
    "authors": [
      "Peter Henderson",
      "Koustuv Sinha",
      "Nicolas Angelard-Gontier",
      "Nan Rosemary Ke",
      "Genevieve Fried",
      "Ryan Lowe",
      "Joelle Pineau"
    ],
    "author_ids": [],
    "abstract": "The use of dialogue systems as a medium for human-machine interaction is an\nincreasingly prevalent paradigm. A growing number of dialogue systems use\nconversation strategies that are learned from large datasets. There are well\ndocumented instances where interactions with these system have resulted in\nbiased or even offensive conversations due to the data-driven training process.\nHere, we highlight potential ethical issues that arise in dialogue systems\nresearch, including: implicit biases in data-driven systems, the rise of\nadversarial examples, potential sources of privacy violations, safety concerns,\nspecial considerations for reinforcement learning systems, and reproducibility\nconcerns. We also suggest areas stemming from these issues that deserve further\ninvestigation. Through this initial survey, we hope to spur research leading to\nrobust, safe, and ethically sound dialogue systems.",
    "published_date": "2017-11-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.09050v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.08801v1",
    "title": "Server, server in the cloud. Who is the fairest in the crowd?",
    "authors": [
      "Marc Böhlen",
      "Varun Chandola",
      "Amol Salunkhe"
    ],
    "author_ids": [],
    "abstract": "This paper follows the recent history of automated beauty competitions to\ndiscuss how machine learning techniques, in particular neural networks, alter\nthe way attractiveness is handled and how this impacts the cultural landscape.\nWe describe experiments performed to probe the behavior of two different\nconvolutional neural network architectures in the classification of facial\nattractiveness in a large database of celebrity faces. As opposed to other\neasily definable facial features, attractiveness is difficult to detect\nrobustly even for the best classification systems. Based on the observations\nfrom these experiments, we discuss several approaches to detect factors that\ncome into play when a machine evaluates human features, and how bias can occur\nnot only in data selection but in network architectures; in multiple forms on\nmultiple levels throughout the process. The overall goal is to map out with\nmixed methods a novel condition: slippages produced by platform level machine\nlearning systems that make judgements in domains considered dependent on high\nlevel human intelligence.",
    "published_date": "2017-11-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.08801v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.08690v2",
    "title": "Attended End-to-end Architecture for Age Estimation from Facial Expression Videos",
    "authors": [
      "Wenjie Pei",
      "Hamdi Dibeklioğlu",
      "Tadas Baltrušaitis",
      "David M. J. Tax"
    ],
    "author_ids": [],
    "abstract": "The main challenges of age estimation from facial expression videos lie not\nonly in the modeling of the static facial appearance, but also in the capturing\nof the temporal facial dynamics. Traditional techniques to this problem focus\non constructing handcrafted features to explore the discriminative information\ncontained in facial appearance and dynamics separately. This relies on\nsophisticated feature-refinement and framework-design. In this paper, we\npresent an end-to-end architecture for age estimation, called Spatially-Indexed\nAttention Model (SIAM), which is able to simultaneously learn both the\nappearance and dynamics of age from raw videos of facial expressions.\nSpecifically, we employ convolutional neural networks to extract effective\nlatent appearance representations and feed them into recurrent networks to\nmodel the temporal dynamics. More importantly, we propose to leverage attention\nmodels for salience detection in both the spatial domain for each single image\nand the temporal domain for the whole video as well. We design a specific\nspatially-indexed attention mechanism among the convolutional layers to extract\nthe salient facial regions in each individual image, and a temporal attention\nlayer to assign attention weights to each frame. This two-pronged approach not\nonly improves the performance by allowing the model to focus on informative\nframes and facial areas, but it also offers an interpretable correspondence\nbetween the spatial facial regions as well as temporal frames, and the task of\nage estimation. We demonstrate the strong performance of our model in\nexperiments on a large, gender-balanced database with 400 subjects with ages\nspanning from 8 to 76 years. Experiments reveal that our model exhibits\nsignificant superiority over the state-of-the-art methods given sufficient\ntraining data.",
    "published_date": "2017-11-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.08690v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.08513v2",
    "title": "Calibration for the (Computationally-Identifiable) Masses",
    "authors": [
      "Úrsula Hébert-Johnson",
      "Michael P. Kim",
      "Omer Reingold",
      "Guy N. Rothblum"
    ],
    "author_ids": [],
    "abstract": "As algorithms increasingly inform and influence decisions made about\nindividuals, it becomes increasingly important to address concerns that these\nalgorithms might be discriminatory. The output of an algorithm can be\ndiscriminatory for many reasons, most notably: (1) the data used to train the\nalgorithm might be biased (in various ways) to favor certain populations over\nothers; (2) the analysis of this training data might inadvertently or\nmaliciously introduce biases that are not borne out in the data. This work\nfocuses on the latter concern.\n  We develop and study multicalbration -- a new measure of algorithmic fairness\nthat aims to mitigate concerns about discrimination that is introduced in the\nprocess of learning a predictor from data. Multicalibration guarantees accurate\n(calibrated) predictions for every subpopulation that can be identified within\na specified class of computations. We think of the class as being quite rich;\nin particular, it can contain many overlapping subgroups of a protected group.\n  We show that in many settings this strong notion of protection from\ndiscrimination is both attainable and aligned with the goal of obtaining\naccurate predictions. Along the way, we present new algorithms for learning a\nmulticalibrated predictor, study the computational complexity of this task, and\ndraw new connections to computational learning models such as agnostic\nlearning.",
    "published_date": "2017-11-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.08513v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.08155v1",
    "title": "A Face Fairness Framework for 3D Meshes",
    "authors": [
      "Sk. Mohammadul Haque",
      "Venu Madhav Govindu"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a face fairness framework for 3D meshes that\npreserves the regular shape of faces and is applicable to a variety of 3D mesh\nrestoration tasks. Specifically, we present a number of desirable properties\nfor any mesh restoration method and show that our framework satisfies them. We\nthen apply our framework to two different tasks --- mesh-denoising and\nmesh-refinement, and present comparative results for these two tasks showing\nimprovement over other relevant methods in the literature.",
    "published_date": "2017-11-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.08155v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.07414v2",
    "title": "The Promise and Peril of Human Evaluation for Model Interpretability",
    "authors": [
      "Bernease Herman"
    ],
    "author_ids": [],
    "abstract": "Transparency, user trust, and human comprehension are popular ethical\nmotivations for interpretable machine learning. In support of these goals,\nresearchers evaluate model explanation performance using humans and real world\napplications. This alone presents a challenge in many areas of artificial\nintelligence. In this position paper, we propose a distinction between\ndescriptive and persuasive explanations. We discuss reasoning suggesting that\nfunctional interpretability may be correlated with cognitive function and user\npreferences. If this is indeed the case, evaluation and optimization using\nfunctional metrics could perpetuate implicit cognitive bias in explanations\nthat threaten transparency. Finally, we propose two potential research\ndirections to disambiguate cognitive function and explanation models, retaining\ncontrol over the tradeoff between accuracy and interpretability.",
    "published_date": "2017-11-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.07414v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.07112v2",
    "title": "Deletion-Robust Submodular Maximization at Scale",
    "authors": [
      "Ehsan Kazemi",
      "Morteza Zadimoghaddam",
      "Amin Karbasi"
    ],
    "author_ids": [],
    "abstract": "Can we efficiently extract useful information from a large user-generated\ndataset while protecting the privacy of the users and/or ensuring fairness in\nrepresentation. We cast this problem as an instance of a deletion-robust\nsubmodular maximization where part of the data may be deleted due to privacy\nconcerns or fairness criteria. We propose the first memory-efficient\ncentralized, streaming, and distributed methods with constant-factor\napproximation guarantees against any number of adversarial deletions. We\nextensively evaluate the performance of our algorithms against prior\nstate-of-the-art on real-world applications, including (i) Uber-pick up\nlocations with location privacy constraints; (ii) feature selection with\nfairness constraints for income prediction and crime rate prediction; and (iii)\nrobust to deletion summarization of census data, consisting of 2,458,285\nfeature vectors.",
    "published_date": "2017-11-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.07112v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.07111v1",
    "title": "Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions",
    "authors": [
      "Marisa Vasconcelos",
      "Carlos Cardonha",
      "Bernardo Gonçalves"
    ],
    "author_ids": [],
    "abstract": "Artificial Intelligence (AI) has been used extensively in automatic decision\nmaking in a broad variety of scenarios, ranging from credit ratings for loans\nto recommendations of movies. Traditional design guidelines for AI models focus\nessentially on accuracy maximization, but recent work has shown that\neconomically irrational and socially unacceptable scenarios of discrimination\nand unfairness are likely to arise unless these issues are explicitly\naddressed. This undesirable behavior has several possible sources, such as\nbiased datasets used for training that may not be detected in black-box models.\nAfter pointing out connections between such bias of AI and the problem of\ninduction, we focus on Popper's contributions after Hume's, which offer a\nlogical theory of preferences. An AI model can be preferred over others on\npurely rational grounds after one or more attempts at refutation based on\naccuracy and fairness. Inspired by such epistemological principles, this paper\nproposes a structured approach to mitigate discrimination and unfairness caused\nby bias in AI systems. In the proposed computational framework, models are\nselected and enhanced after attempts at refutation. To illustrate our\ndiscussion, we focus on hiring decision scenarios where an AI system filters in\nwhich job applicants should go to the interview phase.",
    "published_date": "2017-11-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.07111v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.07077v4",
    "title": "Estimation Considerations in Contextual Bandits",
    "authors": [
      "Maria Dimakopoulou",
      "Zhengyuan Zhou",
      "Susan Athey",
      "Guido Imbens"
    ],
    "author_ids": [],
    "abstract": "Contextual bandit algorithms are sensitive to the estimation method of the\noutcome model as well as the exploration method used, particularly in the\npresence of rich heterogeneity or complex outcome models, which can lead to\ndifficult estimation problems along the path of learning. We study a\nconsideration for the exploration vs. exploitation framework that does not\narise in multi-armed bandits but is crucial in contextual bandits; the way\nexploration and exploitation is conducted in the present affects the bias and\nvariance in the potential outcome model estimation in subsequent stages of\nlearning. We develop parametric and non-parametric contextual bandits that\nintegrate balancing methods from the causal inference literature in their\nestimation to make it less prone to problems of estimation bias. We provide the\nfirst regret bound analyses for contextual bandits with balancing in the domain\nof linear contextual bandits that match the state of the art regret bounds. We\ndemonstrate the strong practical advantage of balanced contextual bandits on a\nlarge number of supervised learning datasets and on a synthetic example that\nsimulates model mis-specification and prejudice in the initial training data.\nAdditionally, we develop contextual bandits with simpler assignment policies by\nleveraging sparse model estimation methods from the econometrics literature and\ndemonstrate empirically that in the early stages they can improve the rate of\nlearning and decrease regret.",
    "published_date": "2017-11-19T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.07077v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.07076v3",
    "title": "Does mitigating ML's impact disparity require treatment disparity?",
    "authors": [
      "Zachary C. Lipton",
      "Alexandra Chouldechova",
      "Julian McAuley"
    ],
    "author_ids": [],
    "abstract": "Following related work in law and policy, two notions of disparity have come\nto shape the study of fairness in algorithmic decision-making. Algorithms\nexhibit treatment disparity if they formally treat members of protected\nsubgroups differently; algorithms exhibit impact disparity when outcomes differ\nacross subgroups, even if the correlation arises unintentionally. Naturally, we\ncan achieve impact parity through purposeful treatment disparity. In one thread\nof technical work, papers aim to reconcile the two forms of parity proposing\ndisparate learning processes (DLPs). Here, the learning algorithm can see group\nmembership during training but produce a classifier that is group-blind at test\ntime. In this paper, we show theoretically that: (i) When other features\ncorrelate to group membership, DLPs will (indirectly) implement treatment\ndisparity, undermining the policy desiderata they are designed to address; (ii)\nWhen group membership is partly revealed by other features, DLPs induce\nwithin-class discrimination; and (iii) In general, DLPs provide a suboptimal\ntrade-off between accuracy and impact parity. Based on our technical analysis,\nwe argue that transparent treatment disparity is preferable to occluded methods\nfor achieving impact parity. Experimental results on several real-world\ndatasets highlight the practical consequences of applying DLPs vs. per-group\nthresholds.",
    "published_date": "2017-11-19T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.07076v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06867v2",
    "title": "From Common to Special: When Multi-Attribute Learning Meets Personalized Opinions",
    "authors": [
      "Zhiyong Yang",
      "Qianqian Xu",
      "Xiaochun Cao",
      "Qingming Huang"
    ],
    "author_ids": [],
    "abstract": "Visual attributes, which refer to human-labeled semantic annotations, have\ngained increasing popularity in a wide range of real world applications.\nGenerally, the existing attribute learning methods fall into two categories:\none focuses on learning user-specific labels separately for different\nattributes, while the other one focuses on learning crowd-sourced global labels\njointly for multiple attributes. However, both categories ignore the joint\neffect of the two mentioned factors: the personal diversity with respect to the\nglobal consensus; and the intrinsic correlation among multiple attributes. To\novercome this challenge, we propose a novel model to learn user-specific\npredictors across multiple attributes. In our proposed model, the diversity of\npersonalized opinions and the intrinsic relationship among multiple attributes\nare unified in a common-to-special manner. To this end, we adopt a\nthree-component decomposition. Specifically, our model integrates a common\ncognition factor, an attribute-specific bias factor and a user-specific bias\nfactor. Meanwhile Lasso and group Lasso penalties are adopted to leverage\nefficient feature selection. Furthermore, theoretical analysis is conducted to\nshow that our proposed method could reach reasonable performance. Eventually,\nthe empirical study carried out in this paper demonstrates the effectiveness of\nour proposed method.",
    "published_date": "2017-11-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06867v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06664v3",
    "title": "Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer",
    "authors": [
      "David Madras",
      "Toniann Pitassi",
      "Richard Zemel"
    ],
    "author_ids": [],
    "abstract": "In many machine learning applications, there are multiple decision-makers\ninvolved, both automated and human. The interaction between these agents often\ngoes unaddressed in algorithmic development. In this work, we explore a simple\nversion of this interaction with a two-stage framework containing an automated\nmodel and an external decision-maker. The model can choose to say \"Pass\", and\npass the decision downstream, as explored in rejection learning. We extend this\nconcept by proposing \"learning to defer\", which generalizes rejection learning\nby considering the effect of other agents in the decision-making process. We\npropose a learning algorithm which accounts for potential biases held by\nexternal decision-makers in a system. Experiments demonstrate that learning to\ndefer can make systems not only more accurate but also less biased. Even when\nworking with inconsistent or biased users, we show that deferring models still\ngreatly improve the accuracy and/or fairness of the entire system.",
    "published_date": "2017-11-17T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06664v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06491v18",
    "title": "High-resolution Deep Convolutional Generative Adversarial Networks",
    "authors": [
      "J. D. Curtó",
      "I. C. Zarza",
      "Fernando de la Torre",
      "Irwin King",
      "Michael R. Lyu"
    ],
    "author_ids": [],
    "abstract": "Generative Adversarial Networks (GANs) [Goodfellow et al. 2014] convergence\nin a high-resolution setting with a computational constrain of GPU memory\ncapacity has been beset with difficulty due to the known lack of convergence\nrate stability. In order to boost network convergence of DCGAN (Deep\nConvolutional Generative Adversarial Networks) [Radford et al. 2016] and\nachieve good-looking high-resolution results we propose a new layered network,\nHDCGAN, that incorporates current state-of-the-art techniques for this effect.\nGlasses, a mechanism to arbitrarily improve the final GAN generated results by\nenlarging the input size by a telescope {\\zeta} is also presented. A novel\nbias-free dataset, Curt\\'o & Zarza, containing human faces from different\nethnical groups in a wide variety of illumination conditions and image\nresolutions is introduced. Curt\\'o is enhanced with HDCGAN synthetic images,\nthus being the first GAN augmented dataset of faces. We conduct extensive\nexperiments on CelebA [Liu et al. 2015], CelebA-hq [Karras et al. 2018] and\nCurt\\'o. HDCGAN is the current state-of-the-art in synthetic image generation\non CelebA achieving a MS-SSIM of 0.1978 and a FR\\'ECHET Inception Distance of\n8.44.",
    "published_date": "2017-11-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06491v18",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06451v1",
    "title": "A Fusion-based Gender Recognition Method Using Facial Images",
    "authors": [
      "Benyamin Ghojogh",
      "Saeed Bagheri Shouraki",
      "Hoda Mohammadzade",
      "Ensieh Iranmehr"
    ],
    "author_ids": [],
    "abstract": "This paper proposes a fusion-based gender recognition method which uses\nfacial images as input. Firstly, this paper utilizes pre-processing and a\nlandmark detection method in order to find the important landmarks of faces.\nThereafter, four different frameworks are proposed which are inspired by\nstate-of-the-art gender recognition systems. The first framework extracts\nfeatures using Local Binary Pattern (LBP) and Principal Component Analysis\n(PCA) and uses back propagation neural network. The second framework uses Gabor\nfilters, PCA, and kernel Support Vector Machine (SVM). The third framework uses\nlower part of faces as input and classifies them using kernel SVM. The fourth\nframework uses Linear Discriminant Analysis (LDA) in order to classify the side\noutline landmarks of faces. Finally, the four decisions of frameworks are fused\nusing weighted voting. This paper takes advantage of both texture and\ngeometrical information, the two dominant types of information in facial gender\nrecognition. Experimental results show the power and effectiveness of the\nproposed method. This method obtains recognition rate of 94% for neutral faces\nof FEI face dataset, which is equal to state-of-the-art rate for this dataset.",
    "published_date": "2017-11-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06451v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06396v1",
    "title": "VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection",
    "authors": [
      "Yin Zhou",
      "Oncel Tuzel"
    ],
    "author_ids": [],
    "abstract": "Accurate detection of objects in 3D point clouds is a central problem in many\napplications, such as autonomous navigation, housekeeping robots, and\naugmented/virtual reality. To interface a highly sparse LiDAR point cloud with\na region proposal network (RPN), most existing efforts have focused on\nhand-crafted feature representations, for example, a bird's eye view\nprojection. In this work, we remove the need of manual feature engineering for\n3D point clouds and propose VoxelNet, a generic 3D detection network that\nunifies feature extraction and bounding box prediction into a single stage,\nend-to-end trainable deep network. Specifically, VoxelNet divides a point cloud\ninto equally spaced 3D voxels and transforms a group of points within each\nvoxel into a unified feature representation through the newly introduced voxel\nfeature encoding (VFE) layer. In this way, the point cloud is encoded as a\ndescriptive volumetric representation, which is then connected to a RPN to\ngenerate detections. Experiments on the KITTI car detection benchmark show that\nVoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a\nlarge margin. Furthermore, our network learns an effective discriminative\nrepresentation of objects with various geometries, leading to encouraging\nresults in 3D detection of pedestrians and cyclists, based on only LiDAR.",
    "published_date": "2017-11-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06396v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.06035v1",
    "title": "From Algorithmic Black Boxes to Adaptive White Boxes: Declarative Decision-Theoretic Ethical Programs as Codes of Ethics",
    "authors": [
      "Martijn van Otterlo"
    ],
    "author_ids": [],
    "abstract": "Ethics of algorithms is an emerging topic in various disciplines such as\nsocial science, law, and philosophy, but also artificial intelligence (AI). The\nvalue alignment problem expresses the challenge of (machine) learning values\nthat are, in some way, aligned with human requirements or values. In this paper\nI argue for looking at how humans have formalized and communicated values, in\nprofessional codes of ethics, and for exploring declarative decision-theoretic\nethical programs (DDTEP) to formalize codes of ethics. This renders machine\nethical reasoning and decision-making, as well as learning, more transparent\nand hopefully more accountable. The paper includes proof-of-concept examples of\nknown toy dilemmas and gatekeeping domains such as archives and libraries.",
    "published_date": "2017-11-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.06035v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05905v1",
    "title": "Using experimental game theory to transit human values to ethical AI",
    "authors": [
      "Yijia Wang",
      "Yan Wan",
      "Zhijian Wang"
    ],
    "author_ids": [],
    "abstract": "Knowing the reflection of game theory and ethics, we develop a mathematical\nrepresentation to bridge the gap between the concepts in moral philosophy\n(e.g., Kantian and Utilitarian) and AI ethics industry technology standard\n(e.g., IEEE P7000 standard series for Ethical AI). As an application, we\ndemonstrate how human value can be obtained from the experimental game theory\n(e.g., trust game experiment) so as to build an ethical AI. Moreover, an\napproach to test the ethics (rightness or wrongness) of a given AI algorithm by\nusing an iterated Prisoner's Dilemma Game experiment is discussed as an\nexample. Compared with existing mathematical frameworks and testing method on\nAI ethics technology, the advantages of the proposed approach are analyzed.",
    "published_date": "2017-11-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05905v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05820v2",
    "title": "Zero-Shot Learning via Class-Conditioned Deep Generative Models",
    "authors": [
      "Wenlin Wang",
      "Yunchen Pu",
      "Vinay Kumar Verma",
      "Kai Fan",
      "Yizhe Zhang",
      "Changyou Chen",
      "Piyush Rai",
      "Lawrence Carin"
    ],
    "author_ids": [],
    "abstract": "We present a deep generative model for learning to predict classes not seen\nat training time. Unlike most existing methods for this problem, that represent\neach class as a point (via a semantic embedding), we represent each seen/unseen\nclass using a class-specific latent-space distribution, conditioned on class\nattributes. We use these latent-space distributions as a prior for a supervised\nvariational autoencoder (VAE), which also facilitates learning highly\ndiscriminative feature representations for the inputs. The entire framework is\nlearned end-to-end using only the seen-class training data. The model infers\ncorresponding attributes of a test image by maximizing the VAE lower bound; the\ninferred attributes may be linked to labels not seen when training. We further\nextend our model to a (1) semi-supervised/transductive setting by leveraging\nunlabeled unseen-class data via an unsupervised learning module, and (2)\nfew-shot learning where we also have a small number of labeled inputs from the\nunseen classes. We compare our model with several state-of-the-art methods\nthrough a comprehensive set of experiments on a variety of benchmark data sets.",
    "published_date": "2017-11-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05820v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05791v2",
    "title": "Maintaining The Humanity of Our Models",
    "authors": [
      "Umang Bhatt"
    ],
    "author_ids": [],
    "abstract": "Artificial intelligence and machine learning have been major research\ninterests in computer science for the better part of the last few decades.\nHowever, all too recently, both AI and ML have rapidly grown to be media\nfrenzies, pressuring companies and researchers to claim they use these\ntechnologies. As ML continues to percolate into daily life, we, as computer\nscientists and machine learning researchers, are responsible for ensuring we\nclearly convey the extent of our work and the humanity of our models.\nRegularizing ML for mass adoption requires a rigorous standard for model\ninterpretability, a deep consideration for human bias in data, and a\ntransparent understanding of a model's societal effects.",
    "published_date": "2017-11-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05791v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05535v4",
    "title": "Dual-Path Convolutional Image-Text Embeddings with Instance Loss",
    "authors": [
      "Zhedong Zheng",
      "Liang Zheng",
      "Michael Garrett",
      "Yi Yang",
      "Mingliang Xu",
      "Yi-Dong Shen"
    ],
    "author_ids": [],
    "abstract": "Matching images and sentences demands a fine understanding of both\nmodalities. In this paper, we propose a new system to discriminatively embed\nthe image and text to a shared visual-textual space. In this field, most\nexisting works apply the ranking loss to pull the positive image / text pairs\nclose and push the negative pairs apart from each other. However, directly\ndeploying the ranking loss is hard for network learning, since it starts from\nthe two heterogeneous features to build inter-modal relationship. To address\nthis problem, we propose the instance loss which explicitly considers the\nintra-modal data distribution. It is based on an unsupervised assumption that\neach image / text group can be viewed as a class. So the network can learn the\nfine granularity from every image/text group. The experiment shows that the\ninstance loss offers better weight initialization for the ranking loss, so that\nmore discriminative embeddings can be learned. Besides, existing works usually\napply the off-the-shelf features, i.e., word2vec and fixed visual feature. So\nin a minor contribution, this paper constructs an end-to-end dual-path\nconvolutional network to learn the image and text representations. End-to-end\nlearning allows the system to directly learn from the data and fully utilize\nthe supervision. On two generic retrieval datasets (Flickr30k and MSCOCO),\nexperiments demonstrate that our method yields competitive accuracy compared to\nstate-of-the-art methods. Moreover, in language based person retrieval, we\nimprove the state of the art by a large margin. The code has been made publicly\navailable.",
    "published_date": "2017-11-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05535v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05486v3",
    "title": "A Lie bracket approximation approach to distributed optimization over directed graphs",
    "authors": [
      "Simon Michalowsky",
      "Bahman Gharesifard",
      "Christian Ebenbauer"
    ],
    "author_ids": [],
    "abstract": "We consider a group of computation units trying to cooperatively solve a\ndistributed optimization problem with shared linear equality and inequality\nconstraints. Assuming that the computation units are communicating over a\nnetwork whose topology is described by a time-invariant directed graph, by\ncombining saddle-point dynamics with Lie bracket approximation techniques we\nderive a methodology that allows to design distributed continuous-time\noptimization algorithms that solve this problem under minimal assumptions on\nthe graph topology as well as on the structure of the constraints. We discuss\nseveral extensions as well as special cases in which the proposed procedure\nbecomes particularly simple.",
    "published_date": "2017-11-15T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05486v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.05482v1",
    "title": "Efficient Estimation of Generalization Error and Bias-Variance Components of Ensembles",
    "authors": [
      "Dhruv Mahajan",
      "Vivek Gupta",
      "S Sathiya Keerthi",
      "Sellamanickam Sundararajan",
      "Shravan Narayanamurthy",
      "Rahul Kidambi"
    ],
    "author_ids": [],
    "abstract": "For many applications, an ensemble of base classifiers is an effective\nsolution. The tuning of its parameters(number of classes, amount of data on\nwhich each classifier is to be trained on, etc.) requires G, the generalization\nerror of a given ensemble. The efficient estimation of G is the focus of this\npaper. The key idea is to approximate the variance of the class\nscores/probabilities of the base classifiers over the randomness imposed by the\ntraining subset by normal/beta distribution at each point x in the input\nfeature space. We estimate the parameters of the distribution using a small set\nof randomly chosen base classifiers and use those parameters to give efficient\nestimation schemes for G. We give empirical evidence for the quality of the\nvarious estimators. We also demonstrate their usefulness in making design\nchoices such as the number of classifiers in the ensemble and the size of a\nsubset of data used for training that is needed to achieve a certain value of\ngeneralization error. Our approach also has great potential for designing\ndistributed ensemble classifiers.",
    "published_date": "2017-11-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05482v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.05144v5",
    "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness",
    "authors": [
      "Michael Kearns",
      "Seth Neel",
      "Aaron Roth",
      "Zhiwei Steven Wu"
    ],
    "author_ids": [],
    "abstract": "The most prevalent notions of fairness in machine learning are statistical\ndefinitions: they fix a small collection of pre-defined groups, and then ask\nfor parity of some statistic of the classifier across these groups. Constraints\nof this form are susceptible to intentional or inadvertent \"fairness\ngerrymandering\", in which a classifier appears to be fair on each individual\ngroup, but badly violates the fairness constraint on one or more structured\nsubgroups defined over the protected attributes. We propose instead to demand\nstatistical notions of fairness across exponentially (or infinitely) many\nsubgroups, defined by a structured class of functions over the protected\nattributes. This interpolates between statistical definitions of fairness and\nrecently proposed individual notions of fairness, but raises several\ncomputational challenges. It is no longer clear how to audit a fixed classifier\nto see if it satisfies such a strong definition of fairness. We prove that the\ncomputational problem of auditing subgroup fairness for both equality of false\npositive rates and statistical parity is equivalent to the problem of weak\nagnostic learning, which means it is computationally hard in the worst case,\neven for simple structured subclasses.\n  We then derive two algorithms that provably converge to the best fair\nclassifier, given access to oracles which can solve the agnostic learning\nproblem. The algorithms are based on a formulation of subgroup fairness as a\ntwo-player zero-sum game between a Learner and an Auditor. Our first algorithm\nprovably converges in a polynomial number of steps. Our second algorithm enjoys\nonly provably asymptotic convergence, but has the merit of simplicity and\nfaster per-step computation. We implement the simpler algorithm using linear\nregression as a heuristic oracle, and show that we can effectively both audit\nand learn fair classifiers on real datasets.",
    "published_date": "2017-11-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.05144v5",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.04240v1",
    "title": "Ensuring Liveness Properties of Distributed Systems (A Research Agenda)",
    "authors": [
      "Rob van Glabbeek"
    ],
    "author_ids": [],
    "abstract": "Often fairness assumptions need to be made in order to establish liveness\nproperties of distributed systems, but in many situations these lead to false\nconclusions.\n  This document presents a research agenda aiming at laying the foundations of\na theory of concurrency that is equipped to ensure liveness properties of\ndistributed systems without making fairness assumptions. This theory will\nencompass process algebra, temporal logic and semantic models, as well as\ntreatments of real-time. The agenda also includes developing a methodology that\nallows successful application of this theory to the specification, analysis and\nverification of realistic distributed systems, including routing protocols for\nwireless networks.\n  Contemporary process algebras and temporal logics fail to make distinctions\nbetween systems of which one has a crucial liveness property and the other does\nnot, at least when assuming justness, a strong progress property, but not\nassuming fairness. Setting up an alternative framework involves giving up on\nidentifying strongly bisimilar systems, inventing new induction principles,\ndeveloping new axiomatic bases for process algebras and new congruence formats\nfor operational semantics, and creating new treatments of time and probability.\n  Even simple systems like fair schedulers or mutual exclusion protocols cannot\nbe accurately specified in standard process algebras (or Petri nets) in the\nabsence of fairness assumptions. Hence the work involves the study of adequate\nlanguage or model extensions, and their expressive power.",
    "published_date": "2017-11-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO",
      "F.3.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.04240v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.04066v2",
    "title": "Communication Complexity of Discrete Fair Division",
    "authors": [
      "Benjamin Plaut",
      "Tim Roughgarden"
    ],
    "author_ids": [],
    "abstract": "We initiate the study of the communication complexity of fair division with\nindivisible goods. We focus on some of the most well-studied fairness notions\n(envy-freeness, proportionality, and approximations thereof) and valuation\nclasses (submodular, subadditive and unrestricted). Within these parameters,\nour results completely resolve whether the communication complexity of\ncomputing a fair allocation (or determining that none exist) is polynomial or\nexponential (in the number of goods), for every combination of fairness notion,\nvaluation class, and number of players, for both deterministic and randomized\nprotocols.",
    "published_date": "2017-11-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.04066v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.03115v1",
    "title": "A Cross-Country Comparison of Crowdworker Motivations",
    "authors": [
      "Lisa Posch",
      "Arnim Bleier",
      "Fabian Flöck",
      "Markus Strohmaier"
    ],
    "author_ids": [],
    "abstract": "Crowd employment is a new form of short term employment that has been rapidly\nbecoming a source of income for a vast number of people around the globe. It\ndiffers considerably from more traditional forms of work, yet similar ethical\nand optimization issues arise. One key to tackle such challenges is to\nunderstand what motivates the international crowd workforce. In this work, we\nstudy the motivation of workers involved in one particularly prevalent type of\ncrowd employment: micro-tasks. We report on the results of applying the\nMultidimensional Crowdworker Motivation Scale (MCMS) in ten countries, which\nunveil significant international differences.",
    "published_date": "2017-11-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.03115v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.02880v3",
    "title": "Performance of Balanced Fairness in Resource Pools: A Recursive Approach",
    "authors": [
      "Thomas Bonald",
      "Céline Comte",
      "Fabien Mathieu"
    ],
    "author_ids": [],
    "abstract": "Understanding the performance of a pool of servers is crucial for proper\ndimensioning. One of the main challenges is to take into account the complex\ninteractions between servers that are pooled to process jobs. In particular, a\njob can generally not be processed by any server of the cluster due to various\nconstraints like data locality. In this paper, we represent these constraints\nby some assignment graph between jobs and servers. We present a recursive\napproach to computing performance metrics like mean response times when the\nserver capacities are shared according to balanced fairness. While the\ncomputational cost of these formulas can be exponential in the number of\nservers in the worst case, we illustrate their practical interest by\nintroducing broad classes of pool structures that can be exactly analyzed in\npolynomial time. This extends considerably the class of models for which\nexplicit performance metrics are accessible.",
    "published_date": "2017-11-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.02880v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.02776v3",
    "title": "Fairness and Transmission-Aware Caching and Delivery Policies in OFDMA-Based HetNets",
    "authors": [
      "Sepehr Rezvani",
      "Nader Mokari",
      "Mohammad R. Javan",
      "Eduard A. Jorswieck"
    ],
    "author_ids": [],
    "abstract": "Recently, wireless edge caching has been emerged as a promising technology\nfor future wireless networks to cope with exponentially increasing demands for\nhigh data rate and low latency multimedia services by proactively storing\ncontents at the network edge. Here, we aim to design efficient cache placement\nand delivery strategies for an orthogonal frequency division multiple access\n(OFDMA)-based cache-enabled heterogeneous cellular network (C-HetNet) which\noperates in two separated phases: caching phase (CP) and delivery phase (DP).\nSince guaranteeing fairness among mobile users (MUs) is not well investigated\nin cache-assisted wireless networks, we first propose two delay-based fairness\nschemes called proportional fairness (PF) and min-max fairness (MMF). The PF\nscheme deals with minimizing the total weighted latency of MUs while MMF aims\nat minimizing the maximum latency among them. In the CP, we propose a novel\nproactive fairness and transmission-aware cache placement strategy (CPS)\ncorresponding to each target fairness scheme by exploiting the flexible\nwireless access and backhaul transmission opportunities. Specifically, we\njointly perform the allocation of physical resources as storage and radio, and\nuser association to improve the flexibility of the CPSs. Moreover, In the DP of\neach fairness scheme, an efficient delivery policy is proposed based on the\narrival requests of MUs, CSI, and caching status. Numerical assessments\ndemonstrate that our proposed CPSs outperform the total latency of MUs up to\n27% compared to the conventional baseline popular CPSs.",
    "published_date": "2017-11-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT",
      "90C11",
      "G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.02776v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.02771v2",
    "title": "On the Discrimination-Generalization Tradeoff in GANs",
    "authors": [
      "Pengchuan Zhang",
      "Qiang Liu",
      "Dengyong Zhou",
      "Tao Xu",
      "Xiaodong He"
    ],
    "author_ids": [],
    "abstract": "Generative adversarial training can be generally understood as minimizing\ncertain moment matching loss defined by a set of discriminator functions,\ntypically neural networks. The discriminator set should be large enough to be\nable to uniquely identify the true distribution (discriminative), and also be\nsmall enough to go beyond memorizing samples (generalizable). In this paper, we\nshow that a discriminator set is guaranteed to be discriminative whenever its\nlinear span is dense in the set of bounded continuous functions. This is a very\nmild condition satisfied even by neural networks with a single neuron. Further,\nwe develop generalization bounds between the learned distribution and true\ndistribution under different evaluation metrics. When evaluated with neural\ndistance, our bounds show that generalization is guaranteed as long as the\ndiscriminator set is small enough, regardless of the size of the generator or\nhypothesis set. When evaluated with KL divergence, our bound provides an\nexplanation on the counter-intuitive behaviors of testing likelihood in GAN\ntraining. Our analysis sheds lights on understanding the practical performance\nof GANs.",
    "published_date": "2017-11-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.02771v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.02209v1",
    "title": "Unsupervised Learning of Semantic Audio Representations",
    "authors": [
      "Aren Jansen",
      "Manoj Plakal",
      "Ratheet Pandya",
      "Daniel P. W. Ellis",
      "Shawn Hershey",
      "Jiayang Liu",
      "R. Channing Moore",
      "Rif A. Saurous"
    ],
    "author_ids": [],
    "abstract": "Even in the absence of any explicit semantic annotation, vast collections of\naudio recordings provide valuable information for learning the categorical\nstructure of sounds. We consider several class-agnostic semantic constraints\nthat apply to unlabeled nonspeech audio: (i) noise and translations in time do\nnot change the underlying sound category, (ii) a mixture of two sound events\ninherits the categories of the constituents, and (iii) the categories of events\nin close temporal proximity are likely to be the same or related. Without\nlabels to ground them, these constraints are incompatible with classification\nloss functions. However, they may still be leveraged to identify geometric\ninequalities needed for triplet loss-based training of convolutional neural\nnetworks. The result is low-dimensional embeddings of the input spectrograms\nthat recover 41% and 84% of the performance of their fully-supervised\ncounterparts when applied to downstream query-by-example sound retrieval and\nsound event classification tasks, respectively. Moreover, in\nlimited-supervision settings, our unsupervised embeddings double the\nstate-of-the-art classification performance.",
    "published_date": "2017-11-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.02209v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1711.01834v1",
    "title": "Prophet Secretary: Surpassing the $1-1/e$ Barrier",
    "authors": [
      "Yossi Azar",
      "Ashish Chiplunkar",
      "Haim Kaplan"
    ],
    "author_ids": [],
    "abstract": "In the Prophet Secretary problem, samples from a known set of probability\ndistributions arrive one by one in a uniformly random order, and an algorithm\nmust irrevocably pick one of the samples as soon as it arrives. The goal is to\nmaximize the expected value of the sample picked relative to the expected\nmaximum of the distributions. This is one of the most simple and fundamental\nproblems in online decision making that models the process selling one item to\na sequence of costumers. For a closely related problem called the Prophet\nInequality where the order of the random variables is adversarial, it is known\nthat one can achieve in expectation $1/2$ of the expected maximum, and no\nbetter ratio is possible. For the Prophet Secretary problem, that is, when the\nvariables arrive in a random order, Esfandiari et al.\\ (ESA 2015) showed that\none can actually get $1-1/e$ of the maximum. The $1-1/e$ bound was recently\nextended to more general settings (Ehsani et al., 2017). Given these results,\none might be tempted to believe that $1-1/e$ is the correct bound. We show that\nthis is not the case by providing an algorithm for the Prophet Secretary\nproblem that beats the $1-1/e$ bound and achieves $1-1/e+1/400$ of the optimum\nvalue. We also prove a hardness result on the performance of algorithms under a\nnatural restriction which we call deterministic distribution-insensitivity.",
    "published_date": "2017-11-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.01834v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.01401v1",
    "title": "Tighter Einstein-Podolsky-Rosen steering inequality based on the sum uncertainty relation",
    "authors": [
      "Ananda G. Maity",
      "Shounak Datta",
      "A. S. Majumdar"
    ],
    "author_ids": [],
    "abstract": "We consider the uncertainty bound on the sum of variances of two incompatible\nobservables in order to derive a corresponding steering inequality. Our\nsteering criterion when applied to discrete variables yields the optimum\nsteering range for two qubit Werner states in the two measurement and two\noutcome scenario. We further employ the derived steering relation for several\nclasses of continuous variable systems. We show that non-Gaussian entangled\nstates such as the photon subtracted squeezed vacuum state and the\ntwo-dimensional harmonic oscillator state furnish greater violation of the sum\nsteering relation compared to the Reid criterion as well as the entropic\nsteering criterion. The sum steering inequality provides a tighter steering\ncondition to reveal the steerability of continuous variable states.",
    "published_date": "2017-11-04T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.01401v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1711.00748v3",
    "title": "Geometric k-nearest neighbor estimation of entropy and mutual information",
    "authors": [
      "Warren M. Lord",
      "Jie Sun",
      "Erik M. Bollt"
    ],
    "author_ids": [],
    "abstract": "Nonparametric estimation of mutual information is used in a wide range of\nscientific problems to quantify dependence between variables. The k-nearest\nneighbor (knn) methods are consistent, and therefore expected to work well for\nlarge sample size. These methods use geometrically regular local volume\nelements. This practice allows maximum localization of the volume elements, but\ncan also induce a bias due to a poor description of the local geometry of the\nunderlying probability measure. We introduce a new class of knn estimators that\nwe call geometric knn estimators (g-knn), which use more complex local volume\nelements to better model the local geometry of the probability measures. As an\nexample of this class of estimators, we develop a g-knn estimator of entropy\nand mutual information based on elliptical volume elements, capturing the local\nstretching and compression common to a wide range of dynamical systems\nattractors. A series of numerical examples in which the thickness of the\nunderlying distribution and the sample sizes are varied suggest that local\ngeometry is a source of problems for knn methods such as the\nKraskov-St\\\"{o}gbauer-Grassberger (KSG) estimator when local geometric effects\ncannot be removed by global preprocessing of the data. The g-knn method\nperforms well despite the manipulation of the local geometry. In addition, the\nexamples suggest that the g-knn estimators can be of particular relevance to\napplications in which the system is large, but data size is limited.",
    "published_date": "2017-11-02T00:00:00",
    "year": 2017,
    "categories": [
      "math.ST",
      "cs.IT",
      "math.DS",
      "math.IT",
      "stat.ME",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1711.00748v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.11345v1",
    "title": "Tensor Regression Meets Gaussian Processes",
    "authors": [
      "Rose Yu",
      "Guangyu Li",
      "Yan Liu"
    ],
    "author_ids": [],
    "abstract": "Low-rank tensor regression, a new model class that learns high-order\ncorrelation from data, has recently received considerable attention. At the\nsame time, Gaussian processes (GP) are well-studied machine learning models for\nstructure learning. In this paper, we demonstrate interesting connections\nbetween the two, especially for multi-way data analysis. We show that low-rank\ntensor regression is essentially learning a multi-linear kernel in Gaussian\nprocesses, and the low-rank assumption translates to the constrained Bayesian\ninference problem. We prove the oracle inequality and derive the average case\nlearning curve for the equivalent GP model. Our finding implies that low-rank\ntensor regression, though empirically successful, is highly dependent on the\neigenvalues of covariance functions as well as variable correlations.",
    "published_date": "2017-10-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.11345v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.10695v1",
    "title": "Multilinear Class-Specific Discriminant Analysis",
    "authors": [
      "Dat Thanh Tran",
      "Moncef Gabbouj",
      "Alexandros Iosifidis"
    ],
    "author_ids": [],
    "abstract": "There has been a great effort to transfer linear discriminant techniques that\noperate on vector data to high-order data, generally referred to as Multilinear\nDiscriminant Analysis (MDA) techniques. Many existing works focus on maximizing\nthe inter-class variances to intra-class variances defined on tensor data\nrepresentations. However, there has not been any attempt to employ\nclass-specific discrimination criteria for the tensor data. In this paper, we\npropose a multilinear subspace learning technique suitable for applications\nrequiring class-specific tensor models. The method maximizes the discrimination\nof each individual class in the feature space while retains the spatial\nstructure of the input. We evaluate the efficiency of the proposed method on\ntwo problems, i.e. facial image analysis and stock price prediction based on\nlimit order book data.",
    "published_date": "2017-10-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.10695v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.10577v2",
    "title": "Examining CNN Representations with respect to Dataset Bias",
    "authors": [
      "Quanshi Zhang",
      "Wenguan Wang",
      "Song-Chun Zhu"
    ],
    "author_ids": [],
    "abstract": "Given a pre-trained CNN without any testing samples, this paper proposes a\nsimple yet effective method to diagnose feature representations of the CNN. We\naim to discover representation flaws caused by potential dataset bias. More\nspecifically, when the CNN is trained to estimate image attributes, we mine\nlatent relationships between representations of different attributes inside the\nCNN. Then, we compare the mined attribute relationships with ground-truth\nattribute relationships to discover the CNN's blind spots and failure modes due\nto dataset bias. In fact, representation flaws caused by dataset bias cannot be\nexamined by conventional evaluation strategies based on testing images, because\ntesting images may also have a similar bias. Experiments have demonstrated the\neffectiveness of our method.",
    "published_date": "2017-10-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.10577v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.10345v7",
    "title": "The Implicit Bias of Gradient Descent on Separable Data",
    "authors": [
      "Daniel Soudry",
      "Elad Hoffer",
      "Mor Shpigel Nacson",
      "Suriya Gunasekar",
      "Nathan Srebro"
    ],
    "author_ids": [],
    "abstract": "We examine gradient descent on unregularized logistic regression problems,\nwith homogeneous linear predictors on linearly separable datasets. We show the\npredictor converges to the direction of the max-margin (hard margin SVM)\nsolution. The result also generalizes to other monotone decreasing loss\nfunctions with an infimum at infinity, to multi-class problems, and to training\na weight layer in a deep network in a certain restricted setting. Furthermore,\nwe show this convergence is very slow, and only logarithmic in the convergence\nof the loss itself. This can help explain the benefit of continuing to optimize\nthe logistic or cross-entropy loss even after the training error is zero and\nthe training loss is extremely small, and, as we show, even if the validation\nloss increases. Our methodology can also aid in understanding implicit\nregularization n more complex models and with other optimization methods.",
    "published_date": "2017-10-27T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.10345v7",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.10057v2",
    "title": "Multiwinner Voting with Fairness Constraints",
    "authors": [
      "L. Elisa Celis",
      "Lingxiao Huang",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Multiwinner voting rules are used to select a small representative subset of\ncandidates or items from a larger set given the preferences of voters. However,\nif candidates have sensitive attributes such as gender or ethnicity (when\nselecting a committee), or specified types such as political leaning (when\nselecting a subset of news items), an algorithm that chooses a subset by\noptimizing a multiwinner voting rule may be unbalanced in its selection -- it\nmay under or over represent a particular gender or political orientation in the\nexamples above. We introduce an algorithmic framework for multiwinner voting\nproblems when there is an additional requirement that the selected subset\nshould be \"fair\" with respect to a given set of attributes. Our framework\nprovides the flexibility to (1) specify fairness with respect to multiple,\nnon-disjoint attributes (e.g., ethnicity and gender) and (2) specify a score\nfunction. We study the computational complexity of this constrained multiwinner\nvoting problem for monotone and submodular score functions and present several\napproximation algorithms and matching hardness of approximation results for\nvarious attribute group structure and types of score functions. We also present\nsimulations that suggest that adding fairness constraints may not affect the\nscores significantly when compared to the unconstrained case.",
    "published_date": "2017-10-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.10057v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.10022v2",
    "title": "An Online Consent Maturity Model: Moving from Acceptable Use towards Ethical Practice",
    "authors": [
      "Vivien M. Rooney",
      "Simon N. Foley"
    ],
    "author_ids": [],
    "abstract": "The particular characteristics associated with qualitative longitudinal\nresearch in the disciplines of psychology and social science have prompted the\ndevelopment of informed consent. There are analogies between these\ncharacteristics and the collection and analysis of data in online settings. How\nand why informed consent has developed in qualitative longitudinal research,\nboth theoretically and practically, can provide a useful resource for\nconsidering what informed consent means in online settings. Building on this\nanalogy, criteria are proposed that can be used to provide an ethical judgement\non consent practices in an online data handling activity, and form the basis\nfor a consent maturity model. It is argued that if we are to learn from from\nthe history of informed consent in qualitative longitudinal research, then we\nshould strive for an Ethics of Virtue approach to informed consent online, the\nhighest level of maturity.",
    "published_date": "2017-10-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.10022v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.07765v2",
    "title": "On the Derivative Imbalance and Ambiguity of Functions",
    "authors": [
      "Shihui Fu",
      "Xiutao Feng",
      "Qiang Wang",
      "Claude Carlet"
    ],
    "author_ids": [],
    "abstract": "In 2007, Carlet and Ding introduced two parameters, denoted by $Nb_F$ and\n$NB_F$, quantifying respectively the balancedness of general functions $F$\nbetween finite Abelian groups and the (global) balancedness of their\nderivatives $D_a F(x)=F(x+a)-F(x)$, $a\\in G\\setminus\\{0\\}$ (providing an\nindicator of the nonlinearity of the functions). These authors studied the\nproperties and cryptographic significance of these two measures. They provided\nfor S-boxes inequalities relating the nonlinearity $\\mathcal{NL}(F)$ to $NB_F$,\nand obtained in particular an upper bound on the nonlinearity which unifies\nSidelnikov-Chabaud-Vaudenay's bound and the covering radius bound. At the\nWorkshop WCC 2009 and in its postproceedings in 2011, a further study of these\nparameters was made; in particular, the first parameter was applied to the\nfunctions $F+L$ where $L$ is affine, providing more nonlinearity parameters.\n  In 2010, motivated by the study of Costas arrays, two parameters called\nambiguity and deficiency were introduced by Panario \\emph{et al.} for\npermutations over finite Abelian groups to measure the injectivity and\nsurjectivity of the derivatives respectively. These authors also studied some\nfundamental properties and cryptographic significance of these two measures.\nFurther studies followed without that the second pair of parameters be compared\nto the first one.\n  In the present paper, we observe that ambiguity is the same parameter as\n$NB_F$, up to additive and multiplicative constants (i.e. up to rescaling). We\nmake the necessary work of comparison and unification of the results on $NB_F$,\nrespectively on ambiguity, which have been obtained in the five papers devoted\nto these parameters. We generalize some known results to any Abelian groups and\nwe more importantly derive many new results on these parameters.",
    "published_date": "2017-10-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "cs.CR",
      "math.IT",
      "94A60, 20K01, 11T06"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07765v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.07617v3",
    "title": "Asymptotically Optimal Resource Block Allocation With Limited Feedback",
    "authors": [
      "Ilai Bistritz",
      "Amir Leshem"
    ],
    "author_ids": [],
    "abstract": "Consider a channel allocation problem over a frequency-selective\nchannel.There are K channels (frequency bands) and N users such that K=bN for\nsome positive integer b. We want to allocate b channels (or resource blocks) to\neach user. Due to the nature of the frequency-selective channel, each user\nconsiders some channels to be better than others. The optimal solution to this\nresource allocation problem can be computed using the Hungarian algorithm.\nHowever, this requires knowledge of the numerical value of all the channel\ngains, which makes this approach impractical for large networks. We suggest a\nsuboptimal approach, that only requires knowing what the M-best channels of\neach user are. We find the minimal value of M such that there exists an\nallocation where all the b channels each user gets are among his M-best. This\nleads to feedback of significantly less than one bit per user per channel. For\na large class of fading distributions, including Rayleigh, Rician, m-Nakagami\nand others, this suboptimal approach leads to both an asymptotically (in K)\noptimal sum-rate and an asymptotically optimal minimal rate. Our\nnon-opportunistic approach achieves (asymptotically) full multiuser diversity\nas well as optimal fairness, by contrast to all other limited feedback\nalgorithms.",
    "published_date": "2017-10-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07617v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.07453v1",
    "title": "Finite-dimensional Gaussian approximation with linear inequality constraints",
    "authors": [
      "Andrés F. López-Lopera",
      "François Bachoc",
      "Nicolas Durrande",
      "Olivier Roustant"
    ],
    "author_ids": [],
    "abstract": "Introducing inequality constraints in Gaussian process (GP) models can lead\nto more realistic uncertainties in learning a great variety of real-world\nproblems. We consider the finite-dimensional Gaussian approach from Maatouk and\nBay (2017) which can satisfy inequality conditions everywhere (either\nboundedness, monotonicity or convexity). Our contributions are threefold.\nFirst, we extend their approach in order to deal with general sets of linear\ninequalities. Second, we explore several Markov Chain Monte Carlo (MCMC)\ntechniques to approximate the posterior distribution. Third, we investigate\ntheoretical and numerical properties of the constrained likelihood for\ncovariance parameter estimation. According to experiments on both artificial\nand real data, our full framework together with a Hamiltonian Monte Carlo-based\nsampler provides efficient results on both data fitting and uncertainty\nquantification.",
    "published_date": "2017-10-20T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07453v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.07394v2",
    "title": "Recognizing Explicit and Implicit Hate Speech Using a Weakly Supervised Two-path Bootstrapping Approach",
    "authors": [
      "Lei Gao",
      "Alexis Kuppersmith",
      "Ruihong Huang"
    ],
    "author_ids": [],
    "abstract": "In the wake of a polarizing election, social media is laden with hateful\ncontent. To address various limitations of supervised hate speech\nclassification methods including corpus bias and huge cost of annotation, we\npropose a weakly supervised two-path bootstrapping approach for an online hate\nspeech detection model leveraging large-scale unlabeled data. This system\nsignificantly outperforms hate speech detection systems that are trained in a\nsupervised manner using manually annotated data. Applying this model on a large\nquantity of tweets collected before, after, and on election day reveals\nmotivations and patterns of inflammatory language.",
    "published_date": "2017-10-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07394v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.07087v3",
    "title": "Does Campaigning on Social Media Make a Difference? Evidence from candidate use of Twitter during the 2015 and 2017 UK Elections",
    "authors": [
      "Jonathan Bright",
      "Scott A Hale",
      "Bharath Ganesh",
      "Andrew Bulovsky",
      "Helen Margetts",
      "Phil Howard"
    ],
    "author_ids": [],
    "abstract": "Social media are now a routine part of political campaigns all over the\nworld. However, studies of the impact of campaigning on social platform have\nthus far been limited to cross-sectional datasets from one election period\nwhich are vulnerable to unobserved variable bias. Hence empirical evidence on\nthe effectiveness of political social media activity is thin. We address this\ndeficit by analysing a novel panel dataset of political Twitter activity in the\n2015 and 2017 elections in the United Kingdom. We find that Twitter based\ncampaigning does seem to help win votes, a finding which is consistent across a\nvariety of different model specifications including a first difference\nregression. The impact of Twitter use is small in absolute terms, though\ncomparable with that of campaign spending. Our data also support the idea that\neffects are mediated through other communication channels, hence challenging\nthe relevance of engaging in an interactive fashion.",
    "published_date": "2017-10-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07087v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.06921v1",
    "title": "Themis-ml: A Fairness-aware Machine Learning Interface for End-to-end Discrimination Discovery and Mitigation",
    "authors": [
      "Niels Bantilan"
    ],
    "author_ids": [],
    "abstract": "As more industries integrate machine learning into socially sensitive\ndecision processes like hiring, loan-approval, and parole-granting, we are at\nrisk of perpetuating historical and contemporary socioeconomic disparities.\nThis is a critical problem because on the one hand, organizations who use but\ndo not understand the discriminatory potential of such systems will facilitate\nthe widening of social disparities under the assumption that algorithms are\ncategorically objective. On the other hand, the responsible use of machine\nlearning can help us measure, understand, and mitigate the implicit historical\nbiases in socially sensitive data by expressing implicit decision-making mental\nmodels in terms of explicit statistical models. In this paper we specify,\nimplement, and evaluate a \"fairness-aware\" machine learning interface called\nthemis-ml, which is intended for use by individual data scientists and\nengineers, academic research teams, or larger product teams who use machine\nlearning in production systems.",
    "published_date": "2017-10-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06921v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.06882v1",
    "title": "Mapping for accessibility: A case study of ethics in data science for social good",
    "authors": [
      "Anissa Tanweer",
      "Nicholas Bolten",
      "Margaret Drouhard",
      "Jess Hamilton",
      "Anat Caspi",
      "Brittany Fiore-Gartland",
      "Kaicheng Tan"
    ],
    "author_ids": [],
    "abstract": "Ethics in the emerging world of data science are often discussed through\ncautionary tales about the dire consequences of missteps taken by high profile\ncompanies or organizations. We take a different approach by foregrounding the\nways that ethics are implicated in the day-to-day work of data science,\nfocusing on instances in which data scientists recognize, grapple with, and\nconscientiously respond to ethical challenges. This paper presents a case study\nof ethical dilemmas that arose in a \"data science for social good\" (DSSG)\nproject focused on improving navigation for people with limited mobility. We\ndescribe how this particular DSSG team responded to those dilemmas, and how\nthose responses gave rise to still more dilemmas. While the details of the case\ndiscussed here are unique, the ethical dilemmas they illuminate can commonly be\nfound across many DSSG projects. These include: the risk of exacerbating\ndisparities; the thorniness of algorithmic accountability; the evolving\nopportunities for mischief presented by new technologies; the subjective and\nvalue- laden interpretations at the heart of any data-intensive project; the\npotential for data to amplify or mute particular voices; the possibility of\nprivacy violations; and the folly of technological solutionism. Based on our\ntracing of the team's responses to these dilemmas, we distill lessons for an\nethical data science practice that can be more generally applied across DSSG\nprojects. Specifically, this case experience highlights the importance of: 1)\nSetting the scene early on for ethical thinking 2) Recognizing ethical\ndecision-making as an emergent phenomenon intertwined with the quotidian work\nof data science for social good 3) Approaching ethical thinking as a thoughtful\nand intentional balancing of priorities rather than a binary differentiation\nbetween right and wrong.",
    "published_date": "2017-10-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06882v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.06881v1",
    "title": "Children and the Data Cycle: Rights and Ethics in a Big Data World",
    "authors": [
      "Gabrielle Berman",
      "Kerry Albright"
    ],
    "author_ids": [],
    "abstract": "In an era of increasing dependence on data science and big data, the voices\nof one set of major stakeholders - the world's children and those who advocate\non their behalf - have been largely absent. A recent paper estimates one in\nthree global internet users is a child, yet there has been little rigorous\ndebate or understanding of how to adapt traditional, offline ethical standards\nfor research, involving data collection from children, to a big data, online\nenvironment (Livingstone et al., 2015). This paper argues that due to the\npotential for severe, long-lasting and differential impacts on children, child\nrights need to be firmly integrated onto the agendas of global debates about\nethics and data science. The authors outline their rationale for a greater\nfocus on child rights and ethics in data science and suggest steps to move\nforward, focussing on the various actors within the data chain including data\ngenerators, collectors, analysts and end users. It concludes by calling for a\nmuch stronger appreciation of the links between child rights, ethics and data\nscience disciplines and for enhanced discourse between stakeholders in the data\nchain and those responsible for upholding the rights of children globally.",
    "published_date": "2017-10-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06881v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.06876v1",
    "title": "An End-To-End Machine Learning Pipeline That Ensures Fairness Policies",
    "authors": [
      "Samiulla Shaikh",
      "Harit Vishwakarma",
      "Sameep Mehta",
      "Kush R. Varshney",
      "Karthikeyan Natesan Ramamurthy",
      "Dennis Wei"
    ],
    "author_ids": [],
    "abstract": "In consequential real-world applications, machine learning (ML) based systems\nare expected to provide fair and non-discriminatory decisions on candidates\nfrom groups defined by protected attributes such as gender and race. These\nexpectations are set via policies or regulations governing data usage and\ndecision criteria (sometimes explicitly calling out decisions by automated\nsystems). Often, the data creator, the feature engineer, the author of the\nalgorithm and the user of the results are different entities, making the task\nof ensuring fairness in an end-to-end ML pipeline challenging. Manually\nunderstanding the policies and ensuring fairness in opaque ML systems is\ntime-consuming and error-prone, thus necessitating an end-to-end system that\ncan: 1) understand policies written in natural language, 2) alert users to\npolicy violations during data usage, and 3) log each activity performed using\nthe data in an immutable storage so that policy compliance or violation can be\nproven later. We propose such a system to ensure that data owners and users are\nalways in compliance with fairness policies.",
    "published_date": "2017-10-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06876v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.06842v1",
    "title": "Measuring the unmeasurable - a project of domestic violence risk prediction and management",
    "authors": [
      "Ya-Yun Chen",
      "Chia-Kai Liu",
      "Yu-Hsiu Wang",
      "Sue-Chuan Chen",
      "Yi-Shan Hsieh",
      "Jing-Tai Ke",
      "T. C. Hsieh"
    ],
    "author_ids": [],
    "abstract": "The prevention of domestic violence (DV) have aroused serious concerns in\nTaiwan because of the disparity between the increasing amount of reported DV\ncases that doubled over the past decade and the scarcity of social workers.\nAdditionally, a large amount of data was collected when social workers use the\npredominant case management approach to document case reports information.\nHowever, these data were not properly stored or organized.\n  To improve the efficiency of DV prevention and risk management, we worked\nwith Taipei City Government and utilized the 2015 data from its DV database to\nperform a spatial pattern analysis of the reports of DV cases to build a DV\nrisk map. However, during our map building process, the issue of confounding\nbias arose because we were not able to verify if reported cases truly reflected\nreal violence occurrence or were simply false reports from potential victim's\nneighbors. Therefore, we used the random forest method to build a repeat\nvictimization risk prediction model. The accuracy and F1-measure of our model\nwere 96.3% and 62.8%. This model helped social workers differentiate the risk\nlevel of new cases, which further reduced their major workload significantly.\nTo our knowledge, this is the first project that utilized machine learning in\nDV prevention. The research approach and results of this project not only can\nimprove DV prevention process, but also be applied to other social work or\ncriminal prevention areas.",
    "published_date": "2017-10-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06842v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.06514v3",
    "title": "Robust importance-weighted cross-validation under sample selection bias",
    "authors": [
      "Wouter M. Kouw",
      "Jesse H. Krijthe",
      "Marco Loog"
    ],
    "author_ids": [],
    "abstract": "Cross-validation under sample selection bias can, in principle, be done by\nimportance-weighting the empirical risk. However, the importance-weighted risk\nestimator produces sub-optimal hyperparameter estimates in problem settings\nwhere large weights arise with high probability. We study its sampling variance\nas a function of the training data distribution and introduce a control variate\nto increase its robustness to problematically large weights.",
    "published_date": "2017-10-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06514v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.06487v3",
    "title": "Classification and Geometry of General Perceptual Manifolds",
    "authors": [
      "SueYeon Chung",
      "Daniel D. Lee",
      "Haim Sompolinsky"
    ],
    "author_ids": [],
    "abstract": "Perceptual manifolds arise when a neural population responds to an ensemble\nof sensory signals associated with different physical features (e.g.,\norientation, pose, scale, location, and intensity) of the same perceptual\nobject. Object recognition and discrimination requires classifying the\nmanifolds in a manner that is insensitive to variability within a manifold. How\nneuronal systems give rise to invariant object classification and recognition\nis a fundamental problem in brain theory as well as in machine learning. Here\nwe study the ability of a readout network to classify objects from their\nperceptual manifold representations. We develop a statistical mechanical theory\nfor the linear classification of manifolds with arbitrary geometry revealing a\nremarkable relation to the mathematics of conic decomposition. Novel\ngeometrical measures of manifold radius and manifold dimension are introduced\nwhich can explain the classification capacity for manifolds of various\ngeometries. The general theory is demonstrated on a number of representative\nmanifolds, including L2 ellipsoids prototypical of strictly convex manifolds,\nL1 balls representing polytopes consisting of finite sample points, and\norientation manifolds which arise from neurons tuned to respond to a continuous\nangle variable, such as object orientation. The effects of label sparsity on\nthe classification capacity of manifolds are elucidated, revealing a scaling\nrelation between label sparsity and manifold radius. Theoretical predictions\nare corroborated by numerical simulations using recently developed algorithms\nto compute maximum margin solutions for manifold dichotomies. Our theory and\nits extensions provide a powerful and rich framework for applying statistical\nmechanics of linear classification to data arising from neuronal responses to\nobject stimuli, as well as to artificial deep networks trained for object\nrecognition tasks.",
    "published_date": "2017-10-17T00:00:00",
    "year": 2017,
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.NE",
      "q-bio.NC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06487v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.06228v2",
    "title": "Dissipative analysis of linear coupled differential-difference systems with distributed delays",
    "authors": [
      "Qian Feng",
      "Sing Kiong Nguang",
      "Alexandre Seuret"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a new method for the dissipativity and stability\nanalysis of a linear coupled differential-difference system (CDDS) with general\ndistributed delays at both state and output. More precisely, the distributed\ndelay terms under consideration can contain any $\\fL^{2}$ functions which are\napproximated via a class of elementary functions which includes the option of\nLegendre polynomials. By using this broader class of functions compared to the\nexisting Legendre polynomials approximation approach, one can construct a\nLiapunov-Krasovskii functional which is parameterized by non-polynomial\nfunctions . Furthermore, a novel generalized integral inequality is also\nproposed to incorporate approximation error in our stability (dissipativity)\nconditions. Based on the proposed approximation scenario with the proposed\nintegral inequality, sufficient conditions determining the dissipativity and\nstability of a CDDS are derived in terms of linear matrix inequalities. In\naddition, several hierarchies in terms of the feasibility of the proposed\nconditions are derived under certain constraints. Finally, several numerical\nexamples are presented in this paper to show the effectiveness of our proposed\nmethodologies.",
    "published_date": "2017-10-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.06228v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.05895v1",
    "title": "Spectral Algorithms for Computing Fair Support Vector Machines",
    "authors": [
      "Matt Olfat",
      "Anil Aswani"
    ],
    "author_ids": [],
    "abstract": "Classifiers and rating scores are prone to implicitly codifying biases, which\nmay be present in the training data, against protected classes (i.e., age,\ngender, or race). So it is important to understand how to design classifiers\nand scores that prevent discrimination in predictions. This paper develops\ncomputationally tractable algorithms for designing accurate but fair support\nvector machines (SVM's). Our approach imposes a constraint on the covariance\nmatrices conditioned on each protected class, which leads to a nonconvex\nquadratic constraint in the SVM formulation. We develop iterative algorithms to\ncompute fair linear and kernel SVM's, which solve a sequence of relaxations\nconstructed using a spectral decomposition of the nonconvex constraint. Its\neffectiveness in achieving high prediction accuracy while ensuring fairness is\nshown through numerical experiments on several data sets.",
    "published_date": "2017-10-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.05895v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.05106v2",
    "title": "CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning",
    "authors": [
      "Yuxin Peng",
      "Jinwei Qi",
      "Yuxin Yuan"
    ],
    "author_ids": [],
    "abstract": "It is known that the inconsistent distribution and representation of\ndifferent modalities, such as image and text, cause the heterogeneity gap that\nmakes it challenging to correlate such heterogeneous data. Generative\nadversarial networks (GANs) have shown its strong ability of modeling data\ndistribution and learning discriminative representation, existing GANs-based\nworks mainly focus on generative problem to generate new data. We have\ndifferent goal, aim to correlate heterogeneous data, by utilizing the power of\nGANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs\nto learn discriminative common representation for bridging heterogeneity gap.\nThe main contributions are: (1) Cross-modal GANs architecture is proposed to\nmodel joint distribution over data of different modalities. The inter-modality\nand intra-modality correlation can be explored simultaneously in generative and\ndiscriminative models. Both of them beat each other to promote cross-modal\ncorrelation learning. (2) Cross-modal convolutional autoencoders with\nweight-sharing constraint are proposed to form generative model. They can not\nonly exploit cross-modal correlation for learning common representation, but\nalso preserve reconstruction information for capturing semantic consistency\nwithin each modality. (3) Cross-modal adversarial mechanism is proposed, which\nutilizes two kinds of discriminative models to simultaneously conduct\nintra-modality and inter-modality discrimination. They can mutually boost to\nmake common representation more discriminative by adversarial training process.\nTo the best of our knowledge, our proposed CM-GANs approach is the first to\nutilize GANs to perform cross-modal common representation learning. Experiments\nare conducted to verify the performance of our proposed approach on cross-modal\nretrieval paradigm, compared with 10 methods on 3 cross-modal datasets.",
    "published_date": "2017-10-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MM",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.05106v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.04924v1",
    "title": "Two-stage Algorithm for Fairness-aware Machine Learning",
    "authors": [
      "Junpei Komiyama",
      "Hajime Shimao"
    ],
    "author_ids": [],
    "abstract": "Algorithmic decision making process now affects many aspects of our lives.\nStandard tools for machine learning, such as classification and regression, are\nsubject to the bias in data, and thus direct application of such off-the-shelf\ntools could lead to a specific group being unfairly discriminated. Removing\nsensitive attributes of data does not solve this problem because a\n\\textit{disparate impact} can arise when non-sensitive attributes and sensitive\nattributes are correlated. Here, we study a fair machine learning algorithm\nthat avoids such a disparate impact when making a decision. Inspired by the\ntwo-stage least squares method that is widely used in the field of economics,\nwe propose a two-stage algorithm that removes bias in the training data. The\nproposed algorithm is conceptually simple. Unlike most of existing fair\nalgorithms that are designed for classification tasks, the proposed method is\nable to (i) deal with regression tasks, (ii) combine explanatory attributes to\nremove reverse discrimination, and (iii) deal with numerical sensitive\nattributes. The performance and fairness of the proposed algorithm are\nevaluated in simulations with synthetic and real-world datasets.",
    "published_date": "2017-10-13T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.04924v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.04422v1",
    "title": "Shortcuts through Colocation Facilities",
    "authors": [
      "Vasileios Kotronis",
      "George Nomikos",
      "Lefteris Manassakis",
      "Dimitris Mavrommatis",
      "Xenofontas Dimitropoulos"
    ],
    "author_ids": [],
    "abstract": "Network overlays, running on top of the existing Internet substrate, are of\nperennial value to Internet end-users in the context of, e.g., real-time\napplications. Such overlays can employ traffic relays to yield path latencies\nlower than the direct paths, a phenomenon known as Triangle Inequality\nViolation (TIV). Past studies identify the opportunities of reducing latency\nusing TIVs. However, they do not investigate the gains of strategically\nselecting relays in Colocation Facilities (Colos). In this work, we answer the\nfollowing questions: (i) how Colo-hosted relays compare with other relays as\nwell as with the direct Internet, in terms of latency (RTT) reductions; (ii)\nwhat are the best locations for placing the relays to yield these reductions.\nTo this end, we conduct a large-scale one-month measurement of inter-domain\npaths between RIPE Atlas (RA) nodes as endpoints, located at eyeball networks.\nWe employ as relays Planetlab nodes, other RA nodes, and machines in Colos. We\nexamine the RTTs of the overlay paths obtained via the selected relays, as well\nas the direct paths. We find that Colo-based relays perform the best and can\nachieve latency reductions against direct paths, ranging from a few to 100s of\nmilliseconds, in 76% of the total cases; 75% (58% of total cases) of these\nreductions require only 10 relays in 6 large Colos.",
    "published_date": "2017-10-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.04422v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.04394v1",
    "title": "Provably Fair Representations",
    "authors": [
      "Daniel McNamara",
      "Cheng Soon Ong",
      "Robert C. Williamson"
    ],
    "author_ids": [],
    "abstract": "Machine learning systems are increasingly used to make decisions about\npeople's lives, such as whether to give someone a loan or whether to interview\nsomeone for a job. This has led to considerable interest in making such machine\nlearning systems fair. One approach is to transform the input data used by the\nalgorithm. This can be achieved by passing each input data point through a\nrepresentation function prior to its use in training or testing. Techniques for\nlearning such representation functions from data have been successful\nempirically, but typically lack theoretical fairness guarantees. We show that\nit is possible to prove that a representation function is fair according to\ncommon measures of both group and individual fairness, as well as useful with\nrespect to a target task. These provable properties can be used in a governance\nmodel involving a data producer, a data user and a data regulator, where there\nis a separation of concerns between fairness and target task utility to ensure\ntransparency and prevent perverse incentives. We formally define the 'cost of\nmistrust' of using this model compared to the setting where there is a single\ntrusted party, and provide bounds on this cost in particular cases. We present\na practical approach to learning fair representation functions and apply it to\nfinancial and criminal justice datasets. We evaluate the fairness and utility\nof these representation functions using measures motivated by our theoretical\nresults.",
    "published_date": "2017-10-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.04394v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.04142v1",
    "title": "Bollywood Movie Corpus for Text, Images and Videos",
    "authors": [
      "Nishtha Madaan",
      "Sameep Mehta",
      "Mayank Saxena",
      "Aditi Aggarwal",
      "Taneea S Agrawaal",
      "Vrinda Malhotra"
    ],
    "author_ids": [],
    "abstract": "In past few years, several data-sets have been released for text and images.\nWe present an approach to create the data-set for use in detecting and removing\ngender bias from text. We also include a set of challenges we have faced while\ncreating this corpora. In this work, we have worked with movie data from\nWikipedia plots and movie trailers from YouTube. Our Bollywood Movie corpus\ncontains 4000 movies extracted from Wikipedia and 880 trailers extracted from\nYouTube which were released from 1970-2017. The corpus contains csv files with\nthe following data about each movie - Wikipedia title of movie, cast, plot\ntext, co-referenced plot text, soundtrack information, link to movie poster,\ncaption of movie poster, number of males in poster, number of females in\nposter. In addition to that, corresponding to each cast member the following\ndata is available - cast name, cast gender, cast verbs, cast adjectives, cast\nrelations, cast centrality, cast mentions. We present some preliminary results\non the task of bias removal which suggest that the data-set is quite useful for\nperforming such tasks.",
    "published_date": "2017-10-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.04142v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.04117v1",
    "title": "Analyzing Gender Stereotyping in Bollywood Movies",
    "authors": [
      "Nishtha Madaan",
      "Sameep Mehta",
      "Taneea S Agrawaal",
      "Vrinda Malhotra",
      "Aditi Aggarwal",
      "Mayank Saxena"
    ],
    "author_ids": [],
    "abstract": "The presence of gender stereotypes in many aspects of society is a well-known\nphenomenon. In this paper, we focus on studying such stereotypes and bias in\nHindi movie industry (Bollywood). We analyze movie plots and posters for all\nmovies released since 1970. The gender bias is detected by semantic modeling of\nplots at inter-sentence and intra-sentence level. Different features like\noccupation, introduction of cast in text, associated actions and descriptions\nare captured to show the pervasiveness of gender bias and stereo- type in\nmovies. We derive a semantic graph and compute centrality of each character and\nobserve similar bias there. We also show that such bias is not applicable for\nmovie posters where females get equal importance even though their character\nhas little or no impact on the movie plot. Furthermore, we explore the movie\ntrailers to estimate on-screen time for males and females and also study the\nportrayal of emotions by gender in them. The silver lining is that our system\nwas able to identify 30 movies over last 3 years where such stereotypes were\nbroken.",
    "published_date": "2017-10-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.04117v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.05817v1",
    "title": "Densely Connected Convolutional Networks and Signal Quality Analysis to Detect Atrial Fibrillation Using Short Single-Lead ECG Recordings",
    "authors": [
      "Jonathan Rubin",
      "Saman Parvaneh",
      "Asif Rahman",
      "Bryan Conroy",
      "Saeed Babaeizadeh"
    ],
    "author_ids": [],
    "abstract": "The development of new technology such as wearables that record high-quality\nsingle channel ECG, provides an opportunity for ECG screening in a larger\npopulation, especially for atrial fibrillation screening. The main goal of this\nstudy is to develop an automatic classification algorithm for normal sinus\nrhythm (NSR), atrial fibrillation (AF), other rhythms (O), and noise from a\nsingle channel short ECG segment (9-60 seconds). For this purpose, signal\nquality index (SQI) along with dense convolutional neural networks was used.\nTwo convolutional neural network (CNN) models (main model that accepts 15\nseconds ECG and secondary model that processes 9 seconds shorter ECG) were\ntrained using the training data set. If the recording is determined to be of\nlow quality by SQI, it is immediately classified as noisy. Otherwise, it is\ntransformed to a time-frequency representation and classified with the CNN as\nNSR, AF, O, or noise. At the final step, a feature-based post-processing\nalgorithm classifies the rhythm as either NSR or O in case the CNN model's\ndiscrimination between the two is indeterminate. The best result achieved at\nthe official phase of the PhysioNet/CinC challenge on the blind test set was\n0.80 (F1 for NSR, AF, and O were 0.90, 0.80, and 0.70, respectively).",
    "published_date": "2017-10-10T00:00:00",
    "year": 2017,
    "categories": [
      "eess.SP",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.05817v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.03705v2",
    "title": "Analyzing gender inequality through large-scale Facebook advertising data",
    "authors": [
      "David Garcia",
      "Yonas Mitike Kassa",
      "Angel Cuevas",
      "Manuel Cebrian",
      "Esteban Moro",
      "Iyad Rahwan",
      "Ruben Cuevas"
    ],
    "author_ids": [],
    "abstract": "Online social media are information resources that can have a transformative\npower in society. While the Web was envisioned as an equalizing force that\nallows everyone to access information, the digital divide prevents large\namounts of people from being present online. Online social media in particular\nare prone to gender inequality, an important issue given the link between\nsocial media use and employment. Understanding gender inequality in social\nmedia is a challenging task due to the necessity of data sources that can\nprovide large-scale measurements across multiple countries. Here we show how\nthe Facebook Gender Divide (FGD), a metric based on aggregated statistics of\nmore than 1.4 Billion users in 217 countries, explains various aspects of\nworldwide gender inequality. Our analysis shows that the FGD encodes gender\nequality indices in education, health, and economic opportunity. We find gender\ndifferences in network externalities that suggest that using social media has\nan added value for women. Furthermore, we find that low values of the FGD are\nassociated with increases in economic gender equality. Our results suggest that\nonline social networks, while suffering evident gender imbalance, may lower the\nbarriers that women have to access informational resources and help to narrow\nthe economic gender gap.",
    "published_date": "2017-10-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.03705v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.03370v2",
    "title": "iVQA: Inverse Visual Question Answering",
    "authors": [
      "Feng Liu",
      "Tao Xiang",
      "Timothy M. Hospedales",
      "Wankou Yang",
      "Changyin Sun"
    ],
    "author_ids": [],
    "abstract": "We propose the inverse problem of Visual question answering (iVQA), and\nexplore its suitability as a benchmark for visuo-linguistic understanding. The\niVQA task is to generate a question that corresponds to a given image and\nanswer pair. Since the answers are less informative than the questions, and the\nquestions have less learnable bias, an iVQA model needs to better understand\nthe image to be successful than a VQA model. We pose question generation as a\nmulti-modal dynamic inference process and propose an iVQA model that can\ngradually adjust its focus of attention guided by both a partially generated\nquestion and the answer. For evaluation, apart from existing linguistic\nmetrics, we propose a new ranking metric. This metric compares the ground truth\nquestion's rank among a list of distractors, which allows the drawbacks of\ndifferent algorithms and sources of error to be studied. Experimental results\nshow that our model can generate diverse, grammatically correct and content\ncorrelated questions that match the given answer.",
    "published_date": "2017-10-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.03370v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.03253v2",
    "title": "Low Complexity Fair Scheduling in LTE/LTE-A Uplink Involving Multiple Traffic Classes",
    "authors": [
      "Atri Mukhopadhyay",
      "Goutam Das"
    ],
    "author_ids": [],
    "abstract": "The bulk of the research on Long Term Evolution/Long Term Evolution-Advanced\npacket scheduling is concentrated in the downlink and the uplink is\ncomparatively less explored. In up-link, channel aware scheduling with\nthroughput maximization has been widely studied while considering an infinitely\nback-logged buffer model, which makes the investigations unrealistic.\nTherefore, we propose an optimal uplink packet scheduling pro-cedure with\nrealistic traffic sources. Firstly, we advocate a joint channel and buffer\naware algorithm, which maximizes the actual transmitted bit-count. Thereafter,\nwe introduce delay constraints in our algorithm to support real-time traffic.\nWe further enhance our algorithm by incorporating the varied delay and\nthroughput requirements demanded by mixed traffic classes. Finally, we\nin-troduce priority flipping to minimize bandwidth starvation of lower priority\ntraffic in presence of higher percentage of high priority traffic. We observe\nthat a delay constraint may render the optimization-based proposals infeasible.\nTherefore, to avoid infeasibility, we replace the delay constraint with delay\noutage minimization (DOM). DOM aims at minimizing the packet drop due to delay\nviolation. Moreover, DOM also helps in reducing the problems to a well-known\nassignment problem, which can be solved by applying the Hungarian algorithm.\nHence, our approach delivers an optimal allocation with low computational\ncomplexity.",
    "published_date": "2017-10-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.03253v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.03184v3",
    "title": "On Formalizing Fairness in Prediction with Machine Learning",
    "authors": [
      "Pratik Gajane",
      "Mykola Pechenizkiy"
    ],
    "author_ids": [],
    "abstract": "Machine learning algorithms for prediction are increasingly being used in\ncritical decisions affecting human lives. Various fairness formalizations, with\nno firm consensus yet, are employed to prevent such algorithms from\nsystematically discriminating against people based on certain attributes\nprotected by law. The aim of this article is to survey how fairness is\nformalized in the machine learning literature for the task of prediction and\npresent these formalizations with their corresponding notions of distributive\njustice from the social sciences literature. We provide theoretical as well as\nempirical critiques of these notions from the social sciences literature and\nexplain how these critiques limit the suitability of the corresponding fairness\nformalizations to certain domains. We also suggest two notions of distributive\njustice which address some of these critiques and discuss avenues for\nprospective fairness formalizations.",
    "published_date": "2017-10-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.03184v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.02856v1",
    "title": "Gender and Ethnicity Classification of Iris Images using Deep Class-Encoder",
    "authors": [
      "Maneet Singh",
      "Shruti Nagpal",
      "Mayank Vatsa",
      "Richa Singh",
      "Afzel Noore",
      "Angshul Majumdar"
    ],
    "author_ids": [],
    "abstract": "Soft biometric modalities have shown their utility in different applications\nincluding reducing the search space significantly. This leads to improved\nrecognition performance, reduced computation time, and faster processing of\ntest samples. Some common soft biometric modalities are ethnicity, gender, age,\nhair color, iris color, presence of facial hair or moles, and markers. This\nresearch focuses on performing ethnicity and gender classification on iris\nimages. We present a novel supervised autoencoder based approach, Deep\nClass-Encoder, which uses class labels to learn discriminative representation\nfor the given sample by mapping the learned feature vector to its label. The\nproposed model is evaluated on two datasets each for ethnicity and gender\nclassification. The results obtained using the proposed Deep Class-Encoder\ndemonstrate its effectiveness in comparison to existing approaches and\nstate-of-the-art methods.",
    "published_date": "2017-10-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.02856v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.02808v2",
    "title": "Optimal Estimation of Sensor Biases for Asynchronous Multi-Sensor Data Fusion",
    "authors": [
      "Wenqiang Pu",
      "Ya-Feng Liu",
      "Junkun Yan",
      "Hongwei Liu",
      "Zhi-Quan Luo"
    ],
    "author_ids": [],
    "abstract": "An important step in a multi-sensor surveillance system is to estimate sensor\nbiases from their noisy asynchronous measurements. This estimation problem is\ncomputationally challenging due to the highly nonlinear transformation between\nthe global and local coordinate systems as well as the measurement asynchrony\nfrom different sensors. In this paper, we propose a novel nonlinear least\nsquares (LS) formulation for the problem by assuming the existence of a\nreference target moving with an (unknown) constant velocity. We also propose an\nefficient block coordinate decent (BCD) optimization algorithm, with a\njudicious initialization, to solve the problem. The proposed BCD algorithm\nalternately updates the range and azimuth bias estimates by solving linear\nleast squares problems and semidefinite programs (SDPs). In the absence of\nmeasurement noise, the proposed algorithm is guaranteed to find the global\nsolution of the problem and the true biases. Simulation results show that the\nproposed algorithm significantly outperforms the existing approaches in terms\nof the root mean square error (RMSE).",
    "published_date": "2017-10-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.02808v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.05711v1",
    "title": "Deep Self-Paced Learning for Person Re-Identification",
    "authors": [
      "Sanping Zhou",
      "Jinjun Wang",
      "Deyu Meng",
      "Xiaomeng Xin",
      "Yubing Li",
      "Yihong Gong",
      "Nanning Zheng"
    ],
    "author_ids": [],
    "abstract": "Person re-identification (Re-ID) usually suffers from noisy samples with\nbackground clutter and mutual occlusion, which makes it extremely difficult to\ndistinguish different individuals across the disjoint camera views. In this\npaper, we propose a novel deep self-paced learning (DSPL) algorithm to\nalleviate this problem, in which we apply a self-paced constraint and symmetric\nregularization to help the relative distance metric training the deep neural\nnetwork, so as to learn the stable and discriminative features for person\nRe-ID. Firstly, we propose a soft polynomial regularizer term which can derive\nthe adaptive weights to samples based on both the training loss and model age.\nAs a result, the high-confidence fidelity samples will be emphasized and the\nlow-confidence noisy samples will be suppressed at early stage of the whole\ntraining process. Such a learning regime is naturally implemented under a\nself-paced learning (SPL) framework, in which samples weights are adaptively\nupdated based on both model age and sample loss using an alternative\noptimization method. Secondly, we introduce a symmetric regularizer term to\nrevise the asymmetric gradient back-propagation derived by the relative\ndistance metric, so as to simultaneously minimize the intra-class distance and\nmaximize the inter-class distance in each triplet unit. Finally, we build a\npart-based deep neural network, in which the features of different body parts\nare first discriminately learned in the lower convolutional layers and then\nfused in the higher fully connected layers. Experiments on several benchmark\ndatasets have demonstrated the superior performance of our method as compared\nwith the state-of-the-art approaches.",
    "published_date": "2017-10-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.05711v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.02159v1",
    "title": "Preferential Attachment and Vertex Arrival Times",
    "authors": [
      "Benjamin Bloem-Reddy",
      "Peter Orbanz"
    ],
    "author_ids": [],
    "abstract": "We study preferential attachment mechanisms in random graphs that are\nparameterized by (i) a constant bias affecting the degree-biased distribution\non the vertex set and (ii) the distribution of times at which new vertices are\ncreated by the model. The class of random graphs so defined admits a\nrepresentation theorem reminiscent of residual allocation, or \"stick-breaking\"\nschemes. We characterize how the vertex arrival times affect the asymptotic\ndegree distribution, and relate the latter to neutral-to-the-left processes.\nOur random graphs generate edges \"one end at a time\", which sets up a\none-to-one correspondence between random graphs and random partitions of\nnatural numbers; via this map, our representation induces a result on (not\nnecessarily exchangeable) random partitions that generalizes a theorem of\nGriffiths and Span\\'o. A number of examples clarify how the class intersects\nwith several known random graph models.",
    "published_date": "2017-10-05T00:00:00",
    "year": 2017,
    "categories": [
      "math.PR",
      "cs.SI",
      "math.ST",
      "physics.soc-ph",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.02159v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.02030v2",
    "title": "McDiarmid Drift Detection Methods for Evolving Data Streams",
    "authors": [
      "Ali Pesaranghader",
      "Herna Viktor",
      "Eric Paquet"
    ],
    "author_ids": [],
    "abstract": "Increasingly, Internet of Things (IoT) domains, such as sensor networks,\nsmart cities, and social networks, generate vast amounts of data. Such data are\nnot only unbounded and rapidly evolving. Rather, the content thereof\ndynamically evolves over time, often in unforeseen ways. These variations are\ndue to so-called concept drifts, caused by changes in the underlying data\ngeneration mechanisms. In a classification setting, concept drift causes the\npreviously learned models to become inaccurate, unsafe and even unusable.\nAccordingly, concept drifts need to be detected, and handled, as soon as\npossible. In medical applications and emergency response settings, for example,\nchange in behaviours should be detected in near real-time, to avoid potential\nloss of life. To this end, we introduce the McDiarmid Drift Detection Method\n(MDDM), which utilizes McDiarmid's inequality in order to detect concept drift.\nThe MDDM approach proceeds by sliding a window over prediction results, and\nassociate window entries with weights. Higher weights are assigned to the most\nrecent entries, in order to emphasize their importance. As instances are\nprocessed, the detection algorithm compares a weighted mean of elements inside\nthe sliding window with the maximum weighted mean observed so far. A\nsignificant difference between the two weighted means, upper-bounded by the\nMcDiarmid inequality, implies a concept drift. Our extensive experimentation\nagainst synthetic and real-world data streams show that our novel method\noutperforms the state-of-the-art. Specifically, MDDM yields shorter detection\ndelays as well as lower false negative rates, while maintaining high\nclassification accuracies.",
    "published_date": "2017-10-05T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.02030v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.01852v2",
    "title": "Finite Time Identification in Unstable Linear Systems",
    "authors": [
      "Mohamad Kazem Shirani Faradonbeh",
      "Ambuj Tewari",
      "George Michailidis"
    ],
    "author_ids": [],
    "abstract": "Identification of the parameters of stable linear dynamical systems is a\nwell-studied problem in the literature, both in the low and high-dimensional\nsettings. However, there are hardly any results for the unstable case,\nespecially regarding finite time bounds. For this setting, classical results on\nleast-squares estimation of the dynamics parameters are not applicable and\ntherefore new concepts and technical approaches need to be developed to address\nthe issue. Unstable linear systems arise in key real applications in control\ntheory, econometrics, and finance. This study establishes finite time bounds\nfor the identification error of the least-squares estimates for a fairly large\nclass of heavy-tailed noise distributions, and transition matrices of such\nsystems. The results relate the time length (samples) required for estimation\nto a function of the problem dimension and key characteristics of the true\nunderlying transition matrix and the noise distribution. To establish them,\nappropriate concentration inequalities for random matrices and for sequences of\nmartingale differences are leveraged.",
    "published_date": "2017-10-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "econ.EM",
      "eess.SP",
      "math.ST",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.01852v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.01820v1",
    "title": "Energy-Based Spherical Sparse Coding",
    "authors": [
      "Bailey Kong",
      "Charless C. Fowlkes"
    ],
    "author_ids": [],
    "abstract": "In this paper, we explore an efficient variant of convolutional sparse coding\nwith unit norm code vectors where reconstruction quality is evaluated using an\ninner product (cosine distance). To use these codes for discriminative\nclassification, we describe a model we term Energy-Based Spherical Sparse\nCoding (EB-SSC) in which the hypothesized class label introduces a learned\nlinear bias into the coding step. We evaluate and visualize performance of\nstacking this encoder to make a deep layered model for image classification.",
    "published_date": "2017-10-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.01820v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.01458v2",
    "title": "Sum of Square Proof for Brascamp-Lieb Type Inequality",
    "authors": [
      "Zhixian Lei",
      "Yueqi Sheng"
    ],
    "author_ids": [],
    "abstract": "Brascamp-Lieb inequality is an important mathematical tool in analysis,\ngeometry and information theory. There are various ways to prove Brascamp-Lieb\ninequality such as heat flow method, Brownian motion and subadditivity of the\nentropy. While Brascamp-Lieb inequality is originally stated in Euclidean\nSpace, discussed Brascamp-Lieb inequality for discrete Abelian group and\ndiscussed Brascamp-Lieb inequality for Markov semigroups.\n  Many mathematical inequalities can be formulated as algebraic inequalities\nwhich asserts some given polynomial is nonnegative. In 1927, Artin proved that\nany non- negative polynomial can be represented as a sum of squares of rational\nfunctions, which can be further formulated as a polynomial certificate of the\nnonnegativity of the polynomial. This is a Sum of Square proof of the\ninequality. Take the degree of the polynomial certificate as the degree of Sum\nof Square proof. The degree of an Sum of Square proof determines the complexity\nof generating such proof by Sum of Square algorithm which is a powerful tool\nfor optimization and computer aided proof.\n  In this paper, we give a Sum of Square proof for some special settings of\nBrascamp- Lieb inequality following and and discuss some applications of\nBrascamp-Lieb inequality on Abelian group and Euclidean Sphere. If the original\ndescription of the inequality has constant degree and d is constant, the degree\nof the proof is also constant. Therefore, low degree sum of square algorithm\ncan fully capture the power of low degree finite Brascamp-Lieb inequality.",
    "published_date": "2017-10-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CC",
      "math.CA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.01458v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.01420v2",
    "title": "Usable & Scalable Learning Over Relational Data With Automatic Language Bias",
    "authors": [
      "Jose Picado",
      "Arash Termehchy",
      "Sudhanshu Pathak",
      "Alan Fern",
      "Praveen Ilango",
      "Yunqiao Cai"
    ],
    "author_ids": [],
    "abstract": "Relational databases are valuable resources for learning novel and\ninteresting relations and concepts. In order to constraint the search through\nthe large space of candidate definitions, users must tune the algorithm by\nspecifying a language bias. Unfortunately, specifying the language bias is done\nvia trial and error and is guided by the expert's intuitions. We propose\nAutoBias, a system that leverages information in the schema and content of the\ndatabase to automatically induce the language bias used by popular relational\nlearning systems. We show that AutoBias delivers the same accuracy as using\nmanually-written language bias by imposing only a slight overhead on the\nrunning time of the learning algorithm.",
    "published_date": "2017-10-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.01420v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.00870v2",
    "title": "Rethinking Feature Discrimination and Polymerization for Large-scale Recognition",
    "authors": [
      "Yu Liu",
      "Hongyang Li",
      "Xiaogang Wang"
    ],
    "author_ids": [],
    "abstract": "Feature matters. How to train a deep network to acquire discriminative\nfeatures across categories and polymerized features within classes has always\nbeen at the core of many computer vision tasks, specially for large-scale\nrecognition systems where test identities are unseen during training and the\nnumber of classes could be at million scale. In this paper, we address this\nproblem based on the simple intuition that the cosine distance of features in\nhigh-dimensional space should be close enough within one class and far away\nacross categories. To this end, we proposed the congenerous cosine (COCO)\nalgorithm to simultaneously optimize the cosine similarity among data. It\ninherits the softmax property to make inter-class features discriminative as\nwell as shares the idea of class centroid in metric learning. Unlike previous\nwork where the center is a temporal, statistical variable within one mini-batch\nduring training, the formulated centroid is responsible for clustering\ninner-class features to enforce them polymerized around the network truncus.\nCOCO is bundled with discriminative training and learned end-to-end with stable\nconvergence. Experiments on five benchmarks have been extensively conducted to\nverify the effectiveness of our approach on both small-scale classification\ntask and large-scale human recognition problem.",
    "published_date": "2017-10-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.00870v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1710.00861v1",
    "title": "Robust Adaptive Sliding Mode Control of Markovian Jump Systems with Uncertain Mode-dependent Time-varying Delays and Partly Unknown Transition Probabilities",
    "authors": [
      "Nasibeh Zohrabi",
      "Hasan Zakeri",
      "Amir Hossein Abolmasoumi",
      "Hamid Reza Momeni"
    ],
    "author_ids": [],
    "abstract": "This paper deals with the problems of stochastic stability and sliding mode\ncontrol for a class of continuous-time Markovian jump systems with\nmode-dependent time-varying delays and partly unknown transition probabilities.\nThe design method is general enough to cover a wide spectrum of systems from\nthose with completely known transition probability rates to those with\ncompletely unknown transition probability rates. Based on some mode-dependent\nLyapunov-Krasovski functionals and making use of the free-connection weighting\nmatrices, new delay-dependent conditions guaranteeing the existence of linear\nswitching surfaces and the stochastic stability of sliding mode dynamics are\nderived in terms of linear matrix inequalities (LMIs). Then, a sliding mode\ncontroller is designed such that the resulted closed-loop system's trajectories\nconverge to predefined sliding surfaces in a finite time and remain there for\nall subsequent times. This paper also proposes an adaptive sliding mode\ncontroller design method which applies to cases in which mode-dependent\ntime-varying delays are unknown. All the conditions obtained in this paper are\nin terms of LMI feasibility problems. Numerical examples are given to\nillustrate the effectiveness of the proposed methods.",
    "published_date": "2017-10-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.00861v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.00800v3",
    "title": "On the entropy power inequality for the Rényi entropy of order [0,1]",
    "authors": [
      "Arnaud Marsiglietti",
      "James Melbourne"
    ],
    "author_ids": [],
    "abstract": "Using a sharp version of the reverse Young inequality, and a R\\'enyi entropy\ncomparison result due to Fradelizi, Madiman, and Wang, the authors are able to\nderive R\\'enyi entropy power inequalities for log-concave random vectors when\nR\\'enyi parameters belong to $(0,1)$. Furthermore, the estimates are shown to\nbe sharp up to absolute constants.",
    "published_date": "2017-10-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.00800v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.00501v1",
    "title": "Robust Distributed Fusion with Labeled Random Finite Sets",
    "authors": [
      "Suqi Li",
      "Wei Yi",
      "Reza Hoseinnezhad",
      "Giorgio Battistelli",
      "Bailu Wang",
      "Lingjiang Kong"
    ],
    "author_ids": [],
    "abstract": "This paper considers the problem of the distributed fusion of multi-object\nposteriors in the labeled random finite set filtering framework, using\nGeneralized Covariance Intersection (GCI) method. Our analysis shows that GCI\nfusion with labeled multi-object densities strongly relies on label\nconsistencies between local multi-object posteriors at different sensor nodes,\nand hence suffers from a severe performance degradation when perfect label\nconsistencies are violated. Moreover, we mathematically analyze this phenomenon\nfrom the perspective of Principle of Minimum Discrimination Information and the\nso called yes-object probability. Inspired by the analysis, we propose a novel\nand general solution for the distributed fusion with labeled multi-object\ndensities that is robust to label inconsistencies between sensors.\nSpecifically, the labeled multi-object posteriors are firstly marginalized to\ntheir unlabeled posteriors which are then fused using GCI method. We also\nintroduce a principled method to construct the labeled fused density and\nproduce tracks formally. Based on the developed theoretical framework, we\npresent tractable algorithms for the family of generalized labeled\nmulti-Bernoulli (GLMB) filters including $\\delta$-GLMB, marginalized\n$\\delta$-GLMB and labeled multi-Bernoulli filters. The robustness and\nefficiency of the proposed distributed fusion algorithm are demonstrated in\nchallenging tracking scenarios via numerical experiments.",
    "published_date": "2017-10-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.00501v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1710.00269v1",
    "title": "Bounded Rationality in Scholarly Knowledge Discovery",
    "authors": [
      "Kristina Lerman",
      "Nathan Hodas",
      "Hao Wu"
    ],
    "author_ids": [],
    "abstract": "In an information-rich world, people's time and attention must be divided\namong rapidly changing information sources and the diverse tasks demanded of\nthem. How people decide which of the many sources, such as scientific articles\nor patents, to read and use in their own work affects dissemination of\nscholarly knowledge and adoption of innovation. We analyze the choices people\nmake about what information to propagate on the citation networks of Physical\nReview journals, US patents and legal opinions. We observe regularities in\nbehavior consistent with human bounded rationality: rather than evaluate all\navailable choices, people rely on simply cognitive heuristics to decide what\ninformation to attend to. We demonstrate that these heuristics bias choices, so\nthat people preferentially propagate information that is easier to discover,\noften because it is newer or more popular. However, we do not find evidence\nthat popular sources help to amplify the spread of information beyond making it\nmore salient. Our paper provides novel evidence of the critical role that\nbounded rationality plays in the decisions to allocate attention in social\ncommunication.",
    "published_date": "2017-09-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.00269v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.10402v4",
    "title": "Distributions of Centrality on Networks",
    "authors": [
      "Krishna Dasaratha"
    ],
    "author_ids": [],
    "abstract": "We provide a framework for determining the centralities of agents in a broad\nfamily of random networks. Current understanding of network centrality is\nlargely restricted to deterministic settings, but practitioners frequently use\nrandom network models to accommodate data limitations or prove asymptotic\nresults. Our main theorems show that on large random networks, centrality\nmeasures are close to their expected values with high probability. We\nillustrate the economic consequences of these results by presenting three\napplications: (1) In network formation models based on community structure\n(called stochastic block models), we show network segregation and differences\nin community size produce inequality. Benefits from peer effects tend to accrue\ndisproportionately to bigger and better-connected communities. (2) When link\nprobabilities depend on geography, we can compute and compare the centralities\nof agents in different locations. (3) In models where connections depend on\nseveral independent characteristics, we give a formula that determines\ncentralities 'characteristic-by-characteristic'. The basic techniques from\nthese applications, which use the main theorems to reduce questions about\nrandom networks to deterministic calculations, extend to many network games.",
    "published_date": "2017-09-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "q-fin.EC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.10402v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.09936v1",
    "title": "A Branch-and-Cut Algorithm to Design LDPC Codes without Small Cycles in Communication Systems",
    "authors": [
      "Banu Kabakulak",
      "Z. Caner Taşkın",
      "Ali Emre Pusane"
    ],
    "author_ids": [],
    "abstract": "In a digital communication system, information is sent from one place to\nanother over a noisy communication channel using binary symbols (bits).\nOriginal information is encoded by adding redundant bits, which are then used\nby low--density parity--check (LDPC) codes to detect and correct errors that\nmay have been introduced during transmission. Error correction capability of an\nLDPC code is severely degraded due to harmful structures such as small cycles\nin its bipartite graph representation known as Tanner graph (TG). We introduce\nan integer programming formulation to generate a TG for a given smallest cycle\nlength. We propose a branch-and-cut algorithm for its solution and investigate\nstructural properties of the problem to derive valid inequalities and variable\nfixing rules. We introduce a heuristic to obtain feasible solutions of the\nproblem. Our computational experiments show that our algorithm can generate\nLDPC codes without small cycles in acceptable amount of time for practically\nrelevant code lengths.",
    "published_date": "2017-09-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.09936v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.09885v2",
    "title": "Sentiment Classification with Word Attention based on Weakly Supervised Learning with a Convolutional Neural Network",
    "authors": [
      "Gichang Lee",
      "Jaeyun Jeong",
      "Seungwan Seo",
      "CzangYeob Kim",
      "Pilsung Kang"
    ],
    "author_ids": [],
    "abstract": "In order to maximize the applicability of sentiment analysis results, it is\nnecessary to not only classify the overall sentiment (positive/negative) of a\ngiven document but also to identify the main words that contribute to the\nclassification. However, most datasets for sentiment analysis only have the\nsentiment label for each document or sentence. In other words, there is no\ninformation about which words play an important role in sentiment\nclassification. In this paper, we propose a method for identifying key words\ndiscriminating positive and negative sentences by using a weakly supervised\nlearning method based on a convolutional neural network (CNN). In our model,\neach word is represented as a continuous-valued vector and each sentence is\nrepresented as a matrix whose rows correspond to the word vector used in the\nsentence. Then, the CNN model is trained using these sentence matrices as\ninputs and the sentiment labels as the output. Once the CNN model is trained,\nwe implement the word attention mechanism that identifies high-contributing\nwords to classification results with a class activation map, using the weights\nfrom the fully connected layer at the end of the learned CNN model. In order to\nverify the proposed methodology, we evaluated the classification accuracy and\ninclusion rate of polarity words using two movie review datasets. Experimental\nresult show that the proposed model can not only correctly classify the\nsentence polarity but also successfully identify the corresponding words with\nhigh polarity scores.",
    "published_date": "2017-09-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.09885v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.09452v2",
    "title": "Rate of Orientation Change as a New Metric for Robot-Assisted and Open Surgical Skill Evaluation",
    "authors": [
      "Yarden Sharon",
      "Anthony M. Jarc",
      "Thomas S. Lendvay",
      "Ilana Nisky"
    ],
    "author_ids": [],
    "abstract": "Surgeons' technical skill directly impacts patient outcomes. To date, the\nangular motion of the instruments has been largely overlooked in objective\nskill evaluation. To fill this gap, we have developed metrics for surgical\nskill evaluation that are based on the orientation of surgical instruments. We\ntested our new metrics on two datasets with different conditions: (1) a dataset\nof experienced robotic surgeons and nonmedical users performing needle-driving\non a dry lab model, and (2) a small dataset of suturing movements performed by\nsurgeons training on a porcine model. We evaluated the performance of our new\nmetrics (angular displacement and the rate of orientation change) alongside the\nperformances of classical metrics (task time and path length). We calculated\neach metric on different segments of the movement. Our results highlighted the\nimportance of segmentation rather than calculating the metrics on the entire\nmovement. Our new metric, the rate of orientation change, showed statistically\nsignificant differences between experienced surgeons and nonmedical users /\nnovice surgeons, which were consistent with the classical task time metric. The\nrate of orientation change captures technical aspects that are taught during\nsurgeons' training, and together with classical metrics can lead to a more\ncomprehensive discrimination of skills.",
    "published_date": "2017-09-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.09452v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.09093v2",
    "title": "Beyond opening up the black box: Investigating the role of algorithmic systems in Wikipedian organizational culture",
    "authors": [
      "R. Stuart Geiger"
    ],
    "author_ids": [],
    "abstract": "Scholars and practitioners across domains are increasingly concerned with\nalgorithmic transparency and opacity, interrogating the values and assumptions\nembedded in automated, black-boxed systems, particularly in user-generated\ncontent platforms. I report from an ethnography of infrastructure in Wikipedia\nto discuss an often understudied aspect of this topic: the local, contextual,\nlearned expertise involved in participating in a highly automated\nsocial-technical environment. Today, the organizational culture of Wikipedia is\ndeeply intertwined with various data-driven algorithmic systems, which\nWikipedians rely on to help manage and govern the \"anyone can edit\"\nencyclopedia at a massive scale. These bots, scripts, tools, plugins, and\ndashboards make Wikipedia more efficient for those who know how to work with\nthem, but like all organizational culture, newcomers must learn them if they\nwant to fully participate. I illustrate how cultural and organizational\nexpertise is enacted around algorithmic agents by discussing two\nautoethnographic vignettes, which relate my personal experience as a veteran in\nWikipedia. I present thick descriptions of how governance and gatekeeping\npractices are articulated through and in alignment with these automated\ninfrastructures. Over the past 15 years, Wikipedian veterans and administrators\nhave made specific decisions to support administrative and editorial workflows\nwith automation in particular ways and not others. I use these cases of\nWikipedia's bot-supported bureaucracy to discuss several issues in the fields\nof critical algorithms studies, critical data studies, and fairness,\naccountability, and transparency in machine learning -- most principally\narguing that scholarship and practice must go beyond trying to \"open up the\nblack box\" of such systems and also examine sociocultural processes like\nnewcomer socialization.",
    "published_date": "2017-09-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.09093v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.08753v1",
    "title": "Automated Behavioral Analysis of Malware A Case Study of WannaCry Ransomware",
    "authors": [
      "Qian Chen",
      "Robert A. Bridges"
    ],
    "author_ids": [],
    "abstract": "Ransomware, a class of self-propagating malware that uses encryption to hold\nthe victims' data ransom, has emerged in recent years as one of the most\ndangerous cyber threats, with widespread damage; e.g., zero-day ransomware\nWannaCry has caused world-wide catastrophe, from knocking U.K. National Health\nService hospitals offline to shutting down a Honda Motor Company in Japan[1].\nOur close collaboration with security operations of large enterprises reveals\nthat defense against ransomware relies on tedious analysis from high-volume\nsystems logs of the first few infections. Sandbox analysis of freshly captured\nmalware is also commonplace in operation.\n  We introduce a method to identify and rank the most discriminating ransomware\nfeatures from a set of ambient (non-attack) system logs and at least one log\nstream containing both ambient and ransomware behavior. These ranked features\nreveal a set of malware actions that are produced automatically from system\nlogs, and can help automate tedious manual analysis. We test our approach using\nWannaCry and two polymorphic samples by producing logs with Cuckoo Sandbox\nduring both ambient, and ambient plus ransomware executions. Our goal is to\nextract the features of the malware from the logs with only knowledge that\nmalware was present. We compare outputs with a detailed analysis of WannaCry\nallowing validation of the algorithm's feature extraction and provide analysis\nof the method's robustness to variations of input data\\textemdash changing\nquality/quantity of ambient data and testing polymorphic ransomware. Most\nnotably, our patterns are accurate and unwavering when generated from\npolymorphic WannaCry copies, on which 63 (of 63 tested) anti-virus (AV)\nproducts fail.",
    "published_date": "2017-09-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.08753v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.07966v7",
    "title": "High Degree Sum of Squares Proofs, Bienstock-Zuckerberg hierarchy and Chvatal-Gomory cuts",
    "authors": [
      "Monaldo Mastrolilli"
    ],
    "author_ids": [],
    "abstract": "Chvatal-Gomory (CG) cuts and the Bienstock-Zuckerberg hierarchy capture\nuseful linear programs that the standard bounded degree Lasserre/Sum-of-Squares\nSOS hierarchy fails to capture.\n  In this paper we present a novel polynomial time SOS hierarchy for 0/1\nproblems with a custom subspace of high degree polynomials (not the standard\nsubspace of low-degree polynomials). We show that the new SOS hierarchy\nrecovers the Bienstock-Zuckerberg hierarchy. Our result implies a linear\nprogram that reproduces the Bienstock-Zuckerberg hierarchy as a polynomial\nsized, efficiently constructive extended formulation that satisfies all\nconstant pitch inequalities. The construction is also very simple, and it is\nfully defined by giving the supporting polynomials. Moreover, for a class of\npolytopes (e.g. set covering and packing problems), the resulting SOS hierarchy\noptimizes in polynomial time over the polytope resulting from any constant\nrounds of CG-cuts, up to an arbitrarily small error.\n  Arguably, this is the first example where different basis functions can be\nuseful in asymmetric situations to obtain a hierarchy of relaxations.",
    "published_date": "2017-09-22T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.CC",
      "cs.SC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07966v7",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.07899v1",
    "title": "On the Discrimination Power and Effective Utilization of Active Learning Measures in Version Space Search",
    "authors": [
      "Patrick Rodler"
    ],
    "author_ids": [],
    "abstract": "Active Learning (AL) methods have proven cost-saving against passive\nsupervised methods in many application domains. An active learner, aiming to\nfind some target hypothesis, formulates sequential queries to some oracle. The\nset of hypotheses consistent with the already answered queries is called\nversion space. Several query selection measures (QSMs) for determining the best\nquery to ask next have been proposed. Assuming binaryoutcome queries, we\nanalyze various QSMs wrt. to the discrimination power of their selected queries\nwithin the current version space. As a result, we derive superiority and\nequivalence relations between these QSMs and introduce improved versions of\nexisting QSMs to overcome identified issues. The obtained picture gives a hint\nabout which QSMs should preferably be used in pool-based AL scenarios.\nMoreover, we deduce properties optimal queries wrt. QSMs must satisfy. Based on\nthese, we demonstrate how efficient heuristic search methods for optimal\nqueries in query synthesis AL scenarios can be devised.",
    "published_date": "2017-09-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07899v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.07796v2",
    "title": "On overfitting and asymptotic bias in batch reinforcement learning with partial observability",
    "authors": [
      "Vincent Francois-Lavet",
      "Guillaume Rabusseau",
      "Joelle Pineau",
      "Damien Ernst",
      "Raphael Fonteneau"
    ],
    "author_ids": [],
    "abstract": "This paper provides an analysis of the tradeoff between asymptotic bias\n(suboptimality with unlimited data) and overfitting (additional suboptimality\ndue to limited data) in the context of reinforcement learning with partial\nobservability. Our theoretical analysis formally characterizes that while\npotentially increasing the asymptotic bias, a smaller state representation\ndecreases the risk of overfitting. This analysis relies on expressing the\nquality of a state representation by bounding L1 error terms of the associated\nbelief states. Theoretical results are empirically illustrated when the state\nrepresentation is a truncated history of observations, both on synthetic POMDPs\nand on a large-scale POMDP in the context of smartgrids, with real-world data.\nFinally, similarly to known results in the fully observable setting, we also\nbriefly discuss and empirically illustrate how using function approximators and\nadapting the discount factor may enhance the tradeoff between asymptotic bias\nand overfitting in the partially observable context.",
    "published_date": "2017-09-22T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07796v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.07601v1",
    "title": "Stochastic Input Models in Online Computing",
    "authors": [
      "Yasushi Kawase"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study twelve stochastic input models for online problems\nand reveal the relationships among the competitive ratios for the models. The\ncompetitive ratio is defined as the worst ratio between the expected optimal\nvalue and the expected profit of the solution obtained by the online algorithm\nwhere the input distribution is restricted according to the model. To handle a\nbroad class of online problems, we use a framework called request-answer games\nthat is introduced by Ben-David et al. The stochastic input models consist of\ntwo types: known distribution and unknown distribution. For each type, we\nconsider six classes of distributions: dependent distributions, deterministic\ninput, independent distributions, identical independent distribution, random\norder of a deterministic input, and random order of independent distributions.\nAs an application of the models, we consider two basic online problems, which\nare variants of the secretary problem and the prophet inequality problem, under\nthe twelve stochastic input models. We see the difference of the competitive\nratios through these problems.",
    "published_date": "2017-09-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "math.ST",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07601v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.07433v2",
    "title": "Perturbative Black Box Variational Inference",
    "authors": [
      "Robert Bamler",
      "Cheng Zhang",
      "Manfred Opper",
      "Stephan Mandt"
    ],
    "author_ids": [],
    "abstract": "Black box variational inference (BBVI) with reparameterization gradients\ntriggered the exploration of divergence measures other than the\nKullback-Leibler (KL) divergence, such as alpha divergences. In this paper, we\nview BBVI with generalized divergences as a form of estimating the marginal\nlikelihood via biased importance sampling. The choice of divergence determines\na bias-variance trade-off between the tightness of a bound on the marginal\nlikelihood (low bias) and the variance of its gradient estimators. Drawing on\nvariational perturbation theory of statistical physics, we use these insights\nto construct a family of new variational bounds. Enumerated by an odd integer\norder $K$, this family captures the standard KL bound for $K=1$, and converges\nto the exact marginal likelihood as $K\\to\\infty$. Compared to\nalpha-divergences, our reparameterization gradients have a lower variance. We\nshow in experiments on Gaussian Processes and Variational Autoencoders that the\nnew bounds are more mass covering, and that the resulting posterior covariances\nare closer to the true posterior and lead to higher likelihoods on held-out\ndata.",
    "published_date": "2017-09-21T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07433v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.07078v2",
    "title": "Max-Min Fair Resource Allocation in Millimetre-Wave Backhauls",
    "authors": [
      "Rui Li",
      "Paul Patras"
    ],
    "author_ids": [],
    "abstract": "5G mobile networks are expected to provide pervasive high speed wireless\nconnectivity, to support increasingly resource intensive user applications.\nNetwork hyper-densification therefore becomes necessary, though connecting to\nthe Internet tens of thousands of base stations is non-trivial, especially in\nurban scenarios where optical fibre is difficult and costly to deploy. The\nmillimetre wave (mm-wave) spectrum is a promising candidate for inexpensive\nmulti-Gbps wireless backhauling, but exploiting this band for effective\nmulti-hop data communications is challenging. In particular, resource\nallocation and scheduling of very narrow transmission/ reception beams requires\nto overcome terminal deafness and link blockage problems, while managing\nfairness issues that arise when flows encounter dissimilar competition and\ntraverse different numbers of links with heterogeneous quality. In this paper,\nwe propose WiHaul, an airtime allocation and scheduling mechanism that\novercomes these challenges specific to multi-hop mm-wave networks, guarantees\nmax-min fairness among traffic flows, and ensures the overall available\nbackhaul resources are fully utilised. We evaluate the proposed WiHaul scheme\nover a broad range of practical network conditions, and demonstrate up to 5\ntimes individual throughput gains and a fivefold improvement in terms of\nmeasurable fairness, over recent mm-wave scheduling solutions.",
    "published_date": "2017-09-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.07078v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.06995v10",
    "title": "Dependent randomized rounding for clustering and partition systems with knapsack constraints",
    "authors": [
      "David G. Harris",
      "Thomas Pensyl",
      "Aravind Srinivasan",
      "Khoa Trinh"
    ],
    "author_ids": [],
    "abstract": "Clustering problems are fundamental to unsupervised learning. There is an\nincreased emphasis on fairness in machine learning and AI; one representative\nnotion of fairness is that no single demographic group should be\nover-represented among the cluster-centers. This, and much more general\nclustering problems, can be formulated with \"knapsack\" and \"partition\"\nconstraints. We develop new randomized algorithms targeting such problems, and\nstudy two in particular: multi-knapsack median and multi-knapsack center. Our\nrounding algorithms give new approximation and pseudo-approximation algorithms\nfor these problems. One key technical tool, which may be of independent\ninterest, is a new tail bound analogous to Feige (2006) for sums of random\nvariables with unbounded variances. Such bounds can be useful in inferring\nproperties of large networks using few samples.",
    "published_date": "2017-09-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.06995v10",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.06809v1",
    "title": "Block-Diagonal Solutions to Lyapunov Inequalities and Generalisations of Diagonal Dominance",
    "authors": [
      "Aivar Sootla",
      "Yang Zheng",
      "Antonis Papachristodoulou"
    ],
    "author_ids": [],
    "abstract": "Diagonally dominant matrices have many applications in systems and control\ntheory. Linear dynamical systems with scaled diagonally dominant drift\nmatrices, which include stable positive systems, allow for scalable stability\nanalysis. For example, it is known that Lyapunov inequalities for this class of\nsystems admit diagonal solutions. In this paper, we present an extension of\nscaled diagonally dominance to block partitioned matrices. We show that our\ndefinition describes matrices admitting block-diagonal solutions to Lyapunov\ninequalities and that these solutions can be computed using linear algebraic\ntools. We also show how in some cases the Lyapunov inequalities can be\ndecoupled into a set of lower dimensional linear matrix inequalities, thus\nleading to improved scalability. We conclude by illustrating some advantages\nand limitations of our results with numerical examples.",
    "published_date": "2017-09-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.06809v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.06692v2",
    "title": "A Voting-Based System for Ethical Decision Making",
    "authors": [
      "Ritesh Noothigattu",
      "Snehalkumar 'Neil' S. Gaikwad",
      "Edmond Awad",
      "Sohan Dsouza",
      "Iyad Rahwan",
      "Pradeep Ravikumar",
      "Ariel D. Procaccia"
    ],
    "author_ids": [],
    "abstract": "We present a general approach to automating ethical decisions, drawing on\nmachine learning and computational social choice. In a nutshell, we propose to\nlearn a model of societal preferences, and, when faced with a specific ethical\ndilemma at runtime, efficiently aggregate those preferences to identify a\ndesirable choice. We provide a concrete algorithm that instantiates our\napproach; some of its crucial steps are informed by a new theory of\nswap-dominance efficient voting rules. Finally, we implement and evaluate a\nsystem for ethical decision making in the autonomous vehicle domain, using\npreference data collected from 1.3 million people through the Moral Machine\nwebsite.",
    "published_date": "2017-09-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.06692v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.05970v1",
    "title": "On the Dependence of Linear Coding Rates on the Characteristic of the Finite Field",
    "authors": [
      "Niladri Das",
      "Brijesh Kumar Rai"
    ],
    "author_ids": [],
    "abstract": "It is known that for any finite/co-finite set of primes there exists a\nnetwork which has a rate $1$ solution if and only if the characteristic of the\nfinite field belongs to the given set. We generalize this result to show that\nfor any positive rational number $k/n$, and for any given finite/co-finite set\nof primes, there exists a network which has a rate $k/n$ fractional linear\nnetwork coding solution if and only if the characteristic of the finite field\nbelongs to the given set. For this purpose we construct two networks:\n$\\mathcal{N}_1$ and $\\mathcal{N}_2$; the network $\\mathcal{N}_1$ has a $k/n$\nfractional linear network coding solution if and only if the characteristic of\nthe finite field belongs to the given finite set of primes, and the network\n$\\mathcal{N}_2$ has a $k/n$ fractional linear network coding solution if and\nonly if the characteristic of the finite field belongs to the given co-finite\nset of primes.\n  Recently, a method has been introduced where characteristic-dependent linear\nrank inequalities are produced from networks whose linear coding capacity\ndepends on the characteristic of the finite field. By employing this method on\nthe networks $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we construct two classes of\ncharacteristic-dependent linear rank inequalities. For any given set of primes,\nthe first class contains an inequality which holds if the characteristic of the\nfinite field does not belong to the given set of primes but may not hold\notherwise; the second class contains an inequality which holds if the\ncharacteristic of the finite field belongs to the given set of primes but may\nnot hold otherwise. We then use these inequalities to obtain an upper-bound on\nthe linear coding capacity of $\\mathcal{N}_1$ and $\\mathcal{N}_2$.",
    "published_date": "2017-09-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.05970v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.03221v1",
    "title": "Fairness Testing: Testing Software for Discrimination",
    "authors": [
      "Sainyam Galhotra",
      "Yuriy Brun",
      "Alexandra Meliou"
    ],
    "author_ids": [],
    "abstract": "This paper defines software fairness and discrimination and develops a\ntesting-based method for measuring if and how much software discriminates,\nfocusing on causality in discriminatory behavior. Evidence of software\ndiscrimination has been found in modern software systems that recommend\ncriminal sentences, grant access to financial products, and determine who is\nallowed to participate in promotions. Our approach, Themis, generates efficient\ntest suites to measure discrimination. Given a schema describing valid system\ninputs, Themis generates discrimination tests automatically and does not\nrequire an oracle. We evaluate Themis on 20 software systems, 12 of which come\nfrom prior work with explicit focus on avoiding discrimination. We find that\n(1) Themis is effective at discovering software discrimination, (2)\nstate-of-the-art techniques for removing discrimination from algorithms fail in\nmany situations, at times discriminating against as much as 98% of an input\nsubdomain, (3) Themis optimizations are effective at producing efficient test\nsuites for measuring discrimination, and (4) Themis is more efficient on\nsystems that exhibit more discrimination. We thus demonstrate that fairness\ntesting is a critical aspect of the software development cycle in domains with\npossible discrimination and provide initial tools for measuring software\ndiscrimination.",
    "published_date": "2017-09-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.DB",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.03221v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.02884v1",
    "title": "Degrees of Freedom of the Broadcast Channel with Hybrid CSI at Transmitter and Receivers",
    "authors": [
      "Mohamed Fadel",
      "Aria Nosratinia"
    ],
    "author_ids": [],
    "abstract": "In general, the different links of a broadcast channel may experience\ndifferent fading dynamics and, potentially, unequal or hybrid channel state\ninformation (CSI) conditions. The faster the fading and the shorter the fading\nblock length, the more often the link needs to be trained and estimated at the\nreceiver, and the more likely that CSI is stale or unavailable at the\ntransmitter. Disparity of link fading dynamics in the presence of CSI\nlimitations can be modeled by a multi-user broadcast channel with both\nnon-identical link fading block lengths as well as dissimilar link CSIR/CSIT\nconditions. This paper investigates a MISO broadcast channel where some\nreceivers experience longer coherence intervals (static receivers) and have\nCSIR, while some other receivers experience shorter coherence intervals\n(dynamic receivers) and do not enjoy free CSIR. We consider a variety of CSIT\nconditions for the above mentioned model, including no CSIT, delayed CSIT, or\nhybrid CSIT. To investigate the degrees of freedom region, we employ\ninterference alignment and beamforming along with a product superposition that\nallows simultaneous but non-contaminating transmission of pilots and data to\ndifferent receivers. Outer bounds employ the extremal entropy inequality as\nwell as a bounding of the performance of a discrete memoryless multiuser\nmultilevel broadcast channel. For several cases, inner and outer bounds are\nestablished that either partially meet, or the gap diminishes with increasing\ncoherence times.",
    "published_date": "2017-09-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.02884v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.02564v7",
    "title": "Democratic Fair Allocation of Indivisible Goods",
    "authors": [
      "Erel Segal-Halevi",
      "Warut Suksompong"
    ],
    "author_ids": [],
    "abstract": "We study the problem of fairly allocating indivisible goods to groups of\nagents. Agents in the same group share the same set of goods even though they\nmay have different preferences. Previous work has focused on unanimous\nfairness, in which all agents in each group must agree that their group's share\nis fair. Under this strict requirement, fair allocations exist only for small\ngroups. We introduce the concept of democratic fairness, which aims to satisfy\na certain fraction of the agents in each group. This concept is better suited\nto large groups such as cities or countries. We present protocols for\ndemocratic fair allocation among two or more arbitrarily large groups of agents\nwith monotonic, additive, or binary valuations. For two groups with arbitrary\nmonotonic valuations, we give an efficient protocol that guarantees\nenvy-freeness up to one good for at least $1/2$ of the agents in each group,\nand prove that the $1/2$ fraction is optimal. We also present other protocols\nthat make weaker fairness guarantees to more agents in each group, or to more\ngroups. Our protocols combine techniques from different fields, including\ncombinatorial game theory, cake cutting, and voting.",
    "published_date": "2017-09-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.02564v7",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.02012v2",
    "title": "On Fairness and Calibration",
    "authors": [
      "Geoff Pleiss",
      "Manish Raghavan",
      "Felix Wu",
      "Jon Kleinberg",
      "Kilian Q. Weinberger"
    ],
    "author_ids": [],
    "abstract": "The machine learning community has become increasingly concerned with the\npotential for bias and discrimination in predictive models. This has motivated\na growing line of work on what it means for a classification procedure to be\n\"fair.\" In this paper, we investigate the tension between minimizing error\ndisparity across different population groups while maintaining calibrated\nprobability estimates. We show that calibration is compatible only with a\nsingle error constraint (i.e. equal false-negatives rates across groups), and\nshow that any algorithm that satisfies this relaxation is no better than\nrandomizing a percentage of predictions for an existing classifier. These\nunsettling findings, which extend and generalize existing results, are\nempirically confirmed on several datasets.",
    "published_date": "2017-09-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.02012v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.01572v3",
    "title": "Sequence Prediction with Neural Segmental Models",
    "authors": [
      "Hao Tang"
    ],
    "author_ids": [],
    "abstract": "Segments that span contiguous parts of inputs, such as phonemes in speech,\nnamed entities in sentences, actions in videos, occur frequently in sequence\nprediction problems. Segmental models, a class of models that explicitly\nhypothesizes segments, have allowed the exploration of rich segment features\nfor sequence prediction. However, segmental models suffer from slow decoding,\nhampering the use of computationally expensive features.\n  In this thesis, we introduce discriminative segmental cascades, a multi-pass\ninference framework that allows us to improve accuracy by adding higher-order\nfeatures and neural segmental features while maintaining efficiency. We also\nshow that instead of including more features to obtain better accuracy,\nsegmental cascades can be used to speed up training and decoding.\n  Segmental models, similarly to conventional speech recognizers, are typically\ntrained in multiple stages. In the first stage, a frame classifier is trained\nwith manual alignments, and then in the second stage, segmental models are\ntrained with manual alignments and the out- puts of the frame classifier.\nHowever, obtaining manual alignments are time-consuming and expensive. We\nexplore end-to-end training for segmental models with various loss functions,\nand show how end-to-end training with marginal log loss can eliminate the need\nfor detailed manual alignments.\n  We draw the connections between the marginal log loss and a popular\nend-to-end training approach called connectionist temporal classification. We\npresent a unifying framework for various end-to-end graph search-based models,\nsuch as hidden Markov models, connectionist temporal classification, and\nsegmental models. Finally, we discuss possible extensions of segmental models\nto large-vocabulary sequence prediction tasks.",
    "published_date": "2017-09-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.01572v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.01433v1",
    "title": "An Exact Approach for the Balanced k-Way Partitioning Problem with Weight Constraints and its Application to Sports Team Realignment",
    "authors": [
      "Diego Recalde",
      "Daniel Severín",
      "Ramiro Torres",
      "Polo Vaca"
    ],
    "author_ids": [],
    "abstract": "In this work a balanced k-way partitioning problem with weight constraints is\ndefined to model the sports team realignment. Sports teams must be partitioned\ninto a fixed number of groups according to some regulations, where the total\ndistance of the road trips that all teams must travel to play a Double Round\nRobin Tournament in each group is minimized. Two integer programming\nformulations for this problem are introduced, and the validity of three\nfamilies of inequalities associated to the polytope of these formulations is\nproved. The performance of a tabu search procedure and a Branch & Cut\nalgorithm, which uses the valid inequalities as cuts, is evaluated over\nsimulated and real-world instances. In particular, an optimal solution for the\nrealignment of the Ecuadorian Football league is reported and the methodology\ncan be suitable adapted for the realignment of other sports leagues.",
    "published_date": "2017-09-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM",
      "math.CO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.01433v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.00826v1",
    "title": "Analysing Mutual Exclusion using Process Algebra with Signals",
    "authors": [
      "Victor Dyseryn",
      "Rob van Glabbeek",
      "Peter Höfner"
    ],
    "author_ids": [],
    "abstract": "In contrast to common belief, the Calculus of Communicating Systems (CCS) and\nsimilar process algebras lack the expressive power to accurately capture mutual\nexclusion protocols without enriching the language with fairness assumptions.\nAdding a fairness assumption to implement a mutual exclusion protocol seems\ncounter-intuitive. We employ a signalling operator, which can be combined with\nCCS, or other process calculi, and show that this minimal extension is\nexpressive enough to model mutual exclusion: we confirm the correctness of\nPeterson's mutual exclusion algorithm for two processes, as well as Lamport's\nbakery algorithm, under reasonable assumptions on the underlying memory model.\nThe correctness of Peterson's algorithm for more than two processes requires\nstronger, less realistic assumptions on the underlying memory model.",
    "published_date": "2017-09-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO",
      "F.3.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.00826v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.00672v1",
    "title": "Unsupervised feature learning with discriminative encoder",
    "authors": [
      "Gaurav Pandey",
      "Ambedkar Dukkipati"
    ],
    "author_ids": [],
    "abstract": "In recent years, deep discriminative models have achieved extraordinary\nperformance on supervised learning tasks, significantly outperforming their\ngenerative counterparts. However, their success relies on the presence of a\nlarge amount of labeled data. How can one use the same discriminative models\nfor learning useful features in the absence of labels? We address this question\nin this paper, by jointly modeling the distribution of data and latent features\nin a manner that explicitly assigns zero probability to unobserved data. Rather\nthan maximizing the marginal probability of observed data, we maximize the\njoint probability of the data and the latent features using a two step EM-like\nprocedure. To prevent the model from overfitting to our initial selection of\nlatent features, we use adversarial regularization. Depending on the task, we\nallow the latent features to be one-hot or real-valued vectors and define a\nsuitable prior on the features. For instance, one-hot features correspond to\nclass labels and are directly used for the unsupervised and semi-supervised\nclassification task, whereas real-valued feature vectors are fed as input to\nsimple classifiers for auxiliary supervised discrimination tasks. The proposed\nmodel, which we dub discriminative encoder (or DisCoder), is flexible in the\ntype of latent features that it can capture. The proposed model achieves\nstate-of-the-art performance on several challenging tasks.",
    "published_date": "2017-09-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.00672v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1709.00615v1",
    "title": "Distributed Multi-task Formation Control under Parametric Communication Uncertainties",
    "authors": [
      "Dongkun Han",
      "Dimitra Panagou"
    ],
    "author_ids": [],
    "abstract": "Formation control is a key problem in the coordination of multiple agents. It\narises new challenges to traditional formation control strategy when the\ncommunication among agents is affected by uncertainties. This paper considers\nthe robust multi-task formation control problem of multiple non-point agents\nwhose communications are disturbed by uncertain parameters. The control\nobjectives include 1. achieving the desired configuration; 2. avoiding\ncollisions; 3. preserving the connectedness of uncertain topology. To achieve\nthese objectives, firstly, a condition of Linear Matrix Inequalities (LMIs) is\nproposed for checking the connectedness of an uncertain communication topology.\nThen, by preserving the initial topological connectedness, a gradient-based\ndistributed controller is designed via Lyapunov-like barrier functions. Two\nnumerical examples illustrate the effectiveness of the proposed method.",
    "published_date": "2017-09-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.00615v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1709.00572v2",
    "title": "XFlow: Cross-modal Deep Neural Networks for Audiovisual Classification",
    "authors": [
      "Cătălina Cangea",
      "Petar Veličković",
      "Pietro Liò"
    ],
    "author_ids": [],
    "abstract": "In recent years, there have been numerous developments towards solving\nmultimodal tasks, aiming to learn a stronger representation than through a\nsingle modality. Certain aspects of the data can be particularly useful in this\ncase - for example, correlations in the space or time domain across modalities\n- but should be wisely exploited in order to benefit from their full predictive\npotential. We propose two deep learning architectures with multimodal\ncross-connections that allow for dataflow between several feature extractors\n(XFlow). Our models derive more interpretable features and achieve better\nperformances than models which do not exchange representations, usefully\nexploiting correlations between audio and visual data, which have a different\ndimensionality and are nontrivially exchangeable. Our work improves on existing\nmultimodal deep learning algorithms in two essential ways: (1) it presents a\nnovel method for performing cross-modality (before features are learned from\nindividual modalities) and (2) extends the previously proposed\ncross-connections which only transfer information between streams that process\ncompatible data. Illustrating some of the representations learned by the\nconnections, we analyse their contribution to the increase in discrimination\nability and reveal their compatibility with a lip-reading network intermediate\nrepresentation. We provide the research community with Digits, a new dataset\nconsisting of three data types extracted from videos of people saying the\ndigits 0-9. Results show that both cross-modal architectures outperform their\nbaselines (by up to 11.5%) when evaluated on the AVletters, CUAVE and Digits\ndatasets, achieving state-of-the-art results.",
    "published_date": "2017-09-02T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1709.00572v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.09642v1",
    "title": "Neural Class-Specific Regression for face verification",
    "authors": [
      "Guanqun Cao",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "author_ids": [],
    "abstract": "Face verification is a problem approached in the literature mainly using\nnonlinear class-specific subspace learning techniques. While it has been shown\nthat kernel-based Class-Specific Discriminant Analysis is able to provide\nexcellent performance in small- and medium-scale face verification problems,\nits application in today's large-scale problems is difficult due to its\ntraining space and computational requirements. In this paper, generalizing our\nprevious work on kernel-based class-specific discriminant analysis, we show\nthat class-specific subspace learning can be cast as a regression problem. This\nallows us to derive linear, (reduced) kernel and neural network-based\nclass-specific discriminant analysis methods using efficient batch and/or\niterative training schemes, suited for large-scale learning problems. We test\nthe performance of these methods in two datasets describing medium- and\nlarge-scale face verification problems.",
    "published_date": "2017-08-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.09642v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.08735v1",
    "title": "Gender and Emotion Recognition with Implicit User Signals",
    "authors": [
      "Maneesh Bilalpur",
      "Seyed Mostafa Kia",
      "Manisha Chawla",
      "Tat-Seng Chua",
      "Ramanathan Subramanian"
    ],
    "author_ids": [],
    "abstract": "We examine the utility of implicit user behavioral signals captured using\nlow-cost, off-the-shelf devices for anonymous gender and emotion recognition. A\nuser study designed to examine male and female sensitivity to facial emotions\nconfirms that females recognize (especially negative) emotions quicker and more\naccurately than men, mirroring prior findings. Implicit viewer responses in the\nform of EEG brain signals and eye movements are then examined for existence of\n(a) emotion and gender-specific patterns from event-related potentials (ERPs)\nand fixation distributions and (b) emotion and gender discriminability.\nExperiments reveal that (i) Gender and emotion-specific differences are\nobservable from ERPs, (ii) multiple similarities exist between explicit\nresponses gathered from users and their implicit behavioral signals, and (iii)\nSignificantly above-chance ($\\approx$70%) gender recognition is achievable on\ncomparing emotion-specific EEG responses-- gender differences are encoded best\nfor anger and disgust. Also, fairly modest valence (positive vs negative\nemotion) recognition is achieved with EEG and eye-based features.",
    "published_date": "2017-08-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC",
      "H.5.2; I.3.6; H.1.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.08735v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.07871v1",
    "title": "A European research roadmap for optimizing societal impact of big data on environment and energy efficiency",
    "authors": [
      "Martí Cuquet",
      "Anna Fensel",
      "Lorenzo Bigagli"
    ],
    "author_ids": [],
    "abstract": "We present a roadmap to guide European research efforts towards a socially\nresponsible big data economy that maximizes the positive impact of big data in\nenvironment and energy efficiency. The goal of the roadmap is to allow\nstakeholders and the big data community to identify and meet big data\nchallenges, and to proceed with a shared understanding of the societal impact,\npositive and negative externalities, and concrete problems worth investigating.\nIt builds upon a case study focused on the impact of big data practices in the\ncontext of Earth Observation that reveals both positive and negative effects in\nthe areas of economy, society and ethics, legal frameworks and political\nissues. The roadmap identifies European technical and non-technical priorities\nin research and innovation to be addressed in the upcoming five years in order\nto deliver societal impact, develop skills and contribute to standardization.",
    "published_date": "2017-08-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07871v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.07715v1",
    "title": "The Price of Uncertainty in Present-Biased Planning",
    "authors": [
      "Susanne Albers",
      "Dennis Kraft"
    ],
    "author_ids": [],
    "abstract": "The tendency to overestimate immediate utility is a common cognitive bias. As\na result people behave inconsistently over time and fail to reach long-term\ngoals. Behavioral economics tries to help affected individuals by implementing\nexternal incentives. However, designing robust incentives is often difficult\ndue to imperfect knowledge of the parameter $\\beta \\in (0,1]$ quantifying a\nperson's present bias. Using the graphical model of Kleinberg and Oren, we\napproach this problem from an algorithmic perspective. Based on the assumption\nthat the only information about $\\beta$ is its membership in some set $B\n\\subset (0,1]$, we distinguish between two models of uncertainty: one in which\n$\\beta$ is fixed and one in which it varies over time. As our main result we\nshow that the conceptual loss of efficiency incurred by incentives in the form\nof penalty fees is at most $2$ in the former and $1 + \\max B/\\min B$ in the\nlatter model. We also give asymptotically matching lower bounds and\napproximation algorithms.",
    "published_date": "2017-08-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07715v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.07549v2",
    "title": "Objective Classes for Micro-Facial Expression Recognition",
    "authors": [
      "Adrian K. Davison",
      "Walied Merghani",
      "Moi Hoon Yap"
    ],
    "author_ids": [],
    "abstract": "Micro-expressions are brief spontaneous facial expressions that appear on a\nface when a person conceals an emotion, making them different to normal facial\nexpressions in subtlety and duration. Currently, emotion classes within the\nCASME II dataset are based on Action Units and self-reports, creating conflicts\nduring machine learning training. We will show that classifying expressions\nusing Action Units, instead of predicted emotion, removes the potential bias of\nhuman reporting. The proposed classes are tested using LBP-TOP, HOOF and HOG 3D\nfeature descriptors. The experiments are evaluated on two benchmark FACS coded\ndatasets: CASME II and SAMM. The best result achieves 86.35\\% accuracy when\nclassifying the proposed 5 classes on CASME II using HOG 3D, outperforming the\nresult of the state-of-the-art 5-class emotional-based classification in CASME\nII. Results indicate that classification based on Action Units provides an\nobjective method to improve micro-expression recognition.",
    "published_date": "2017-08-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07549v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.07755v2",
    "title": "Gait Recognition from Motion Capture Data",
    "authors": [
      "Michal Balazia",
      "Petr Sojka"
    ],
    "author_ids": [],
    "abstract": "Gait recognition from motion capture data, as a pattern classification\ndiscipline, can be improved by the use of machine learning. This paper\ncontributes to the state-of-the-art with a statistical approach for extracting\nrobust gait features directly from raw data by a modification of Linear\nDiscriminant Analysis with Maximum Margin Criterion. Experiments on the CMU\nMoCap database show that the suggested method outperforms thirteen relevant\nmethods based on geometric features and a method to learn the features by a\ncombination of Principal Component Analysis and Linear Discriminant Analysis.\nThe methods are evaluated in terms of the distribution of biometric templates\nin respective feature spaces expressed in a number of class separability\ncoefficients and classification metrics. Results also indicate a high\nportability of learned features, that means, we can learn what aspects of walk\npeople generally differ in and extract those as general gait features.\nRecognizing people without needing group-specific features is convenient as\nparticular people might not always provide annotated learning data. As a\ncontribution to reproducible research, our evaluation framework and database\nhave been made publicly available. This research makes motion capture\ntechnology directly applicable for human recognition.",
    "published_date": "2017-08-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "68T05, 68T10",
      "I.5"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07755v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.07308v1",
    "title": "Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning Workloads",
    "authors": [
      "Tian Li",
      "Jie Zhong",
      "Ji Liu",
      "Wentao Wu",
      "Ce Zhang"
    ],
    "author_ids": [],
    "abstract": "We present ease.ml, a declarative machine learning service platform we built\nto support more than ten research groups outside the computer science\ndepartments at ETH Zurich for their machine learning needs. With ease.ml, a\nuser defines the high-level schema of a machine learning application and\nsubmits the task via a Web interface. The system automatically deals with the\nrest, such as model selection and data movement. In this paper, we describe the\nease.ml architecture and focus on a novel technical problem introduced by\nease.ml regarding resource allocation. We ask, as a \"service provider\" that\nmanages a shared cluster of machines among all our users running machine\nlearning workloads, what is the resource allocation strategy that maximizes the\nglobal satisfaction of all our users?\n  Resource allocation is a critical yet subtle issue in this multi-tenant\nscenario, as we have to balance between efficiency and fairness. We first\nformalize the problem that we call multi-tenant model selection, aiming for\nminimizing the total regret of all users running automatic model selection\ntasks. We then develop a novel algorithm that combines multi-armed bandits with\nBayesian optimization and prove a regret bound under the multi-tenant setting.\nFinally, we report our evaluation of ease.ml on synthetic data and on one\nservice we are providing to our users, namely, image classification with deep\nneural networks. Our experimental evaluation results show that our proposed\nsolution can be up to 9.8x faster in achieving the same global quality for all\nusers as the two popular heuristics used by our users before ease.ml.",
    "published_date": "2017-08-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DB",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07308v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.07157v1",
    "title": "Evaluation Measures for Relevance and Credibility in Ranked Lists",
    "authors": [
      "Christina Lioma",
      "Jakob Grue Simonsen",
      "Birger Larsen"
    ],
    "author_ids": [],
    "abstract": "Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.",
    "published_date": "2017-08-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.07157v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.06656v2",
    "title": "Causally Regularized Learning with Agnostic Data Selection Bias",
    "authors": [
      "Zheyan Shen",
      "Peng Cui",
      "Kun Kuang",
      "Bo Li",
      "Peixuan Chen"
    ],
    "author_ids": [],
    "abstract": "Most of previous machine learning algorithms are proposed based on the i.i.d.\nhypothesis. However, this ideal assumption is often violated in real\napplications, where selection bias may arise between training and testing\nprocess. Moreover, in many scenarios, the testing data is not even available\nduring the training process, which makes the traditional methods like transfer\nlearning infeasible due to their need on prior of test distribution. Therefore,\nhow to address the agnostic selection bias for robust model learning is of\nparamount importance for both academic research and real applications. In this\npaper, under the assumption that causal relationships among variables are\nrobust across domains, we incorporate causal technique into predictive modeling\nand propose a novel Causally Regularized Logistic Regression (CRLR) algorithm\nby jointly optimize global confounder balancing and weighted logistic\nregression. Global confounder balancing helps to identify causal features,\nwhose causal effect on outcome are stable across domains, then performing\nlogistic regression on those causal features constructs a robust predictive\nmodel against the agnostic bias. To validate the effectiveness of our CRLR\nalgorithm, we conduct comprehensive experiments on both synthetic and real\nworld datasets. Experimental results clearly demonstrate that our CRLR\nalgorithm outperforms the state-of-the-art methods, and the interpretability of\nour method can be fully depicted by the feature visualization.",
    "published_date": "2017-08-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.MM",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.06656v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.06298v2",
    "title": "Bounds on absolutely maximally entangled states from shadow inequalities, and the quantum MacWilliams identity",
    "authors": [
      "Felix Huber",
      "Christopher Eltschka",
      "Jens Siewert",
      "Otfried Gühne"
    ],
    "author_ids": [],
    "abstract": "A pure multipartite quantum state is called absolutely maximally entangled\n(AME), if all reductions obtained by tracing out at least half of its parties\nare maximally mixed. Maximal entanglement is then present across every\nbipartition. The existence of such states is in many cases unclear. With the\nhelp of the weight enumerator machinery known from quantum error correction and\nthe generalized shadow inequalities, we obtain new bounds on the existence of\nAME states in dimensions larger than two. To complete the treatment on the\nweight enumerator machinery, the quantum MacWilliams identity is derived in the\nBloch representation. Finally, we consider AME states whose subsystems have\ndifferent local dimensions, and present an example for a $2 \\times3 \\times 3\n\\times 3$ system that shows maximal entanglement across every bipartition.",
    "published_date": "2017-08-21T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.06298v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.05512v1",
    "title": "Large Margin Learning in Set to Set Similarity Comparison for Person Re-identification",
    "authors": [
      "Sanping Zhou",
      "Jinjun Wang",
      "Rui Shi",
      "Qiqi Hou",
      "Yihong Gong",
      "Nanning Zheng"
    ],
    "author_ids": [],
    "abstract": "Person re-identification (Re-ID) aims at matching images of the same person\nacross disjoint camera views, which is a challenging problem in multimedia\nanalysis, multimedia editing and content-based media retrieval communities. The\nmajor challenge lies in how to preserve similarity of the same person across\nvideo footages with large appearance variations, while discriminating different\nindividuals. To address this problem, conventional methods usually consider the\npairwise similarity between persons by only measuring the point to point (P2P)\ndistance. In this paper, we propose to use deep learning technique to model a\nnovel set to set (S2S) distance, in which the underline objective focuses on\npreserving the compactness of intra-class samples for each camera view, while\nmaximizing the margin between the intra-class set and inter-class set. The S2S\ndistance metric is consisted of three terms, namely the class-identity term,\nthe relative distance term and the regularization term. The class-identity term\nkeeps the intra-class samples within each camera view gathering together, the\nrelative distance term maximizes the distance between the intra-class class set\nand inter-class set across different camera views, and the regularization term\nsmoothness the parameters of deep convolutional neural network (CNN). As a\nresult, the final learned deep model can effectively find out the matched\ntarget to the probe object among various candidates in the video gallery by\nlearning discriminative and stable feature representations. Using the CUHK01,\nCUHK03, PRID2011 and Market1501 benchmark datasets, we extensively conducted\ncomparative evaluations to demonstrate the advantages of our method over the\nstate-of-the-art approaches.",
    "published_date": "2017-08-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.05512v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.05256v1",
    "title": "Deep Learning at 15PF: Supervised and Semi-Supervised Classification for Scientific Data",
    "authors": [
      "Thorsten Kurth",
      "Jian Zhang",
      "Nadathur Satish",
      "Ioannis Mitliagkas",
      "Evan Racah",
      "Mostofa Ali Patwary",
      "Tareq Malas",
      "Narayanan Sundaram",
      "Wahid Bhimji",
      "Mikhail Smorkalov",
      "Jack Deslippe",
      "Mikhail Shiryaev",
      "Srinivas Sridharan",
      "Prabhat",
      "Pradeep Dubey"
    ],
    "author_ids": [],
    "abstract": "This paper presents the first, 15-PetaFLOP Deep Learning system for solving\nscientific pattern classification problems on contemporary HPC architectures.\nWe develop supervised convolutional architectures for discriminating signals in\nhigh-energy physics data as well as semi-supervised architectures for\nlocalizing and classifying extreme weather in climate data. Our\nIntelcaffe-based implementation obtains $\\sim$2TFLOP/s on a single Cori\nPhase-II Xeon-Phi node. We use a hybrid strategy employing synchronous\nnode-groups, while using asynchronous communication across groups. We use this\nstrategy to scale training of a single model to $\\sim$9600 Xeon-Phi nodes;\nobtaining peak performance of 11.73-15.07 PFLOP/s and sustained performance of\n11.41-13.27 PFLOP/s. At scale, our HEP architecture produces state-of-the-art\nclassification accuracy on a dataset with 10M images, exceeding that achieved\nby selections on high-level physics-motivated features. Our semi-supervised\narchitecture successfully extracts weather patterns in a 15TB climate dataset.\nOur results demonstrate that Deep Learning can be optimized and scaled\neffectively on many-core, HPC systems.",
    "published_date": "2017-08-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.PF",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.05256v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.05078v1",
    "title": "Rapid Mixing of $k$-Class Biased Permutations",
    "authors": [
      "Sarah Miracle",
      "Amanda Pascoe Streib"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study a biased version of the nearest-neighbor\ntransposition Markov chain on the set of permutations where neighboring\nelements $i$ and $j$ are placed in order $(i,j)$ with probability $p_{i,j}$.\nOur goal is to identify the class of parameter sets ${\\bf P} = \\{p_{i,j}\\}$ for\nwhich this Markov chain is rapidly mixing. Specifically, we consider the open\nconjecture of Jim Fill that all monotone, positively biased distributions are\nrapidly mixing.\n  We resolve Fill's conjecture in the affirmative for distributions arising\nfrom $k$-class particle processes, where the elements are divided into $k$\nclasses and the probability of exchanging neighboring elements depends on the\nparticular classes the elements are in. We further require that $k$ is a\nconstant, and all probabilities between elements in different classes are\nbounded away from $1/2$. These particle processes arise in the context of\nself-organizing lists and our result also applies beyond permutations to the\nsetting where all particles in a class are indistinguishable. Additionally we\nshow that a broader class of distributions based on trees is also rapidly\nmixing, which generalizes a class analyzed by Bhakta et. al. (SODA '13). Our\nwork generalizes recent work by Haddadan and Winkler (STACS '17) studying\n3-class particle processes.\n  Our proof involves analyzing a generalized biased exclusion process, which is\na nearest-neighbor transposition chain applied to a 2-particle system. Biased\nexclusion processes are of independent interest, with applications in\nself-assembly. We generalize the results of Greenberg et al. (SODA '09) and\nBenjamini et. al (Trans. AMS '05) on biased exclusion processes to allow the\nprobability of swapping neighboring elements to depend on the entire system, as\nlong as the minimum bias is bounded away from $1$.",
    "published_date": "2017-08-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.05078v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.03200v1",
    "title": "Achieving an Efficient and Fair Equilibrium Through Taxation",
    "authors": [
      "Lin Gao",
      "Jianwei Huang"
    ],
    "author_ids": [],
    "abstract": "It is well known that a game equilibrium can be far from efficient or fair,\ndue to the misalignment between individual and social objectives. The focus of\nthis paper is to design a new mechanism framework that induces an efficient and\nfair equilibrium in a general class of games. To achieve this goal, we propose\na taxation framework, which first imposes a tax on each player based on the\nperceived payoff (income), and then redistributes the collected tax to other\nplayers properly. By turning the tax rate, this framework spans the continuum\nspace between strategic interactions (of selfish players) and altruistic\ninteractions (of unselfish players), hence provides rich modeling\npossibilities. The key challenge in the design of this framework is the proper\ntaxing rule (i.e., the tax exemption and tax rate) that induces the desired\nequilibrium in a wide range of games. First, we propose a flat tax rate (i.e.,\na single tax rate for all players), which is necessary and sufficient for\nachieving an efficient equilibrium in any static strategic game with common\nknowledge. Then, we provide several tax exemption rules that achieve some\ntypical fairness criterions (such as the Max-min fairness) at the equilibrium.\nWe further illustrate the implementation of the framework in the game of\nPrisoners' Dilemma.",
    "published_date": "2017-08-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.03200v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.05085v1",
    "title": "Multilingual Website Usability Analysis Based on an International User Survey",
    "authors": [
      "Mahdi H. Miraz",
      "Maaruf Ali",
      "Peter Excell"
    ],
    "author_ids": [],
    "abstract": "A study was undertaken to determine the important usability factors (UF) used\nin the English and the non-English version of a website. The important\nusability factors were determined, based on a detailed questionnaire used in an\ninternational survey. Analysis of the questionnaire found inequalities in the\nuser satisfaction and a general dissatisfaction with the non-English version of\nthe website. The study concluded that more care should be taken in creating the\ntext, taking into account the cultural and linguistic background of the users\nand the use of graphics in multilingual websites.",
    "published_date": "2017-08-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.05085v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.02859v1",
    "title": "Joint Optimization of QoE and Fairness Through Network Assisted Adaptive Mobile Video Streaming",
    "authors": [
      "Abbas Mehrabi",
      "Matti Siekkinen",
      "Antti Ylä-Jääski"
    ],
    "author_ids": [],
    "abstract": "MPEG has recently proposed Server and Network Assisted Dynamic Adaptive\nStreaming over HTTP (SAND-DASH) for video streaming over the Internet. In\ncontrast to the purely client-based video streaming in which each client makes\nits own decision to adjust its bitrate, SAND-DASH enables a group of\nsimultaneous clients to select their bitrates in a coordinated fashion in order\nto improve resource utilization and quality of experience. In this paper, we\nstudy the performance of such an adaptation strategy compared to the\ntraditional approach with large number of clients having mobile Internet\naccess. We propose a multi-servers multi-coordinators (MSs-MCs) framework to\nmodel groups of remote clients accessing video content replicated to spatially\ndistributed edge servers. We then formulate an optimization problem to maximize\njointly the QoE of individual clients, proportional fairness in allocating the\nlimited resources of base stations as well as balancing the utilized resources\namong multiple serves. We then present an efficient heuristic-based solution to\nthe problem and perform simulations in order to explore parameter space of the\nscheme as well as to compare the performance to purely client-based DASH.",
    "published_date": "2017-08-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02859v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.02763v2",
    "title": "Has the Online Discussion Been Manipulated? Quantifying Online Discussion Authenticity within Online Social Media",
    "authors": [
      "Aviad Elyashar",
      "Jorge Bendahan",
      "Rami Puzis"
    ],
    "author_ids": [],
    "abstract": "Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest.",
    "published_date": "2017-08-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02763v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.02536v1",
    "title": "A Framework for Inferring Causality from Multi-Relational Observational Data using Conditional Independence",
    "authors": [
      "Sudeepa Roy",
      "Babak Salimi"
    ],
    "author_ids": [],
    "abstract": "The study of causality or causal inference - how much a given treatment\ncausally affects a given outcome in a population - goes way beyond correlation\nor association analysis of variables, and is critical in making sound data\ndriven decisions and policies in a multitude of applications. The gold standard\nin causal inference is performing \"controlled experiments\", which often is not\npossible due to logistical or ethical reasons. As an alternative, inferring\ncausality on \"observational data\" based on the \"Neyman-Rubin potential outcome\nmodel\" has been extensively used in statistics, economics, and social sciences\nover several decades. In this paper, we present a formal framework for sound\ncausal analysis on observational datasets that are given as multiple relations\nand where the population under study is obtained by joining these base\nrelations. We study a crucial condition for inferring causality from\nobservational data, called the \"strong ignorability assumption\" (the treatment\nand outcome variables should be independent in the joined relation given the\nobserved covariates), using known conditional independences that hold in the\nbase relations. We also discuss how the structure of the conditional\nindependences in base relations given as graphical models help infer new\nconditional independences in the joined relation. The proposed framework\ncombines concepts from databases, statistics, and graphical models, and aims to\ninitiate new research directions spanning these fields to facilitate powerful\ndata-driven decisions in today's big data world.",
    "published_date": "2017-08-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02536v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.02274v1",
    "title": "FixMyStreet Brussels: Socio-Demographic Inequality in Crowdsourced Civic Participation",
    "authors": [
      "Burak Pak",
      "Alvin Chua",
      "Andrew Vande Moere"
    ],
    "author_ids": [],
    "abstract": "FixMyStreet (FMS) is a web-based civic participation platform that allows\ninhabitants to report environmental defects like potholes and damaged pavements\nto the government. In this paper, we examine the use of FMS in Brussels, the\ncapital city of Belgium. Analyzing a total of 30,041 reports since its\ninception in 2013, we demonstrate how civic participation on FMS varies between\nthe ethnically diverse districts in Brussels. We compare FMS use to a range of\nsociodemographic indicators derived from official city statistics as well as\ngeotagged social media data from Twitter. Our statistical analysis revealed\nseveral significant differences between the districts that suggested that\ncrowdsourced civic participation platforms tend to marginalize low-income and\nethnically diverse communities. In this respect, our findings provide timely\nevidence to inform the design of more inclusive crowdsourced, civic\nparticipation platforms in the future.",
    "published_date": "2017-08-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02274v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.02205v1",
    "title": "Robust Dynamic Locomotion via Reinforcement Learning and Novel Whole Body Controller",
    "authors": [
      "Donghyun Kim",
      "Jaemin Lee",
      "Luis Sentis"
    ],
    "author_ids": [],
    "abstract": "We propose a robust dynamic walking controller consisting of a dynamic\nlocomotion planner, a reinforcement learning process for robustness, and a\nnovel whole-body locomotion controller (WBLC). Previous approaches specify\neither the position or the timing of steps, however, the proposed locomotion\nplanner simultaneously computes both of these parameters as locomotion outputs.\nOur locomotion strategy relies on devising a reinforcement learning (RL)\napproach for robust walking. The learned policy generates multi step walking\npatterns, and the process is quick enough to be suitable for real-time\ncontrols. For learning, we devise an RL strategy that uses a phase space\nplanner (PSP) and a linear inverted pendulum model to make the problem\ntractable and very fast. Then, the learned policy is used to provide goal-based\ncommands to the WBLC, which calculates the torque commands to be executed in\nfull-humanoid robots. The WBLC combines multiple prioritized tasks and\ncalculates the associated reaction forces based on practical inequality\nconstraints. The novel formulation includes efficient calculation of the time\nderivatives of various Jacobians. This provides high-fidelity dynamic control\nof fast motions. More specifically, we compute the time derivative of the\nJacobian for various tasks and the Jacobian of the centroidal momentum task by\nutilizing Lie group operators and operational space dynamics respectively. The\nintegration of RL-PSP and the WBLC provides highly robust, versatile, and\npractical locomotion including steering while walking and handling push\ndisturbances of up to 520 N during an interval of 0.1 sec. Theoretical and\nnumerical results are tested through a 3D physics-based simulation of the\nhumanoid robot Valkyrie.",
    "published_date": "2017-08-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02205v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.01977v2",
    "title": "Why Adaptively Collected Data Have Negative Bias and How to Correct for It",
    "authors": [
      "Xinkun Nie",
      "Xiaoying Tian",
      "Jonathan Taylor",
      "James Zou"
    ],
    "author_ids": [],
    "abstract": "From scientific experiments to online A/B testing, the previously observed\ndata often affects how future experiments are performed, which in turn affects\nwhich data will be collected. Such adaptivity introduces complex correlations\nbetween the data and the collection procedure. In this paper, we prove that\nwhen the data collection procedure satisfies natural conditions, then sample\nmeans of the data have systematic \\emph{negative} biases. As an example,\nconsider an adaptive clinical trial where additional data points are more\nlikely to be tested for treatments that show initial promise. Our surprising\nresult implies that the average observed treatment effects would underestimate\nthe true effects of each treatment. We quantitatively analyze the magnitude and\nbehavior of this negative bias in a variety of settings. We also propose a\nnovel debiasing algorithm based on selective inference techniques. In\nexperiments, our method can effectively reduce bias and estimation error.",
    "published_date": "2017-08-07T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01977v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.01960v1",
    "title": "Learning Theory of Distributed Regression with Bias Corrected Regularization Kernel Network",
    "authors": [
      "Zhengchu Guo",
      "Lei Shi",
      "Qiang Wu"
    ],
    "author_ids": [],
    "abstract": "Distributed learning is an effective way to analyze big data. In distributed\nregression, a typical approach is to divide the big data into multiple blocks,\napply a base regression algorithm on each of them, and then simply average the\noutput functions learnt from these blocks. Since the average process will\ndecrease the variance, not the bias, bias correction is expected to improve the\nlearning performance if the base regression algorithm is a biased one.\nRegularization kernel network is an effective and widely used method for\nnonlinear regression analysis. In this paper we will investigate a bias\ncorrected version of regularization kernel network. We derive the error bounds\nwhen it is applied to a single data set and when it is applied as a base\nalgorithm in distributed regression. We show that, under certain appropriate\nconditions, the optimal learning rates can be reached in both situations.",
    "published_date": "2017-08-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML",
      "68T05"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01960v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.01910v1",
    "title": "Empathy in Bimatrix Games",
    "authors": [
      "Brian Powers",
      "Michalis Smyrnakis",
      "Hamidou Tembine"
    ],
    "author_ids": [],
    "abstract": "Although the definition of what empathetic preferences exactly are is still\nevolving, there is a general consensus in the psychology, science and\nengineering communities that the evolution toward players' behaviors in\ninteractive decision-making problems will be accompanied by the exploitation of\ntheir empathy, sympathy, compassion, antipathy, spitefulness, selfishness,\naltruism, and self-abnegating states in the payoffs. In this article, we study\none-shot bimatrix games from a psychological game theory viewpoint. A new\nempathetic payoff model is calculated to fit empirical observations and both\npure and mixed equilibria are investigated. For a realized empathy structure,\nthe bimatrix game is categorized among four generic class of games. Number of\ninteresting results are derived. A notable level of involvement can be observed\nin the empathetic one-shot game compared the non-empathetic one and this holds\neven for games with dominated strategies. Partial altruism can help in breaking\nsymmetry, in reducing payoff-inequality and in selecting social welfare and\nmore efficient outcomes. By contrast, partial spite and self-abnegating may\nworsen payoff equity. Empathetic evolutionary game dynamics are introduced to\ncapture the resulting empathetic evolutionarily stable strategies under wide\nrange of revision protocols including Brown-von Neumann-Nash, Smith, imitation,\nreplicator, and hybrid dynamics. Finally, mutual support and Berge solution are\ninvestigated and their connection with empathetic preferences are established.\nWe show that pure altruism is logically inconsistent, only by balancing it with\nsome partial selfishness does it create a consistent psychology.",
    "published_date": "2017-08-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01910v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.01403v2",
    "title": "Optimal Throughput Fairness Trade-offs for Downlink Non-Orthogonal Multiple Access over Fading Channels",
    "authors": [
      "Hong Xing",
      "Yuanwei Liu",
      "Arumugam Nallanathan",
      "Zhiguo Ding",
      "H. Vincent Poor"
    ],
    "author_ids": [],
    "abstract": "Recently, non-orthogonal multiple access (NOMA) has attracted considerable\ninterest as one of the 5G-enabling techniques. However, users with better\nchannel conditions in downlink communications intrinsically benefits from NOMA\nthanks to successive decoding, judicious designs are required to guarantee user\nfairness. In this paper, a two-user downlink NOMA system over fading channels\nis considered. For delay-tolerant transmission, the average sum-rate is\nmaximized subject to both average and peak power constraints as well as a\nminimum average user rate constraint. The optimal resource allocation is\nobtained using Lagrangian dual decomposition under full channel state\ninformation at the transmitter (CSIT), while an effective power allocation\npolicy under partial CSIT is also developed based on analytical results. In\nparallel, for delay-limited transmission, the sum of delay-limited throughput\n(DLT) is maximized subject to a maximum allowable user outage constraint under\nfull CSIT, and the analysis for the sum of DLT is also performed under partial\nCSIT. Furthermore, an optimal orthogonal multiple access (OMA) scheme is also\nstudied as a benchmark to prove the superiority of NOMA over OMA under full\nCSIT. Finally, the theoretical analysis is verified by simulations via\ndifferent trade-offs for the average sum-rate (sum-DLT) versus the minimum\n(maximum) average user rate (outage) requirement.",
    "published_date": "2017-08-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01403v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.01298v1",
    "title": "Effective sketching methods for value function approximation",
    "authors": [
      "Yangchen Pan",
      "Erfan Sadeqi Azer",
      "Martha White"
    ],
    "author_ids": [],
    "abstract": "High-dimensional representations, such as radial basis function networks or\ntile coding, are common choices for policy evaluation in reinforcement\nlearning. Learning with such high-dimensional representations, however, can be\nexpensive, particularly for matrix methods, such as least-squares temporal\ndifference learning or quasi-Newton methods that approximate matrix step-sizes.\nIn this work, we explore the utility of sketching for these two classes of\nalgorithms. We highlight issues with sketching the high-dimensional features\ndirectly, which can incur significant bias. As a remedy, we demonstrate how to\nuse sketching more sparingly, with only a left-sided sketch, that can still\nenable significant computational gains and the use of these matrix-based\nlearning algorithms that are less sensitive to parameters. We empirically\ninvestigate these algorithms, in four domains with a variety of\nrepresentations. Our aim is to provide insights into effective use of sketching\nin practice.",
    "published_date": "2017-08-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01298v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.01183v1",
    "title": "Optimal Power Allocation Scheme for Non-Orthogonal Multiple Access with $α$-Fairness",
    "authors": [
      "Peng Xu",
      "Kanapathippillai Cumanan"
    ],
    "author_ids": [],
    "abstract": "This paper investigates the optimal power allocation scheme for sum\nthroughput maximization of non-orthogonal multiple access (NOMA) system with\n$\\alpha$-fairness. In contrast to the existing fairness NOMA models,\n$\\alpha$-fairness can only utilize a single scalar to achieve different user\nfairness levels. Two different channel state information at the transmitter\n(CSIT) assumptions are considered, namely, statistical and perfect CSIT. For\nstatistical CSIT, fixed target data rates are predefined, and the power\nallocation problem is solved for sum throughput maximization with\n$\\alpha$-fairness, through characterizing several properties of the optimal\npower allocation solution. For perfect CSIT, the optimal power allocation is\ndetermined to maximize the instantaneous sum rate with $\\alpha$-fairness, where\nuser rates are adapted according to the instantaneous channel state information\n(CSI). In particular, a simple alternate optimization (AO) algorithm is\nproposed, which is demonstrated to yield the optimal solution. Numerical\nresults reveal that, at the same fairness level, NOMA significantly outperforms\nthe conventional orthogonal multiple access (MA) for both the scenarios with\nstatistical and perfect CSIT.",
    "published_date": "2017-08-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01183v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.01513v1",
    "title": "Spatial Mixing and Non-local Markov chains",
    "authors": [
      "Antonio Blanca",
      "Pietro Caputo",
      "Alistair Sinclair",
      "Eric Vigoda"
    ],
    "author_ids": [],
    "abstract": "We consider spin systems with nearest-neighbor interactions on an $n$-vertex\n$d$-dimensional cube of the integer lattice graph $\\mathbb{Z}^d$. We study the\neffects that exponential decay with distance of spin correlations, specifically\nthe strong spatial mixing condition (SSM), has on the rate of convergence to\nequilibrium distribution of non-local Markov chains. We prove that SSM implies\n$O(\\log n)$ mixing of a block dynamics whose steps can be implemented\nefficiently. We then develop a methodology, consisting of several new\ncomparison inequalities concerning various block dynamics, that allow us to\nextend this result to other non-local dynamics. As a first application of our\nmethod we prove that, if SSM holds, then the relaxation time (i.e., the inverse\nspectral gap) of general block dynamics is $O(r)$, where $r$ is the number of\nblocks. A second application of our technology concerns the Swendsen-Wang\ndynamics for the ferromagnetic Ising and Potts models. We show that SSM implies\nan $O(1)$ bound for the relaxation time. As a by-product of this implication we\nobserve that the relaxation time of the Swendsen-Wang dynamics in square boxes\nof $\\mathbb{Z}^2$ is $O(1)$ throughout the subcritical regime of the $q$-state\nPotts model, for all $q \\ge 2$. We also prove that for monotone spin systems\nSSM implies that the mixing time of systematic scan dynamics is $O(\\log n (\\log\n\\log n)^2)$. Systematic scan dynamics are widely employed in practice but have\nproved hard to analyze. Our proofs use a variety of techniques for the analysis\nof Markov chains including coupling, functional analysis and linear algebra.",
    "published_date": "2017-08-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM",
      "math-ph",
      "math.MP",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01513v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.00754v1",
    "title": "Fairness-aware machine learning: a perspective",
    "authors": [
      "Indre Zliobaite"
    ],
    "author_ids": [],
    "abstract": "Algorithms learned from data are increasingly used for deciding many aspects\nin our life: from movies we see, to prices we pay, or medicine we get. Yet\nthere is growing evidence that decision making by inappropriately trained\nalgorithms may unintentionally discriminate people. For example, in automated\nmatching of candidate CVs with job descriptions, algorithms may capture and\npropagate ethnicity related biases. Several repairs for selected algorithms\nhave already been proposed, but the underlying mechanisms how such\ndiscrimination happens from the computational perspective are not yet\nscientifically understood. We need to develop theoretical understanding how\nalgorithms may become discriminatory, and establish fundamental machine\nlearning principles for prevention. We need to analyze machine learning process\nas a whole to systematically explain the roots of discrimination occurrence,\nwhich will allow to devise global machine learning optimization criteria for\nguaranteed prevention, as opposed to pushing empirical constraints into\nexisting algorithms case-by-case. As a result, the state-of-the-art will\nadvance from heuristic repairing, to proactive and theoretically supported\nprevention. This is needed not only because law requires to protect vulnerable\npeople. Penetration of big data initiatives will only increase, and computer\nscience needs to provide solid explanations and accountability to the public,\nbefore public concerns lead to unnecessarily restrictive regulations against\nmachine learning.",
    "published_date": "2017-08-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.00754v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1708.00043v3",
    "title": "Pricing for Online Resource Allocation: Intervals and Paths",
    "authors": [
      "Shuchi Chawla",
      "J. Benjamin Miller",
      "Yifeng Teng"
    ],
    "author_ids": [],
    "abstract": "We present pricing mechanisms for several online resource allocation problems\nwhich obtain tight or nearly tight approximations to social welfare. In our\nsettings, buyers arrive online and purchase bundles of items; buyers' values\nfor the bundles are drawn from known distributions. This problem is closely\nrelated to the so-called prophet-inequality of Krengel and Sucheston and its\nextensions in recent literature. Motivated by applications to cloud economics,\nwe consider two kinds of buyer preferences. In the first, items correspond to\ndifferent units of time at which a resource is available; the items are\narranged in a total order and buyers desire intervals of items. The second\ncorresponds to bandwidth allocation over a tree network; the items are edges in\nthe network and buyers desire paths.\n  Because buyers' preferences have complementarities in the settings we\nconsider, recent constant-factor approximations via item prices do not apply,\nand indeed strong negative results are known. We develop static, anonymous\nbundle pricing mechanisms.\n  For the interval preferences setting, we show that static, anonymous bundle\npricings achieve a sublogarithmic competitive ratio, which is optimal (within\nconstant factors) over the class of all online allocation algorithms, truthful\nor not. For the path preferences setting, we obtain a nearly-tight logarithmic\ncompetitive ratio. Both of these results exhibit an exponential improvement\nover item pricings for these settings. Our results extend to settings where the\nseller has multiple copies of each item, with the competitive ratio decreasing\nlinearly with supply. Such a gradual tradeoff between supply and the\ncompetitive ratio for welfare was previously known only for the single item\nprophet inequality.",
    "published_date": "2017-07-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.00043v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.09827v1",
    "title": "Bias Estimation for Decentralized Sensor Fusion -- Multi-Agent Based Bias Estimation Method",
    "authors": [
      "Hidetoshi Furukawa"
    ],
    "author_ids": [],
    "abstract": "In multi-sensor data fusion (or sensor fusion), sensor biases (or offsets)\noften affect the accuracy of the correlation and integration results of the\ntracking targets. Therefore, to estimate and compensate the bias, several\nmethods are proposed. However, most methods involve bias estimation and sensor\nfusion simultaneously by using Kalman filter after collecting the plot data\ntogether. Hence, these methods cannot support to fuse the track data prepared\nby tracking filter at each sensor node. This report proposes the new bias\nestimation method based on multi-agent model, in order to estimate and\ncompensate the bias for decentralized sensor fusion.",
    "published_date": "2017-07-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.09827v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.02993v3",
    "title": "On Euler's inequality and automated reasoning with dynamic geometry",
    "authors": [
      "Zoltán Kovács",
      "Róbert Vajda",
      "Aaron Montag"
    ],
    "author_ids": [],
    "abstract": "Euler's inequality $R\\geq 2r$ can be investigated in a novel way by using\nimplicit loci in GeoGebra. Some unavoidable side effects of the implicit locus\ncomputation introduce unexpected algebraic curves. By using a mixture of\nsymbolic and numerical methods a possible approach is sketched up to\ninvestigate the situation. By exploiting fast GPU computations, a web\napplication written in CindyJS helps in understanding the situation even\nbetter.",
    "published_date": "2017-07-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SC",
      "math.HO",
      "I.3.5"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.02993v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1708.01870v2",
    "title": "Transparency: Motivations and Challenges",
    "authors": [
      "Adrian Weller"
    ],
    "author_ids": [],
    "abstract": "Transparency is often deemed critical to enable effective real-world\ndeployment of intelligent systems. Yet the motivations for and benefits of\ndifferent types of transparency can vary significantly depending on context,\nand objective measurement criteria are difficult to identify. We provide a\nbrief survey, suggesting challenges and related concerns. We highlight and\nreview settings where transparency may cause harm, discussing connections\nacross privacy, multi-agent game theory, economics, fairness and trust.",
    "published_date": "2017-07-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.01870v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.09496v2",
    "title": "Local-ring network automata and the impact of hyperbolic geometry in complex network link-prediction",
    "authors": [
      "Alessandro Muscoloni",
      "Umberto Michieli",
      "Carlo Vittorio Cannistraci"
    ],
    "author_ids": [],
    "abstract": "Topological link-prediction can exploit the entire network topology (global\nmethods) or only the neighbourhood (local methods) of the link to predict.\nGlobal methods are believed the best. Is this common belief well-founded?\nStochastic-Block-Model (SBM) is a global method believed as one of the best\nlink-predictors, therefore it is considered a reference for comparison. But,\nour results suggest that SBM, whose computational time is high, cannot in\ngeneral overcome the Cannistraci-Hebb (CH) network automaton model that is a\nsimple local-learning-rule of topological self-organization proved as the\ncurrent best local-based and parameter-free deterministic rule for\nlink-prediction. To elucidate the reasons of this unexpected result, we\nformally introduce the notion of local-ring network automata models and their\nrelation with the nature of common-neighbours' definition in complex network\ntheory. After extensive tests, we recommend Structural-Perturbation-Method\n(SPM) as the new best global method baseline. However, even SPM overall does\nnot outperform CH and in several evaluation frameworks we astonishingly found\nthe opposite. In particular, CH was the best predictor for synthetic networks\ngenerated by the Popularity-Similarity-Optimization (PSO) model, and its\nperformance in PSO networks with community structure was even better than using\nthe original internode-hyperbolic-distance as link-predictor. Interestingly,\nwhen tested on non-hyperbolic synthetic networks the performance of CH\nsignificantly dropped down indicating that this rule of network\nself-organization could be strongly associated to the rise of hyperbolic\ngeometry in complex networks. The superiority of global methods seems a\n\"misleading belief\" caused by a latent geometry bias of the few small networks\nused as benchmark in previous studies. We propose to found a latent geometry\ntheory of link-prediction in complex networks.",
    "published_date": "2017-07-29T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.09496v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.09457v1",
    "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints",
    "authors": [
      "Jieyu Zhao",
      "Tianlu Wang",
      "Mark Yatskar",
      "Vicente Ordonez",
      "Kai-Wei Chang"
    ],
    "author_ids": [],
    "abstract": "Language is increasingly being used to define rich visual recognition\nproblems with supporting image collections sourced from the web. Structured\nprediction models are used in these tasks to take advantage of correlations\nbetween co-occurring labels and visual input but risk inadvertently encoding\nsocial biases found in web corpora. In this work, we study data and models\nassociated with multilabel object classification and visual semantic role\nlabeling. We find that (a) datasets for these tasks contain significant gender\nbias and (b) models trained on these datasets further amplify existing bias.\nFor example, the activity cooking is over 33% more likely to involve females\nthan males in a training set, and a trained model further amplifies the\ndisparity to 68% at test time. We propose to inject corpus-level constraints\nfor calibrating existing structured prediction models and design an algorithm\nbased on Lagrangian relaxation for collective inference. Our method results in\nalmost no performance loss for the underlying recognition task but decreases\nthe magnitude of bias amplification by 47.5% and 40.5% for multilabel\nclassification and visual semantic role labeling, respectively.",
    "published_date": "2017-07-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.09457v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.09425v1",
    "title": "Proceedings of the IJCAI 2017 Workshop on Learning in the Presence of Class Imbalance and Concept Drift (LPCICD'17)",
    "authors": [
      "Shuo Wang",
      "Leandro L. Minku",
      "Nitesh Chawla",
      "Xin Yao"
    ],
    "author_ids": [],
    "abstract": "With the wide application of machine learning algorithms to the real world,\nclass imbalance and concept drift have become crucial learning issues. Class\nimbalance happens when the data categories are not equally represented, i.e.,\nat least one category is minority compared to other categories. It can cause\nlearning bias towards the majority class and poor generalization. Concept drift\nis a change in the underlying distribution of the problem, and is a significant\nissue specially when learning from data streams. It requires learners to be\nadaptive to dynamic changes.\n  Class imbalance and concept drift can significantly hinder predictive\nperformance, and the problem becomes particularly challenging when they occur\nsimultaneously. This challenge arises from the fact that one problem can affect\nthe treatment of the other. For example, drift detection algorithms based on\nthe traditional classification error may be sensitive to the imbalanced degree\nand become less effective; and class imbalance techniques need to be adaptive\nto changing imbalance rates, otherwise the class receiving the preferential\ntreatment may not be the correct minority class at the current moment.\nTherefore, the mutual effect of class imbalance and concept drift should be\nconsidered during algorithm design.\n  The aim of this workshop is to bring together researchers from the areas of\nclass imbalance learning and concept drift in order to encourage discussions\nand new collaborations on solving the combined issue of class imbalance and\nconcept drift. It provides a forum for international researchers and\npractitioners to share and discuss their original work on addressing new\nchallenges and research issues in class imbalance learning, concept drift, and\nthe combined issues of class imbalance and concept drift. The proceedings\ninclude 8 papers on these topics.",
    "published_date": "2017-07-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.09425v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.08361v2",
    "title": "Supermetric Search",
    "authors": [
      "Richard Connor",
      "Lucia Vadicamo",
      "Franco Alberto Cardillo",
      "Fausto Rabitti"
    ],
    "author_ids": [],
    "abstract": "Metric search is concerned with the efficient evaluation of queries in metric\nspaces. In general,a large space of objects is arranged in such a way that,\nwhen a further object is presented as a query, those objects most similar to\nthe query can be efficiently found. Most mechanisms rely upon the triangle\ninequality property of the metric governing the space. The triangle inequality\nproperty is equivalent to a finite embedding property, which states that any\nthree points of the space can be isometrically embedded in two-dimensional\nEuclidean space. In this paper, we examine a class of semimetric space which is\nfinitely four-embeddable in three-dimensional Euclidean space. In mathematics\nthis property has been extensively studied and is generally known as the\nfour-point property. All spaces with the four-point property are metric spaces,\nbut they also have some stronger geometric guarantees. We coin the term\nsupermetric space as, in terms of metric search, they are significantly more\ntractable. Supermetric spaces include all those governed by Euclidean, Cosine,\nJensen-Shannon and Triangular distances, and are thus commonly used within many\ndomains. In previous work we have given a generic mathematical basis for the\nsupermetric property and shown how it can improve indexing performance for a\ngiven exact search structure. Here we present a full investigation into its use\nwithin a variety of different hyperplane partition indexing structures, and go\non to show some more of its flexibility by examining a search structure whose\npartition and exclusion conditions are tailored, at each node, to suit the\nindividual reference points and data set present there. Among the results\ngiven, we show a new best performance for exact search using a well-known\nbenchmark.",
    "published_date": "2017-07-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IR",
      "H.3.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.08361v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.08120v1",
    "title": "Proxy Non-Discrimination in Data-Driven Systems",
    "authors": [
      "Anupam Datta",
      "Matt Fredrikson",
      "Gihyuk Ko",
      "Piotr Mardziel",
      "Shayak Sen"
    ],
    "author_ids": [],
    "abstract": "Machine learnt systems inherit biases against protected classes, historically\ndisparaged groups, from training data. Usually, these biases are not explicit,\nthey rely on subtle correlations discovered by training algorithms, and are\ntherefore difficult to detect. We formalize proxy discrimination in data-driven\nsystems, a class of properties indicative of bias, as the presence of protected\nclass correlates that have causal influence on the system's output. We evaluate\nan implementation on a corpus of social datasets, demonstrating how to validate\nsystems against these properties and to repair violations where they occur.",
    "published_date": "2017-07-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.08120v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.08037v1",
    "title": "Automatic Liver Segmentation Using an Adversarial Image-to-Image Network",
    "authors": [
      "Dong Yang",
      "Daguang Xu",
      "S. Kevin Zhou",
      "Bogdan Georgescu",
      "Mingqing Chen",
      "Sasa Grbic",
      "Dimitris Metaxas",
      "Dorin Comaniciu"
    ],
    "author_ids": [],
    "abstract": "Automatic liver segmentation in 3D medical images is essential in many\nclinical applications, such as pathological diagnosis of hepatic diseases,\nsurgical planning, and postoperative assessment. However, it is still a very\nchallenging task due to the complex background, fuzzy boundary, and various\nappearance of liver. In this paper, we propose an automatic and efficient\nalgorithm to segment liver from 3D CT volumes. A deep image-to-image network\n(DI2IN) is first deployed to generate the liver segmentation, employing a\nconvolutional encoder-decoder architecture combined with multi-level feature\nconcatenation and deep supervision. Then an adversarial network is utilized\nduring training process to discriminate the output of DI2IN from ground truth,\nwhich further boosts the performance of DI2IN. The proposed method is trained\non an annotated dataset of 1000 CT volumes with various different scanning\nprotocols (e.g., contrast and non-contrast, various resolution and position)\nand large variations in populations (e.g., ages and pathology). Our approach\noutperforms the state-of-the-art solutions in terms of segmentation accuracy\nand computing efficiency.",
    "published_date": "2017-07-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.08037v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.07676v1",
    "title": "Spectrum Sharing for LTE-A Network in TV White Space",
    "authors": [
      "Meghna Khaturia",
      "Sweety Suman",
      "Abhay Karandikar",
      "Prasanna Chaporkar"
    ],
    "author_ids": [],
    "abstract": "Rural areas in the developing countries are predominantly devoid of Internet\naccess as it is not viable for operators to provide broadband service in these\nareas. To solve this problem, we propose a middle mile Long erm Evolution\nAdvanced (LTE-A) network operating in TV white space to connect villages to an\noptical Point of Presence (PoP) located in the vicinity of a rural area. We\nstudy the problem of spectrum sharing for the middle mile networks deployed by\nmultiple operators. A graph theory based Fairness Constrained Channel\nAllocation (FCCA) algorithm is proposed, employing Carrier Aggregation (CA) and\nListen Before Talk (LBT) features of LTE-A. We perform extensive system level\nsimulations to demonstrate that FCCA not only increases spectral efficiency but\nalso improves system fairness.",
    "published_date": "2017-07-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.07676v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.07232v2",
    "title": "Society-in-the-Loop: Programming the Algorithmic Social Contract",
    "authors": [
      "Iyad Rahwan"
    ],
    "author_ids": [],
    "abstract": "Recent rapid advances in Artificial Intelligence (AI) and Machine Learning\nhave raised many questions about the regulatory and governance mechanisms for\nautonomous machines. Many commentators, scholars, and policy-makers now call\nfor ensuring that algorithms governing our lives are transparent, fair, and\naccountable. Here, I propose a conceptual framework for the regulation of AI\nand algorithmic systems. I argue that we need tools to program, debug and\nmaintain an algorithmic social contract, a pact between various human\nstakeholders, mediated by machines. To achieve this, we can adapt the concept\nof human-in-the-loop (HITL) from the fields of modeling and simulation, and\ninteractive machine learning. In particular, I propose an agenda I call\nsociety-in-the-loop (SITL), which combines the HITL control paradigm with\nmechanisms for negotiating the values of various stakeholders affected by AI\nsystems, and monitoring compliance with the agreement. In short, `SITL = HITL +\nSocial Contract.'",
    "published_date": "2017-07-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "K.4.1, K.5.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.07232v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.06613v1",
    "title": "Decoupled classifiers for fair and efficient machine learning",
    "authors": [
      "Cynthia Dwork",
      "Nicole Immorlica",
      "Adam Tauman Kalai",
      "Max Leiserson"
    ],
    "author_ids": [],
    "abstract": "When it is ethical and legal to use a sensitive attribute (such as gender or\nrace) in machine learning systems, the question remains how to do so. We show\nthat the naive application of machine learning algorithms using sensitive\nfeatures leads to an inherent tradeoff in accuracy between groups. We provide a\nsimple and efficient decoupling technique, that can be added on top of any\nblack-box machine learning algorithm, to learn different classifiers for\ndifferent groups. Transfer learning is used to mitigate the problem of having\ntoo little data on any one group.\n  The method can apply to a range of fairness criteria. In particular, we\nrequire the application designer to specify as joint loss function that makes\nexplicit the trade-off between fairness and accuracy. Our reduction is shown to\nefficiently find the minimum loss as long as the objective has a certain\nnatural monotonicity property which may be of independent interest in the study\nof fairness in algorithms.",
    "published_date": "2017-07-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.06613v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.06600v2",
    "title": "A multi-agent reinforcement learning model of common-pool resource appropriation",
    "authors": [
      "Julien Perolat",
      "Joel Z. Leibo",
      "Vinicius Zambaldi",
      "Charles Beattie",
      "Karl Tuyls",
      "Thore Graepel"
    ],
    "author_ids": [],
    "abstract": "Humanity faces numerous problems of common-pool resource appropriation. This\nclass of multi-agent social dilemma includes the problems of ensuring\nsustainable use of fresh water, common fisheries, grazing pastures, and\nirrigation systems. Abstract models of common-pool resource appropriation based\non non-cooperative game theory predict that self-interested agents will\ngenerally fail to find socially positive equilibria---a phenomenon called the\ntragedy of the commons. However, in reality, human societies are sometimes able\nto discover and implement stable cooperative solutions. Decades of behavioral\ngame theory research have sought to uncover aspects of human behavior that make\nthis possible. Most of that work was based on laboratory experiments where\nparticipants only make a single choice: how much to appropriate. Recognizing\nthe importance of spatial and temporal resource dynamics, a recent trend has\nbeen toward experiments in more complex real-time video game-like environments.\nHowever, standard methods of non-cooperative game theory can no longer be used\nto generate predictions for this case. Here we show that deep reinforcement\nlearning can be used instead. To that end, we study the emergent behavior of\ngroups of independently learning agents in a partially observed Markov game\nmodeling common-pool resource appropriation. Our experiments highlight the\nimportance of trial-and-error learning in common-pool resource appropriation\nand shed light on the relationship between exclusion, sustainability, and\ninequality.",
    "published_date": "2017-07-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MA",
      "cs.NE",
      "q-bio.PE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.06600v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.06359v1",
    "title": "Recency Bias in the Era of Big Data: The Need to Strengthen the Status of History of Mathematics in Nigerian Schools",
    "authors": [
      "Joshua Abah Abah"
    ],
    "author_ids": [],
    "abstract": "The amount of information available to the mathematics teacher is so enormous\nthat the selection of desirable content is gradually becoming a huge task in\nitself. With respect to the inclusion of elements of history of mathematics in\nmathematics instruction, the era of Big Data introduces a high likelihood of\nRecency Bias, a hitherto unconnected challenge for stakeholders in mathematics\neducation. This tendency to choose recent information at the expense of\nrelevant older, composite, historical facts stands to defeat the aims and\nobjectives of the epistemological and cultural approach to mathematics\ninstructional delivery. This study is a didactic discourse with focus on this\nthreat to the history and pedagogy of mathematics, particularly as it affects\nmathematics education in Nigeria. The implications for mathematics curriculum\ndevelopers, teacher-training programmes, teacher lesson preparation, and\npublication of mathematics instructional materials were also deeply considered.",
    "published_date": "2017-07-20T00:00:00",
    "year": 2017,
    "categories": [
      "math.HO",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.06359v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.05961v1",
    "title": "Multidimensional classification of hippocampal shape features discriminates Alzheimer's disease and mild cognitive impairment from normal aging",
    "authors": [
      "Emilie Gerardin",
      "Gaël Chételat",
      "Marie Chupin",
      "Rémi Cuingnet",
      "Béatrice Desgranges",
      "Ho-Sung Kim",
      "Marc Niethammer",
      "Bruno Dubois",
      "Stéphane Lehéricy",
      "Line Garnero",
      "Francis Eustache",
      "Olivier Colliot"
    ],
    "author_ids": [],
    "abstract": "We describe a new method to automatically discriminate between patients with\nAlzheimer's disease (AD) or mild cognitive impairment (MCI) and elderly\ncontrols, based on multidimensional classification of hippocampal shape\nfeatures. This approach uses spherical harmonics (SPHARM) coefficients to model\nthe shape of the hippocampi, which are segmented from magnetic resonance images\n(MRI) using a fully automatic method that we previously developed. SPHARM\ncoefficients are used as features in a classification procedure based on\nsupport vector machines (SVM). The most relevant features for classification\nare selected using a bagging strategy. We evaluate the accuracy of our method\nin a group of 23 patients with AD (10 males, 13 females, age $\\pm$\nstandard-deviation (SD) = 73 $\\pm$ 6 years, mini-mental score (MMS) = 24.4\n$\\pm$ 2.8), 23 patients with amnestic MCI (10 males, 13 females, age $\\pm$ SD =\n74 $\\pm$ 8 years, MMS = 27.3 $\\pm$ 1.4) and 25 elderly healthy controls (13\nmales, 12 females, age $\\pm$ SD = 64 $\\pm$ 8 years), using leave-one-out\ncross-validation. For AD vs controls, we obtain a correct classification rate\nof 94%, a sensitivity of 96%, and a specificity of 92%. For MCI vs controls, we\nobtain a classification rate of 83%, a sensitivity of 83%, and a specificity of\n84%. This accuracy is superior to that of hippocampal volumetry and is\ncomparable to recently published SVM-based whole-brain classification methods,\nwhich relied on a different strategy. This new method may become a useful tool\nto assist in the diagnosis of Alzheimer's disease.",
    "published_date": "2017-07-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "q-bio.NC",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.05961v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.05647v2",
    "title": "Fast Screening Algorithm for Rotation and Scale Invariant Template Matching",
    "authors": [
      "Bolin Liu",
      "Xiao Shu",
      "Xiaolin Wu"
    ],
    "author_ids": [],
    "abstract": "This paper presents a generic pre-processor for expediting conventional\ntemplate matching techniques. Instead of locating the best matched patch in the\nreference image to a query template via exhaustive search, the proposed\nalgorithm rules out regions with no possible matches with minimum computational\nefforts. While working on simple patch features, such as mean, variance and\ngradient, the fast pre-screening is highly discriminative. Its computational\nefficiency is gained by using a novel octagonal-star-shaped template and the\ninclusion-exclusion principle to extract and compare patch features. Moreover,\nit can handle arbitrary rotation and scaling of reference images effectively.\nExtensive experiments demonstrate that the proposed algorithm greatly reduces\nthe search space while never missing the best match.",
    "published_date": "2017-07-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.05647v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.04769v3",
    "title": "Almost Envy-Freeness with General Valuations",
    "authors": [
      "Benjamin Plaut",
      "Tim Roughgarden"
    ],
    "author_ids": [],
    "abstract": "The goal of fair division is to distribute resources among competing players\nin a \"fair\" way. Envy-freeness is the most extensively studied fairness notion\nin fair division. Envy-free allocations do not always exist with indivisible\ngoods, motivating the study of relaxed versions of envy-freeness. We study the\nenvy-freeness up to any good (EFX) property, which states that no player\nprefers the bundle of another player following the removal of any single good,\nand prove the first general results about this property. We use the leximin\nsolution to show existence of EFX allocations in several contexts, sometimes in\nconjunction with Pareto optimality. For two players with valuations obeying a\nmild assumption, one of these results provides stronger guarantees than the\ncurrently deployed algorithm on Spliddit, a popular fair division website.\nUnfortunately, finding the leximin solution can require exponential time. We\nshow that this is necessary by proving an exponential lower bound on the number\nof value queries needed to identify an EFX allocation, even for two players\nwith identical valuations. We consider both additive and more general\nvaluations, and our work suggests that there is a rich landscape of problems to\nexplore in the fair division of indivisible goods with different classes of\nplayer valuations.",
    "published_date": "2017-07-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.04769v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.04731v2",
    "title": "Finding Fair and Efficient Allocations",
    "authors": [
      "Siddharth Barman",
      "Sanath Kumar Krishnamurthy",
      "Rohit Vaish"
    ],
    "author_ids": [],
    "abstract": "We study the problem of allocating a set of indivisible goods among a set of\nagents in a fair and efficient manner. An allocation is said to be fair if it\nis envy-free up to one good (EF1), which means that each agent prefers its own\nbundle over the bundle of any other agent up to the removal of one good. In\naddition, an allocation is deemed efficient if it satisfies Pareto optimality\n(PO). While each of these well-studied properties is easy to achieve\nseparately, achieving them together is far from obvious. Recently, Caragiannis\net al. (2016) established the surprising result that when agents have additive\nvaluations for the goods, there always exists an allocation that simultaneously\nsatisfies these two seemingly incompatible properties. Specifically, they\nshowed that an allocation that maximizes the Nash social welfare (NSW)\nobjective is both EF1 and PO. However, the problem of maximizing NSW is\nNP-hard. As a result, this approach does not provide an efficient algorithm for\nfinding a fair and efficient allocation.\n  In this paper, we bypass this barrier, and develop a pseudopolynomial time\nalgorithm for finding allocations that are EF1 and PO; in particular, when the\nvaluations are bounded, our algorithm finds such an allocation in polynomial\ntime. Furthermore, we establish a stronger existence result compared to\nCaragiannis et al. (2016): For additive valuations, there always exists an\nallocation that is EF1 and fractionally PO.\n  Another contribution of our work is to show that our algorithm provides a\npolynomial-time 1.45-approximation to the NSW objective. This improves upon the\nbest known approximation ratio for this problem (namely, the 2-approximation\nalgorithm of Cole et al. (2017)). Unlike many of the existing approaches, our\nalgorithm is completely combinatorial.",
    "published_date": "2017-07-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.04731v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.04127v1",
    "title": "Bridging Static and Dynamic Program Analysis using Fuzzy Logic",
    "authors": [
      "Jacob Lidman",
      "Josef Svenningsson"
    ],
    "author_ids": [],
    "abstract": "Static program analysis is used to summarize properties over all dynamic\nexecutions. In a unifying approach based on 3-valued logic properties are\neither assigned a definite value or unknown. But in summarizing a set of\nexecutions, a property is more accurately represented as being biased towards\ntrue, or towards false. Compilers use program analysis to determine benefit of\nan optimization. Since benefit (e.g., performance) is justified based on the\ncommon case understanding bias is essential in guiding the compiler.\nFurthermore, successful optimization also relies on understanding the quality\nof the information, i.e. the plausibility of the bias. If the quality of the\nstatic information is too low to form a decision we would like a mechanism that\nimproves dynamically.\n  We consider the problem of building such a reasoning framework and present\nthe fuzzy data-flow analysis. Our approach generalize previous work that use\n3-valued logic. We derive fuzzy extensions of data-flow analyses used by the\nlazy code motion optimization and unveil opportunities previous work would not\ndetect due to limited expressiveness. Furthermore we show how the results of\nour analysis can be used in an adaptive classifier that improve as the\napplication executes.",
    "published_date": "2017-07-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.PL",
      "cs.LO",
      "cs.SE",
      "D.2.4; D.3.0; F.1.2; F.3; G.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.04127v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.03869v3",
    "title": "Cognitive Biases in Software Engineering: A Systematic Mapping Study",
    "authors": [
      "Rahul Mohanani",
      "Iflaah Salman",
      "Burak Turhan",
      "Pilar Rodriguez",
      "Paul Ralph"
    ],
    "author_ids": [],
    "abstract": "One source of software project challenges and failures is the systematic\nerrors introduced by human cognitive biases. Although extensively explored in\ncognitive psychology, investigations concerning cognitive biases have only\nrecently gained popularity in software engineering (SE) research. This paper\ntherefore systematically maps, aggregates and synthesizes the literature on\ncognitive biases in software engineering to generate a comprehensive body of\nknowledge, understand state of the art research and provide guidelines for\nfuture research and practise. Focusing on bias antecedents, effects and\nmitigation techniques, we identified 65 articles, which investigate 37\ncognitive biases, published between 1990 and 2016. Despite strong and\nincreasing interest, the results reveal a scarcity of research on mitigation\ntechniques and poor theoretical foundations in understanding and interpreting\ncognitive biases. Although bias-related research has generated many new\ninsights in the software engineering community, specific bias mitigation\ntechniques are still needed for software professionals to overcome the\ndeleterious effects of cognitive biases on their work.",
    "published_date": "2017-07-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.03869v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.05259v1",
    "title": "Ethics of autonomous information systems towards an artificial thinking",
    "authors": [
      "Joël Colloc"
    ],
    "author_ids": [],
    "abstract": "Many projects relies on cognitives sciences, neurosciences, computer sciences\nand robotics. They concerned today the building of autonomous artificial beings\nable to think. This paper shows a model to compare the human thinking with an\nhypothetic numerical way of thinking based on four hierarchies : the\ninformation system classification, the cognitive pyramid, the linguistic\npyramid and the digital information hierarchy. After a state of art on the\nnature of human thinking, feasibility of autonomous multi-agent systems\nprovided with artificial consciousness which are able to think is discussed.\nThe ethical aspects and consequences for humanity of such systems is evaluated.\nThese systems lead the scientific community to react.",
    "published_date": "2017-07-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.OH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.05259v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.02757v2",
    "title": "Subdeterminant Maximization via Nonconvex Relaxations and Anti-concentration",
    "authors": [
      "Javad B. Ebrahimi",
      "Damian Straszak",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Several fundamental problems that arise in optimization and computer science\ncan be cast as follows: Given vectors $v_1,\\ldots,v_m \\in \\mathbb{R}^d$ and a\nconstraint family ${\\cal B}\\subseteq 2^{[m]}$, find a set $S \\in \\cal{B}$ that\nmaximizes the squared volume of the simplex spanned by the vectors in $S$. A\nmotivating example is the data-summarization problem in machine learning where\none is given a collection of vectors that represent data such as documents or\nimages. The volume of a set of vectors is used as a measure of their diversity,\nand partition or matroid constraints over $[m]$ are imposed in order to ensure\nresource or fairness constraints. Recently, Nikolov and Singh presented a\nconvex program and showed how it can be used to estimate the value of the most\ndiverse set when ${\\cal B}$ corresponds to a partition matroid. This result was\nrecently extended to regular matroids in works of Straszak and Vishnoi, and\nAnari and Oveis Gharan. The question of whether these estimation algorithms can\nbe converted into the more useful approximation algorithms -- that also output\na set -- remained open.\n  The main contribution of this paper is to give the first approximation\nalgorithms for both partition and regular matroids. We present novel\nformulations for the subdeterminant maximization problem for these matroids;\nthis reduces them to the problem of finding a point that maximizes the absolute\nvalue of a nonconvex function over a Cartesian product of probability\nsimplices. The technical core of our results is a new anti-concentration\ninequality for dependent random variables that allows us to relate the optimal\nvalue of these nonconvex functions to their value at a random point. Unlike\nprior work on the constrained subdeterminant maximization problem, our proofs\ndo not rely on real-stability or convexity and could be of independent interest\nboth in algorithms and complexity.",
    "published_date": "2017-07-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.LG",
      "math.OC",
      "math.PR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02757v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.02581v1",
    "title": "Class-Weighted Convolutional Features for Visual Instance Search",
    "authors": [
      "Albert Jimenez",
      "Jose M. Alvarez",
      "Xavier Giro-i-Nieto"
    ],
    "author_ids": [],
    "abstract": "Image retrieval in realistic scenarios targets large dynamic datasets of\nunlabeled images. In these cases, training or fine-tuning a model every time\nnew images are added to the database is neither efficient nor scalable.\nConvolutional neural networks trained for image classification over large\ndatasets have been proven effective feature extractors for image retrieval. The\nmost successful approaches are based on encoding the activations of\nconvolutional layers, as they convey the image spatial information. In this\npaper, we go beyond this spatial information and propose a local-aware encoding\nof convolutional features based on semantic information predicted in the target\nimage. To this end, we obtain the most discriminative regions of an image using\nClass Activation Maps (CAMs). CAMs are based on the knowledge contained in the\nnetwork and therefore, our approach, has the additional advantage of not\nrequiring external information. In addition, we use CAMs to generate object\nproposals during an unsupervised re-ranking stage after a first fast search.\nOur experiments on two public available datasets for instance retrieval,\nOxford5k and Paris6k, demonstrate the competitiveness of our approach\noutperforming the current state-of-the-art when using off-the-shelf models\ntrained on ImageNet. The source code and model used in this paper are publicly\navailable at http://imatge-upc.github.io/retrieval-2017-cam/.",
    "published_date": "2017-07-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.IR",
      "cs.MM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02581v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.02353v1",
    "title": "Evaluating race and sex diversity in the world's largest companies using deep neural networks",
    "authors": [
      "Konstantin Chekanov",
      "Polina Mamoshina",
      "Roman V. Yampolskiy",
      "Radu Timofte",
      "Morten Scheibye-Knudsen",
      "Alex Zhavoronkov"
    ],
    "author_ids": [],
    "abstract": "Diversity is one of the fundamental properties for the survival of species,\npopulations, and organizations. Recent advances in deep learning allow for the\nrapid and automatic assessment of organizational diversity and possible\ndiscrimination by race, sex, age and other parameters. Automating the process\nof assessing the organizational diversity using the deep neural networks and\neliminating the human factor may provide a set of real-time unbiased reports to\nall stakeholders. In this pilot study we applied the deep-learned predictors of\nrace and sex to the executive management and board member profiles of the 500\nlargest companies from the 2016 Forbes Global 2000 list and compared the\npredicted ratios to the ratios within each company's country of origin and\nranked them by the sex-, age- and race- diversity index (DI). While the study\nhas many limitations and no claims are being made concerning the individual\ncompanies, it demonstrates a method for the rapid and impartial assessment of\norganizational diversity using deep neural networks.",
    "published_date": "2017-07-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02353v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.02418v1",
    "title": "Stability, Fairness and Random Walks in the Bargaining Problem",
    "authors": [
      "Jakob Kapeller",
      "Stefan Steinerberger"
    ],
    "author_ids": [],
    "abstract": "We study the classical bargaining problem and its two canonical solutions,\n(Nash and Kalai-Smorodinsky), from a novel point of view: we ask for stability\nof the solution if both players are able distort the underlying bargaining\nprocess by reference to a third party (e.g. a court). By exploring the simplest\ncase, where decisions of the third party are made randomly we obtain a stable\nsolution, where players do not have any incentive to refer to such a third\nparty. While neither the Nash nor the Kalai-Smorodinsky solution are able to\nensure stability in case reference to a third party is possible, we found that\nthe Kalai-Smorodinsky solution seems to always dominate the stable allocation\nwhich constitutes novel support in favor of the latter.",
    "published_date": "2017-07-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02418v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.02260v1",
    "title": "Fair Personalization",
    "authors": [
      "L. Elisa Celis",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Personalization is pervasive in the online space as, when combined with\nlearning, it leads to higher efficiency and revenue by allowing the most\nrelevant content to be served to each user. However, recent studies suggest\nthat such personalization can propagate societal or systemic biases, which has\nled to calls for regulatory mechanisms and algorithms to combat inequality.\nHere we propose a rigorous algorithmic framework that allows for the\npossibility to control biased or discriminatory personalization with respect to\nsensitive attributes of users without losing all of the benefits of\npersonalization.",
    "published_date": "2017-07-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.DS",
      "cs.IR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02260v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.02033v1",
    "title": "Networked Fairness in Cake Cutting",
    "authors": [
      "Xiaohui Bei",
      "Youming Qiao",
      "Shengyu Zhang"
    ],
    "author_ids": [],
    "abstract": "We introduce a graphical framework for fair division in cake cutting, where\ncomparisons between agents are limited by an underlying network structure. We\ngeneralize the classical fairness notions of envy-freeness and proportionality\nto this graphical setting. Given a simple undirected graph G, an allocation is\nenvy-free on G if no agent envies any of her neighbor's share, and is\nproportional on G if every agent values her own share no less than the average\namong her neighbors, with respect to her own measure. These generalizations\nopen new research directions in developing simple and efficient algorithms that\ncan produce fair allocations under specific graph structures.\n  On the algorithmic frontier, we first propose a moving-knife algorithm that\noutputs an envy-free allocation on trees. The algorithm is significantly\nsimpler than the discrete and bounded envy-free algorithm recently designed by\nAziz and Mackenzie for complete graphs. Next, we give a discrete and bounded\nalgorithm for computing a proportional allocation on descendant graphs, a class\nof graphs by taking a rooted tree and connecting all its ancestor-descendant\npairs.",
    "published_date": "2017-07-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.02033v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.01875v1",
    "title": "Calibrated Fairness in Bandits",
    "authors": [
      "Yang Liu",
      "Goran Radanovic",
      "Christos Dimitrakakis",
      "Debmalya Mandal",
      "David C. Parkes"
    ],
    "author_ids": [],
    "abstract": "We study fairness within the stochastic, \\emph{multi-armed bandit} (MAB)\ndecision making framework. We adapt the fairness framework of \"treating similar\nindividuals similarly\" to this setting. Here, an `individual' corresponds to an\narm and two arms are `similar' if they have a similar quality distribution.\nFirst, we adopt a {\\em smoothness constraint} that if two arms have a similar\nquality distribution then the probability of selecting each arm should be\nsimilar. In addition, we define the {\\em fairness regret}, which corresponds to\nthe degree to which an algorithm is not calibrated, where perfect calibration\nrequires that the probability of selecting an arm is equal to the probability\nwith which the arm has the best quality realization. We show that a variation\non Thompson sampling satisfies smooth fairness for total variation distance,\nand give an $\\tilde{O}((kT)^{2/3})$ bound on fairness regret. This complements\nprior work, which protects an on-average better arm from being less favored. We\nalso explain how to extend our algorithm to the dueling bandit setting.",
    "published_date": "2017-07-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.01875v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.01590v1",
    "title": "Fairness at Equilibrium in the Labor Market",
    "authors": [
      "Lily Hu",
      "Yiling Chen"
    ],
    "author_ids": [],
    "abstract": "Recent literature on computational notions of fairness has been broadly\ndivided into two distinct camps, supporting interventions that address either\nindividual-based or group-based fairness. Rather than privilege a single\ndefinition, we seek to resolve both within the particular domain of employment\ndiscrimination. To this end, we construct a dual labor market model composed of\na Temporary Labor Market, in which firm strategies are constrained to ensure\ngroup-level fairness, and a Permanent Labor Market, in which individual worker\nfairness is guaranteed. We show that such restrictions on hiring practices\ninduces an equilibrium that Pareto-dominates those arising from strategies that\nemploy statistical discrimination or a \"group-blind\" criterion. Individual\nworker reputations produce externalities for collective reputation, generating\na feedback loop termed a \"self-fulfilling prophecy.\" Our model produces its own\nfeedback loop, raising the collective reputation of an initially disadvantaged\ngroup via a fairness intervention that need not be permanent. Moreover, we show\nthat, contrary to popular assumption, the asymmetric equilibria resulting from\nhiring practices that disregard group-fairness may be immovable without\ntargeted intervention. The enduring nature of such equilibria that are both\ninequitable and Pareto inefficient suggest that fairness interventions are of\ncritical importance in moving the labor market to be more socially just and\nefficient.",
    "published_date": "2017-07-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.01590v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.01477v1",
    "title": "Like trainer, like bot? Inheritance of bias in algorithmic content moderation",
    "authors": [
      "Reuben Binns",
      "Michael Veale",
      "Max Van Kleek",
      "Nigel Shadbolt"
    ],
    "author_ids": [],
    "abstract": "The internet has become a central medium through which `networked publics'\nexpress their opinions and engage in debate. Offensive comments and personal\nattacks can inhibit participation in these spaces. Automated content moderation\naims to overcome this problem using machine learning classifiers trained on\nlarge corpora of texts manually annotated for offence. While such systems could\nhelp encourage more civil debate, they must navigate inherently normatively\ncontestable boundaries, and are subject to the idiosyncratic norms of the human\nraters who provide the training data. An important objective for platforms\nimplementing such measures might be to ensure that they are not unduly biased\ntowards or against particular norms of offence. This paper provides some\nexploratory methods by which the normative biases of algorithmic content\nmoderation systems can be measured, by way of a case study using an existing\ndataset of comments labelled for offence. We train classifiers on comments\nlabelled by different demographic subsets (men and women) to understand how\ndifferences in conceptions of offence between these groups might affect the\nperformance of the resulting models on various test sets. We conclude by\ndiscussing some of the ethical choices facing the implementers of algorithmic\nmoderation systems, given various desired levels of diversity of viewpoints\namongst discussion participants.",
    "published_date": "2017-07-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.LG",
      "H.1.2; I.2.6; I.2.1; J.7; J.4; K.4.1; K.4.3; K.5.2; I.2.7; K.4.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.01477v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.01195v3",
    "title": "The impossibility of \"fairness\": a generalized impossibility result for decisions",
    "authors": [
      "Thomas Miconi"
    ],
    "author_ids": [],
    "abstract": "Various measures can be used to estimate bias or unfairness in a predictor.\nPrevious work has already established that some of these measures are\nincompatible with each other. Here we show that, when groups differ in\nprevalence of the predicted event, several intuitive, reasonable measures of\nfairness (probability of positive prediction given occurrence or\nnon-occurrence; probability of occurrence given prediction or non-prediction;\nand ratio of predictions over occurrences for each group) are all mutually\nexclusive: if one of them is equal among groups, the other two must differ. The\nonly exceptions are for perfect, or trivial (always-positive or\nalways-negative) predictors. As a consequence, any non-perfect, non-trivial\npredictor must necessarily be \"unfair\" under two out of three reasonable sets\nof criteria. This result readily generalizes to a wide range of well-known\nstatistical quantities (sensitivity, specificity, false positive rate,\nprecision, etc.), all of which can be divided into three mutually exclusive\ngroups. Importantly, The results applies to all predictors, whether algorithmic\nor human. We conclude with possible ways to handle this effect when assessing\nand designing prediction methods.",
    "published_date": "2017-07-05T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.AI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.01195v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00838v1",
    "title": "Worse Than Spam: Issues In Sampling Software Developers",
    "authors": [
      "Sebastian Baltes",
      "Stephan Diehl"
    ],
    "author_ids": [],
    "abstract": "Background: Reaching out to professional software developers is a crucial\npart of empirical software engineering research. One important method to\ninvestigate the state of practice is survey research. As drawing a random\nsample of professional software developers for a survey is rarely possible,\nresearchers rely on various sampling strategies. Objective: In this paper, we\nreport on our experience with different sampling strategies we employed,\nhighlight ethical issues, and motivate the need to maintain a collection of key\ndemographics about software developers to ease the assessment of the external\nvalidity of studies. Method: Our report is based on data from two studies we\nconducted in the past. Results: Contacting developers over public media proved\nto be the most effective and efficient sampling strategy. However, we not only\ndescribe the perspective of researchers who are interested in reaching goals\nlike a large number of participants or a high response rate, but we also shed\nlight onto ethical implications of different sampling strategies. We present\none specific ethical guideline and point to debates in other research\ncommunities to start a discussion in the software engineering research\ncommunity about which sampling strategies should be considered ethical.",
    "published_date": "2017-07-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00838v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.00780v4",
    "title": "Discriminatory Transfer",
    "authors": [
      "Chao Lan",
      "Jun Huan"
    ],
    "author_ids": [],
    "abstract": "We observe standard transfer learning can improve prediction accuracies of\ntarget tasks at the cost of lowering their prediction fairness -- a phenomenon\nwe named discriminatory transfer. We examine prediction fairness of a standard\nhypothesis transfer algorithm and a standard multi-task learning algorithm, and\nshow they both suffer discriminatory transfer on the real-world Communities and\nCrime data set. The presented case study introduces an interaction between\nfairness and transfer learning, as an extension of existing fairness studies\nthat focus on single task learning.",
    "published_date": "2017-07-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00780v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00574v2",
    "title": "How algorithmic popularity bias hinders or promotes quality",
    "authors": [
      "Azadeh Nematzadeh",
      "Giovanni Luca Ciampaglia",
      "Filippo Menczer",
      "Alessandro Flammini"
    ],
    "author_ids": [],
    "abstract": "Algorithms that favor popular items are used to help us select among many\nchoices, from engaging articles on a social media news feed to songs and books\nthat others have purchased, and from top-raked search engine results to\nhighly-cited scientific papers. The goal of these algorithms is to identify\nhigh-quality items such as reliable news, beautiful movies, prestigious\ninformation sources, and important discoveries --- in short, high-quality\ncontent should rank at the top. Prior work has shown that choosing what is\npopular may amplify random fluctuations and ultimately lead to sub-optimal\nrankings. Nonetheless, it is often assumed that recommending what is popular\nwill help high-quality content \"bubble up\" in practice. Here we identify the\nconditions in which popularity may be a viable proxy for quality content by\nstudying a simple model of cultural market endowed with an intrinsic notion of\nquality. A parameter representing the cognitive cost of exploration controls\nthe critical trade-off between quality and popularity. We find a regime of\nintermediate exploration cost where an optimal balance exists, such that\nchoosing what is popular actually promotes high-quality items to the top.\nOutside of these limits, however, popularity bias is more likely to hinder\nquality. These findings clarify the effects of algorithmic popularity bias on\nquality outcomes, and may inform the design of more principled mechanisms for\ntechno-social cultural markets.",
    "published_date": "2017-07-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00574v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.00536v2",
    "title": "Robust Cost-Sensitive Learning for Recommendation with Implicit Feedback",
    "authors": [
      "Peng Yang",
      "Peilin Zhao",
      "Xin Gao",
      "Yong Liu"
    ],
    "author_ids": [],
    "abstract": "Recommendation is the task of improving customer experience through\npersonalized recommendation based on users' past feedback. In this paper, we\ninvestigate the most common scenario: the user-item (U-I) matrix of implicit\nfeedback. Even though many recommendation approaches are designed based on\nimplicit feedback, they attempt to project the U-I matrix into a low-rank\nlatent space, which is a strict restriction that rarely holds in practice. In\naddition, although misclassification costs from imbalanced classes are\nsignificantly different, few methods take the cost of classification error into\naccount. To address aforementioned issues, we propose a robust framework by\ndecomposing the U-I matrix into two components: (1) a low-rank matrix that\ncaptures the common preference, and (2) a sparse matrix that detects the\nuser-specific preference of individuals. A cost-sensitive learning model is\nembedded into the framework. Specifically, this model exploits different costs\nin the loss function for the observed and unobserved instances. We show that\nthe resulting non-smooth convex objective can be optimized efficiently by an\naccelerated projected gradient method with closed-form solutions. Morever, the\nproposed algorithm can be scaled up to large-sized datasets after a relaxation.\nThe theoretical result shows that even with a small fraction of 1's in the U-I\nmatrix $M\\in\\mathbb{R}^{n\\times m}$, the cost-sensitive error of the proposed\nmodel is upper bounded by $O(\\frac{\\alpha}{\\sqrt{mn}})$, where $\\alpha$ is a\nbias over imbalanced classes. Finally, empirical experiments are extensively\ncarried out to evaluate the effectiveness of our proposed algorithm.\nEncouraging experimental results show that our algorithm outperforms several\nstate-of-the-art algorithms on benchmark recommendation datasets.",
    "published_date": "2017-07-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.IR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00536v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00391v1",
    "title": "Fair Pipelines",
    "authors": [
      "Amanda Bower",
      "Sarah N. Kitchen",
      "Laura Niss",
      "Martin J. Strauss",
      "Alexander Vargas",
      "Suresh Venkatasubramanian"
    ],
    "author_ids": [],
    "abstract": "This work facilitates ensuring fairness of machine learning in the real world\nby decoupling fairness considerations in compound decisions. In particular,\nthis work studies how fairness propagates through a compound decision-making\nprocesses, which we call a pipeline. Prior work in algorithmic fairness only\nfocuses on fairness with respect to one decision. However, many decision-making\nprocesses require more than one decision. For instance, hiring is at least a\ntwo stage model: deciding who to interview from the applicant pool and then\ndeciding who to hire from the interview pool. Perhaps surprisingly, we show\nthat the composition of fair components may not guarantee a fair pipeline under\na $(1+\\varepsilon)$-equal opportunity definition of fair. However, we identify\ncircumstances that do provide that guarantee. We also propose numerous\ndirections for future work on more general compound machine learning decisions.",
    "published_date": "2017-07-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00391v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00375v1",
    "title": "Adaptive Stimulus Selection in ERP-Based Brain-Computer Interfaces by Maximizing Expected Discrimination Gain",
    "authors": [
      "Dmitry Kalika",
      "Leslie M. Collins",
      "Chandra S. Throckmorton",
      "Boyla O. Mainsah"
    ],
    "author_ids": [],
    "abstract": "Brain-computer interfaces (BCIs) can provide an alternative means of\ncommunication for individuals with severe neuromuscular limitations. The\nP300-based BCI speller relies on eliciting and detecting transient\nevent-related potentials (ERPs) in electroencephalography (EEG) data, in\nresponse to a user attending to rarely occurring target stimuli amongst a\nseries of non-target stimuli. However, in most P300 speller implementations,\nthe stimuli to be presented are randomly selected from a limited set of options\nand stimulus selection and presentation are not optimized based on previous\nuser data. In this work, we propose a data-driven method for stimulus selection\nbased on the expected discrimination gain metric. The data-driven approach\nselects stimuli based on previously observed stimulus responses, with the aim\nof choosing a set of stimuli that will provide the most information about the\nuser's intended target character. Our approach incorporates knowledge of\nphysiological and system constraints imposed due to real-time BCI\nimplementation. Simulations were performed to compare our stimulus selection\napproach to the row-column paradigm, the conventional stimulus selection method\nfor P300 spellers. Results from the simulations demonstrated that our adaptive\nstimulus selection approach has the potential to significantly improve\nperformance from the conventional method: up to 34% improvement in accuracy and\n43% reduction in the mean number of stimulus presentations required to spell a\ncharacter in a 72-character grid. In addition, our greedy approach to stimulus\nselection provides the flexibility to accommodate design constraints.",
    "published_date": "2017-07-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00375v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.00304v1",
    "title": "Rate-Splitting for Max-Min Fair Multigroup Multicast Beamforming in Overloaded Systems",
    "authors": [
      "Hamdi Joudeh",
      "Bruno Clerckx"
    ],
    "author_ids": [],
    "abstract": "In this paper, we consider the problem of achieving max-min fairness amongst\nmultiple co-channel multicast groups through transmit beamforming. We\nexplicitly focus on overloaded scenarios in which the number of transmitting\nantennas is insufficient to neutralize all inter-group interference. Such\nscenarios are becoming increasingly relevant in the light of growing\nlow-latency content delivery demands, and also commonly appear in multibeam\nsatellite systems. We derive performance limits of classical beamforming\nstrategies using DoF analysis unveiling their limitations; for example, rates\nsaturate in overloaded scenarios due to inter-group interference. To tackle\ninterference, we propose a strategy based on degraded beamforming and\nsuccessive interference cancellation. While the degraded strategy resolves the\nrate-saturation issue, this comes at a price of sacrificing all spatial\nmultiplexing gains. This motivates the development of a unifying strategy that\ncombines the benefits of the two previous strategies. We propose a beamforming\nstrategy based on rate-splitting (RS) which divides the messages intended to\neach group into a degraded part and a designated part, and transmits a\nsuperposition of both degraded and designated beamformed streams. The\nsuperiority of the proposed strategy is demonstrated through DoF analysis.\nFinally, we solve the RS beamforming design problem and demonstrate significant\nperformance gains through simulations.",
    "published_date": "2017-07-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00304v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.00227v2",
    "title": "Relationship between Cross-Polarization Discrimination (XPD) and Spatial Correlation in Indoor Small-Cell MIMO Systems",
    "authors": [
      "Yeon-Geun Lim",
      "Yae Jee Cho",
      "TaeckKeun Oh",
      "Yongshik Lee",
      "Chan-Byoung Chae"
    ],
    "author_ids": [],
    "abstract": "In this letter, we present a correlated channel model for a dual-polarization\nantenna to omnidirectional antennas in indoor small-cell multiple-input\nmultiple-output (MIMO) systems. In an indoor environment, we confirm that the\ncross-polarization discrimination (XPD) in the direction of angle-of-departure\ncan be represented as the spatial correlation of the MIMO channel. We also\nevaluate a dual-polarization antenna-based MIMO channel model and a spatially\ncorrelated channel model using a three-dimensional (3D) ray-tracing simulator.\nFurthermore, we provide the equivalent distance between adjacent antennas\naccording to the XPD, providing insights into designing a dual-polarization\nantenna and its arrays.",
    "published_date": "2017-07-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00227v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1707.00093v2",
    "title": "Multisided Fairness for Recommendation",
    "authors": [
      "Robin Burke"
    ],
    "author_ids": [],
    "abstract": "Recent work on machine learning has begun to consider issues of fairness. In\nthis paper, we extend the concept of fairness to recommendation. In particular,\nwe show that in some recommendation contexts, fairness may be a multisided\nconcept, in which fair outcomes for multiple individuals need to be considered.\nBased on these considerations, we present a taxonomy of classes of\nfairness-aware recommender systems and suggest possible fairness-aware\nrecommendation architectures.",
    "published_date": "2017-07-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00093v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00075v2",
    "title": "Data Decisions and Theoretical Implications when Adversarially Learning Fair Representations",
    "authors": [
      "Alex Beutel",
      "Jilin Chen",
      "Zhe Zhao",
      "Ed H. Chi"
    ],
    "author_ids": [],
    "abstract": "How can we learn a classifier that is \"fair\" for a protected or sensitive\ngroup, when we do not know if the input to the classifier belongs to the\nprotected group? How can we train such a classifier when data on the protected\ngroup is difficult to attain? In many settings, finding out the sensitive input\nattribute can be prohibitively expensive even during model training, and\nsometimes impossible during model serving. For example, in recommender systems,\nif we want to predict if a user will click on a given recommendation, we often\ndo not know many attributes of the user, e.g., race or age, and many attributes\nof the content are hard to determine, e.g., the language or topic. Thus, it is\nnot feasible to use a different classifier calibrated based on knowledge of the\nsensitive attribute.\n  Here, we use an adversarial training procedure to remove information about\nthe sensitive attribute from the latent representation learned by a neural\nnetwork. In particular, we study how the choice of data for the adversarial\ntraining effects the resulting fairness properties. We find two interesting\nresults: a small amount of data is needed to train these adversarial models,\nand the data distribution empirically drives the adversary's notion of\nfairness.",
    "published_date": "2017-07-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00075v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00061v1",
    "title": "Racial Disparity in Natural Language Processing: A Case Study of Social Media African-American English",
    "authors": [
      "Su Lin Blodgett",
      "Brendan O'Connor"
    ],
    "author_ids": [],
    "abstract": "We highlight an important frontier in algorithmic fairness: disparity in the\nquality of natural language processing algorithms when applied to language from\nauthors of different social groups. For example, current systems sometimes\nanalyze the language of females and minorities more poorly than they do of\nwhites and males. We conduct an empirical analysis of racial disparity in\nlanguage identification for tweets written in African-American English, and\ndiscuss implications of disparity in NLP.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00061v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00046v1",
    "title": "Fairer and more accurate, but for whom?",
    "authors": [
      "Alexandra Chouldechova",
      "Max G'Sell"
    ],
    "author_ids": [],
    "abstract": "Complex statistical machine learning models are increasingly being used or\nconsidered for use in high-stakes decision-making pipelines in domains such as\nfinancial services, health care, criminal justice and human services. These\nmodels are often investigated as possible improvements over more classical\ntools such as regression models or human judgement. While the modeling approach\nmay be new, the practice of using some form of risk assessment to inform\ndecisions is not. When determining whether a new model should be adopted, it is\ntherefore essential to be able to compare the proposed model to the existing\napproach across a range of task-relevant accuracy and fairness metrics. Looking\nat overall performance metrics, however, may be misleading. Even when two\nmodels have comparable overall performance, they may nevertheless disagree in\ntheir classifications on a considerable fraction of cases. In this paper we\nintroduce a model comparison framework for automatically identifying subgroups\nin which the differences between models are most pronounced. Our primary focus\nis on identifying subgroups where the models differ in terms of\nfairness-related quantities such as racial or gender disparities. We present\nexperimental results from a recidivism prediction task and a hypothetical\nlending example.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00046v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00044v3",
    "title": "Penalizing Unfairness in Binary Classification",
    "authors": [
      "Yahav Bechavod",
      "Katrina Ligett"
    ],
    "author_ids": [],
    "abstract": "We present a new approach for mitigating unfairness in learned classifiers.\nIn particular, we focus on binary classification tasks over individuals from\ntwo populations, where, as our criterion for fairness, we wish to achieve\nsimilar false positive rates in both populations, and similar false negative\nrates in both populations. As a proof of concept, we implement our approach and\nempirically evaluate its ability to achieve both fairness and accuracy, using\ndatasets from the fields of criminal risk assessment, credit, lending, and\ncollege admissions.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00044v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1707.00010v2",
    "title": "From Parity to Preference-based Notions of Fairness in Classification",
    "authors": [
      "Muhammad Bilal Zafar",
      "Isabel Valera",
      "Manuel Gomez Rodriguez",
      "Krishna P. Gummadi",
      "Adrian Weller"
    ],
    "author_ids": [],
    "abstract": "The adoption of automated, data-driven decision making in an ever expanding\nrange of applications has raised concerns about its potential unfairness\ntowards certain social groups. In this context, a number of recent studies have\nfocused on defining, detecting, and removing unfairness from data-driven\ndecision systems. However, the existing notions of fairness, based on parity\n(equality) in treatment or outcomes for different social groups, tend to be\nquite stringent, limiting the overall decision making accuracy. In this paper,\nwe draw inspiration from the fair-division and envy-freeness literature in\neconomics and game theory and propose preference-based notions of fairness --\ngiven the choice between various sets of decision treatments or outcomes, any\ngroup of users would collectively prefer its treatment or outcomes, regardless\nof the (dis)parity as compared to the other groups. Then, we introduce\ntractable proxies to design margin-based classifiers that satisfy these\npreference-based notions of fairness. Finally, we experiment with a variety of\nsynthetic and real-world datasets and show that preference-based fairness\nallows for greater decision accuracy than parity-based fairness.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1707.00010v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.10237v1",
    "title": "Is it ethical to avoid error analysis?",
    "authors": [
      "Eva García-Martín",
      "Niklas Lavesson"
    ],
    "author_ids": [],
    "abstract": "Machine learning algorithms tend to create more accurate models with the\navailability of large datasets. In some cases, highly accurate models can hide\nthe presence of bias in the data. There are several studies published that\ntackle the development of discriminatory-aware machine learning algorithms. We\ncenter on the further evaluation of machine learning models by doing error\nanalysis, to understand under what conditions the model is not working as\nexpected. We focus on the ethical implications of avoiding error analysis, from\na falsification of results and discrimination perspective. Finally, we show\ndifferent ways to approach error analysis in non-interpretable machine learning\nalgorithms such as deep learning.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.10237v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.10208v1",
    "title": "On Fairness, Diversity and Randomness in Algorithmic Decision Making",
    "authors": [
      "Nina Grgić-Hlača",
      "Muhammad Bilal Zafar",
      "Krishna P. Gummadi",
      "Adrian Weller"
    ],
    "author_ids": [],
    "abstract": "Consider a binary decision making process where a single machine learning\nclassifier replaces a multitude of humans. We raise questions about the\nresulting loss of diversity in the decision making process. We study the\npotential benefits of using random classifier ensembles instead of a single\nclassifier in the context of fairness-aware learning and demonstrate various\nattractive properties: (i) an ensemble of fair classifiers is guaranteed to be\nfair, for several different measures of fairness, (ii) an ensemble of unfair\nclassifiers can still achieve fair outcomes, and (iii) an ensemble of\nclassifiers can achieve better accuracy-fairness trade-offs than a single\nclassifier. Finally, we introduce notions of distributional fairness to\ncharacterize further potential benefits of random classifier ensembles.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.10208v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.10102v3",
    "title": "Tableaux for Policy Synthesis for MDPs with PCTL* Constraints",
    "authors": [
      "Peter Baumgartner",
      "Sylvie Thiébaux",
      "Felipe Trevizan"
    ],
    "author_ids": [],
    "abstract": "Markov decision processes (MDPs) are the standard formalism for modelling\nsequential decision making in stochastic environments. Policy synthesis\naddresses the problem of how to control or limit the decisions an agent makes\nso that a given specification is met. In this paper we consider PCTL*, the\nprobabilistic counterpart of CTL*, as the specification language. Because in\ngeneral the policy synthesis problem for PCTL* is undecidable, we restrict to\npolicies whose execution history memory is finitely bounded a priori.\n  Surprisingly, no algorithm for policy synthesis for this natural and\nexpressive framework has been developed so far. We close this gap and describe\na tableau-based algorithm that, given an MDP and a PCTL* specification, derives\nin a non-deterministic way a system of (possibly nonlinear) equalities and\ninequalities. The solutions of this system, if any, describe the desired\n(stochastic) policies.\n  Our main result in this paper is the correctness of our method, i.e.,\nsoundness, completeness and termination.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.10102v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.10030v2",
    "title": "On the Solution of Linear Programming Problems in the Age of Big Data",
    "authors": [
      "Irina Sokolinskaya",
      "Leonid B. Sokolinsky"
    ],
    "author_ids": [],
    "abstract": "The Big Data phenomenon has spawned large-scale linear programming problems.\nIn many cases, these problems are non-stationary. In this paper, we describe a\nnew scalable algorithm called NSLP for solving high-dimensional, non-stationary\nlinear programming problems on modern cluster computing systems. The algorithm\nconsists of two phases: Quest and Targeting. The Quest phase calculates a\nsolution of the system of inequalities defining the constraint system of the\nlinear programming problem under the condition of dynamic changes in input\ndata. To this end, the apparatus of Fejer mappings is used. The Targeting phase\nforms a special system of points having the shape of an n-dimensional\naxisymmetric cross. The cross moves in the n-dimensional space in such a way\nthat the solution of the linear programming problem is located all the time in\nan \"-vicinity of the central point of the cross.",
    "published_date": "2017-06-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.10030v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.09976v2",
    "title": "The Authority of \"Fair\" in Machine Learning",
    "authors": [
      "Michael Skirpan",
      "Micha Gorelick"
    ],
    "author_ids": [],
    "abstract": "In this paper, we argue for the adoption of a normative definition of\nfairness within the machine learning community. After characterizing this\ndefinition, we review the current literature of Fair ML in light of its\nimplications. We end by suggesting ways to incorporate a broader community and\ngenerate further debate around how to decide what is fair in ML.",
    "published_date": "2017-06-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09976v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.09854v4",
    "title": "Quantum computation with indefinite causal structures",
    "authors": [
      "Mateus Araújo",
      "Philippe Allard Guérin",
      "Ämin Baumeler"
    ],
    "author_ids": [],
    "abstract": "One way to study the physical plausibility of closed timelike curves (CTCs)\nis to examine their computational power. This has been done for Deutschian CTCs\n(D-CTCs) and post-selection CTCs (P-CTCs), with the result that they allow for\nthe efficient solution of problems in PSPACE and PP, respectively. Since these\nare extremely powerful complexity classes, which are not expected to be\nsolvable in reality, this can be taken as evidence that these models for CTCs\nare pathological. This problem is closely related to the nonlinearity of this\nmodels, which also allows for example cloning quantum states, in the case of\nD-CTCs, or distinguishing non-orthogonal quantum states, in the case of P-CTCs.\nIn contrast, the process matrix formalism allows one to model indefinite causal\nstructures in a linear way, getting rid of these effects, and raising the\npossibility that its computational power is rather tame. In this paper we show\nthat process matrices correspond to a linear particular case of P-CTCs, and\ntherefore that its computational power is upperbounded by that of PP. We show,\nfurthermore, a family of processes that can violate causal inequalities but\nnevertheless can be simulated by a causally ordered quantum circuit with only a\nconstant overhead, showing that indefinite causality is not necessarily hard to\nsimulate.",
    "published_date": "2017-06-29T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09854v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.09838v2",
    "title": "New Fairness Metrics for Recommendation that Embrace Differences",
    "authors": [
      "Sirui Yao",
      "Bert Huang"
    ],
    "author_ids": [],
    "abstract": "We study fairness in collaborative-filtering recommender systems, which are\nsensitive to discrimination that exists in historical data. Biased data can\nlead collaborative filtering methods to make unfair predictions against\nminority groups of users. We identify the insufficiency of existing fairness\nmetrics and propose four new metrics that address different forms of\nunfairness. These fairness metrics can be optimized by adding fairness terms to\nthe learning objective. Experiments on synthetic and real data show that our\nnew metrics can better measure fairness than the baseline, and that the\nfairness objectives effectively help reduce unfairness.",
    "published_date": "2017-06-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09838v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.09494v2",
    "title": "Misinformation spreading on Facebook",
    "authors": [
      "Fabiana Zollo",
      "Walter Quattrociocchi"
    ],
    "author_ids": [],
    "abstract": "Social media are pervaded by unsubstantiated or untruthful rumors, that\ncontribute to the alarming phenomenon of misinformation. The widespread\npresence of a heterogeneous mass of information sources may affect the\nmechanisms behind the formation of public opinion. Such a scenario is a florid\nenvironment for digital wildfires when combined with functional illiteracy,\ninformation overload, and confirmation bias. In this essay, we focus on a\ncollection of works aiming at providing quantitative evidence about the\ncognitive determinants behind misinformation and rumor spreading. We account\nfor users' behavior with respect to two distinct narratives: a) conspiracy and\nb) scientific information sources. In particular, we analyze Facebook data on a\ntime span of five years in both the Italian and the US context, and measure\nusers' response to i) information consistent with one's narrative, ii) troll\ncontents, and iii) dissenting information e.g., debunking attempts. Our\nfindings suggest that users tend to a) join polarized communities sharing a\ncommon narrative (echo chambers), b) acquire information confirming their\nbeliefs (confirmation bias) even if containing false claims, and c) ignore\ndissenting information.",
    "published_date": "2017-06-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09494v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.09115v2",
    "title": "Fairness of Congestion-Based Congestion Control: Experimental Evaluation and Analysis",
    "authors": [
      "Shiyao Ma",
      "Jingjie Jiang",
      "Wei Wang",
      "Bo Li"
    ],
    "author_ids": [],
    "abstract": "BBR is a new congestion-based congestion control algorithm proposed by\nGoogle. A BBR flow sequentially measures the bottleneck bandwidth and\nround-trip delay of the network pipe, and uses the measured results to govern\nits sending behavior, maximizing the delivery bandwidth while minimizing the\ndelay. However, our deployment in geo-distributed cloud servers reveals a\nsevere RTT fairness problem: a BBR flow with longer RTT dominates a competing\nflow with shorter RTT.\n  Somewhat surprisingly, our deployment of BBR on the Internet and an in-house\ncluster unearthed a consistent bandwidth disparity among competing flows. Long\nBBR flows are bound to seize bandwidth from short ones. Intrigued by this\nunexpected behavior, we ask, is the phenomenon intrinsic to BBR? how's the\nseverity? and what's the root cause? To this end, we conduct thorough\nmeasurements and develop a theoretical model on bandwidth dynamics. We find, as\nlong as the competing flows are of different RTTs, bandwidth disparities will\narise. With an RTT ratio of 10, even flow starvation can happen. We blame it on\nBBR's connivance at sending an excessive amount of data when probing bandwidth.\nSpecifically, the amount of data is in proportion to RTT, making long RTT flows\noverwhelming short ones. Based on this observation, we design a derivative of\nBBR that achieves guaranteed flow fairness, at the meantime without losing any\nmerits. We have implemented our proposed solution in Linux kernel and evaluated\nit through extensive experiments.",
    "published_date": "2017-06-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09115v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.08693v1",
    "title": "Sensitivity analysis for network aggregative games",
    "authors": [
      "Francesca Parise",
      "Asuman Ozdaglar"
    ],
    "author_ids": [],
    "abstract": "We investigate the sensitivity of the Nash equilibrium of constrained network\naggregative games to changes in exogenous parameters affecting the cost\nfunction of the players. This setting is motivated by two applications. The\nfirst is the analysis of interventions by a social planner with a networked\nobjective function while the second is network routing games with atomic\nplayers and information constraints. By exploiting a primal reformulation of a\nsensitivity analysis result for variational inequalities, we provide a\ncharacterization of the sensitivity of the Nash equilibrium that depends on\nprimal variables only. To derive this result we assume strong monotonicity of\nthe mapping associated with the game. As the second main result, we derive\nsufficient conditions that guarantee this strong monotonicity property in\nnetwork aggregative games. These two characterizations allows us to\nsystematically study changes in the Nash equilibrium due to perturbations or\nparameter variations in the two applications mentioned above.",
    "published_date": "2017-06-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08693v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.08619v1",
    "title": "White, Man, and Highly Followed: Gender and Race Inequalities in Twitter",
    "authors": [
      "Johnnatan Messias",
      "Pantelis Vikatos",
      "Fabricio Benevenuto"
    ],
    "author_ids": [],
    "abstract": "Social media is considered a democratic space in which people connect and\ninteract with each other regardless of their gender, race, or any other\ndemographic factor. Despite numerous efforts that explore demographic factors\nin social media, it is still unclear whether social media perpetuates old\ninequalities from the offline world. In this paper, we attempt to identify\ngender and race of Twitter users located in U.S. using advanced image\nprocessing algorithms from Face++. Then, we investigate how different\ndemographic groups (i.e. male/female, Asian/Black/White) connect with other. We\nquantify to what extent one group follow and interact with each other and the\nextent to which these connections and interactions reflect in inequalities in\nTwitter. Our analysis shows that users identified as White and male tend to\nattain higher positions in Twitter, in terms of the number of followers and\nnumber of times in user's lists. We hope our effort can stimulate the\ndevelopment of new theories of demographic information in the online space.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08619v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.08606v2",
    "title": "Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study",
    "authors": [
      "Samuel Ritter",
      "David G. T. Barrett",
      "Adam Santoro",
      "Matt M. Botvinick"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks (DNNs) have achieved unprecedented performance on a wide\nrange of complex tasks, rapidly outpacing our understanding of the nature of\ntheir solutions. This has caused a recent surge of interest in methods for\nrendering modern neural systems more interpretable. In this work, we propose to\naddress the interpretability problem in modern DNNs using the rich history of\nproblem descriptions, theories and experimental methods developed by cognitive\npsychologists to study the human mind. To explore the potential value of these\ntools, we chose a well-established analysis from developmental psychology that\nexplains how children learn word labels for objects, and applied that analysis\nto DNNs. Using datasets of stimuli inspired by the original cognitive\npsychology experiments, we find that state-of-the-art one shot learning models\ntrained on ImageNet exhibit a similar bias to that observed in humans: they\nprefer to categorize objects according to shape rather than color. The\nmagnitude of this shape bias varies greatly among architecturally identical,\nbut differently seeded models, and even fluctuates within seeds throughout\ntraining, despite nearly equivalent classification performance. These results\ndemonstrate the capability of tools from cognitive psychology for exposing\nhidden computational properties of DNNs, while concurrently providing us with a\ncomputational model for human word learning.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08606v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.08590v1",
    "title": "Robust Sonar ATR Through Bayesian Pose Corrected Sparse Classification",
    "authors": [
      "John McKay",
      "Vishal Monga",
      "Raghu G. Raj"
    ],
    "author_ids": [],
    "abstract": "Sonar imaging has seen vast improvements over the last few decades due in\npart to advances in synthetic aperture Sonar (SAS). Sophisticated\nclassification techniques can now be used in Sonar automatic target recognition\n(ATR) to locate mines and other threatening objects. Among the most promising\nof these methods is sparse reconstruction-based classification (SRC) which has\nshown an impressive resiliency to noise, blur, and occlusion. We present a\ncoherent strategy for expanding upon SRC for Sonar ATR that retains SRC's\nrobustness while also being able to handle targets with diverse geometric\narrangements, bothersome Rayleigh noise, and unavoidable background clutter.\nOur method, pose corrected sparsity (PCS), incorporates a novel interpretation\nof a spike and slab probability distribution towards use as a Bayesian prior\nfor class-specific discrimination in combination with a dictionary learning\nscheme for localized patch extractions. Additionally, PCS offers the potential\nfor anomaly detection in order to avoid false identifications of tested objects\nfrom outside the training set with no additional training required. Compelling\nresults are shown using a database provided by the United States Naval Surface\nWarfare Center.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08590v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.08550v3",
    "title": "Semidefinite Programming and Nash Equilibria in Bimatrix Games",
    "authors": [
      "Amir Ali Ahmadi",
      "Jeffrey Zhang"
    ],
    "author_ids": [],
    "abstract": "We explore the power of semidefinite programming (SDP) for finding additive\n$epsilon$-approximate Nash equilibria in bimatrix games. We introduce an SDP\nrelaxation for a quadratic programming formulation of the Nash equilibrium (NE)\nproblem and provide a number of valid inequalities to improve the quality of\nthe relaxation. If a rank-1 solution to this SDP is found, then an exact NE can\nbe recovered. We show that for a strictly competitive game, our SDP is\nguaranteed to return a rank-1 solution. We propose two algorithms based on\niterative linearization of smooth nonconvex objective functions whose global\nminima by design coincide with rank-1 solutions. Empirically, we demonstrate\nthat these algorithms often recover solutions of rank at most two and $epsilon$\nclose to zero. Furthermore, we prove that if a rank-2 solution to our SDP is\nfound, then a 5/11-NE can be recovered for any game, or a 1/3-NE for a\nsymmetric game. We then show how our SDP approach can address two (NP-hard)\nproblems of economic interest: finding the maximum welfare achievable under any\nNE, and testing whether there exists a NE where a particular set of strategies\nis not played. Finally, we show the connection between our SDP and the first\nlevel of the Lasserre/sum of squares hierarchy.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.DS",
      "cs.GT",
      "90C90 (Primary) 90C22, 91A5, 91A10 (Secondary)",
      "G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08550v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.08519v1",
    "title": "On conditional parity as a notion of non-discrimination in machine learning",
    "authors": [
      "Ya'acov Ritov",
      "Yuekai Sun",
      "Ruofei Zhao"
    ],
    "author_ids": [],
    "abstract": "We identify conditional parity as a general notion of non-discrimination in\nmachine learning. In fact, several recently proposed notions of\nnon-discrimination, including a few counterfactual notions, are instances of\nconditional parity. We show that conditional parity is amenable to statistical\nanalysis by studying randomization as a general mechanism for achieving\nconditional parity and a kernel-based test of conditional parity.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08519v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.08461v1",
    "title": "Methodological Approach for the Design of a Complex Inclusive Human-Machine System",
    "authors": [
      "Lorenzo Sabattini",
      "Valeria Villani",
      "Julia N. Czerniak",
      "Alexander Mertens",
      "Cesare Fantuzzi"
    ],
    "author_ids": [],
    "abstract": "Modern industrial automatic machines and robotic cells are equipped with\nhighly complex human-machine interfaces (HMIs) that often prevent human\noperators from an effective use of the automatic systems. In particular, this\napplies to vulnerable users, such as those with low experience or education\nlevel, the elderly and the disabled. To tackle this issue, it becomes necessary\nto design user-oriented HMIs, which adapt to the capabilities and skills of\nusers, thus compensating their limitations and taking full advantage of their\nknowledge. In this paper, we propose a methodological approach to the design of\ncomplex adaptive human-machine systems that might be inclusive of all users, in\nparticular the vulnerable ones. The proposed approach takes into account both\nthe technical requirements and the requirements for ethical, legal and social\nimplications (ELSI) for the design of automatic systems. The technical\nrequirements derive from a thorough analysis of three use cases taken from the\nEuropean project INCLUSIVE. To achieve the ELSI requirements, the MEESTAR\napproach is combined with the specific legal issues for occupational systems\nand requirements of the target users.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08461v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.08219v3",
    "title": "Asymptotic Existence of Fair Divisions for Groups",
    "authors": [
      "Pasin Manurangsi",
      "Warut Suksompong"
    ],
    "author_ids": [],
    "abstract": "The problem of dividing resources fairly occurs in many practical situations\nand is therefore an important topic of study in economics. In this paper, we\ninvestigate envy-free divisions in the setting where there are multiple players\nin each interested party. While all players in a party share the same set of\nresources, each player has her own preferences. Under additive valuations drawn\nrandomly from probability distributions, we show that when all groups contain\nan equal number of players, a welfare-maximizing allocation is likely to be\nenvy-free if the number of items exceeds the total number of players by a\nlogarithmic factor. On the other hand, an envy-free allocation is unlikely to\nexist if the number of items is less than the total number of players. In\naddition, we show that a simple truthful mechanism, namely the random\nassignment mechanism, yields an allocation that satisfies the weaker notion of\napproximate envy-freeness with high probability.",
    "published_date": "2017-06-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.08219v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.07901v1",
    "title": "Deep Mixture of Diverse Experts for Large-Scale Visual Recognition",
    "authors": [
      "Tianyi Zhao",
      "Jun Yu",
      "Zhenzhong Kuang",
      "Wei Zhang",
      "Jianping Fan"
    ],
    "author_ids": [],
    "abstract": "In this paper, a deep mixture of diverse experts algorithm is developed for\nseamlessly combining a set of base deep CNNs (convolutional neural networks)\nwith diverse outputs (task spaces), e.g., such base deep CNNs are trained to\nrecognize different subsets of tens of thousands of atomic object classes.\nFirst, a two-layer (category layer and object class layer) ontology is\nconstructed to achieve more effective solution for task group generation, e.g.,\nassigning the semantically-related atomic object classes at the sibling leaf\nnodes into the same task group because they may share similar learning\ncomplexities. Second, one particular base deep CNNs with $M+1$ ($M \\leq 1,000$)\noutputs is learned for each task group to recognize its $M$ atomic object\nclasses effectively and identify one special class of \"not-in-group\"\nautomatically, and the network structure (numbers of layers and units in each\nlayer) of the well-designed AlexNet is directly used to configure such base\ndeep CNNs. A deep multi-task learning algorithm is developed to leverage the\ninter-class visual similarities to learn more discriminative base deep CNNs and\nmulti-task softmax for enhancing the separability of the atomic object classes\nin the same task group. Finally, all these base deep CNNs with diverse outputs\n(task spaces) are seamlessly combined to form a deep mixture of diverse experts\nfor recognizing tens of thousands of atomic object classes. Our experimental\nresults have demonstrated that our deep mixture of diverse experts algorithm\ncan achieve very competitive results on large-scale visual recognition.",
    "published_date": "2017-06-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07901v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.07598v2",
    "title": "Named Entity Recognition with stack residual LSTM and trainable bias decoding",
    "authors": [
      "Quan Tran",
      "Andrew MacKinlay",
      "Antonio Jimeno Yepes"
    ],
    "author_ids": [],
    "abstract": "Recurrent Neural Network models are the state-of-the-art for Named Entity\nRecognition (NER). We present two innovations to improve the performance of\nthese models. The first innovation is the introduction of residual connections\nbetween the Stacked Recurrent Neural Network model to address the degradation\nproblem of deep neural networks. The second innovation is a bias decoding\nmechanism that allows the trained system to adapt to non-differentiable and\nexternally computed objectives, such as the entity-based F-measure. Our work\nimproves the state-of-the-art results for both Spanish and English languages on\nthe standard train/development/test split of the CoNLL 2003 Shared Task NER\ndataset.",
    "published_date": "2017-06-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07598v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.07332v2",
    "title": "Human decisions in moral dilemmas are largely described by Utilitarianism: virtual car driving study provides guidelines for ADVs",
    "authors": [
      "Maximilian Alexander Wächter",
      "Anja Faulhaber",
      "Felix Blind",
      "Silja Timm",
      "Anke Dittmer",
      "Leon René Sütfeld",
      "Achim Stephan",
      "Gordon Pipa",
      "Peter König"
    ],
    "author_ids": [],
    "abstract": "Ethical thought experiments such as the trolley dilemma have been\ninvestigated extensively in the past, showing that humans act in a utilitarian\nway, trying to cause as little overall damage as possible. These trolley\ndilemmas have gained renewed attention over the past years; especially due to\nthe necessity of implementing moral decisions in autonomous driving vehicles.\nWe conducted a set of experiments in which participants experienced modified\ntrolley dilemmas as the driver in a virtual reality environment. Participants\nhad to make decisionsbetween two discrete options: driving on one of two lanes\nwhere different obstacles came into view. Obstacles included a variety of\nhuman-like avatars of different ages and group sizes. Furthermore, we tested\nthe influence of a sidewalk as a potential safe harbor and a condition\nimplicating a self-sacrifice. Results showed that subjects, in general, decided\nin a utilitarian manner, sparing the highest number of avatars possible with a\nlimited influence of the other variables. Our findings support that human\nbehavior is in line with the utilitarian approach to moral decision making.\nThis may serve as a guideline for the implementation of moral decisions in\nADVs.",
    "published_date": "2017-06-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07332v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.07269v3",
    "title": "Explanation in Artificial Intelligence: Insights from the Social Sciences",
    "authors": [
      "Tim Miller"
    ],
    "author_ids": [],
    "abstract": "There has been a recent resurgence in the area of explainable artificial\nintelligence as researchers and practitioners seek to make their algorithms\nmore understandable. Much of this research is focused on explicitly explaining\ndecisions or actions to a human observer, and it should not be controversial to\nsay that looking at how humans explain to each other can serve as a useful\nstarting point for explanation in artificial intelligence. However, it is fair\nto say that most work in explainable artificial intelligence uses only the\nresearchers' intuition of what constitutes a `good' explanation. There exists\nvast and valuable bodies of research in philosophy, psychology, and cognitive\nscience of how people define, generate, select, evaluate, and present\nexplanations, which argues that people employ certain cognitive biases and\nsocial expectations towards the explanation process. This paper argues that the\nfield of explainable artificial intelligence should build on this existing\nresearch, and reviews relevant papers from philosophy, cognitive\npsychology/science, and social psychology, which study these topics. It draws\nout some important findings, and discusses ways that these can be infused with\nwork on explainable artificial intelligence.",
    "published_date": "2017-06-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07269v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.07202v1",
    "title": "Living Labs - An Ethical Challenge for Researchers and Platform Providers",
    "authors": [
      "Philipp Schaer"
    ],
    "author_ids": [],
    "abstract": "The infamous Facebook emotion contagion experiment is one of the most\nprominent and best-known online experiments based on the concept of what we\nhere call \"living labs\". In these kinds of experiments, real-world applications\nsuch as social web platforms trigger experimental switches inside their system\nto present experimental changes to their users - most of the time without the\nusers being aware of their role as virtual guinea pigs. In the Facebook example\nthe researches changed the way users' personal timeline was compiled to test\nthe influence on the users' moods and feelings. The reactions to these\nexperiments showed the inherent ethical issues such living labs settings bring\nup, mainly the study's lack of informed consent procedures, as well as a more\ngeneral critique of the flaws in the experimental design.\n  In this chapter, we describe additional use cases: The so-called living labs\nthat focus on experimentation with information systems such as search engines\nand wikis and especially on their real-world usage. The living labs paradigm\nallows researchers to conduct research in real-world environments or systems.\nIn the field of information science and especially information retrieval -\nwhich is the scientific discipline that is concerned with the research of\nsearch engines, information systems, and search related algorithms and\ntechniques - it is still common practice to perform in vitro or offline\nevaluations using static test collections. Living labs are widely unknown or\nunavailable to academic researchers in these fields. A main benefit of living\nlabs is their potential to offer new ways and possibilities to experiment with\ninformation systems and especially their users, but on the other hand they\nintroduce a whole set of ethical issues that we would like to address in this\nchapter.",
    "published_date": "2017-06-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07202v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.07178v1",
    "title": "Shape recognition of volcanic ash by simple convolutional neural network",
    "authors": [
      "Daigo Shoji",
      "Rina Noguchi"
    ],
    "author_ids": [],
    "abstract": "Shape analyses of tephra grains result in understanding eruption mechanism of\nvolcanoes. However, we have to define and select parameter set such as\nconvexity for the precise discrimination of tephra grains. Selection of the\nbest parameter set for the recognition of tephra shapes is complicated.\nActually, many shape parameters have been suggested. Recently, neural network\nhas made a great success in the field of machine learning. Convolutional neural\nnetwork can recognize the shape of images without human bias and shape\nparameters. We applied the simple convolutional neural network developed for\nthe handwritten digits to the recognition of tephra shapes. The network was\ntrained by Morphologi tephra images, and it can recognize the tephra shapes\nwith approximately 90% of accuracy.",
    "published_date": "2017-06-22T00:00:00",
    "year": 2017,
    "categories": [
      "physics.geo-ph",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.07178v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.06749v1",
    "title": "Cross-language Learning with Adversarial Neural Networks: Application to Community Question Answering",
    "authors": [
      "Shafiq Joty",
      "Preslav Nakov",
      "Lluís Màrquez",
      "Israa Jaradat"
    ],
    "author_ids": [],
    "abstract": "We address the problem of cross-language adaptation for question-question\nsimilarity reranking in community question answering, with the objective to\nport a system trained on one input language to another input language given\nlabeled training data for the first language and only unlabeled data for the\nsecond language. In particular, we propose to use adversarial training of\nneural networks to learn high-level features that are discriminative for the\nmain learning task, and at the same time are invariant across the input\nlanguages. The evaluation results show sizable improvements for our\ncross-language adversarial neural network (CLANN) model over a strong\nnon-adversarial system.",
    "published_date": "2017-06-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06749v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.06368v3",
    "title": "FA*IR: A Fair Top-k Ranking Algorithm",
    "authors": [
      "Meike Zehlike",
      "Francesco Bonchi",
      "Carlos Castillo",
      "Sara Hajian",
      "Mohamed Megahed",
      "Ricardo Baeza-Yates"
    ],
    "author_ids": [],
    "abstract": "In this work, we define and solve the Fair Top-k Ranking problem, in which we\nwant to determine a subset of k candidates from a large pool of n >> k\ncandidates, maximizing utility (i.e., select the \"best\" candidates) subject to\ngroup fairness criteria. Our ranked group fairness definition extends group\nfairness using the standard notion of protected groups and is based on ensuring\nthat the proportion of protected candidates in every prefix of the top-k\nranking remains statistically above or indistinguishable from a given minimum.\n  Utility is operationalized in two ways: (i) every candidate included in the\ntop-$k$ should be more qualified than every candidate not included; and (ii)\nfor every pair of candidates in the top-k, the more qualified candidate should\nbe ranked above. An efficient algorithm is presented for producing the Fair\nTop-k Ranking, and tested experimentally on existing datasets as well as new\ndatasets released with this paper, showing that our approach yields small\ndistortions with respect to rankings that maximize utility without considering\nfairness criteria.\n  To the best of our knowledge, this is the first algorithm grounded in\nstatistical tests that can mitigate biases in the representation of an\nunder-represented group along a ranked list.",
    "published_date": "2017-06-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.IR",
      "H.3.3; J.1"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06368v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.06214v2",
    "title": "On the combinatorics of the 2-class classification problem",
    "authors": [
      "Ricardo C. Corrêa",
      "Diego Delle Donne",
      "Javier Marenco"
    ],
    "author_ids": [],
    "abstract": "A set of points $X = X_B \\cup X_R \\subseteq \\mathbb{R}^d$ is linearly\nseparable if the convex hulls of $X_B$ and $X_R$ are disjoint, hence there\nexists a hyperplane separating $X_B$ from $X_R$. Such a hyperplane provides a\nmethod for classifying new points, according to which side of the hyperplane\nthe new points lie. When such a linear separation is not possible, it may still\nbe possible to partition $X_B$ and $X_R$ into prespecified numbers of groups,\nin such a way that every group from $X_B$ is linearly separable from every\ngroup from $X_R$. We may also discard some points as outliers, and seek to\nminimize the number of outliers necessary to find such a partition. Based on\nthese ideas, Bertsimas and Shioda proposed the classification and regression by\ninteger optimization (CRIO) method in 2007. In this work we explore the integer\nprogramming aspects of the classification part of CRIO, in particular\ntheoretical properties of the associated formulation. We are able to find\nfacet-inducing inequalities coming from the stable set polytope, hence showing\nthat this classification problem has exploitable combinatorial properties.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06214v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.06087v1",
    "title": "Aztec: A Platform to Render Biomedical Software Findable, Accessible, Interoperable, and Reusable",
    "authors": [
      "Wei Wang",
      "Brian Bleakley",
      "Chelsea Ju",
      "Vincent Kyi",
      "Patrick Tan",
      "Howard Choi",
      "Xinxin Huang",
      "Yichao Zhou",
      "Justin Wood",
      "Ding Wang",
      "Alex Bui",
      "Peipei Ping"
    ],
    "author_ids": [],
    "abstract": "Precision medicine and health requires the characterization and phenotyping\nof biological systems and patient datasets using a variety of data formats.\nThis scenario mandates the centralization of various tools and resources in a\nunified platform to render them Findable, Accessible, Interoperable, and\nReusable (FAIR Principles). Leveraging these principles, Aztec provides the\nscientific community with a new platform that promotes a long-term, sustainable\necosystem of biomedical research software. Aztec is available at\nhttps://aztec.bio and its source code is hosted at\nhttps://github.com/BD2K-Aztec.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL",
      "H.2.8; H.3.1; H.3.3; H.3.6; H.3.7; I.2.6; I.2.7"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06087v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.06077v1",
    "title": "Explosive Percolation on Directed Networks Due to Monotonic Flow of Activity",
    "authors": [
      "Alex Waagen",
      "Raissa M. D'Souza",
      "Tsai-Ching Lu"
    ],
    "author_ids": [],
    "abstract": "An important class of real-world networks have directed edges, and in\naddition, some rank ordering on the nodes, for instance the \"popularity\" of\nusers in online social networks. Yet, nearly all research related to explosive\npercolation has been restricted to undirected networks. Furthermore,\ninformation on such rank ordered networks typically flows from higher ranked to\nlower ranked individuals, such as follower relations, replies and retweets on\nTwitter.\n  Here we introduce a simple percolation process on an ordered, directed\nnetwork where edges are added monotonically with respect to the rank ordering.\nWe show with a numerical approach that the emergence of a dominant strongly\nconnected component appears to be discontinuous. Large scale connectivity\noccurs at very high density compared with most percolation processes, and this\nholds not just for the strongly connected component structure but for the\nweakly connected component structure as well. We present analysis with\nbranching processes which explains this unusual behavior and gives basic\nintuition for the underlying mechanisms. We also show that before the emergence\nof a dominant strongly connected component, multiple giant strongly connected\ncomponents may exist simultaneously. By adding a competitive percolation rule\nwith a small bias to link uses of similar rank, we show this leads to formation\nof two distinct components, one of high ranked users, and one of low ranked\nusers, with little flow between the two components.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06077v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.09249v3",
    "title": "Logics and practices of transparency and opacity in real-world applications of public sector machine learning",
    "authors": [
      "Michael Veale"
    ],
    "author_ids": [],
    "abstract": "Machine learning systems are increasingly used to support public sector\ndecision-making across a variety of sectors. Given concerns around\naccountability in these domains, and amidst accusations of intentional or\nunintentional bias, there have been increased calls for transparency of these\ntechnologies. Few, however, have considered how logics and practices concerning\ntransparency have been understood by those involved in the machine learning\nsystems already being piloted and deployed in public bodies today. This short\npaper distils insights about transparency on the ground from interviews with 27\nsuch actors, largely public servants and relevant contractors, across 5 OECD\ncountries. Considering transparency and opacity in relation to trust and\nbuy-in, better decision-making, and the avoidance of gaming, it seeks to\nprovide useful insights for those hoping to develop socio-technical approaches\nto transparency that might be useful to practitioners on-the-ground.\n  An extended, archival version of this paper is available as Veale M., Van\nKleek M., & Binns R. (2018). `Fairness and accountability design needs for\nalgorithmic support in high-stakes public sector decision-making' Proceedings\nof the 2018 CHI Conference on Human Factors in Computing Systems (CHI'18),\nhttp://doi.org/10.1145/3173574.3174014.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.LG",
      "H.1.2; I.2.6; H.4.2; I.2.1; J.1; J.4; K.4.1; K.4.3; K.5.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.09249v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.06027v1",
    "title": "Zonotope-based Set-membership Parameter Identification of Linear Systems with Additive and Multiplicative Uncertainties and Its Application to Engine Condition Monitoring",
    "authors": [
      "Hao Wang",
      "Ilya Kolmanovsky",
      "Jing Sun"
    ],
    "author_ids": [],
    "abstract": "In this paper, we develop two zonotope-based set-membership estimation\nalgorithms for identification of time-varying parameters in linear models,\nwhere both additive and multiplicative uncertainties are treated explicitly.\nThe two recursive algorithms can be differentiated by their ways of processing\nthe data and required computations. The first algorithm, which is referred to\nas Cone And Zonotope Intersection (CAZI), requires solving linear programming\nproblems at each iteration. The second algorithm, referred to as the Polyhedron\nAnd Zonotope Intersection (PAZI), involves linear programming as well as an\noptimization subject to linear matrix inequalities (LMIs). Both algorithms are\ncapable of providing tight overbounds of the feasible solution set (FSS) in our\nnumerical case studies. Furthermore, PAZI provides an additional opportunity of\nfurther analyzing the relation between the estimation results at different\niterations. An application to health monitoring of marine engines is considered\nto demonstrate the utility and effectiveness of the algorithms.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.06027v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.05966v1",
    "title": "Deep Counterfactual Networks with Propensity-Dropout",
    "authors": [
      "Ahmed M. Alaa",
      "Michael Weisz",
      "Mihaela van der Schaar"
    ],
    "author_ids": [],
    "abstract": "We propose a novel approach for inferring the individualized causal effects\nof a treatment (intervention) from observational data. Our approach\nconceptualizes causal inference as a multitask learning problem; we model a\nsubject's potential outcomes using a deep multitask network with a set of\nshared layers among the factual and counterfactual outcomes, and a set of\noutcome-specific layers. The impact of selection bias in the observational data\nis alleviated via a propensity-dropout regularization scheme, in which the\nnetwork is thinned for every training example via a dropout probability that\ndepends on the associated propensity score. The network is trained in\nalternating phases, where in each phase we use the training examples of one of\nthe two potential outcomes (treated and control populations) to update the\nweights of the shared layers and the respective outcome-specific layers.\nExperiments conducted on data based on a real-world observational study show\nthat our algorithm outperforms the state-of-the-art.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.05966v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.05801v1",
    "title": "An a Priori Exponential Tail Bound for k-Folds Cross-Validation",
    "authors": [
      "Karim Abou-Moustafa",
      "Csaba Szepesvari"
    ],
    "author_ids": [],
    "abstract": "We consider a priori generalization bounds developed in terms of\ncross-validation estimates and the stability of learners. In particular, we\nfirst derive an exponential Efron-Stein type tail inequality for the\nconcentration of a general function of n independent random variables. Next,\nunder some reasonable notion of stability, we use this exponential tail bound\nto analyze the concentration of the k-fold cross-validation (KFCV) estimate\naround the true risk of a hypothesis generated by a general learning rule.\nWhile the accumulated literature has often attributed this concentration to the\nbias and variance of the estimator, our bound attributes this concentration to\nthe stability of the learning rule and the number of folds k. This insight\nraises valid concerns related to the practical use of KFCV and suggests\nresearch directions to obtain reliable empirical estimates of the actual risk.",
    "published_date": "2017-06-19T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.05801v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.05314v1",
    "title": "NOMA in Distributed Antenna System for Max-Min Fairness and Max-Sum-Rate",
    "authors": [
      "Dong-Jun Han",
      "Minseok Choi",
      "Jaekyun Moon"
    ],
    "author_ids": [],
    "abstract": "Distributed antenna system (DAS) has been deployed for over a decade. DAS has\nadvantages in capacity especially for the cell edge users, in both single-cell\nand multi-cell environments. In this paper, non-orthogonal multiple access\n(NOMA) is suggested in single-cell DAS to maximize user fairness and sumrate.\nTwo transmission strategies are considered: NOMA with single selection\ntransmission and NOMA with blanket transmission. In a two-user scenario, the\ncenter base station (BS) uses NOMA to serve both users and the remote radio\nunits (RRUs) serve only the weak user based on the transmission scheme. The\nsignals sent from the RRUs are not considered as interference at both user\nsides. At one side, the signals from the RRUs are used to detect the required\ndata and at the other side, the signals are used to perform successive\ninterference cancellation (SIC). The max-min performance is studied when\ninstantaneous channel gain information (CGI) or channel distribution\ninformation (CDI) is known at the transmitter. A closed-form expression of the\nupper bound is derived for the data rate of each user with only CDI. In\naddition, the sum-rate is studied with a minimum rate constraint when\ninstantaneous CGI known at the transmitter. The results show that NOMA with\nblanket transmission gives the best performance compared to other schemes;\nconventional-NOMA, conventional single selection scheme and joint-transmission\n(JT) NOMA. It is also shown that with less transmit power, NOMA with single\nselection transmission gives better performance than conventional-NOMA.",
    "published_date": "2017-06-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.05314v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.05029v2",
    "title": "Distance weighted discrimination of face images for gender classification",
    "authors": [
      "Mónica Benito",
      "Eduardo García-Portugués",
      "J. S. Marron",
      "Daniel Peña"
    ],
    "author_ids": [],
    "abstract": "We illustrate the advantages of distance weighted discrimination for\nclassification and feature extraction in a High Dimension Low Sample Size\n(HDLSS) situation. The HDLSS context is a gender classification problem of face\nimages in which the dimension of the data is several orders of magnitude larger\nthan the sample size. We compare distance weighted discrimination with Fisher's\nlinear discriminant, support vector machines, and principal component analysis\nby exploring their classification interpretation through insightful\nvisuanimations and by examining the classifiers' discriminant errors. This\nanalysis enables us to make new contributions to the understanding of the\ndrivers of human discrimination between males and females.",
    "published_date": "2017-06-15T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.CV",
      "stat.ME",
      "62H30, 62H35"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.05029v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.04692v1",
    "title": "Bias and high-dimensional adjustment in observational studies of peer effects",
    "authors": [
      "Dean Eckles",
      "Eytan Bakshy"
    ],
    "author_ids": [],
    "abstract": "Peer effects, in which the behavior of an individual is affected by the\nbehavior of their peers, are posited by multiple theories in the social\nsciences. Other processes can also produce behaviors that are correlated in\nnetworks and groups, thereby generating debate about the credibility of\nobservational (i.e. nonexperimental) studies of peer effects. Randomized field\nexperiments that identify peer effects, however, are often expensive or\ninfeasible. Thus, many studies of peer effects use observational data, and\nprior evaluations of causal inference methods for adjusting observational data\nto estimate peer effects have lacked an experimental \"gold standard\" for\ncomparison. Here we show, in the context of information and media diffusion on\nFacebook, that high-dimensional adjustment of a nonexperimental control group\n(677 million observations) using propensity score models produces estimates of\npeer effects statistically indistinguishable from those from using a large\nrandomized experiment (220 million observations). Naive observational\nestimators overstate peer effects by 320% and commonly used variables (e.g.,\ndemographics) offer little bias reduction, but adjusting for a measure of prior\nbehaviors closely related to the focal behavior reduces bias by 91%.\nHigh-dimensional models adjusting for over 3,700 past behaviors provide\nadditional bias reduction, such that the full model reduces bias by over 97%.\nThis experimental evaluation demonstrates that detailed records of individuals'\npast behavior can improve studies of social influence, information diffusion,\nand imitation; these results are encouraging for the credibility of some\nstudies but also cautionary for studies of rare or new behaviors. More\ngenerally, these results show how large, high-dimensional data sets and\nstatistical learning techniques can be used to improve causal inference in the\nbehavioral sciences.",
    "published_date": "2017-06-14T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ME",
      "cs.SI",
      "stat.AP",
      "stat.ML",
      "62P25, 62P30, 91D30",
      "G.3; J.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.04692v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.04634v2",
    "title": "A distributed algorithm for average aggregative games with coupling constraints",
    "authors": [
      "Francesca Parise",
      "Basilio Gentile",
      "John Lygeros"
    ],
    "author_ids": [],
    "abstract": "We consider the framework of average aggregative games, where the cost\nfunction of each agent depends on his own strategy and on the average\npopulation strategy. We focus on the case in which the agents are coupled not\nonly via their cost functions, but also via constraints coupling their\nstrategies. We propose a distributed algorithm that achieves an almost Nash\nequilibrium by requiring only local communications of the agents, as specified\nby a sparse communication network. The proof of convergence of the algorithm\nrelies on the auxiliary class of network aggregative games and exploits a novel\nresult of parametric convergence of variational inequalities, which is\napplicable beyond the context of games. We apply our theoretical findings to a\nmulti-market Cournot game with transportation costs and maximum market\ncapacity.",
    "published_date": "2017-06-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "cs.GT",
      "cs.MA",
      "cs.SI",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.04634v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.04589v1",
    "title": "Learning without Prejudice: Avoiding Bias in Webly-Supervised Action Recognition",
    "authors": [
      "Christian Rupprecht",
      "Ansh Kapil",
      "Nan Liu",
      "Lamberto Ballan",
      "Federico Tombari"
    ],
    "author_ids": [],
    "abstract": "Webly-supervised learning has recently emerged as an alternative paradigm to\ntraditional supervised learning based on large-scale datasets with manual\nannotations. The key idea is that models such as CNNs can be learned from the\nnoisy visual data available on the web. In this work we aim to exploit web data\nfor video understanding tasks such as action recognition and detection. One of\nthe main problems in webly-supervised learning is cleaning the noisy labeled\ndata from the web. The state-of-the-art paradigm relies on training a first\nclassifier on noisy data that is then used to clean the remaining dataset. Our\nkey insight is that this procedure biases the second classifier towards samples\nthat the first one understands. Here we train two independent CNNs, a RGB\nnetwork on web images and video frames and a second network using temporal\ninformation from optical flow. We show that training the networks independently\nis vastly superior to selecting the frames for the flow classifier by using our\nRGB network. Moreover, we show benefits in enriching the training set with\ndifferent data sources from heterogeneous public web databases. We demonstrate\nthat our framework outperforms all other webly-supervised methods on two public\nbenchmarks, UCF-101 and Thumos'14.",
    "published_date": "2017-06-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.04589v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.04499v3",
    "title": "SEARNN: Training RNNs with Global-Local Losses",
    "authors": [
      "Rémi Leblond",
      "Jean-Baptiste Alayrac",
      "Anton Osokin",
      "Simon Lacoste-Julien"
    ],
    "author_ids": [],
    "abstract": "We propose SEARNN, a novel training algorithm for recurrent neural networks\n(RNNs) inspired by the \"learning to search\" (L2S) approach to structured\nprediction. RNNs have been widely successful in structured prediction\napplications such as machine translation or parsing, and are commonly trained\nusing maximum likelihood estimation (MLE). Unfortunately, this training loss is\nnot always an appropriate surrogate for the test error: by only maximizing the\nground truth probability, it fails to exploit the wealth of information offered\nby structured losses. Further, it introduces discrepancies between training and\npredicting (such as exposure bias) that may hurt test performance. Instead,\nSEARNN leverages test-alike search space exploration to introduce global-local\nlosses that are closer to the test error. We first demonstrate improved\nperformance over MLE on two different tasks: OCR and spelling correction. Then,\nwe propose a subsampling strategy to enable SEARNN to scale to large vocabulary\nsizes. This allows us to validate the benefits of our approach on a machine\ntranslation task.",
    "published_date": "2017-06-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.04499v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.04217v1",
    "title": "Opinion formation in a locally interacting community with recommender",
    "authors": [
      "Simone Santini"
    ],
    "author_ids": [],
    "abstract": "We present a user of model interaction based on the physics of kinetic\nexchange, and extend it to individuals placed in a grid with local interaction.\nWe show with numerical analysis and partial analytical results that the\ncritical symmetry breaking transitions and percolation effects typical of the\nfull interaction model do not take place if the range of interaction is\nlimited, allowing for the co-existence of majorty and minority opinions in the\nsame community.\n  We then introduce a peer recommender system in the model, showing that, even\nwith very local iteraction and a small probability of appeal to the\nrecommender, its presence is sufficient to make both symmetry breaking and\npercolation reappear. This seems to indicate that one effect of a\nrecommendation system is to uniform the opinions of a community, reducing\nminority opinions or making them disappear. Although the recommender system\ndoes uniform the community opinion, it doesn't constrain it, in the sense that\nall opinions have the same probability of becoming the dominating one. We do a\npartial study, however, that suggests that a \"mischievous\" recommender might be\nable to bias a community so that one opinion will emerge over the opposite with\noverwhelming probability.",
    "published_date": "2017-06-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "74A25"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.04217v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.03848v1",
    "title": "\"(Weitergeleitet von Journalistin)\": The Gendered Presentation of Professions on Wikipedia",
    "authors": [
      "Olga Zagovora",
      "Fabian Flöck",
      "Claudia Wagner"
    ],
    "author_ids": [],
    "abstract": "Previous research has shown the existence of gender biases in the depiction\nof professions and occupations in search engine results. Such an unbalanced\npresentation might just as likely occur on Wikipedia, one of the most popular\nknowledge resources on the Web, since the encyclopedia has already been found\nto exhibit such tendencies in past studies. Under this premise, our work\nassesses gender bias with respect to the content of German Wikipedia articles\nabout professions and occupations along three dimensions: used male vs. female\ntitles (and redirects), included images of persons, and names of professionals\nmentioned in the articles. We further use German labor market data to assess\nthe potential misrepresentation of a gender for each specific profession. Our\nfindings in fact provide evidence for systematic over-representation of men on\nall three dimensions. For instance, for professional fields dominated by\nfemales, the respective articles on average still feature almost two times more\nimages of men; and in the mean, 83% of the mentioned names of professionals\nwere male and only 17% female.",
    "published_date": "2017-06-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03848v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.03815v2",
    "title": "Encoding of phonology in a recurrent neural model of grounded speech",
    "authors": [
      "Afra Alishahi",
      "Marie Barking",
      "Grzegorz Chrupała"
    ],
    "author_ids": [],
    "abstract": "We study the representation and encoding of phonemes in a recurrent neural\nnetwork model of grounded speech. We use a model which processes images and\ntheir spoken descriptions, and projects the visual and auditory representations\ninto the same semantic space. We perform a number of analyses on how\ninformation about individual phonemes is encoded in the MFCC features extracted\nfrom the speech signal, and the activations of the layers of the model. Via\nexperiments with phoneme decoding and phoneme discrimination we show that\nphoneme representations are most salient in the lower layers of the model,\nwhere low-level signals are processed at a fine-grained level, although a large\namount of phonological information is retain at the top recurrent layer. We\nfurther find out that the attention mechanism following the top recurrent layer\nsignificantly attenuates encoding of phonology and makes the utterance\nembeddings much more invariant to synonymy. Moreover, a hierarchical clustering\nof phoneme representations learned by the network shows an organizational\nstructure of phonemes similar to those proposed in linguistics.",
    "published_date": "2017-06-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03815v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.03580v1",
    "title": "Fair Airtime Allocation for Content Dissemination in WiFi-Direct-Based Mobile Social Networks",
    "authors": [
      "Zhifei Mao",
      "Yuming Jiang"
    ],
    "author_ids": [],
    "abstract": "The vast penetration of smart mobile devices provides a unique opportunity to\nmake mobile social networking pervasive by leveraging the feature of\nshort-range wireless communication technologies (e.g. WiFi Direct). In this\npaper, we study local content dissemination in WiFi-Direct-based mobile social\nnetworks (MSNs). We propose a simple GO-coordinated dissemination strategy, as\nWiFi Direct does not originally support content dissemination. Due to mobility\nand the short transmission range, the duration of nodes in contact tends to be\nlimited and consequently they compete for the limited airtime to disseminate\ntheir own data. Therefore, fair allocation of the limited airtime among the\nnodes is required. We focus on fairness in content dissemination rate, which is\na key application-layer metric, rather than fairness in throughput or airtime\nand formulate the allocation problem as a generalized Nash bargaining game\nwherein the nodes bargain for a share of the limited airtime. The game is\nproved to have a unique optimal solution, and an algorithm with low complexity\nis designed to find the optimal solution. Furthermore, we propose a detailed\nscheduling approach to implement the optimal solution. We also present\nnumerical results to evaluate the Nash bargaining based allocation and\nscheduling.",
    "published_date": "2017-06-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03580v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.03513v1",
    "title": "A Minimal Set of Shannon-type Inequalities for Functional Dependence Structures",
    "authors": [
      "Satyajit Thakor",
      "Terence Chan",
      "Alex Grant"
    ],
    "author_ids": [],
    "abstract": "The minimal set of Shannon-type inequalities (referred to as elemental\ninequalities), plays a central role in determining whether a given inequality\nis Shannon-type. Often, there arises a situation where one needs to check\nwhether a given inequality is a constrained Shannon-type inequality. Another\nimportant application of elemental inequalities is to formulate and compute the\nShannon outer bound for multi-source multi-sink network coding capacity. Under\nthis formulation, it is the region of feasible source rates subject to the\nelemental inequalities and network coding constraints that is of interest.\nHence it is of fundamental interest to identify the redundancies induced\namongst elemental inequalities when given a set of functional dependence\nconstraints. In this paper, we characterize a minimal set of Shannon-type\ninequalities when functional dependence constraints are present.",
    "published_date": "2017-06-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03513v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.03160v2",
    "title": "Deep Adaptive Feature Embedding with Local Sample Distributions for Person Re-identification",
    "authors": [
      "Lin Wu",
      "Yang Wang",
      "Junbin Gao",
      "Xue Li"
    ],
    "author_ids": [],
    "abstract": "Person re-identification (re-id) aims to match pedestrians observed by\ndisjoint camera views. It attracts increasing attention in computer vision due\nto its importance to surveillance system. To combat the major challenge of\ncross-view visual variations, deep embedding approaches are proposed by\nlearning a compact feature space from images such that the Euclidean distances\ncorrespond to their cross-view similarity metric. However, the global Euclidean\ndistance cannot faithfully characterize the ideal similarity in a complex\nvisual feature space because features of pedestrian images exhibit unknown\ndistributions due to large variations in poses, illumination and occlusion.\nMoreover, intra-personal training samples within a local range are robust to\nguide deep embedding against uncontrolled variations, which however, cannot be\ncaptured by a global Euclidean distance. In this paper, we study the problem of\nperson re-id by proposing a novel sampling to mine suitable \\textit{positives}\n(i.e. intra-class) within a local range to improve the deep embedding in the\ncontext of large intra-class variations. Our method is capable of learning a\ndeep similarity metric adaptive to local sample structure by minimizing each\nsample's local distances while propagating through the relationship between\nsamples to attain the whole intra-class minimization. To this end, a novel\nobjective function is proposed to jointly optimize similarity metric learning,\nlocal positive mining and robust deep embedding. This yields local\ndiscriminations by selecting local-ranged positive samples, and the learned\nfeatures are robust to dramatic intra-class variations. Experiments on\nbenchmarks show state-of-the-art results achieved by our method.",
    "published_date": "2017-06-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03160v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.03102v1",
    "title": "Big Data, Data Science, and Civil Rights",
    "authors": [
      "Solon Barocas",
      "Elizabeth Bradley",
      "Vasant Honavar",
      "Foster Provost"
    ],
    "author_ids": [],
    "abstract": "Advances in data analytics bring with them civil rights implications.\nData-driven and algorithmic decision making increasingly determine how\nbusinesses target advertisements to consumers, how police departments monitor\nindividuals or groups, how banks decide who gets a loan and who does not, how\nemployers hire, how colleges and universities make admissions and financial aid\ndecisions, and much more. As data-driven decisions increasingly affect every\ncorner of our lives, there is an urgent need to ensure they do not become\ninstruments of discrimination, barriers to equality, threats to social justice,\nand sources of unfairness. In this paper, we argue for a concrete research\nagenda aimed at addressing these concerns, comprising five areas of emphasis:\n(i) Determining if models and modeling procedures exhibit objectionable bias;\n(ii) Building awareness of fairness into machine learning methods; (iii)\nImproving the transparency and control of data- and model-driven decision\nmaking; (iv) Looking beyond the algorithm(s) for sources of bias and\nunfairness-in the myriad human decisions made during the problem formulation\nand modeling process; and (v) Supporting the cross-disciplinary scholarship\nnecessary to do all of that well.",
    "published_date": "2017-06-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03102v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.02744v2",
    "title": "Avoiding Discrimination through Causal Reasoning",
    "authors": [
      "Niki Kilbertus",
      "Mateo Rojas-Carulla",
      "Giambattista Parascandolo",
      "Moritz Hardt",
      "Dominik Janzing",
      "Bernhard Schölkopf"
    ],
    "author_ids": [],
    "abstract": "Recent work on fairness in machine learning has focused on various\nstatistical discrimination criteria and how they trade off. Most of these\ncriteria are observational: They depend only on the joint distribution of\npredictor, protected attribute, features, and outcome. While convenient to work\nwith, observational criteria have severe inherent limitations that prevent them\nfrom resolving matters of fairness conclusively.\n  Going beyond observational criteria, we frame the problem of discrimination\nbased on protected attributes in the language of causal reasoning. This\nviewpoint shifts attention from \"What is the right fairness criterion?\" to\n\"What do we want to assume about the causal data generating process?\" Through\nthe lens of causality, we make several contributions. First, we crisply\narticulate why and when observational criteria fail, thus formalizing what was\nbefore a matter of opinion. Second, our approach exposes previously ignored\nsubtleties and why they are fundamental to the problem. Finally, we put forward\nnatural causal non-discrimination criteria and develop algorithms that satisfy\nthem.",
    "published_date": "2017-06-08T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.02744v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.02513v1",
    "title": "Responsible Autonomy",
    "authors": [
      "Virginia Dignum"
    ],
    "author_ids": [],
    "abstract": "As intelligent systems are increasingly making decisions that directly affect\nsociety, perhaps the most important upcoming research direction in AI is to\nrethink the ethical implications of their actions. Means are needed to\nintegrate moral, societal and legal values with technological developments in\nAI, both during the design process as well as part of the deliberation\nalgorithms employed by these systems. In this paper, we describe leading ethics\ntheories and propose alternative ways to ensure ethical behavior by artificial\nsystems. Given that ethics are dependent on the socio-cultural context and are\noften only implicit in deliberation processes, methodologies are needed to\nelicit the values held by designers and stakeholders, and to make these\nexplicit leading to better understanding and trust on artificial autonomous\nsystems.",
    "published_date": "2017-06-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.02513v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.02409v1",
    "title": "A Convex Framework for Fair Regression",
    "authors": [
      "Richard Berk",
      "Hoda Heidari",
      "Shahin Jabbari",
      "Matthew Joseph",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Seth Neel",
      "Aaron Roth"
    ],
    "author_ids": [],
    "abstract": "We introduce a flexible family of fairness regularizers for (linear and\nlogistic) regression problems. These regularizers all enjoy convexity,\npermitting fast optimization, and they span the rang from notions of group\nfairness to strong individual fairness. By varying the weight on the fairness\nregularizer, we can compute the efficient frontier of the accuracy-fairness\ntrade-off on any given dataset, and we measure the severity of this trade-off\nvia a numerical quantity we call the Price of Fairness (PoF). The centerpiece\nof our results is an extensive comparative study of the PoF across six\ndifferent datasets in which fairness is a primary consideration.",
    "published_date": "2017-06-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.02409v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.02295v1",
    "title": "Generative-Discriminative Variational Model for Visual Recognition",
    "authors": [
      "Chih-Kuan Yeh",
      "Yao-Hung Hubert Tsai",
      "Yu-Chiang Frank Wang"
    ],
    "author_ids": [],
    "abstract": "The paradigm shift from shallow classifiers with hand-crafted features to\nend-to-end trainable deep learning models has shown significant improvements on\nsupervised learning tasks. Despite the promising power of deep neural networks\n(DNN), how to alleviate overfitting during training has been a research topic\nof interest. In this paper, we present a Generative-Discriminative Variational\nModel (GDVM) for visual classification, in which we introduce a latent variable\ninferred from inputs for exhibiting generative abilities towards prediction. In\nother words, our GDVM casts the supervised learning task as a generative\nlearning process, with data discrimination to be jointly exploited for improved\nclassification. In our experiments, we consider the tasks of multi-class\nclassification, multi-label classification, and zero-shot learning. We show\nthat our GDVM performs favorably against the baselines or recent generative DNN\nmodels.",
    "published_date": "2017-06-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.02295v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.01531v1",
    "title": "Progressive Boosting for Class Imbalance",
    "authors": [
      "Roghayeh Soleymani",
      "Eric Granger",
      "Giorgio Fumera"
    ],
    "author_ids": [],
    "abstract": "Pattern recognition applications often suffer from skewed data distributions\nbetween classes, which may vary during operations w.r.t. the design data.\nTwo-class classification systems designed using skewed data tend to recognize\nthe majority class better than the minority class of interest. Several\ndata-level techniques have been proposed to alleviate this issue by up-sampling\nminority samples or under-sampling majority samples. However, some informative\nsamples may be neglected by random under-sampling and adding synthetic positive\nsamples through up-sampling adds to training complexity. In this paper, a new\nensemble learning algorithm called Progressive Boosting (PBoost) is proposed\nthat progressively inserts uncorrelated groups of samples into a Boosting\nprocedure to avoid loss of information while generating a diverse pool of\nclassifiers. Base classifiers in this ensemble are generated from one iteration\nto the next, using subsets from a validation set that grows gradually in size\nand imbalance. Consequently, PBoost is more robust to unknown and variable\nlevels of skew in operational data, and has lower computation complexity than\nBoosting ensembles in literature. In PBoost, a new loss factor is proposed to\navoid bias of performance towards the negative class. Using this loss factor,\nthe weight update of samples and classifier contribution in final predictions\nare set based on the ability to recognize both classes. Using the proposed loss\nfactor instead of standard accuracy can avoid biasing performance in any\nBoosting ensemble. The proposed approach was validated and compared using\nsynthetic data, videos from the FIA dataset that emulates face\nre-identification applications, and KEEL collection of datasets. Results show\nthat PBoost can outperform state of the art techniques in terms of both\naccuracy and complexity over different levels of imbalance and overlap between\nclasses.",
    "published_date": "2017-06-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.01531v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.01237v1",
    "title": "Learning Structured Semantic Embeddings for Visual Recognition",
    "authors": [
      "Dong Li",
      "Hsin-Ying Lee",
      "Jia-Bin Huang",
      "Shengjin Wang",
      "Ming-Hsuan Yang"
    ],
    "author_ids": [],
    "abstract": "Numerous embedding models have been recently explored to incorporate semantic\nknowledge into visual recognition. Existing methods typically focus on\nminimizing the distance between the corresponding images and texts in the\nembedding space but do not explicitly optimize the underlying structure. Our\nkey observation is that modeling the pairwise image-image relationship improves\nthe discrimination ability of the embedding model. In this paper, we propose\nthe structured discriminative and difference constraints to learn\nvisual-semantic embeddings. First, we exploit the discriminative constraints to\ncapture the intra- and inter-class relationships of image embeddings. The\ndiscriminative constraints encourage separability for image instances of\ndifferent classes. Second, we align the difference vector between a pair of\nimage embeddings with that of the corresponding word embeddings. The difference\nconstraints help regularize image embeddings to preserve the semantic\nrelationships among word embeddings. Extensive evaluations demonstrate the\neffectiveness of the proposed structured embeddings for single-label\nclassification, multi-label classification, and zero-shot recognition.",
    "published_date": "2017-06-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.01237v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.01062v1",
    "title": "Planning with Multiple Biases",
    "authors": [
      "Jon Kleinberg",
      "Sigal Oren",
      "Manish Raghavan"
    ],
    "author_ids": [],
    "abstract": "Recent work has considered theoretical models for the behavior of agents with\nspecific behavioral biases: rather than making decisions that optimize a given\npayoff function, the agent behaves inefficiently because its decisions suffer\nfrom an underlying bias. These approaches have generally considered an agent\nwho experiences a single behavioral bias, studying the effect of this bias on\nthe outcome.\n  In general, however, decision-making can and will be affected by multiple\nbiases operating at the same time. How do multiple biases interact to produce\nthe overall outcome? Here we consider decisions in the presence of a pair of\nbiases exhibiting an intuitively natural interaction: present bias -- the\ntendency to value costs incurred in the present too highly -- and sunk-cost\nbias -- the tendency to incorporate costs experienced in the past into one's\nplans for the future.\n  We propose a theoretical model for planning with this pair of biases, and we\nshow how certain natural behavioral phenomena can arise in our model only when\nagents exhibit both biases. As part of our model we differentiate between\nagents that are aware of their biases (sophisticated) and agents that are\nunaware of them (naive). Interestingly, we show that the interaction between\nthe two biases is quite complex: in some cases, they mitigate each other's\neffects while in other cases they might amplify each other. We obtain a number\nof further results as well, including the fact that the planning problem in our\nmodel for an agent experiencing and aware of both biases is computationally\nhard in general, though tractable under more relaxed assumptions.",
    "published_date": "2017-06-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.MA",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.01062v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.00884v1",
    "title": "Task-specific Word Identification from Short Texts Using a Convolutional Neural Network",
    "authors": [
      "Shuhan Yuan",
      "Xintao Wu",
      "Yang Xiang"
    ],
    "author_ids": [],
    "abstract": "Task-specific word identification aims to choose the task-related words that\nbest describe a short text. Existing approaches require well-defined seed words\nor lexical dictionaries (e.g., WordNet), which are often unavailable for many\napplications such as social discrimination detection and fake review detection.\nHowever, we often have a set of labeled short texts where each short text has a\ntask-related class label, e.g., discriminatory or non-discriminatory, specified\nby users or learned by classification algorithms. In this paper, we focus on\nidentifying task-specific words and phrases from short texts by exploiting\ntheir class labels rather than using seed words or lexical dictionaries. We\nconsider the task-specific word and phrase identification as feature learning.\nWe train a convolutional neural network over a set of labeled texts and use\nscore vectors to localize the task-specific words and phrases. Experimental\nresults on sentiment word identification show that our approach significantly\noutperforms existing methods. We further conduct two case studies to show the\neffectiveness of our approach. One case study on a crawled tweets dataset\ndemonstrates that our approach can successfully capture the\ndiscrimination-related words/phrases. The other case study on fake review\ndetection shows that our approach can identify the fake-review words/phrases.",
    "published_date": "2017-06-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.00884v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.00440v2",
    "title": "The conditional Entropy Power Inequality for bosonic quantum systems",
    "authors": [
      "Giacomo De Palma",
      "Dario Trevisan"
    ],
    "author_ids": [],
    "abstract": "We prove the conditional Entropy Power Inequality for Gaussian quantum\nsystems. This fundamental inequality determines the minimum quantum conditional\nvon Neumann entropy of the output of the beam-splitter or of the squeezing\namong all the input states where the two inputs are conditionally independent\ngiven the memory and have given quantum conditional entropies. We also prove\nthat, for any couple of values of the quantum conditional entropies of the two\ninputs, the minimum of the quantum conditional entropy of the output given by\nthe conditional Entropy Power Inequality is asymptotically achieved by a\nsuitable sequence of quantum Gaussian input states. Our proof of the\nconditional Entropy Power Inequality is based on a new Stam inequality for the\nquantum conditional Fisher information and on the determination of the\nuniversal asymptotic behaviour of the quantum conditional entropy under the\nheat semigroup evolution. The beam-splitter and the squeezing are the central\nelements of quantum optics, and can model the attenuation, the amplification\nand the noise of electromagnetic signals. This conditional Entropy Power\nInequality will have a strong impact in quantum information and quantum\ncryptography. Among its many possible applications there is the proof of a new\nuncertainty relation for the conditional Wehrl entropy.",
    "published_date": "2017-06-01T00:00:00",
    "year": 2017,
    "categories": [
      "math-ph",
      "cs.IT",
      "math.IT",
      "math.MP",
      "math.PR",
      "quant-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.00440v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.00119v3",
    "title": "Bayesian fairness",
    "authors": [
      "Christos Dimitrakakis",
      "Yang Liu",
      "David Parkes",
      "Goran Radanovic"
    ],
    "author_ids": [],
    "abstract": "We consider the problem of how decision making can be fair when the\nunderlying probabilistic model of the world is not known with certainty. We\nargue that recent notions of fairness in machine learning need to explicitly\nincorporate parameter uncertainty, hence we introduce the notion of {\\em\nBayesian fairness} as a suitable candidate for fair decision rules. Using\nbalance, a definition of fairness introduced by Kleinberg et al (2016), we show\nhow a Bayesian perspective can lead to well-performing, fair decision rules\neven under high uncertainty.",
    "published_date": "2017-05-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.00119v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.00107v1",
    "title": "Green Virtualization for Multiple Collaborative Cellular Operators",
    "authors": [
      "Muhammad Junaid Farooq",
      "Hakim Ghazzai",
      "Elias Yaacoub",
      "Abdullah Kadri",
      "Mohamed-Slim Alouini"
    ],
    "author_ids": [],
    "abstract": "This paper proposes and investigates a green virtualization framework for\ninfrastructure sharing among multiple cellular operators whose networks are\npowered by a combination of conventional and renewable sources of energy. Under\nthe proposed framework, the virtual network formed by unifying radio access\ninfrastructures of all operators is optimized for minimum energy consumption by\ndeactivating base stations (BSs) with low traffic loads. The users initially\nassociated to those BSs are off-loaded to neighboring active ones. A fairness\ncriterion for collaboration based on roaming prices is introduced to cover the\nadditional energy costs incurred by host operators. The framework also ensures\nthat any collaborating operator is not negatively affected by its participation\nin the proposed virtualization. A multi-objective linear programming problem is\nformulated to achieve energy and cost efficiency of the networks' operation by\nidentifying the set of inter-operator roaming prices. For the case when\ncollaboration among all operators is infeasible due to profitability, capacity,\nor power constraints, an iterative algorithm is proposed to determine the\ngroups of operators that can viably collaborate. Results show significant\nenergy savings using the proposed virtualization as compared to the standalone\ncase. Moreover, collaborative operators exploiting locally generated renewable\nenergy are rewarded more than traditional ones.",
    "published_date": "2017-05-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.00107v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.10968v1",
    "title": "Max-Min Fair Transmit Precoding for Multi-group Multicasting in Massive MIMO",
    "authors": [
      "Meysam Sadeghi",
      "Emil Björnson",
      "Erik G. Larsson",
      "Chau Yuen",
      "Thomas L. Marzetta"
    ],
    "author_ids": [],
    "abstract": "This paper considers the downlink precoding for physical layer multicasting\nin massive multiple-input-multiple-output (MIMO) systems. We study the max-min\nfairness (MMF) problem, where channel state information (CSI) at the\ntransmitter is used to design precoding vectors that maximize the minimum\nspectral efficiency (SE) of the system, given fixed power budgets for uplink\ntraining and downlink transmission. Our system model accounts for channel\nestimation, pilot contamination, arbitrary pathlosses, and multi-group\nmulticasting. We consider six scenarios with different transmission\ntechnologies (unicast and multicast), different pilot assignment strategies\n(dedicated or shared pilot assignments), and different precoding schemes\n(maximum ratio transmission and zero forcing), and derive achievable spectral\nefficiencies for all possible combinations. Then we solve the MMF problem for\neach of these scenarios and for any given pilot length we find the SE\nmaximizing uplink pilot and downlink data transmission policies, all in\nclosed-forms. We use these results to draw a general guideline for massive MIMO\nmulticasting design, where for a given number of base station antennas, number\nof users, and coherence interval length, we determine the multicasting scheme\nthat shall be used.",
    "published_date": "2017-05-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.10968v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.10706v1",
    "title": "Truthful Allocation Mechanisms Without Payments: Characterization and Implications on Fairness",
    "authors": [
      "Georgios Amanatidis",
      "Georgios Birmpas",
      "George Christodoulou",
      "Evangelos Markakis"
    ],
    "author_ids": [],
    "abstract": "We study the mechanism design problem of allocating a set of indivisible\nitems without monetary transfers. Despite the vast literature on this very\nstandard model, it still remains unclear how do truthful mechanisms look like.\nWe focus on the case of two players with additive valuation functions and our\npurpose is twofold. First, our main result provides a complete characterization\nof truthful mechanisms that allocate all the items to the players. Our\ncharacterization reveals an interesting structure underlying all truthful\nmechanisms, showing that they can be decomposed into two components: a\nselection part where players pick their best subset among prespecified choices\ndetermined by the mechanism, and an exchange part where players are offered the\nchance to exchange certain subsets if it is favorable to do so. In the\nremaining paper, we apply our main result and derive several consequences on\nthe design of mechanisms with fairness guarantees. We consider various notions\nof fairness, (indicatively, maximin share guarantees and envy-freeness up to\none item) and provide tight bounds for their approximability. Our work settles\nsome of the open problems in this agenda, and we conclude by discussing\npossible extensions to more players.",
    "published_date": "2017-05-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.10706v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.10503v1",
    "title": "Quantum Low Entropy based Associative Reasoning or QLEAR Learning",
    "authors": [
      "Marko V. Jankovic"
    ],
    "author_ids": [],
    "abstract": "In this paper, we propose the classification method based on a learning\nparadigm we are going to call Quantum Low Entropy based Associative Reasoning\nor QLEAR learning. The approach is based on the idea that classification can be\nunderstood as supervised clustering, where a quantum entropy in the context of\nthe quantum probabilistic model, will be used as a \"capturer\" (measure, or\nexternal index), of the \"natural structure\" of the data. By using quantum\nentropy we do not make any assumption about linear separability of the data\nthat are going to be classified. The basic idea is to find close neighbors to a\nquery sample and then use relative change in the quantum entropy as a measure\nof similarity of the newly arrived sample with the representatives of interest.\nIn other words, method is based on calculation of quantum entropy of the\nreferent system and its relative change with the addition of the newly arrived\nsample. Referent system consists of vectors that represent individual classes\nand that are the most similar, in Euclidean distance sense, to the vector that\nis analyzed. Here, we analyze the classification problem in the context of\nmeasuring similarities to prototype examples of categories. While nearest\nneighbor classifiers are natural in this setting, they suffer from the problem\nof high variance (in bias-variance decomposition) in the case of limited\nsampling. Alternatively, one could use machine learning techniques (like\nsupport vector machines) but they involve time-consuming optimization. Here we\npropose a hybrid of nearest neighbor and machine learning technique which deals\nnaturally with the multi-class setting, has reasonable computational complexity\nboth in training and at run time, and yields excellent results in practice.",
    "published_date": "2017-05-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.10503v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.09055v1",
    "title": "The cost of fairness in classification",
    "authors": [
      "Aditya Krishna Menon",
      "Robert C. Williamson"
    ],
    "author_ids": [],
    "abstract": "We study the problem of learning classifiers with a fairness constraint, with\nthree main contributions towards the goal of quantifying the problem's inherent\ntradeoffs. First, we relate two existing fairness measures to cost-sensitive\nrisks. Second, we show that for cost-sensitive classification and fairness\nmeasures, the optimal classifier is an instance-dependent thresholding of the\nclass-probability function. Third, we show how the tradeoff between accuracy\nand fairness is determined by the alignment between the class-probabilities for\nthe target and sensitive features. Underpinning our analysis is a general\nframework that casts the problem of learning with a fairness requirement as one\nof minimising the difference of two statistical risks.",
    "published_date": "2017-05-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.09055v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.08804v2",
    "title": "Beyond Parity: Fairness Objectives for Collaborative Filtering",
    "authors": [
      "Sirui Yao",
      "Bert Huang"
    ],
    "author_ids": [],
    "abstract": "We study fairness in collaborative-filtering recommender systems, which are\nsensitive to discrimination that exists in historical data. Biased data can\nlead collaborative-filtering methods to make unfair predictions for users from\nminority groups. We identify the insufficiency of existing fairness metrics and\npropose four new metrics that address different forms of unfairness. These\nfairness metrics can be optimized by adding fairness terms to the learning\nobjective. Experiments on synthetic and real data show that our new metrics can\nbetter measure fairness than the baseline, and that the fairness objectives\neffectively help reduce unfairness.",
    "published_date": "2017-05-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08804v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1706.05295v2",
    "title": "Nonbacktracking Bounds on the Influence in Independent Cascade Models",
    "authors": [
      "Emmanuel Abbe",
      "Sanjeev Kulkarni",
      "Eun Jee Lee"
    ],
    "author_ids": [],
    "abstract": "This paper develops upper and lower bounds on the influence measure in a\nnetwork, more precisely, the expected number of nodes that a seed set can\ninfluence in the independent cascade model. In particular, our bounds exploit\nnonbacktracking walks, Fortuin-Kasteleyn-Ginibre (FKG) type inequalities, and\nare computed by message passing implementation. Nonbacktracking walks have\nrecently allowed for headways in community detection, and this paper shows that\ntheir use can also impact the influence computation. Further, we provide a knob\nto control the trade-off between the efficiency and the accuracy of the bounds.\nFinally, the tightness of the bounds is illustrated with simulations on various\nnetwork models.",
    "published_date": "2017-05-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CC",
      "cs.IT",
      "math.IT",
      "math.PR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.05295v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.08432v2",
    "title": "Question-Answering with Grammatically-Interpretable Representations",
    "authors": [
      "Hamid Palangi",
      "Paul Smolensky",
      "Xiaodong He",
      "Li Deng"
    ],
    "author_ids": [],
    "abstract": "We introduce an architecture, the Tensor Product Recurrent Network (TPRN). In\nour application of TPRN, internal representations learned by end-to-end\noptimization in a deep neural network performing a textual question-answering\n(QA) task can be interpreted using basic concepts from linguistic theory. No\nperformance penalty need be paid for this increased interpretability: the\nproposed model performs comparably to a state-of-the-art system on the SQuAD QA\ntask. The internal representation which is interpreted is a Tensor Product\nRepresentation: for each input word, the model selects a symbol to encode the\nword, and a role in which to place the symbol, and binds the two together. The\nselection is via soft attention. The overall interpretation is built from\ninterpretations of the symbols, as recruited by the trained model, and\ninterpretations of the roles as used by the model. We find support for our\ninitial hypothesis that symbols can be interpreted as lexical-semantic word\nmeanings, while roles can be interpreted as approximations of grammatical roles\n(or categories) such as subject, wh-word, determiner, etc. Fine-grained\nanalysis reveals specific correspondences between the learned roles and parts\nof speech as assigned by a standard tagger (Toutanova et al. 2003), and finds\nseveral discrepancies in the model's favor. In this sense, the model learns\nsignificant aspects of grammar, after having been exposed solely to\nlinguistically unannotated text, questions, and answers: no prior linguistic\nknowledge is given to the model. What is given is the means to build\nrepresentations using symbols and roles, with an inductive bias favoring use of\nthese in an approximately discrete manner.",
    "published_date": "2017-05-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08432v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.08391v1",
    "title": "Exponential error rates of SDP for block models: Beyond Grothendieck's inequality",
    "authors": [
      "Yingjie Fei",
      "Yudong Chen"
    ],
    "author_ids": [],
    "abstract": "In this paper we consider the cluster estimation problem under the Stochastic\nBlock Model. We show that the semidefinite programming (SDP) formulation for\nthis problem achieves an error rate that decays exponentially in the\nsignal-to-noise ratio. The error bound implies weak recovery in the sparse\ngraph regime with bounded expected degrees, as well as exact recovery in the\ndense regime. An immediate corollary of our results yields error bounds under\nthe Censored Block Model. Moreover, these error bounds are robust, continuing\nto hold under heterogeneous edge probabilities and a form of the so-called\nmonotone attack.\n  Significantly, this error rate is achieved by the SDP solution itself without\nany further pre- or post-processing, and improves upon existing\npolynomially-decaying error bounds proved using the Grothendieck\\textquoteright\ns inequality. Our analysis has two key ingredients: (i) showing that the graph\nhas a well-behaved spectrum, even in the sparse regime, after discounting an\nexponentially small number of edges, and (ii) an order-statistics argument that\ngoverns the final error rate. Both arguments highlight the implicit\nregularization effect of the SDP formulation.",
    "published_date": "2017-05-23T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.SI",
      "math.IT",
      "math.ST",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08391v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.08283v3",
    "title": "Music Playlist Continuation by Learning from Hand-Curated Examples and Song Features: Alleviating the Cold-Start Problem for Rare and Out-of-Set Songs",
    "authors": [
      "Andreu Vall",
      "Hamid Eghbal-zadeh",
      "Matthias Dorfer",
      "Markus Schedl",
      "Gerhard Widmer"
    ],
    "author_ids": [],
    "abstract": "Automated music playlist generation is a specific form of music\nrecommendation. Generally stated, the user receives a set of song suggestions\ndefining a coherent listening session. We hypothesize that the best way to\nconvey such playlist coherence to new recommendations is by learning it from\nactual curated examples, in contrast to imposing ad hoc constraints.\nCollaborative filtering methods can be used to capture underlying patterns in\nhand-curated playlists. However, the scarcity of thoroughly curated playlists\nand the bias towards popular songs result in the vast majority of songs\noccurring in very few playlists and thus being poorly recommended. To overcome\nthis issue, we propose an alternative model based on a song-to-playlist\nclassifier, which learns the underlying structure from actual playlists while\nleveraging song features derived from audio, social tags and independent\nlistening logs. Experiments on two datasets of hand-curated playlists show\ncompetitive performance compared to collaborative filtering when sufficient\ntraining data is available and more robust performance when recommending rare\nand out-of-set songs. For example, both approaches achieve a recall@100 of\nroughly 35% for songs occurring in 5 or more training playists, whereas the\nproposed model achieves a recall@100 of roughly 15% for songs occurring in 4 or\nless training playlists, compared to the 3% achieved by collaborative\nfiltering.",
    "published_date": "2017-05-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08283v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.08197v1",
    "title": "Learning to Succeed while Teaching to Fail: Privacy in Closed Machine Learning Systems",
    "authors": [
      "Jure Sokolic",
      "Qiang Qiu",
      "Miguel R. D. Rodrigues",
      "Guillermo Sapiro"
    ],
    "author_ids": [],
    "abstract": "Security, privacy, and fairness have become critical in the era of data\nscience and machine learning. More and more we see that achieving universally\nsecure, private, and fair systems is practically impossible. We have seen for\nexample how generative adversarial networks can be used to learn about the\nexpected private training data; how the exploitation of additional data can\nreveal private information in the original one; and how what looks like\nunrelated features can teach us about each other. Confronted with this\nchallenge, in this paper we open a new line of research, where the security,\nprivacy, and fairness is learned and used in a closed environment. The goal is\nto ensure that a given entity (e.g., the company or the government), trusted to\ninfer certain information with our data, is blocked from inferring protected\ninformation from it. For example, a hospital might be allowed to produce\ndiagnosis on the patient (the positive task), without being able to infer the\ngender of the subject (negative task). Similarly, a company can guarantee that\ninternally it is not using the provided data for any undesired task, an\nimportant goal that is not contradicting the virtually impossible challenge of\nblocking everybody from the undesired task. We design a system that learns to\nsucceed on the positive task while simultaneously fail at the negative one, and\nillustrate this with challenging cases where the positive task is actually\nharder than the negative one being blocked. Fairness, to the information in the\nnegative task, is often automatically obtained as a result of this proposed\napproach. The particular framework and examples open the door to security,\nprivacy, and fairness in very important closed scenarios, ranging from private\ndata accumulation companies like social networks to law-enforcement and\nhospitals.",
    "published_date": "2017-05-23T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08197v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.08010v1",
    "title": "Dynamic Motion Planning for Aerial Surveillance on a Fixed-Wing UAV",
    "authors": [
      "Vaibhav Darbari",
      "Saksham Gupta",
      "Om Prakash Verma"
    ],
    "author_ids": [],
    "abstract": "We present an efficient path planning algorithm for an Unmanned Aerial\nVehicle surveying a cluttered urban landscape. A special emphasis is on\nmaximizing area surveyed while adhering to constraints of the UAV and partially\nknown and updating environment. A Voronoi bias is introduced in the\nprobabilistic roadmap building phase to identify certain critical milestones\nfor maximal surveillance of the search space. A kinematically feasible but\ncoarse tour connecting these milestones is generated by the global path\nplanner. A local path planner then generates smooth motion primitives between\nconsecutive nodes of the global path based on UAV as a Dubins vehicle and\ntaking into account any impending obstacles. A Markov Decision Process (MDP)\nmodels the control policy for the UAV and determines the optimal action to be\nundertaken for evading the obstacles in the vicinity with minimal deviation\nfrom current path. The efficacy of the proposed algorithm is evaluated in an\nupdating simulation environment with dynamic and static obstacles.",
    "published_date": "2017-05-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.08010v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.07609v1",
    "title": "View-Invariant Recognition of Action Style Self-Dissimilarity",
    "authors": [
      "Yuping Shen",
      "Hassan Foroosh"
    ],
    "author_ids": [],
    "abstract": "Self-similarity was recently introduced as a measure of inter-class\ncongruence for classification of actions. Herein, we investigate the dual\nproblem of intra-class dissimilarity for classification of action styles. We\nintroduce self-dissimilarity matrices that discriminate between same actions\nperformed by different subjects regardless of viewing direction and camera\nparameters. We investigate two frameworks using these invariant style\ndissimilarity measures based on Principal Component Analysis (PCA) and Fisher\nDiscriminant Analysis (FDA). Extensive experiments performed on IXMAS dataset\nindicate remarkably good discriminant characteristics for the proposed\ninvariant measures for gender recognition from video data.",
    "published_date": "2017-05-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.07609v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.07284v2",
    "title": "Gaze Distribution Analysis and Saliency Prediction Across Age Groups",
    "authors": [
      "Onkar Krishna",
      "Kiyoharu Aizawa",
      "Andrea Helo",
      "Rama Pia"
    ],
    "author_ids": [],
    "abstract": "Knowledge of the human visual system helps to develop better computational\nmodels of visual attention. State-of-the-art models have been developed to\nmimic the visual attention system of young adults that, however, largely ignore\nthe variations that occur with age. In this paper, we investigated how visual\nscene processing changes with age and we propose an age-adapted framework that\nhelps to develop a computational model that can predict saliency across\ndifferent age groups. Our analysis uncovers how the explorativeness of an\nobserver varies with age, how well saliency maps of an age group agree with\nfixation points of observers from the same or different age groups, and how age\ninfluences the center bias. We analyzed the eye movement behavior of 82\nobservers belonging to four age groups while they explored visual scenes.\nExplorativeness was quantified in terms of the entropy of a saliency map, and\narea under the curve (AUC) metrics was used to quantify the agreement analysis\nand the center bias. These results were used to develop age adapted saliency\nmodels. Our results suggest that the proposed age-adapted saliency model\noutperforms existing saliency models in predicting the regions of interest\nacross age groups.",
    "published_date": "2017-05-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.07284v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.07183v1",
    "title": "Large System Analysis of Power Normalization Techniques in Massive MIMO",
    "authors": [
      "Meysam Sadeghi",
      "Luca Sanguinetti",
      "Romain Couillet",
      "Chau Yuen"
    ],
    "author_ids": [],
    "abstract": "Linear precoding has been widely studied in the context of Massive\nmultiple-input-multiple-output (MIMO) together with two common power\nnormalization techniques, namely, matrix normalization (MN) and vector\nnormalization (VN). Despite this, their effect on the performance of Massive\nMIMO systems has not been thoroughly studied yet. The aim of this paper is to\nfulfill this gap by using large system analysis. Considering a system model\nthat accounts for channel estimation, pilot contamination, arbitrary pathloss,\nand per-user channel correlation, we compute tight approximations for the\nsignal-to-interference-plus-noise ratio and the rate of each user equipment in\nthe system while employing maximum ratio transmission (MRT), zero forcing (ZF),\nand regularized ZF precoding under both MN and VN techniques. Such\napproximations are used to analytically reveal how the choice of power\nnormalization affects the performance of MRT and ZF under uncorrelated fading\nchannels. It turns out that ZF with VN resembles a sum rate maximizer while it\nprovides a notion of fairness under MN. Numerical results are used to validate\nthe accuracy of the asymptotic analysis and to show that in Massive MIMO,\nnon-coherent interference and noise, rather than pilot contamination, are often\nthe major limiting factors of the considered precoding schemes.",
    "published_date": "2017-05-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.07183v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.06950v1",
    "title": "The Kinetics Human Action Video Dataset",
    "authors": [
      "Will Kay",
      "Joao Carreira",
      "Karen Simonyan",
      "Brian Zhang",
      "Chloe Hillier",
      "Sudheendra Vijayanarasimhan",
      "Fabio Viola",
      "Tim Green",
      "Trevor Back",
      "Paul Natsev",
      "Mustafa Suleyman",
      "Andrew Zisserman"
    ],
    "author_ids": [],
    "abstract": "We describe the DeepMind Kinetics human action video dataset. The dataset\ncontains 400 human action classes, with at least 400 video clips for each\naction. Each clip lasts around 10s and is taken from a different YouTube video.\nThe actions are human focussed and cover a broad range of classes including\nhuman-object interactions such as playing instruments, as well as human-human\ninteractions such as shaking hands. We describe the statistics of the dataset,\nhow it was collected, and give some baseline performance figures for neural\nnetwork architectures trained and tested for human action classification on\nthis dataset. We also carry out a preliminary analysis of whether imbalance in\nthe dataset leads to bias in the classifiers.",
    "published_date": "2017-05-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.06950v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.05920v1",
    "title": "Path Cover and Path Pack Inequalities for the Capacitated Fixed-Charge Network Flow Problem",
    "authors": [
      "Alper Atamturk",
      "Birce Tezel",
      "Simge Kucukyavuz"
    ],
    "author_ids": [],
    "abstract": "Capacitated fixed-charge network flows are used to model a variety of\nproblems in telecommunication, facility location, production planning and\nsupply chain management. In this paper, we investigate capacitated path\nsubstructures and derive strong and easy-to-compute \\emph{path cover and path\npack inequalities}. These inequalities are based on an explicit\ncharacterization of the submodular inequalities through a fast computation of\nparametric minimum cuts on a path, and they generalize the well-known flow\ncover and flow pack inequalities for the single-node relaxations of\nfixed-charge flow models. We provide necessary and sufficient facet conditions.\nComputational results demonstrate the effectiveness of the inequalities when\nused as cuts in a branch-and-cut algorithm.",
    "published_date": "2017-05-16T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.05920v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1706.03021v1",
    "title": "Ethical Artificial Intelligence - An Open Question",
    "authors": [
      "Alice Pavaloiu",
      "Utku Kose"
    ],
    "author_ids": [],
    "abstract": "Artificial Intelligence (AI) is an effective science which employs strong\nenough approaches, methods, and techniques to solve unsolvable real world based\nproblems. Because of its unstoppable rise towards the future, there are also\nsome discussions about its ethics and safety. Shaping an AI friendly\nenvironment for people and a people friendly environment for AI can be a\npossible answer for finding a shared context of values for both humans and\nrobots. In this context, objective of this paper is to address the ethical\nissues of AI and explore the moral dilemmas that arise from ethical algorithms,\nfrom pre set or acquired values. In addition, the paper will also focus on the\nsubject of AI safety. As general, the paper will briefly analyze the concerns\nand potential solutions to solving the ethical issues presented and increase\nreaders awareness on AI safety as another related research interest.",
    "published_date": "2017-05-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1706.03021v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.05344v1",
    "title": "GP-ILQG: Data-driven Robust Optimal Control for Uncertain Nonlinear Dynamical Systems",
    "authors": [
      "Gilwoo Lee",
      "Siddhartha S. Srinivasa",
      "Matthew T. Mason"
    ],
    "author_ids": [],
    "abstract": "As we aim to control complex systems, use of a simulator in model-based\nreinforcement learning is becoming more common. However, it has been\nchallenging to overcome the Reality Gap, which comes from nonlinear model bias\nand susceptibility to disturbance. To address these problems, we propose a\nnovel algorithm that combines data-driven system identification approach\n(Gaussian Process) with a Differential-Dynamic-Programming-based robust optimal\ncontrol method (Iterative Linear Quadratic Control). Our algorithm uses the\nsimulator's model as the mean function for a Gaussian Process and learns only\nthe difference between the simulator's prediction and actual observations,\nmaking it a natural hybrid of simulation and real-world observation. We show\nthat our approach quickly corrects incorrect models, comes up with robust\noptimal controllers, and transfers its acquired model knowledge to new tasks\nefficiently.",
    "published_date": "2017-05-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.RO",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.05344v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.05154v2",
    "title": "Layerwise Systematic Scan: Deep Boltzmann Machines and Beyond",
    "authors": [
      "Heng Guo",
      "Kaan Kara",
      "Ce Zhang"
    ],
    "author_ids": [],
    "abstract": "For Markov chain Monte Carlo methods, one of the greatest discrepancies\nbetween theory and system is the scan order - while most theoretical\ndevelopment on the mixing time analysis deals with random updates, real-world\nsystems are implemented with systematic scans. We bridge this gap for models\nthat exhibit a bipartite structure, including, most notably, the\nRestricted/Deep Boltzmann Machine. The de facto implementation for these models\nscans variables in a layerwise fashion. We show that the Gibbs sampler with a\nlayerwise alternating scan order has its relaxation time (in terms of epochs)\nno larger than that of a random-update Gibbs sampler (in terms of variable\nupdates). We also construct examples to show that this bound is asymptotically\ntight. Through standard inequalities, our result also implies a comparison on\nthe mixing times.",
    "published_date": "2017-05-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.05154v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.05098v2",
    "title": "Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach",
    "authors": [
      "Lahari Poddar",
      "Wynne Hsu",
      "Mong Li Lee"
    ],
    "author_ids": [],
    "abstract": "User opinions expressed in the form of ratings can influence an individual's\nview of an item. However, the true quality of an item is often obfuscated by\nuser biases, and it is not obvious from the observed ratings the importance\ndifferent users place on different aspects of an item. We propose a\nprobabilistic modeling of the observed aspect ratings to infer (i) each user's\naspect bias and (ii) latent intrinsic quality of an item. We model multi-aspect\nratings as ordered discrete data and encode the dependency between different\naspects by using a latent Gaussian structure. We handle the\nGaussian-Categorical non-conjugacy using a stick-breaking formulation coupled\nwith P\\'{o}lya-Gamma auxiliary variable augmentation for a simple, fully\nBayesian inference. On two real world datasets, we demonstrate the predictive\nability of our model and its effectiveness in learning explainable user biases\nto provide insights towards a more reliable product quality estimation.",
    "published_date": "2017-05-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.05098v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.04919v1",
    "title": "Discovery and visualization of structural biomarkers from MRI using transport-based morphometry",
    "authors": [
      "Shinjini Kundu",
      "Soheil Kolouri",
      "Kirk I Erickson",
      "Arthur F Kramer",
      "Edward McAuley",
      "Gustavo K Rohde"
    ],
    "author_ids": [],
    "abstract": "Disease in the brain is often associated with subtle, spatially diffuse, or\ncomplex tissue changes that may lie beneath the level of gross visual\ninspection, even on magnetic resonance imaging (MRI). Unfortunately, current\ncomputer-assisted approaches that examine pre-specified features, whether\nanatomically-defined (i.e. thalamic volume, cortical thickness) or based on\npixelwise comparison (i.e. deformation-based methods), are prone to missing a\nvast array of physical changes that are not well-encapsulated by these metrics.\nIn this paper, we have developed a technique for automated pattern analysis\nthat can fully determine the relationship between brain structure and\nobservable phenotype without requiring any a priori features. Our technique,\ncalled transport-based morphometry (TBM), is an image transformation that maps\nbrain images losslessly to a domain where they become much more separable. The\nnew approach is validated on structural brain images of healthy older adult\nsubjects where even linear models for discrimination, regression, and blind\nsource separation enable TBM to independently discover the characteristic\nchanges of aging and highlight potential mechanisms by which aerobic fitness\nmay mediate brain health later in life. TBM is a generative approach that can\nprovide visualization of physically meaningful shifts in tissue distribution\nthrough inverse transformation. The proposed framework is a powerful technique\nthat can potentially elucidate genotype-structural-behavioral associations in\nmyriad diseases.",
    "published_date": "2017-05-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04919v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.04774v1",
    "title": "Bias and variance in the social structure of gender",
    "authors": [
      "Kristen M. Altenburger",
      "Johan Ugander"
    ],
    "author_ids": [],
    "abstract": "The observation that individuals tend to be friends with people who are\nsimilar to themselves, commonly known as homophily, is a prominent and\nwell-studied feature of social networks. Many machine learning methods exploit\nhomophily to predict attributes of individuals based on the attributes of their\nfriends. Meanwhile, recent work has shown that gender homophily can be weak or\nnonexistent in practice, making gender prediction particularly challenging. In\nthis work, we identify another useful structural feature for predicting gender,\nan overdispersion of gender preferences introduced by individuals who have\nextreme preferences for a particular gender, regardless of their own gender. We\ncall this property monophily for \"love of one,\" and jointly characterize the\nstatistical structure of homophily and monophily in social networks in terms of\npreference bias and preference variance. For prediction, we find that this\npattern of extreme gender preferences introduces friend-of-friend correlations,\nwhere individuals are similar to their friends-of-friends without necessarily\nbeing similar to their friends. We analyze a population of online friendship\nnetworks in U.S. colleges and offline friendship networks in U.S. high schools\nand observe a fundamental difference between the success of prediction methods\nbased on friends, \"the company you keep,\" compared to methods based on\nfriends-of-friends, \"the company you're kept in.\" These findings offer an\nalternative perspective on attribute prediction in general and gender in\nparticular, complicating the already difficult task of protecting attribute\nprivacy.",
    "published_date": "2017-05-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04774v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.04400v1",
    "title": "Reducing Bias in Production Speech Models",
    "authors": [
      "Eric Battenberg",
      "Rewon Child",
      "Adam Coates",
      "Christopher Fougner",
      "Yashesh Gaur",
      "Jiaji Huang",
      "Heewoo Jun",
      "Ajay Kannan",
      "Markus Kliegl",
      "Atul Kumar",
      "Hairong Liu",
      "Vinay Rao",
      "Sanjeev Satheesh",
      "David Seetapun",
      "Anuroop Sriram",
      "Zhenyao Zhu"
    ],
    "author_ids": [],
    "abstract": "Replacing hand-engineered pipelines with end-to-end deep learning systems has\nenabled strong results in applications like speech and object recognition.\nHowever, the causality and latency constraints of production systems put\nend-to-end speech models back into the underfitting regime and expose biases in\nthe model that we show cannot be overcome by \"scaling up\", i.e., training\nbigger models on more data. In this work we systematically identify and address\nsources of bias, reducing error rates by up to 20% while remaining practical\nfor deployment. We achieve this by utilizing improved neural architectures for\nstreaming inference, solving optimization issues, and employing strategies that\nincrease audio and label modelling versatility.",
    "published_date": "2017-05-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04400v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.04300v4",
    "title": "Challenges in Monocular Visual Odometry: Photometric Calibration, Motion Bias and Rolling Shutter Effect",
    "authors": [
      "Nan Yang",
      "Rui Wang",
      "Xiang Gao",
      "Daniel Cremers"
    ],
    "author_ids": [],
    "abstract": "Monocular visual odometry (VO) and simultaneous localization and mapping\n(SLAM) have seen tremendous improvements in accuracy, robustness and\nefficiency, and have gained increasing popularity over recent years.\nNevertheless, not so many discussions have been carried out to reveal the\ninfluences of three very influential yet easily overlooked aspects: photometric\ncalibration, motion bias and rolling shutter effect. In this work, we evaluate\nthese three aspects quantitatively on the state of the art of direct,\nfeature-based and semi-direct methods, providing the community with useful\npractical knowledge both for better applying existing methods and developing\nnew algorithms of VO and SLAM. Conclusions (some of which are\ncounter-intuitive) are drawn with both technical and empirical analyses to all\nof our experiments. Possible improvements on existing methods are directed or\nproposed, such as a sub-pixel accuracy refinement of ORB-SLAM which boosts its\nperformance.",
    "published_date": "2017-05-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04300v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.04212v6",
    "title": "Competitive Equilibrium For Almost All Incomes: Existence and Fairness",
    "authors": [
      "Erel Segal-Halevi"
    ],
    "author_ids": [],
    "abstract": "Competitive equilibrium (CE) is a fundamental concept in market economics.\nIts efficiency and fairness properties make it particularly appealing as a rule\nfor fair allocation of resources among agents with possibly different\nentitlements. However, when the resources are indivisible, a CE might not exist\neven when there is one resource and two agents with equal incomes. Recently,\nBabaioff and Nisan and Talgam-Cohen (2017) have suggested to consider the\nentire space of possible incomes, and check whether there exists a competitive\nequilibrium for almost all income-vectors --- all income-space except a subset\nof measure zero. They proved various existence and non-existence results, but\nleft open the cases of four goods and three or four agents with\nmonotonically-increasing preferences.\n  This paper proves non-existence in both these cases, thus completing the\ncharacterization of CE existence for almost all incomes in the domain of\nmonotonically increasing preferences. Additionally, the paper provides a\ncomplete characterization of CE existence in the domain of monotonically\ndecreasing preferences, corresponding to allocation of chores.\n  On the positive side, the paper proves that CE exists for almost all incomes\nwhen there are four goods and three agents with additive preferences. The proof\nuses a new tool for describing a CE, as a subgame-perfect equilibrium of a\nspecific sequential game. The same tool also enables substantially simpler\nproofs to the cases already proved by Babaioff et al.\n  Additionally, this paper proves several strong fairness properties that are\nsatisfied by any CE allocation, illustrating its usefulness for fair allocation\namong agents with different entitlements.",
    "published_date": "2017-05-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04212v6",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.04148v2",
    "title": "Device-independent Randomness Amplification and Privatization",
    "authors": [
      "Max Kessler",
      "Rotem Arnon-Friedman"
    ],
    "author_ids": [],
    "abstract": "Randomness is an essential resource in computer science. In most applications\nperfect, and sometimes private, randomness is needed, while it is not even\nclear that such a resource exists. It is well known that the tools of classical\ncomputer science do not allow us to create perfect and secret randomness from a\nsingle weak public source. Quantum physics, on the other hand, allows for such\na process, even in the most paranoid cryptographic sense termed \"quantum\ndevice-independent cryptography\". In this work we propose and prove the\nsecurity of a new device-independent protocol that takes any single public\nSantha-Vazirani source as input and creates a secret close to uniform string in\nthe presence of a quantum adversary.\n  Our work is the first to achieve randomness amplification with all the\nfollowing properties: (1) amplification and \"privatization\" of a public\nSantha-Vazirani source with arbitrary bias (2) the use of a device with only\ntwo components (compared to polynomial number of components) (3) non-vanishing\nextraction rate and (4) maximal noise tolerance. In particular, this implies\nthat our protocol is the first protocol that can possibly be implemented with\nreachable parameters. We are able to achieve these by combining three new\ntools: a particular family of Bell inequalities, a proof technique to lower\nbound entropy in the device-independent setting, and a special framework for\nquantum-proof multi-source extractors.",
    "published_date": "2017-05-11T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.04148v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.03460v1",
    "title": "A Probabilistic Framework for Quantifying Biological Complexity",
    "authors": [
      "Stuart M. Marshall",
      "Alastair R. G. Murray",
      "Leroy Cronin"
    ],
    "author_ids": [],
    "abstract": "One thing that discriminates living things from inanimate matter is their\nability to generate similarly complex or non-random architectures in a large\nabundance. From DNA sequences to folded protein structures, living cells,\nmicrobial communities and multicellular structures, the material configurations\nin biology can easily be distinguished from non-living material assemblies.\nThis is also true of the products of complex organisms that can themselves\nconstruct complex tools, machines, and artefacts. Whilst these objects are not\nliving, they cannot randomly form, as they are the product of a biological\norganism and hence are either technological or cultural biosignatures. The\nproblem is that it is not obvious how it might be possible to generalise an\napproach that aims to evaluate complex objects as possible biosignatures.\nHowever, if it was possible such a self-contained approach could be useful to\nexplore the cosmos for new life forms. This would require us to prove\nrigorously that a given artefact is too complex to have formed by chance. In\nthis paper, we present a new type of complexity measure, Pathway Complexity,\nthat allows us to not only threshold the abiotic-biotic divide, but to\ndemonstrate a probabilistic approach based upon object abundance and complexity\nwhich can be used to unambiguously assign complex objects as biosignatures. We\nhope that this approach not only opens up the search for biosignatures beyond\nearth, but allow us to explore earth for new types of biology, as well as\nobserving when a complex chemical system discovered in the laboratory could be\nconsidered alive.",
    "published_date": "2017-05-09T00:00:00",
    "year": 2017,
    "categories": [
      "q-bio.OT",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.03460v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.03258v2",
    "title": "Measuring Social Media Activity of Scientific Literature: An Exhaustive Comparison of Scopus and Novel Altmetrics Big Data",
    "authors": [
      "Saeed-Ul Hassan",
      "Mubashir Imran",
      "Uzair Gillani",
      "Naif Radi Aljohani",
      "Timothy D. Bowman",
      "Fereshteh Didegah"
    ],
    "author_ids": [],
    "abstract": "This paper measures social media activity of 15 broad scientific disciplines\nindexed in Scopus database using Altmetric.com data. First, the presence of\nAltmetric.com data in Scopus database is investigated, overall and across\ndisciplines. Second, the correlation between the bibliometric and altmetric\nindices is examined using Spearman correlation. Third, a zero-truncated\nnegative binomial model is used to determine the association of various factors\nwith increasing or decreasing citations. Lastly, the effectiveness of altmetric\nindices to identify publications with high citation impact is comprehensively\nevaluated by deploying Area Under the Curve (AUC) - an application of receiver\noperating characteristic. Results indicate a rapid increase in the presence of\nAltmetric.com data in Scopus database from 10.19% in 2011 to 20.46% in 2015. A\nzero-truncated negative binomial model is implemented to measure the extent to\nwhich different bibliometric and altmetric factors contribute to citation\ncounts. Blog count appears to be the most important factor increasing the\nnumber of citations by 38.6% in the field of Health Professions and Nursing,\nfollowed by Twitter count increasing the number of citations by 8% in the field\nof Physics and Astronomy. Interestingly, both Blog count and Twitter count\nalways show positive increase in the number of citations across all fields.\nWhile there was a positive weak correlation between bibliometric and altmetric\nindices, the results show that altmetric indices can be a good indicator to\ndiscriminate highly cited publications, with an encouragingly AUC= 0.725\nbetween highly cited publications and total altmetric count. Overall, findings\nsuggest that altmetrics could better distinguish highly cited publications.",
    "published_date": "2017-05-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL",
      "94-02",
      "H.3.7"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.03258v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.03154v3",
    "title": "Cultural Values and Cross-cultural Video Consumption on YouTube",
    "authors": [
      "Minsu Park",
      "Jaram Park",
      "Young Min Baek",
      "Michael Macy"
    ],
    "author_ids": [],
    "abstract": "Video-sharing social media like YouTube provide access to diverse cultural\nproducts from all over the world, making it possible to test theories that the\nWeb facilitates global cultural convergence. Drawing on a daily listing of\nYouTube's most popular videos across 58 countries, we investigate the\nconsumption of popular videos in countries that differ in cultural values,\nlanguage, gross domestic product, and Internet penetration rate. Although\nonline social media facilitate global access to cultural products, we find this\ntechnological capability does not result in universal cultural convergence.\nInstead, consumption of popular videos in culturally different countries\nappears to be constrained by cultural values. Cross-cultural convergence is\nmore advanced in cosmopolitan countries with cultural values that favor\nindividualism and power inequality.",
    "published_date": "2017-05-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.03154v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02972v1",
    "title": "Why Do Men Get More Attention? Exploring Factors Behind Success in an Online Design Community",
    "authors": [
      "Johannes Wachs",
      "Anikó Hannák",
      "András Vörös",
      "Bálint Daróczy"
    ],
    "author_ids": [],
    "abstract": "Online platforms are an increasingly popular tool for people to produce,\npromote or sell their work. However recent studies indicate that social\ndisparities and biases present in the real world might transfer to online\nplatforms and could be exacerbated by seemingly harmless design choices on the\nsite (e.g., recommendation systems or publicly visible success measures). In\nthis paper we analyze an exclusive online community of teams of design\nprofessionals called Dribbble and investigate apparent differences in outcomes\nby gender. Overall, we find that men produce more work, and are able to show it\nto a larger audience thus receiving more likes. Some of this effect can be\nexplained by the fact that women have different skills and design different\nimages. Most importantly however, women and men position themselves differently\nin the Dribbble community. Our investigation of users' position in the social\nnetwork shows that women have more clustered and gender homophilous following\nrelations, which leads them to have smaller and more closely knit social\nnetworks. Overall, our study demonstrates that looking behind the apparent\npatterns of gender inequalities in online markets with the help of social\nnetworks and product differentiation helps us to better understand gender\ndifferences in success and failure.",
    "published_date": "2017-05-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02972v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02928v1",
    "title": "Cross-label Suppression: A Discriminative and Fast Dictionary Learning with Group Regularization",
    "authors": [
      "Xiudong Wang",
      "Yuantao Gu"
    ],
    "author_ids": [],
    "abstract": "This paper addresses image classification through learning a compact and\ndiscriminative dictionary efficiently. Given a structured dictionary with each\natom (columns in the dictionary matrix) related to some label, we propose\ncross-label suppression constraint to enlarge the difference among\nrepresentations for different classes. Meanwhile, we introduce group\nregularization to enforce representations to preserve label properties of\noriginal samples, meaning the representations for the same class are encouraged\nto be similar. Upon the cross-label suppression, we don't resort to\nfrequently-used $\\ell_0$-norm or $\\ell_1$-norm for coding, and obtain\ncomputational efficiency without losing the discriminative power for\ncategorization. Moreover, two simple classification schemes are also developed\nto take full advantage of the learnt dictionary. Extensive experiments on six\ndata sets including face recognition, object categorization, scene\nclassification, texture recognition and sport action categorization are\nconducted, and the results show that the proposed approach can outperform lots\nof recently presented dictionary algorithms on both recognition accuracy and\ncomputational efficiency.",
    "published_date": "2017-05-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02928v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.02667v2",
    "title": "People on Media: Jointly Identifying Credible News and Trustworthy Citizen Journalists in Online Communities",
    "authors": [
      "Subhabrata Mukherjee",
      "Gerhard Weikum"
    ],
    "author_ids": [],
    "abstract": "Media seems to have become more partisan, often providing a biased coverage\nof news catering to the interest of specific groups. It is therefore essential\nto identify credible information content that provides an objective narrative\nof an event. News communities such as digg, reddit, or newstrust offer\nrecommendations, reviews, quality ratings, and further insights on journalistic\nworks. However, there is a complex interaction between different factors in\nsuch online communities: fairness and style of reporting, language clarity and\nobjectivity, topical perspectives (like political viewpoint), expertise and\nbias of community members, and more. This paper presents a model to\nsystematically analyze the different interactions in a news community between\nusers, news, and sources. We develop a probabilistic graphical model that\nleverages this joint interaction to identify 1) highly credible news articles,\n2) trustworthy news sources, and 3) expert users who perform the role of\n\"citizen journalists\" in the community. Our method extends CRF models to\nincorporate real-valued ratings, as some communities have very fine-grained\nscales that cannot be easily discretized without losing information. To the\nbest of our knowledge, this paper is the first full-fledged analysis of\ncredibility, trust, and expertise in news communities.",
    "published_date": "2017-05-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.SI",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02667v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.02505v2",
    "title": "HoloScope: Topology-and-Spike Aware Fraud Detection",
    "authors": [
      "Shenghua Liu",
      "Bryan Hooi",
      "Christos Faloutsos"
    ],
    "author_ids": [],
    "abstract": "As online fraudsters invest more resources, including purchasing large pools\nof fake user accounts and dedicated IPs, fraudulent attacks become less obvious\nand their detection becomes increasingly challenging. Existing approaches such\nas average degree maximization suffer from the bias of including more nodes\nthan necessary, resulting in lower accuracy and increased need for manual\nverification. Hence, we propose HoloScope, which uses information from graph\ntopology and temporal spikes to more accurately detect groups of fraudulent\nusers. In terms of graph topology, we introduce \"contrast suspiciousness,\" a\ndynamic weighting approach, which allows us to more accurately detect\nfraudulent blocks, particularly low-density blocks. In terms of temporal\nspikes, HoloScope takes into account the sudden bursts and drops of fraudsters'\nattacking patterns. In addition, we provide theoretical bounds for how much\nthis increases the time cost needed for fraudsters to conduct adversarial\nattacks. Additionally, from the perspective of ratings, HoloScope incorporates\nthe deviation of rating scores in order to catch fraudsters more accurately.\nMoreover, HoloScope has a concise framework and sub-quadratic time complexity,\nmaking the algorithm reproducible and scalable. Extensive experiments showed\nthat HoloScope achieved significant accuracy improvements on synthetic and real\ndata, compared with state-of-the-art fraud detection methods.",
    "published_date": "2017-05-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02505v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02449v1",
    "title": "Interface and Data Biopolitics in the Age of Hyperconnectivity",
    "authors": [
      "Salvatore Iaconesi"
    ],
    "author_ids": [],
    "abstract": "This article describes their biopolitical implications for design from\npsychological, cultural, legal, functional and aesthetic/perceptive ways, in\nthe framework of Hyperconnectivity: the condition according to which\nperson-to-person, person-to-machine and machine-to-machine communication\nprogressively shift to networked and digital means. A definition is given for\nthe terms of \"interface biopolitics\" and \"data biopolitics\", as well as\nevidence supporting these definitions and a description of the technological,\ntheoretical and practice-based innovations bringing them into meaningful\nexistence. Interfaces, algorithms, artificial intelligences of various types,\nthe tendency in quantified self and the concept of \"information bubbles\" will\nbe examined in terms of interface and data biopolitics, from the point of view\nof design, and for their implications in terms of freedoms, transparency,\njustice and accessibility to human rights. A working hypothesis is described\nfor technologically relevant design practices and education processes, in order\nto confront with these issues in critical, ethical and inclusive ways.",
    "published_date": "2017-05-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02449v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02321v1",
    "title": "Fairness Incentives for Myopic Agents",
    "authors": [
      "Sampath Kannan",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Mallesh Pai",
      "Aaron Roth",
      "Rakesh Vohra",
      "Z. Steven Wu"
    ],
    "author_ids": [],
    "abstract": "We consider settings in which we wish to incentivize myopic agents (such as\nAirbnb landlords, who may emphasize short-term profits and property safety) to\ntreat arriving clients fairly, in order to prevent overall discrimination\nagainst individuals or groups. We model such settings in both classical and\ncontextual bandit models in which the myopic agents maximize rewards according\nto current empirical averages, but are also amenable to exogenous payments that\nmay cause them to alter their choices. Our notion of fairness asks that more\nqualified individuals are never (probabilistically) preferred over less\nqualified ones [Joseph et al].\n  We investigate whether it is possible to design inexpensive {subsidy} or\npayment schemes for a principal to motivate myopic agents to play fairly in all\nor almost all rounds. When the principal has full information about the state\nof the myopic agents, we show it is possible to induce fair play on every round\nwith a subsidy scheme of total cost $o(T)$ (for the classic setting with $k$\narms, $\\tilde{O}(\\sqrt{k^3T})$, and for the $d$-dimensional linear contextual\nsetting $\\tilde{O}(d\\sqrt{k^3 T})$). If the principal has much more limited\ninformation (as might often be the case for an external regulator or watchdog),\nand only observes the number of rounds in which members from each of the $k$\ngroups were selected, but not the empirical estimates maintained by the myopic\nagent, the design of such a scheme becomes more complex. We show both positive\nand negative results in the classic and linear bandit settings by upper and\nlower bounding the cost of fair subsidy schemes.",
    "published_date": "2017-05-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02321v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02135v1",
    "title": "Energy Imbalance Management Using a Robust Pricing Scheme",
    "authors": [
      "Wei-Yu Chiu",
      "Hongjian Sun",
      "H. Vincent Poor"
    ],
    "author_ids": [],
    "abstract": "This paper focuses on the problem of energy imbalance management in\namicrogrid. The problem is investigated from the power market perspective.\nUnlike the traditional power grid, a microgrid can obtain extra energy froma\nrenewable energy source (RES) such as a solar panel or a wind turbine. However,\nthe stochastic input from the RES brings difficulty in balancing the energy\nsupply and demand. In this study, a novel pricing scheme is proposed that\nprovides robustness against such intermittent power input. The proposed scheme\nconsiders possible uncertainty in the marginal benefit and the marginal cost of\nthe power market. It uses all available information on the power supply, power\ndemand, and imbalanced energy. The parameters of the scheme are evaluated using\nan performance index. It is shown that the parameters can be obtained by\nsolving a linear matrix inequality problem, which is efficiently solvable due\nto its convexity. Simulation examples are given to show the favorable\nperformance of the proposed scheme in comparison with existing area control\nerror pricing schemes.",
    "published_date": "2017-05-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02135v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02109v1",
    "title": "Multiobjective controller design by solving a multiobjective matrix inequality problem",
    "authors": [
      "Wei-Yu Chiu"
    ],
    "author_ids": [],
    "abstract": "In this study, linear matrix inequality (LMI) approaches and multiobjective\n(MO) evolutionary algorithms are integrated to design controllers. An MO matrix\ninequality problem (MOMIP) is first defined. A hybrid MO differential evolution\n(HMODE) algorithm is then developed to solve the MOMIP. The hybrid algorithm\ncombines deterministic and stochastic searching schemes. In the solving\nprocess, the deterministic part aims to exploit the structures of matrix\ninequalities, and the stochastic part is used to fully explore the decision\nvariable space. Simulation results show that the HMODE algorithm can produce an\napproximated Pareto front (APF) and Pareto-efficient controllers that stabilise\nthe associated controlled system. In contrast with single-objective designs\nusing LMI approaches, the proposed MO methodology can clearly illustrate how\nthe objectives involved affect each other, that is, a broad perspective on\noptimality is provided. This facilitates the selecting process for a\nrepresentative design, and particularly the design that corresponds to a\nnon-dominated vector lying in the knee region of the APF. In addition,\ncontroller gains can be readily modified to incorporate the preference or need\nof a system designer.",
    "published_date": "2017-05-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02109v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02095v1",
    "title": "Method of Reduction of Variables for Bilinear Matrix Inequality Problems in System and Control Designs",
    "authors": [
      "Wei-Yu Chiu"
    ],
    "author_ids": [],
    "abstract": "Bilinear matrix inequality (BMI) problems in system and control designs are\ninvestigated in this paper. A solution method of reduction of variables (MRVs)\nis proposed. This method consists of a principle of variable classification, a\nprocedure for problem transformation, and a hybrid algorithm that combines\ndeterministic and stochastic search engines. The classification principle is\nused to classify the decision variables of a BMI problem into two categories:\n1) external and 2) internal variables. Theoretical analysis is performed to\nshow that when the classification principle is applicable, a BMI problem can be\ntransformed into an unconstrained optimization problem that has fewer decision\nvariables. Stochastic search and deterministic search are then applied to\ndetermine the decision variables of the unconstrained problem externally and\nexplore the internal problem structure, respectively. The proposed method can\naddress feasibility, single-objective, and multiobjective problems constrained\nby BMIs in a unified manner. A number of numerical examples in system and\ncontrol designs are provided to validate the proposed methodology. Simulations\nshow that the MRVs can outperform existing BMI solution methods in most\nbenchmark problems and achieve similar levels of performance in the remaining\nproblems.",
    "published_date": "2017-05-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02095v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.02004v1",
    "title": "A Rural Lens on a Research Agenda for Intelligent Infrastructure",
    "authors": [
      "Ellen Zegura",
      "Beki Grinter",
      "Elizabeth Belding",
      "Klara Nahrstedt"
    ],
    "author_ids": [],
    "abstract": "A National Agenda for Intelligent Infrastructure is not complete without\nexplicit consideration of the needs of rural communities. While the American\npopulation has urbanized, the United States depends on rural communities for\nagriculture, fishing, forestry, manufacturing and mining. Approximately 20% of\nthe US population lives in rural areas with a skew towards aging adults.\nFurther, nearly 25% of Veterans live in rural America. And yet, when\nintelligent infrastructure is imagined, it is often done so with implicit or\nexplicit bias towards cities. In this brief we describe the unique\nopportunities for rural communities and offer an inclusive vision of\nintelligent infrastructure research. In this paper, we argue for a set of\ncoordinated actions to ensure that rural Americans are not left behind in this\ndigital revolution. These technological platforms and applications, supported\nby appropriate policy, will address key issues in transportation, energy,\nagriculture, public safety and health. We believe that rather than being a set\nof needs, the rural United States presents a set of exciting possibilities for\nnovel innovation benefiting not just those living there, but the American\neconomy more broadly",
    "published_date": "2017-05-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.02004v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.01731v4",
    "title": "A measure of authorship by publications",
    "authors": [
      "Conan Mukherje",
      "Ranojoy Basu",
      "Aftab Alam"
    ],
    "author_ids": [],
    "abstract": "Measuring publication success of a researcher is a complicated task as\npublications are often co-authored by multiple authors, and so, require\ncomparison of solo publications with joint publications. In this paper, like\n\\cite{price1981multiple}, we argue for an egalitarian perspective in\naccomplishing this task.\n  More specifically, we justify the need for an ethical perspective in\nquantifying academic author by identifying certain ethical difficulties of some\npopular contemporary indices used for this purpose. And then we show that for\nany given dataset of research papers, the unique method satisfying the ethical\nnotions of {\\it identity independence} and performance invariance must be the\negaliatarian E-index proposed by \\cite{bps} and \\cite{price1981multiple}. In\nour setting, this egalitarian method divides authorship of joint projects\nequally among authors and sums across all publications of each author.",
    "published_date": "2017-05-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.01731v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.01453v2",
    "title": "Distributed Proportional-Fairness Control in MicroGrids via Blockchain Smart Contracts",
    "authors": [
      "Pietro Danzi",
      "Marko Angjelichinoski",
      "Čedomir Stefanović",
      "Petar Popovski"
    ],
    "author_ids": [],
    "abstract": "Residential microgrids (MGs) may host a large number of Distributed Energy\nResources (DERs). The strategy that maximizes the revenue for each individual\nDER is the one in which the DER operates at capacity, injecting all available\npower into the grid. However, when the DER penetration is high and the\nconsumption low, this strategy may lead to power surplus that causes voltage\nincrease over recommended limits. In order to create incentives for the DER to\noperate below capacity, we propose a proportional-fairness control strategy in\nwhich (i) a subset of DERs decrease their own power output, sacrificing the\nindividual revenue, and (ii) the DERs in the subset are dynamically selected\nbased on the record of their control history. The trustworthy implementation of\nthe scheme is carried out through a custom-designed blockchain mechanism that\nmaintains a distributed database trusted by all DERs. In particular, the\nblockchain is used to stipulate and store a smart contract that enforces\nproportional fairness. The simulation results verify the potential of the\nproposed framework.",
    "published_date": "2017-05-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.01453v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.01371v1",
    "title": "Weakly-supervised Visual Grounding of Phrases with Linguistic Structures",
    "authors": [
      "Fanyi Xiao",
      "Leonid Sigal",
      "Yong Jae Lee"
    ],
    "author_ids": [],
    "abstract": "We propose a weakly-supervised approach that takes image-sentence pairs as\ninput and learns to visually ground (i.e., localize) arbitrary linguistic\nphrases, in the form of spatial attention masks. Specifically, the model is\ntrained with images and their associated image-level captions, without any\nexplicit region-to-phrase correspondence annotations. To this end, we introduce\nan end-to-end model which learns visual groundings of phrases with two types of\ncarefully designed loss functions. In addition to the standard discriminative\nloss, which enforces that attended image regions and phrases are consistently\nencoded, we propose a novel structural loss which makes use of the parse tree\nstructures induced by the sentences. In particular, we ensure complementarity\namong the attention masks that correspond to sibling noun phrases, and\ncompositionality of attention masks among the children and parent phrases, as\ndefined by the sentence parse tree. We validate the effectiveness of our\napproach on the Microsoft COCO and Visual Genome datasets.",
    "published_date": "2017-05-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.01371v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.00813v1",
    "title": "Transforming Bell's Inequalities into State Classifiers with Machine Learning",
    "authors": [
      "Yue-Chi Ma",
      "Man-Hong Yung"
    ],
    "author_ids": [],
    "abstract": "Quantum information science has profoundly changed the ways we understand,\nstore, and process information. A major challenge in this field is to look for\nan efficient means for classifying quantum state. For instance, one may want to\ndetermine if a given quantum state is entangled or not. However, the process of\na complete characterization of quantum states, known as quantum state\ntomography, is a resource-consuming operation in general. An attractive\nproposal would be the use of Bell's inequalities as an entanglement witness,\nwhere only partial information of the quantum state is needed. The problem is\nthat entanglement is necessary but not sufficient for violating Bell's\ninequalities, making it an unreliable state classifier. Here we aim at solving\nthis problem by the methods of machine learning. More precisely, given a family\nof quantum states, we randomly picked a subset of it to construct a\nquantum-state classifier, accepting only partial information of each quantum\nstate. Our results indicated that these transformed Bell-type inequalities can\nperform significantly better than the original Bell's inequalities in\nclassifying entangled states. We further extended our analysis to three-qubit\nand four-qubit systems, performing classification of quantum states into\nmultiple species. These results demonstrate how the tools in machine learning\ncan be applied to solving problems in quantum information science.",
    "published_date": "2017-05-02T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00813v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.00609v1",
    "title": "Mind the Class Weight Bias: Weighted Maximum Mean Discrepancy for Unsupervised Domain Adaptation",
    "authors": [
      "Hongliang Yan",
      "Yukang Ding",
      "Peihua Li",
      "Qilong Wang",
      "Yong Xu",
      "Wangmeng Zuo"
    ],
    "author_ids": [],
    "abstract": "In domain adaptation, maximum mean discrepancy (MMD) has been widely adopted\nas a discrepancy metric between the distributions of source and target domains.\nHowever, existing MMD-based domain adaptation methods generally ignore the\nchanges of class prior distributions, i.e., class weight bias across domains.\nThis remains an open problem but ubiquitous for domain adaptation, which can be\ncaused by changes in sample selection criteria and application scenarios. We\nshow that MMD cannot account for class weight bias and results in degraded\ndomain adaptation performance. To address this issue, a weighted MMD model is\nproposed in this paper. Specifically, we introduce class-specific auxiliary\nweights into the original MMD for exploiting the class prior probability on\nsource and target domains, whose challenge lies in the fact that the class\nlabel in target domain is unavailable. To account for it, our proposed weighted\nMMD model is defined by introducing an auxiliary weight for each class in the\nsource domain, and a classification EM algorithm is suggested by alternating\nbetween assigning the pseudo-labels, estimating auxiliary weights and updating\nmodel parameters. Extensive experiments demonstrate the superiority of our\nweighted MMD over conventional MMD for domain adaptation.",
    "published_date": "2017-05-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "68-45"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00609v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.00544v1",
    "title": "Rank Maximal Equal Contribution: a Probabilistic Social Choice Function",
    "authors": [
      "Haris Aziz",
      "Pang Luo",
      "Christine Rizkallah"
    ],
    "author_ids": [],
    "abstract": "When aggregating preferences of agents via voting, two desirable goals are to\nincentivize agents to participate in the voting process and then identify\noutcomes that are Pareto efficient. We consider participation as formalized by\nBrandl, Brandt, and Hofbauer (2015) based on the stochastic dominance (SD)\nrelation. We formulate a new rule called RMEC (Rank Maximal Equal Contribution)\nthat satisfies the strongest notion of participation and is also ex post\nefficient. The rule is polynomial-time computable and also satisfies many other\ndesirable fairness properties. The rule suggests a general approach to\nachieving ex post efficiency and very strong participation.",
    "published_date": "2017-05-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "91A12, 68Q15",
      "F.2; J.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00544v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1705.00432v1",
    "title": "A Statistical Model for Simultaneous Template Estimation, Bias Correction, and Registration of 3D Brain Images",
    "authors": [
      "Akshay Pai",
      "Stefan Sommer",
      "Lars Lau Raket",
      "Line Kühnel",
      "Sune Darkner",
      "Lauge Sørensen",
      "Mads Nielsen"
    ],
    "author_ids": [],
    "abstract": "Template estimation plays a crucial role in computational anatomy since it\nprovides reference frames for performing statistical analysis of the underlying\nanatomical population variability. While building models for template\nestimation, variability in sites and image acquisition protocols need to be\naccounted for. To account for such variability, we propose a generative\ntemplate estimation model that makes simultaneous inference of both bias fields\nin individual images, deformations for image registration, and variance\nhyperparameters. In contrast, existing maximum a posterori based methods need\nto rely on either bias-invariant similarity measures or robust image\nnormalization. Results on synthetic and real brain MRI images demonstrate the\ncapability of the model to capture heterogeneity in intensities and provide a\nreliable template estimation from registration.",
    "published_date": "2017-05-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00432v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1705.00347v2",
    "title": "Scalable Twin Neural Networks for Classification of Unbalanced Data",
    "authors": [
      "Jayadeva",
      "Himanshu Pant",
      "Sumit Soman",
      "Mayank Sharma"
    ],
    "author_ids": [],
    "abstract": "Twin Support Vector Machines (TWSVMs) have emerged an efficient alternative\nto Support Vector Machines (SVM) for learning from imbalanced datasets. The\nTWSVM learns two non-parallel classifying hyperplanes by solving a couple of\nsmaller sized problems. However, it is unsuitable for large datasets, as it\ninvolves matrix operations. In this paper, we discuss a Twin Neural Network\n(Twin NN) architecture for learning from large unbalanced datasets. The Twin NN\nalso learns an optimal feature map, allowing for better discrimination between\nclasses. We also present an extension of this network architecture for\nmulticlass datasets. Results presented in the paper demonstrate that the Twin\nNN generalizes well and scales well on large unbalanced datasets.",
    "published_date": "2017-04-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "68T05, 68T10, 68Q32"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00347v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.08818v1",
    "title": "A Tribe Competition-Based Genetic Algorithm for Feature Selection in Pattern Classification",
    "authors": [
      "Benteng Ma",
      "Yong Xia"
    ],
    "author_ids": [],
    "abstract": "Feature selection has always been a critical step in pattern recognition, in\nwhich evolutionary algorithms, such as the genetic algorithm (GA), are most\ncommonly used. However, the individual encoding scheme used in various GAs\nwould either pose a bias on the solution or require a pre-specified number of\nfeatures, and hence may lead to less accurate results. In this paper, a tribe\ncompetition-based genetic algorithm (TCbGA) is proposed for feature selection\nin pattern classification. The population of individuals is divided into\nmultiple tribes, and the initialization and evolutionary operations are\nmodified to ensure that the number of selected features in each tribe follows a\nGaussian distribution. Thus each tribe focuses on exploring a specific part of\nthe solution space. Meanwhile, tribe competition is introduced to the evolution\nprocess, which allows the winning tribes, which produce better individuals, to\nenlarge their sizes, i.e. having more individuals to search their parts of the\nsolution space. This algorithm, therefore, avoids the bias on solutions and\nrequirement of a pre-specified number of features. We have evaluated our\nalgorithm against several state-of-the-art feature selection approaches on 20\nbenchmark datasets. Our results suggest that the proposed TCbGA algorithm can\nidentify the optimal feature subset more effectively and produce more accurate\npattern classification.",
    "published_date": "2017-04-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.08818v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.08535v2",
    "title": "TFDASH: A Fairness, Stability, and Efficiency Aware Rate Control Approach for Multiple Clients over DASH",
    "authors": [
      "Chao Zhou",
      "Chia-Wen Lin",
      "Xinggong Zhang",
      "Zongming Guo"
    ],
    "author_ids": [],
    "abstract": "Dynamic adaptive streaming over HTTP (DASH) has recently been widely deployed\nin the Internet and adopted in the industry. It, however, does not impose any\nadaptation logic for selecting the quality of video fragments requested by\nclients and suffers from lackluster performance with respect to a number of\ndesirable properties: efficiency, stability, and fairness when multiple players\ncompete for a bottleneck link. In this paper, we propose a throughput-friendly\nDASH (TFDASH) rate control scheme for video streaming with multiple clients\nover DASH to well balance the trade-offs among efficiency, stability, and\nfairness. The core idea behind guaranteeing fairness and high efficiency\n(bandwidth utilization) is to avoid OFF periods during the downloading process\nfor all clients, i.e., the bandwidth is in perfect-subscription or\nover-subscription with bandwidth utilization approach to 100\\%. We also propose\na dual-threshold buffer model to solve the instability problem caused by the\nabove idea. As a result, by integrating these novel components, we also propose\na probability-driven rate adaption logic taking into account several key\nfactors that most influence visual quality, including buffer occupancy, video\nplayback quality, video bit-rate switching frequency and amplitude, to\nguarantee high-quality video streaming. Our experiments evidently demonstrate\nthe superior performance of the proposed method.",
    "published_date": "2017-04-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MM",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.08535v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.08509v1",
    "title": "No More Discrimination: Cross City Adaptation of Road Scene Segmenters",
    "authors": [
      "Yi-Hsin Chen",
      "Wei-Yu Chen",
      "Yu-Ting Chen",
      "Bo-Cheng Tsai",
      "Yu-Chiang Frank Wang",
      "Min Sun"
    ],
    "author_ids": [],
    "abstract": "Despite the recent success of deep-learning based semantic segmentation,\ndeploying a pre-trained road scene segmenter to a city whose images are not\npresented in the training set would not achieve satisfactory performance due to\ndataset biases. Instead of collecting a large number of annotated images of\neach city of interest to train or refine the segmenter, we propose an\nunsupervised learning approach to adapt road scene segmenters across different\ncities. By utilizing Google Street View and its time-machine feature, we can\ncollect unannotated images for each road scene at different times, so that the\nassociated static-object priors can be extracted accordingly. By advancing a\njoint global and class-specific domain adversarial learning framework,\nadaptation of pre-trained segmenters to that city can be achieved without the\nneed of any user annotation or interaction. We show that our method improves\nthe performance of semantic segmentation in multiple cities across continents,\nwhile it performs favorably against state-of-the-art approaches requiring\nannotated training data.",
    "published_date": "2017-04-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.08509v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.08473v1",
    "title": "Asymptotics of Transmit Antenna Selection: Impact of Multiple Receive Antennas",
    "authors": [
      "Saba Asaad",
      "Ali Bereyhi",
      "Ralf R. Müller",
      "Amir M. Rabiei"
    ],
    "author_ids": [],
    "abstract": "Consider a fading Gaussian MIMO channel with $N_\\mathrm{t}$ transmit and\n$N_\\mathrm{r}$ receive antennas. The transmitter selects $L_\\mathrm{t}$\nantennas corresponding to the strongest channels. For this setup, we study the\ndistribution of the input-output mutual information when $N_\\mathrm{t}$ grows\nlarge. We show that, for any $N_\\mathrm{r}$ and $L_\\mathrm{t}$, the\ndistribution of the input-output mutual information is accurately approximated\nby a Gaussian distribution whose mean grows large and whose variance converges\nto zero. Our analysis depicts that, in the large limit, the gap between the\nexpectation of the mutual information and its corresponding upper bound,\nderived by applying Jensen's inequality, converges to a constant which only\ndepends on $N_\\mathrm{r}$ and $L_\\mathrm{t}$. The result extends the scope of\nchannel hardening to the general case of antenna selection with multiple\nreceive and selected transmit antennas. Although the analyses are given for the\nlarge-system limit, our numerical investigations indicate the robustness of the\napproximated distribution even when the number of antennas is not large.",
    "published_date": "2017-04-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.08473v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.07790v1",
    "title": "FWDA: a Fast Wishart Discriminant Analysis with its Application to Electronic Health Records Data Classification",
    "authors": [
      "Haoyi Xiong",
      "Wei Cheng",
      "Wenqing Hu",
      "Jiang Bian",
      "Zhishan Guo"
    ],
    "author_ids": [],
    "abstract": "Linear Discriminant Analysis (LDA) on Electronic Health Records (EHR) data is\nwidely-used for early detection of diseases. Classical LDA for EHR data\nclassification, however, suffers from two handicaps: the ill-posed estimation\nof LDA parameters (e.g., covariance matrix), and the \"linear inseparability\" of\nEHR data. To handle these two issues, in this paper, we propose a novel\nclassifier FWDA -- Fast Wishart Discriminant Analysis, that makes predictions\nin an ensemble way. Specifically, FWDA first surrogates the distribution of\ninverse covariance matrices using a Wishart distribution estimated from the\ntraining data, then \"weighted-averages\" the classification results of multiple\nLDA classifiers parameterized by the sampled inverse covariance matrices via a\nBayesian Voting scheme. The weights for voting are optimally updated to adapt\neach new input data, so as to enable the nonlinear classification. Theoretical\nanalysis indicates that FWDA possesses a fast convergence rate and a robust\nperformance on high dimensional data. Extensive experiments on large-scale EHR\ndataset show that our approach outperforms state-of-the-art algorithms by a\nlarge margin.",
    "published_date": "2017-04-25T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.07790v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.07433v4",
    "title": "Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples",
    "authors": [
      "Haw-Shiuan Chang",
      "Erik Learned-Miller",
      "Andrew McCallum"
    ],
    "author_ids": [],
    "abstract": "Self-paced learning and hard example mining re-weight training instances to\nimprove learning accuracy. This paper presents two improved alternatives based\non lightweight estimates of sample uncertainty in stochastic gradient descent\n(SGD): the variance in predicted probability of the correct class across\niterations of mini-batch SGD, and the proximity of the correct class\nprobability to the decision threshold. Extensive experimental results on six\ndatasets show that our methods reliably improve accuracy in various network\narchitectures, including additional gains on top of other popular training\ntechniques, such as residual learning, momentum, ADAM, batch normalization,\ndropout, and distillation.",
    "published_date": "2017-04-24T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.07433v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.06840v4",
    "title": "Ranking with Fairness Constraints",
    "authors": [
      "L. Elisa Celis",
      "Damian Straszak",
      "Nisheeth K. Vishnoi"
    ],
    "author_ids": [],
    "abstract": "Ranking algorithms are deployed widely to order a set of items in\napplications such as search engines, news feeds, and recommendation systems.\nRecent studies, however, have shown that, left unchecked, the output of ranking\nalgorithms can result in decreased diversity in the type of content presented,\npromote stereotypes, and polarize opinions. In order to address such issues, we\nstudy the following variant of the traditional ranking problem when, in\naddition, there are fairness or diversity constraints. Given a collection of\nitems along with 1) the value of placing an item in a particular position in\nthe ranking, 2) the collection of sensitive attributes (such as gender, race,\npolitical opinion) of each item and 3) a collection of constraints that, for\neach k, bound the number of items with each attribute that are allowed to\nappear in the top k positions of the ranking, the goal is to output a ranking\nthat maximizes the value with respect to the original rank quality metric while\nrespecting the constraints. This problem encapsulates various well-studied\nproblems related to bipartite and hypergraph matching as special cases and\nturns out to be hard to approximate even with simple constraints. Our main\ntechnical contributions are fast exact and approximation algorithms along with\ncomplementary hardness results that, together, come close to settling the\napproximability of this constrained ranking maximization problem. Unlike prior\nwork on the constrained matching problems, our algorithm runs in linear time,\neven when the number of constraints is large, its approximation ratio does not\ndepend on the number of constraints, and it produces solutions with small\nconstraint violations. Our results rely on insights about the constrained\nmatching problem when the objective satisfies properties that appear in common\nranking metrics such as Discounted Cumulative Gain, Spearman's rho or\nBradley-Terry.",
    "published_date": "2017-04-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.CY",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.06840v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.06528v2",
    "title": "Fairness in Resource Allocation and Slowed-down Dependent Rounding",
    "authors": [
      "David G. Harris",
      "Thomas Pensyl",
      "Aravind Srinivasan",
      "Khoa Trinh"
    ],
    "author_ids": [],
    "abstract": "We consider an issue of much current concern: could fairness, an issue that\nis already difficult to guarantee, worsen when algorithms run much of our\nlives? We consider this in the context of resource-allocation problems, we show\nthat algorithms can guarantee certain types of fairness in a verifiable way.\nOur conceptual contribution is a simple approach to fairness in this context,\nwhich only requires that all users trust some public lottery. Our technical\ncontributions are in ways to address the $k$-center and knapsack-center\nproblems that arise in this context: we develop a novel dependent-rounding\ntechnique that, via the new ingredients of \"slowing down\" and additional\nrandomization, guarantees stronger correlation properties than known before.",
    "published_date": "2017-04-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.06528v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.06305v3",
    "title": "Efficient Gender Classification Using a Deep LDA-Pruned Net",
    "authors": [
      "Qing Tian",
      "Tal Arbel",
      "James J. Clark"
    ],
    "author_ids": [],
    "abstract": "Many real-time tasks, such as human-computer interaction, require fast and\nefficient facial gender classification. Although deep CNN nets have been very\neffective for a multitude of classification tasks, their high space and time\ndemands make them impractical for personal computers and mobile devices without\na powerful GPU. In this paper, we develop a 16-layer, yet lightweight, neural\nnetwork which boosts efficiency while maintaining high accuracy. Our net is\npruned from the VGG-16 model starting from the last convolutional (conv) layer\nwhere we find neuron activations are highly uncorrelated given the gender.\nThrough Fisher's Linear Discriminant Analysis (LDA), we show that this high\ndecorrelation makes it safe to discard directly last conv layer neurons with\nhigh within-class variance and low between-class variance. Combined with either\nSupport Vector Machines (SVM) or Bayesian classification, the reduced CNNs are\ncapable of achieving comparable (or even higher) accuracies on the LFW and\nCelebA datasets than the original net with fully connected layers. On LFW, only\nfour Conv5_3 neurons are able to maintain a comparably high recognition\naccuracy, which results in a reduction of total network size by a factor of 70X\nwith a 11 fold speedup. Comparisons with a state-of-the-art pruning method as\nwell as two smaller nets in terms of accuracy loss and convolutional layers\npruning rate are also provided.",
    "published_date": "2017-04-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.06305v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.06061v4",
    "title": "Multi-view (Joint) Probability Linear Discrimination Analysis for Multi-view Feature Verification",
    "authors": [
      "Ziqiang Shi",
      "Liu Liu",
      "Mengjiao Wang",
      "Rujie Liu"
    ],
    "author_ids": [],
    "abstract": "Multi-view feature has been proved to be very effective in many multimedia\napplications. However, the current back-end classifiers cannot make full use of\nsuch features. In this paper, we propose a method to model the multi-faceted\ninformation in the multi-view features explicitly and jointly. In our approach,\nthe feature was modeled as a result derived by a generative multi-view\n(joint\\footnotemark[1]) Probability Linear Discriminant Analysis (PLDA) model,\nwhich contains multiple kinds of latent variables. The usual PLDA model only\nconsiders one single label. However, in practical use, when using multi-task\nlearned network as feature extractor, the extracted feature are always attached\nto several labels. This type of feature is called multi-view feature. With\nmulti-view (joint) PLDA, we are able to explicitly build a model that can\ncombine multiple heterogeneous information from the multi-view features. In\nverification step, we calculated the likelihood to describe whether the two\nfeatures having consistent labels or not. This likelihood are used in the\nfollowing decision-making. Experiments have been conducted on large scale\nverification task. On the public RSR2015 data corpus, the results showed that\nour approach can achieve 0.02\\% EER and 0.09\\% EER for impostor wrong and\nimpostor correct cases respectively.",
    "published_date": "2017-04-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.06061v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.05920v1",
    "title": "Application of Econometric Data Analysis Methods to Physics Software",
    "authors": [
      "Maria Grazia Pia",
      "Elisabetta Ronchieri"
    ],
    "author_ids": [],
    "abstract": "We report an investigation of data analysis methods derived from other\ndisciplines, which we applied to physics software systems. They concern the\nanalysis of inequality, trend analysis and the analysis of diversity. The\nanalysis of inequality exploits statistical methods originating from\neconometrics; trend analysis is typical of economics and environmental\nsciences; the analysis of diversity is based on concepts derived from ecology\nand treats software as an ecosystem. To the best of our knowledge, this is an\ninnovative exploration, as we could not find track of previous use of these\nmethods in the experimental physics domains within the scope of the IEEE\nNuclear Science Symposium. We applied these methods in the context of Geant4\nphysics validation and Geant4 maintainability assessment.",
    "published_date": "2017-04-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SE",
      "physics.data-an",
      "D.2.4; G.3"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05920v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.05801v3",
    "title": "Gender Disparities in Science? Dropout, Productivity, Collaborations and Success of Male and Female Computer Scientists",
    "authors": [
      "Mohsen Jadidi",
      "Fariba Karimi",
      "Haiko Lietz",
      "Claudia Wagner"
    ],
    "author_ids": [],
    "abstract": "Scientific collaborations shape ideas as well as innovations and are both the\nsubstrate for, and the outcome of, academic careers. Recent studies show that\ngender inequality is still present in many scientific practices ranging from\nhiring to peer-review processes and grant applications. In this work, we\ninvestigate gender-specific differences in collaboration patterns of more than\none million computer scientists over the course of 47 years. We explore how\nthese patterns change over years and career ages and how they impact scientific\nsuccess. Our results highlight that successful male and female scientists\nreveal the same collaboration patterns: compared to scientists in the same\ncareer age, they tend to collaborate with more colleagues than other\nscientists, seek innovations as brokers and establish longer-lasting and more\nrepetitive collaborations. However, women are on average less likely to adapt\nthe collaboration patterns that are related with success, more likely to embed\ninto ego networks devoid of structural holes, and they exhibit stronger gender\nhomophily as well as a consistently higher dropout rate than men in all career\nages.",
    "published_date": "2017-04-19T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05801v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.05730v2",
    "title": "On Measuring Bias in Online Information",
    "authors": [
      "Evaggelia Pitoura",
      "Panayiotis Tsaparas",
      "Giorgos Flouris",
      "Irini Fundulaki",
      "Panagiotis Papadakos",
      "Serge Abiteboul",
      "Gerhard Weikum"
    ],
    "author_ids": [],
    "abstract": "Bias in online information has recently become a pressing issue, with search\nengines, social networks and recommendation services being accused of\nexhibiting some form of bias. In this vision paper, we make the case for a\nsystematic approach towards measuring bias. To this end, we discuss formal\nmeasures for quantifying the various types of bias, we outline the system\ncomponents necessary for realizing them, and we highlight the related research\nchallenges and open problems.",
    "published_date": "2017-04-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DB",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05730v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.05703v2",
    "title": "Quantum Sphere-Packing Bounds with Polynomial Prefactors",
    "authors": [
      "Hao-Chung Cheng",
      "Min-Hsiu Hsieh",
      "Marco Tomamichel"
    ],
    "author_ids": [],
    "abstract": "We study lower bounds on the optimal error probability in classical coding\nover classical-quantum channels at rates below the capacity, commonly termed\nquantum sphere-packing bounds. Winter and Dalai have derived such bounds for\nclassical-quantum channels; however, the exponents in their bounds only\ncoincide when the channel is classical. In this paper, we show that these two\nexponents admit a variational representation and are related by the\nGolden-Thompson inequality, reaffirming that Dalai's expression is stronger in\ngeneral classical-quantum channels. Second, we establish a sphere-packing bound\nfor classical-quantum channels, which significantly improves Dalai's prefactor\nfrom the order of subexponential to polynomial. Furthermore, the gap between\nthe obtained error exponent for constant composition codes and the best known\nclassical random coding exponent vanishes in the order of $o(\\log n / n)$,\nindicating our sphere-packing bound is almost exact in the high rate regime.\nFinally, for a special class of symmetric classical-quantum channels, we can\ncompletely characterize its optimal error probability without the constant\ncomposition code assumption. The main technical contributions are two converse\nHoeffding bounds for quantum hypothesis testing and the saddle-point properties\nof error exponent functions.",
    "published_date": "2017-04-19T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05703v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.05516v2",
    "title": "Graph Model Selection via Random Walks",
    "authors": [
      "Lin Li",
      "William M. Campbell",
      "Rajmonda S. Caceres"
    ],
    "author_ids": [],
    "abstract": "In this paper, we present a novel approach based on the random walk process\nfor finding meaningful representations of a graph model. Our approach leverages\nthe transient behavior of many short random walks with novel initialization\nmechanisms to generate model discriminative features. These features are able\nto capture a more comprehensive structural signature of the underlying graph\nmodel. The resulting representation is invariant to both node permutation and\nthe size of the graph, allowing direct comparison between large classes of\ngraphs. We test our approach on two challenging model selection problems: the\ndiscrimination in the sparse regime of an Erd\\\"{o}s-Renyi model from a\nstochastic block model and the planted clique problem. Our representation\napproach achieves performance that closely matches known theoretical limits in\naddition to being computationally simple and scalable to large graphs.",
    "published_date": "2017-04-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05516v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.05122v1",
    "title": "A Gabor Filter Texture Analysis Approach for Histopathological Brain Tumor Subtype Discrimination",
    "authors": [
      "Omar S. Al-Kadi"
    ],
    "author_ids": [],
    "abstract": "Meningioma brain tumour discrimination is challenging as many histological\npatterns are mixed between the different subtypes. In clinical practice,\ndominant patterns are investigated for signs of specific meningioma pathology;\nhowever the simple observation could result in inter- and intra-observer\nvariation due to the complexity of the histopathological patterns. Also\nemploying a computerised feature extraction approach applied at a single\nresolution scale might not suffice in accurately delineating the mixture of\nhistopathological patterns. In this work we propose a novel multiresolution\nfeature extraction approach for characterising the textural properties of the\ndifferent pathological patterns (i.e. mainly cell nuclei shape, orientation and\nspatial arrangement within the cytoplasm). The pattern textural properties are\ncharacterised at various scales and orientations for an improved separability\nbetween the different extracted features. The Gabor filter energy output of\neach magnitude response was combined with four other fixed-resolution texture\nsignatures (2 model-based and 2 statistical-based) with and without cell nuclei\nsegmentation. The highest classification accuracy of 95% was reported when\ncombining the Gabor filters energy and the meningioma subimage fractal\nsignature as a feature vector without performing any prior cell nuceli\nsegmentation. This indicates that characterising the cell-nuclei\nself-similarity properties via Gabor filters can assists in achieving an\nimproved meningioma subtype classification, which can assist in overcoming\nvariations in reported diagnosis.",
    "published_date": "2017-04-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.05122v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.04651v2",
    "title": "The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning",
    "authors": [
      "Audrunas Gruslys",
      "Will Dabney",
      "Mohammad Gheshlaghi Azar",
      "Bilal Piot",
      "Marc Bellemare",
      "Remi Munos"
    ],
    "author_ids": [],
    "abstract": "In this work we present a new agent architecture, called Reactor, which\ncombines multiple algorithmic and architectural contributions to produce an\nagent with higher sample-efficiency than Prioritized Dueling DQN (Wang et al.,\n2016) and Categorical DQN (Bellemare et al., 2017), while giving better\nrun-time performance than A3C (Mnih et al., 2016). Our first contribution is a\nnew policy evaluation algorithm called Distributional Retrace, which brings\nmulti-step off-policy updates to the distributional reinforcement learning\nsetting. The same approach can be used to convert several classes of multi-step\npolicy evaluation algorithms designed for expected value evaluation into\ndistributional ones. Next, we introduce the \\b{eta}-leave-one-out policy\ngradient algorithm which improves the trade-off between variance and bias by\nusing action values as a baseline. Our final algorithmic contribution is a new\nprioritized replay algorithm for sequences, which exploits the temporal\nlocality of neighboring observations for more efficient replay prioritization.\nUsing the Atari 2600 benchmarks, we show that each of these innovations\ncontribute to both the sample efficiency and final agent performance. Finally,\nwe demonstrate that Reactor reaches state-of-the-art performance after 200\nmillion frames and less than a day of training.",
    "published_date": "2017-04-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.04651v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.04235v1",
    "title": "Close Yet Distinctive Domain Adaptation",
    "authors": [
      "Lingkun Luo",
      "Xiaofang Wang",
      "Shiqiang Hu",
      "Chao Wang",
      "Yuxing Tang",
      "Liming Chen"
    ],
    "author_ids": [],
    "abstract": "Domain adaptation is transfer learning which aims to generalize a learning\nmodel across training and testing data with different distributions. Most\nprevious research tackle this problem in seeking a shared feature\nrepresentation between source and target domains while reducing the mismatch of\ntheir data distributions. In this paper, we propose a close yet discriminative\ndomain adaptation method, namely CDDA, which generates a latent feature\nrepresentation with two interesting properties. First, the discrepancy between\nthe source and target domain, measured in terms of both marginal and\nconditional probability distribution via Maximum Mean Discrepancy is minimized\nso as to attract two domains close to each other. More importantly, we also\ndesign a repulsive force term, which maximizes the distances between each label\ndependent sub-domain to all others so as to drag different class dependent\nsub-domains far away from each other and thereby increase the discriminative\npower of the adapted domain. Moreover, given the fact that the underlying data\nmanifold could have complex geometric structure, we further propose the\nconstraints of label smoothness and geometric structure consistency for label\npropagation. Extensive experiments are conducted on 36 cross-domain image\nclassification tasks over four public datasets. The comprehensive results show\nthat the proposed method consistently outperforms the state-of-the-art methods\nwith significant margins.",
    "published_date": "2017-04-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.04235v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.03755v1",
    "title": "Unsupervised part learning for visual recognition",
    "authors": [
      "Ronan Sicre",
      "Yannis Avrithis",
      "Ewa Kijak",
      "Frederic Jurie"
    ],
    "author_ids": [],
    "abstract": "Part-based image classification aims at representing categories by small sets\nof learned discriminative parts, upon which an image representation is built.\nConsidered as a promising avenue a decade ago, this direction has been\nneglected since the advent of deep neural networks. In this context, this paper\nbrings two contributions: first, it shows that despite the recent success of\nend-to-end holistic models, explicit part learning can boosts classification\nperformance. Second, this work proceeds one step further than recent part-based\nmodels (PBM), focusing on how to learn parts without using any labeled data.\nInstead of learning a set of parts per class, as generally done in the PBM\nliterature, the proposed approach both constructs a partition of a given set of\nimages into visually similar groups, and subsequently learn a set of\ndiscriminative parts per group in a fully unsupervised fashion. This strategy\nopens the door to the use of PBM in new applications for which the notion of\nimage categories is irrelevant, such as instance-based image retrieval, for\nexample. We experimentally show that our learned parts can help building\nefficient image representations, for classification as well as for indexing\ntasks, resulting in performance superior to holistic state-of-the art Deep\nConvolutional Neural Networks (DCNN) encoding.",
    "published_date": "2017-04-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03755v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.03690v5",
    "title": "Symbolic Models for Retarded Jump-Diffusion Systems",
    "authors": [
      "Pushpak Jagtap",
      "Majid Zamani"
    ],
    "author_ids": [],
    "abstract": "In this paper, we provide for the first time an automated,\ncorrect-by-construction, controller synthesis scheme for a class of infinite\ndimensional stochastic systems, namely, retarded jump-diffusion systems. First,\nwe construct finite abstractions approximately bisimilar to non-probabilistic\nretarded systems corresponding to the original systems having some stability\nproperty, namely, incremental input-to-state stability. Then, we provide a\nresult on quantifying the distance between output trajectory of the obtained\nfinite abstraction and that of the original retarded jump-diffusion system in a\nprobabilistic setting. Using the proposed result, one can refine the control\npolicy synthesized using finite abstractions to the original systems while\nproviding guarantee on the probability of satisfaction of high-level\nrequirements. Moreover, we provide sufficient conditions for the proposed\nnotion of incremental stability in terms of the existence of incremental\nLyapunov functions which reduce to some matrix inequalities for the linear\nsystems. Finally, the effectiveness of the proposed results is illustrated by\nsynthesizing a controller regulating the temperatures in a ten-room building\nmodelled as a delayed jump-diffusion system.",
    "published_date": "2017-04-12T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY",
      "93E99",
      "I.2.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03690v5",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.03607v1",
    "title": "Automatic Discovery, Association Estimation and Learning of Semantic Attributes for a Thousand Categories",
    "authors": [
      "Ziad Al-Halah",
      "Rainer Stiefelhagen"
    ],
    "author_ids": [],
    "abstract": "Attribute-based recognition models, due to their impressive performance and\ntheir ability to generalize well on novel categories, have been widely adopted\nfor many computer vision applications. However, usually both the attribute\nvocabulary and the class-attribute associations have to be provided manually by\ndomain experts or large number of annotators. This is very costly and not\nnecessarily optimal regarding recognition performance, and most importantly, it\nlimits the applicability of attribute-based models to large scale data sets. To\ntackle this problem, we propose an end-to-end unsupervised attribute learning\napproach. We utilize online text corpora to automatically discover a salient\nand discriminative vocabulary that correlates well with the human concept of\nsemantic attributes. Moreover, we propose a deep convolutional model to\noptimize class-attribute associations with a linguistic prior that accounts for\nnoise and missing data in text. In a thorough evaluation on ImageNet, we\ndemonstrate that our model is able to efficiently discover and learn semantic\nattributes at a large scale. Furthermore, we demonstrate that our model\noutperforms the state-of-the-art in zero-shot learning on three data sets:\nImageNet, Animals with Attributes and aPascal/aYahoo. Finally, we enable\nattribute-based learning on ImageNet and will share the attributes and\nassociations for future research.",
    "published_date": "2017-04-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03607v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.03526v1",
    "title": "Rich-clubness test: how to determine whether a complex network has or doesn't have a rich-club?",
    "authors": [
      "Alessandro Muscoloni",
      "Carlo Vittorio Cannistraci"
    ],
    "author_ids": [],
    "abstract": "The rich-club concept has been introduced in order to characterize the\npresence of a cohort of nodes with a large number of links (rich nodes) that\ntend to be well connected between each other, creating a tight group (club).\nRich-clubness defines the extent to which a network displays a topological\norganization characterized by the presence of a node rich-club. It is crucial\nfor the investigation of internal organization and function of networks arising\nin systems of disparate fields such as transportation, social, communication\nand neuroscience. Different methods have been proposed for assessing the\nrich-clubness and various null-models have been adopted for performing\nstatistical tests. However, a procedure that assigns a unique value of\nrich-clubness significance to a given network is still missing. Our solution to\nthis problem grows on the basis of three new pillars. We introduce: i) a\nnull-model characterized by a lower rich-club coefficient; ii) a fair strategy\nto normalize the level of rich-clubness of a network in respect to the\nnull-model; iii) a statistical test that, exploiting the maximum deviation of\nthe normalized rich-club coefficient attributes a unique p-value of\nrich-clubness to a given network. In conclusion, this study proposes the first\nattempt to quantify, using a unique measure, whether a network presents a\nsignificant rich-club topological organization. The general impact of our study\non engineering and science is that simulations investigating how the functional\nperformance of a network is changing in relation to rich-clubness might be more\neasily tuned controlling one unique value: the proposed rich-clubness measure.",
    "published_date": "2017-04-11T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cond-mat.dis-nn",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03526v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.03441v1",
    "title": "Node-centric community detection in multilayer networks with layer-coverage diversification bias",
    "authors": [
      "Roberto Interdonato",
      "Andrea Tagarelli",
      "Dino Ienco",
      "Arnaud Sallaberry",
      "Pascal Poncelet"
    ],
    "author_ids": [],
    "abstract": "The problem of node-centric, or local, community detection in information\nnetworks refers to the identification of a community for a given input node,\nhaving limited information about the network topology. Existing methods for\nsolving this problem, however, are not conceived to work on complex networks.\nIn this paper, we propose a novel framework for local community detection based\non the multilayer network model. Our approach relies on the maximization of the\nratio between the community internal connection density and the external\nconnection density, according to multilayer similarity-based community\nrelations. We also define a biasing scheme that allows the discovery of local\ncommunities characterized by different degrees of layer-coverage\ndiversification. Experimental evaluation conducted on real-world multilayer\nnetworks has shown the significance of our approach.",
    "published_date": "2017-04-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03441v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.03361v1",
    "title": "Societal impacts of big data: challenges and opportunities in Europe",
    "authors": [
      "Martí Cuquet",
      "Guillermo Vega-Gorgojo",
      "Hans Lammerant",
      "Rachel Finn",
      "Umair ul Hassan"
    ],
    "author_ids": [],
    "abstract": "This paper presents the risks and opportunities of big data and the potential\nsocial benefits it can bring. The research is based on an analysis of the\nsocietal impacts observed in a set of six case studies across different\nEuropean sectors. These impacts are divided into economic, social and ethical,\nlegal and political impacts, and affect areas such as improved efficiency,\ninnovation and decision making, changing business models, dependency on public\nfunding, participation, equality, discrimination and trust, data protection and\nintellectual property rights, private and public tensions and losing control to\nactors abroad. A special focus is given to the risks and opportunities coming\nfrom the legal framework and how to counter the negative impacts of big data.\nRecommendations are presented for four specific legal frameworks: copyright and\ndatabase protection, protection of trade secrets, privacy and data protection\nand anti-discrimination. In addition, the potential social benefits of big data\nare exemplified in six domains: improved decision making and event detection;\ndata-driven innovations and new business models; direct social, environmental\nand other citizen benefits; citizen participation, transparency and public\ntrust; privacy-aware data practices; and big data for identifying\ndiscrimination. Several best practices are suggested to capture these benefits.",
    "published_date": "2017-04-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03361v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.03354v1",
    "title": "Optimized Data Pre-Processing for Discrimination Prevention",
    "authors": [
      "Flavio P. Calmon",
      "Dennis Wei",
      "Karthikeyan Natesan Ramamurthy",
      "Kush R. Varshney"
    ],
    "author_ids": [],
    "abstract": "Non-discrimination is a recognized objective in algorithmic decision making.\nIn this paper, we introduce a novel probabilistic formulation of data\npre-processing for reducing discrimination. We propose a convex optimization\nfor learning a data transformation with three goals: controlling\ndiscrimination, limiting distortion in individual data samples, and preserving\nutility. We characterize the impact of limited sample size in accomplishing\nthis objective, and apply two instances of the proposed optimization to\ndatasets, including one on real-world criminal recidivism. The results\ndemonstrate that all three criteria can be simultaneously achieved and also\nreveal interesting patterns of bias in American society.",
    "published_date": "2017-04-11T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03354v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.03141v1",
    "title": "Federated Tensor Factorization for Computational Phenotyping",
    "authors": [
      "Yejin Kim",
      "Jimeng Sun",
      "Hwanjo Yu",
      "Xiaoqian Jiang"
    ],
    "author_ids": [],
    "abstract": "Tensor factorization models offer an effective approach to convert massive\nelectronic health records into meaningful clinical concepts (phenotypes) for\ndata analysis. These models need a large amount of diverse samples to avoid\npopulation bias. An open challenge is how to derive phenotypes jointly across\nmultiple hospitals, in which direct patient-level data sharing is not possible\n(e.g., due to institutional policies). In this paper, we developed a novel\nsolution to enable federated tensor factorization for computational phenotyping\nwithout sharing patient-level data. We developed secure data harmonization and\nfederated computation procedures based on alternating direction method of\nmultipliers (ADMM). Using this method, the multiple hospitals iteratively\nupdate tensors and transfer secure summarized information to a central server,\nand the server aggregates the information to generate phenotypes. We\ndemonstrated with real medical datasets that our method resembles the\ncentralized training model (based on combined datasets) in terms of accuracy\nand phenotypes discovery while respecting privacy.",
    "published_date": "2017-04-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.03141v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.02801v2",
    "title": "Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes",
    "authors": [
      "Ahmed M. Alaa",
      "Mihaela van der Schaar"
    ],
    "author_ids": [],
    "abstract": "Predicated on the increasing abundance of electronic health records, we\ninvesti- gate the problem of inferring individualized treatment effects using\nobservational data. Stemming from the potential outcomes model, we propose a\nnovel multi- task learning framework in which factual and counterfactual\noutcomes are mod- eled as the outputs of a function in a vector-valued\nreproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian\nmethod for learning the treatment effects using a multi-task Gaussian process\n(GP) with a linear coregion- alization kernel as a prior over the vvRKHS. The\nBayesian approach allows us to compute individualized measures of confidence in\nour estimates via pointwise credible intervals, which are crucial for realizing\nthe full potential of precision medicine. The impact of selection bias is\nalleviated via a risk-based empirical Bayes method for adapting the multi-task\nGP prior, which jointly minimizes the empirical error in factual outcomes and\nthe uncertainty in (unobserved) counter- factual outcomes. We conduct\nexperiments on observational datasets for an inter- ventional social program\napplied to premature infants, and a left ventricular assist device applied to\ncardiac patients wait-listed for a heart transplant. In both experi- ments, we\nshow that our method significantly outperforms the state-of-the-art.",
    "published_date": "2017-04-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.02801v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.02634v2",
    "title": "Rényi entropy power inequality and a reverse",
    "authors": [
      "Jiange Li"
    ],
    "author_ids": [],
    "abstract": "This paper is twofold. In the first part, we present a refinement of the\nR\\'enyi Entropy Power Inequality (EPI) recently obtained in \\cite{BM16}. The\nproof largely follows the approach in \\cite{DCT91} of employing Young's\nconvolution inequalities with sharp constants. In the second part, we study the\nreversibility of the R\\'enyi EPI, and confirm a conjecture in \\cite{BNT15,\nMMX16} in two cases. Connections with various $p$-th mean bodies in convex\ngeometry are also explored.",
    "published_date": "2017-04-09T00:00:00",
    "year": 2017,
    "categories": [
      "math.PR",
      "cs.IT",
      "math.FA",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.02634v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.02231v1",
    "title": "Clothing and People - A Social Signal Processing Perspective",
    "authors": [
      "Maedeh Aghaei",
      "Federico Parezzan",
      "Mariella Dimiccoli",
      "Petia Radeva",
      "Marco Cristani"
    ],
    "author_ids": [],
    "abstract": "In our society and century, clothing is not anymore used only as a means for\nbody protection. Our paper builds upon the evidence, studied within the social\nsciences, that clothing brings a clear communicative message in terms of social\nsignals, influencing the impression and behaviour of others towards a person.\nIn fact, clothing correlates with personality traits, both in terms of\nself-assessment and assessments that unacquainted people give to an individual.\nThe consequences of these facts are important: the influence of clothing on the\ndecision making of individuals has been investigated in the literature, showing\nthat it represents a discriminative factor to differentiate among diverse\ngroups of people. Unfortunately, this has been observed after cumbersome and\nexpensive manual annotations, on very restricted populations, limiting the\nscope of the resulting claims. With this position paper, we want to sketch the\nmain steps of the very first systematic analysis, driven by social signal\nprocessing techniques, of the relationship between clothing and social signals,\nboth sent and perceived. Thanks to human parsing technologies, which exhibit\nhigh robustness owing to deep learning architectures, we are now capable to\nisolate visual patterns characterising a large types of garments. These\nalgorithms will be used to capture statistical relations on a large corpus of\nevidence to confirm the sociological findings and to go beyond the state of the\nart.",
    "published_date": "2017-04-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.02231v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.02218v1",
    "title": "Investigating Natural Image Pleasantness Recognition using Deep Features and Eye Tracking for Loosely Controlled Human-computer Interaction",
    "authors": [
      "Hamed R. Tavakoli",
      "Jorma Laaksonen",
      "Esa Rahtu"
    ],
    "author_ids": [],
    "abstract": "This paper revisits recognition of natural image pleasantness by employing\ndeep convolutional neural networks and affordable eye trackers. There exist\nseveral approaches to recognize image pleasantness: (1) computer vision, and\n(2) psychophysical signals. For natural images, computer vision approaches have\nnot been as successful as for abstract paintings and is lagging behind the\npsychophysical signals like eye movements. Despite better results, the\nscalability of eye movements is adversely affected by the sensor cost. While\nthe introduction of affordable sensors have helped the scalability issue by\nmaking the sensors more accessible, the application of such sensors in a\nloosely controlled human-computer interaction setup is not yet studied for\naffective image tagging. On the other hand, deep convolutional neural networks\nhave boosted the performance of vision-based techniques significantly in recent\nyears. To investigate the current status in regard to affective image tagging,\nwe (1) introduce a new eye movement dataset using an affordable eye tracker,\n(2) study the use of deep neural networks for pleasantness recognition, (3)\ninvestigate the gap between deep features and eye movements. To meet these\nends, we record eye movements in a less controlled setup, akin to daily\nhuman-computer interaction. We assess features from eye movements, visual\nfeatures, and their combination. Our results show that (1) recognizing natural\nimage pleasantness from eye movement under less restricted setup is difficult\nand previously used techniques are prone to fail, and (2) visual class\ncategories are strong cues for predicting pleasantness, due to their\ncorrelation with emotions, necessitating careful study of this phenomenon. This\nlatter finding is alerting as some deep learning approaches may fit to the\nclass category bias.",
    "published_date": "2017-04-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.02218v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.02183v3",
    "title": "Proportional Approval Voting, Harmonic k-median, and Negative Association",
    "authors": [
      "Jarosław Byrka",
      "Piotr Skowron",
      "Krzysztof Sornat"
    ],
    "author_ids": [],
    "abstract": "We study a generic framework that provides a unified view on two important\nclasses of problems: (i) extensions of the k-median problem where clients are\ninterested in having multiple facilities in their vicinity (e.g., due to the\nfact that, with some small probability, the closest facility might be\nmalfunctioning and so might not be available for using), and (ii) finding\nwinners according to some appealing multiwinner election rules, i.e., election\nsystem aimed for choosing representatives bodies, such as parliaments, based on\npreferences of a population of voters over individual candidates. Each problem\nin our framework is associated with a vector of weights: we show that the\napproximability of the problem depends on structural properties of these\nvectors. We specifically focus on the harmonic sequence of weights for which\nthe objective function interpreted in a multiwinner election setup reflects to\nthe well-known Proportional Approval Voting (PAV) rule.\n  Our main result is that, due to the specific (harmonic) structure of weights,\nthe problem allows constant factor approximation. This is surprising since the\nproblem can be interpreted as a variant of the k-median problem where we do not\nassume that the connection costs satisfy the triangle inequality. The algorithm\nwe propose is based on dependent rounding [Srinivasan, FOCS'01] applied to the\nsolution of a natural LP-relaxation of the problem. The rounding process is\nwell known to produce distributions over integral solutions satisfying Negative\nCorrelation (NC), which is usually sufficient for the analysis of approximation\nguarantees offered by rounding procedures. In our analysis, however, we need to\nuse the fact that the carefully implemented rounding process satisfies a\nstronger property, called Negative Association (NA), which allows us to apply\nstandard concentration bounds for conditional random variables.",
    "published_date": "2017-04-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.GT",
      "68W20, 68W25, 68Q25",
      "F.2.2; G.3; I.2.11"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.02183v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.01754v2",
    "title": "Enhance Feature Discrimination for Unsupervised Hashing",
    "authors": [
      "Tuan Hoang",
      "Thanh-Toan Do",
      "Dang-Khoa Le Tan",
      "Ngai-Man Cheung"
    ],
    "author_ids": [],
    "abstract": "We introduce a novel approach to improve unsupervised hashing. Specifically,\nwe propose a very efficient embedding method: Gaussian Mixture Model embedding\n(Gemb). The proposed method, using Gaussian Mixture Model, embeds feature\nvector into a low-dimensional vector and, simultaneously, enhances the\ndiscriminative property of features before passing them into hashing. Our\nexperiment shows that the proposed method boosts the hashing performance of\nmany state-of-the-art, e.g. Binary Autoencoder (BA) [1], Iterative Quantization\n(ITQ) [2], in standard evaluation metrics for the three main benchmark\ndatasets.",
    "published_date": "2017-04-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01754v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1704.01722v3",
    "title": "On the equivalence between multiclass processor sharing and random order scheduling policies",
    "authors": [
      "Konstantin Avrachenkov",
      "Tejas Bodas"
    ],
    "author_ids": [],
    "abstract": "Consider a single server system serving a multiclass population. Some popular\nscheduling policies for such system are the discriminatory processor sharing\n(DPS), discriminatory random order service (DROS), generalized processor\nsharing (GPS) and weighted fair queueing (WFQ). In this paper, we propose two\nclasses of policies, namely MPS (multiclass processor sharing) and MROS\n(multiclass random order service), that generalize the four policies mentioned\nabove. For the special case when the multiclass population arrive according to\nPoisson processes and have independent and exponential service requirement with\nparameter $\\mu$, we show that the tail of the sojourn time distribution for a\nclass $i$ customer in a system with the MPS policy is a constant multiple of\nthe tail of the waiting time distribution of a class $i$ customer in a system\nwith the MROS policy. This result implies that for a class $i$ customer, the\ntail of the sojourn time distribution in a system with the DPS (GPS) scheduling\npolicy is a constant multiple of the tail of the waiting time distribution in a\nsystem with the DROS (respectively WFQ) policy.",
    "published_date": "2017-04-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.PF",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01722v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.01347v1",
    "title": "Quantifying Search Bias: Investigating Sources of Bias for Political Searches in Social Media",
    "authors": [
      "Juhi Kulshrestha",
      "Motahhare Eslami",
      "Johnnatan Messias",
      "Muhammad Bilal Zafar",
      "Saptarshi Ghosh",
      "Krishna P. Gummadi",
      "Karrie Karahalios"
    ],
    "author_ids": [],
    "abstract": "Search systems in online social media sites are frequently used to find\ninformation about ongoing events and people. For topics with multiple competing\nperspectives, such as political events or political candidates, bias in the top\nranked results significantly shapes public opinion. However, bias does not\nemerge from an algorithm alone. It is important to distinguish between the bias\nthat arises from the data that serves as the input to the ranking system and\nthe bias that arises from the ranking system itself. In this paper, we propose\na framework to quantify these distinct biases and apply this framework to\npolitics-related queries on Twitter. We found that both the input data and the\nranking system contribute significantly to produce varying amounts of bias in\nthe search results and in different ways. We discuss the consequences of these\nbiases and possible mechanisms to signal this bias in social media search\nsystems' interfaces.",
    "published_date": "2017-04-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01347v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.01572v1",
    "title": "Inferring Personal Economic Status from Social Network Location",
    "authors": [
      "Shaojun Luo",
      "Flaviano Morone",
      "Carlos Sarraute",
      "Matías Travizano",
      "Hernán A. Makse"
    ],
    "author_ids": [],
    "abstract": "It is commonly believed that patterns of social ties affect individuals'\neconomic status. Here, we translate this concept into an operational definition\nat the network level, which allows us to infer the economic wellbeing of\nindividuals through a measure of their location and influence in the social\nnetwork. We analyze two large-scale sources: telecommunications and financial\ndata of a whole country's population. Our results show that an individual's\nlocation, measured as the optimal collective influence to the structural\nintegrity of the social network, is highly correlated with personal economic\nstatus. The observed social network patterns of influence mimics the patterns\nof economic inequality. For pragmatic use and validation, we carry out a\nmarketing campaign that shows a three-fold increase in response rate by\ntargeting individuals identified by our social network metrics as compared to\nrandom targeting. Our strategy can also be useful in maximizing the effects of\nlarge-scale economic stimulus policies.",
    "published_date": "2017-04-05T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cs.SI",
      "91D30, 05C82"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01572v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.01177v2",
    "title": "Combinatorial Entropy Power Inequalities: A Preliminary Study of the Stam region",
    "authors": [
      "Mokshay Madiman",
      "Farhad Ghassemi"
    ],
    "author_ids": [],
    "abstract": "We initiate the study of the Stam region, defined as the subset of the\npositive orthant in $\\mathbb{R}^{2^n-1}$ that arises from considering entropy\npowers of subset sums of $n$ independent random vectors in a Euclidean space of\nfinite dimension. We show that the class of fractionally superadditive set\nfunctions provides an outer bound to the Stam region, resolving a conjecture of\nA. R. Barron and the first author. On the other hand, the entropy power of a\nsum of independent random vectors is not supermodular in any dimension. We also\ndevelop some qualitative properties of the Stam region, showing for instance\nthat its closure is a logarithmically convex cone.",
    "published_date": "2017-04-04T00:00:00",
    "year": 2017,
    "categories": [
      "math.PR",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01177v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.00575v1",
    "title": "Sparse mean localization by information theory",
    "authors": [
      "Emiliano Diaz"
    ],
    "author_ids": [],
    "abstract": "Sparse feature selection is necessary when we fit statistical models, we have\naccess to a large group of features, don't know which are relevant, but assume\nthat most are not. Alternatively, when the number of features is larger than\nthe available data the model becomes over parametrized and the sparse feature\nselection task involves selecting the most informative variables for the model.\nWhen the model is a simple location model and the number of relevant features\ndoes not grow with the total number of features, sparse feature selection\ncorresponds to sparse mean estimation. We deal with a simplified mean\nestimation problem consisting of an additive model with gaussian noise and mean\nthat is in a restricted, finite hypothesis space. This restriction simplifies\nthe mean estimation problem into a selection problem of combinatorial nature.\nAlthough the hypothesis space is finite, its size is exponential in the\ndimension of the mean. In limited data settings and when the size of the\nhypothesis space depends on the amount of data or on the dimension of the data,\nchoosing an approximation set of hypotheses is a desirable approach. Choosing a\nset of hypotheses instead of a single one implies replacing the bias-variance\ntrade off with a resolution-stability trade off. Generalization capacity\nprovides a resolution selection criterion based on allowing the learning\nalgorithm to communicate the largest amount of information in the data to the\nlearner without error. In this work the theory of approximation set coding and\ngeneralization capacity is explored in order to understand this approach. We\nthen apply the generalization capacity criterion to the simplified sparse mean\nestimation problem and detail an importance sampling algorithm which at once\nsolves the difficulty posed by large hypothesis spaces and the slow convergence\nof uniform sampling algorithms.",
    "published_date": "2017-04-03T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.00575v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.00534v1",
    "title": "Controlling a triangular flexible formation of autonomous agents",
    "authors": [
      "Hector Garcia de Marina",
      "Zhiyong Sun",
      "Ming Cao",
      "Brian D. O. Anderson"
    ],
    "author_ids": [],
    "abstract": "In formation control, triangular formations consisting of three autonomous\nagents serve as a class of benchmarks that can be used to test and compare the\nperformances of different controllers. We present an algorithm that combines\nthe advantages of both position- and distance-based gradient descent control\nlaws. For example, only two pairs of neighboring agents need to be controlled,\nagents can work in their own local frame of coordinates and the orientation of\nthe formation with respect to a global frame of coordinates is not prescribed.\nWe first present a novel technique based on adding artificial biases to\nneighboring agents' range sensors such that their eventual positions correspond\nto a collinear configuration. Right after, a small modification in the bias\nterms by introducing a prescribed rotation matrix will allow the control of the\nbearing of the neighboring agents.",
    "published_date": "2017-04-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.00534v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1704.00222v3",
    "title": "Fair Allocation of Indivisible Goods: Improvement and Generalization",
    "authors": [
      "Mohammad Ghodsi",
      "MohammadTaghi Hajiaghayi",
      "Masoud Seddighin",
      "Saeed Seddighin",
      "Hadi Yami"
    ],
    "author_ids": [],
    "abstract": "We study the problem of fair allocation for indivisible goods. We use the the\nmaxmin share paradigm introduced by Budish as a measure for fairness. Procaccia\nand Wang (EC'14) were first to investigate this fundamental problem in the\nadditive setting. In contrast to what real-world experiments suggest, they show\nthat a maxmin guarantee (1-MMS allocation) is not always possible even when the\nnumber of agents is limited to 3. While the existence of an approximation\nsolution (e.g. a $1/2$-MMS allocation) is quite straightforward, improving the\nguarantee becomes subtler for larger constants. Procaccia provide a proof for\nexistence of a $2/3$-MMS allocation and leave the question open for better\nguarantees.\n  Our main contribution is an answer to the above question. We improve the\nresult of [Procaccia and Wang] to a $3/4$ factor in the additive setting. The\nmain idea for our $3/4$-MMS allocation method is clustering the agents. To this\nend, we introduce three notions and techniques, namely reducibility, matching\nallocation, and cycle-envy-freeness, and prove the approximation guarantee of\nour algorithm via non-trivial applications of these techniques. Our analysis\ninvolves coloring and double counting arguments that might be of independent\ninterest.\n  One major shortcoming of the current studies on fair allocation is the\nadditivity assumption on the valuations. We alleviate this by extending our\nresults to the case of submodular, fractionally subadditive, and subadditive\nsettings. More precisely, we give constant approximation guarantees for\nsubmodular and XOS agents, and a logarithmic approximation for the case of\nsubadditive agents. Furthermore, we complement our results by providing close\nupper bounds for each class of valuation functions. Finally, we present\nalgorithms to find such allocations for additive, submodular, and XOS settings\nin polynomial time.",
    "published_date": "2017-04-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.00222v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.10897v6",
    "title": "Multi-unit Assignment under Dichotomous Preferences",
    "authors": [
      "Josue Ortega"
    ],
    "author_ids": [],
    "abstract": "I study the problem of allocating objects among agents without using money.\nAgents can receive several objects and have dichotomous preferences, meaning\nthat they either consider objects to be acceptable or not. In this setup, the\negalitarian solution is more appealing than the competitive equilibrium with\nequal incomes because it is Lorenz dominant, unique in utilities, and group\nstrategy-proof. Moreover, it can be adapted to satisfy a new fairness axiom\nthat arises naturally in this context. Both solutions are disjoint.",
    "published_date": "2017-03-31T00:00:00",
    "year": 2017,
    "categories": [
      "q-fin.EC",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10897v6",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.10729v1",
    "title": "Deep Domain Adaptation Based Video Smoke Detection using Synthetic Smoke Images",
    "authors": [
      "Gao Xu",
      "Yongming Zhang",
      "Qixing Zhang",
      "Gaohua Lin",
      "Jinjun Wang"
    ],
    "author_ids": [],
    "abstract": "In this paper, a deep domain adaptation based method for video smoke\ndetection is proposed to extract a powerful feature representation of smoke.\nDue to the smoke image samples limited in scale and diversity for deep CNN\ntraining, we systematically produced adequate synthetic smoke images with a\nwide variation in the smoke shape, background and lighting conditions.\nConsidering that the appearance gap (dataset bias) between synthetic and real\nsmoke images degrades significantly the performance of the trained model on the\ntest set composed fully of real images, we build deep architectures based on\ndomain adaptation to confuse the distributions of features extracted from\nsynthetic and real smoke images. This approach expands the domain-invariant\nfeature space for smoke image samples. With their approximate feature\ndistribution off non-smoke images, the recognition rate of the trained model is\nimproved significantly compared to the model trained directly on mixed dataset\nof synthetic and real images. Experimentally, several deep architectures with\ndifferent design choices are applied to the smoke detector. The ultimate\nframework can get a satisfactory result on the test set. We believe that our\napproach is a start in the direction of utilizing deep neural networks enhanced\nwith synthetic smoke images for video smoke detection.",
    "published_date": "2017-03-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "68T45",
      "I.4.9; I.5.4; I.6.8; J.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10729v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.10725v1",
    "title": "UNBIAS PUF: A Physical Implementation Bias Agnostic Strong PUF",
    "authors": [
      "Wei-Che Wang",
      "Zhuoqi Li",
      "Joseph Skudlarek",
      "Mario Larouche",
      "Michael Chen",
      "Puneet Gupta"
    ],
    "author_ids": [],
    "abstract": "The Physical Unclonable Function (PUF) is a promising hardware security\nprimitive because of its inherent uniqueness and low cost. To extract the\ndevice-specific variation from delay-based strong PUFs, complex routing\nconstraints are imposed to achieve symmetric path delays; and systematic\nvariations can severely compromise the uniqueness of the PUF. In addition, the\nmetastability of the arbiter circuit of an Arbiter PUF can also degrade the\nquality of the PUF due to the induced instability. In this paper we propose a\nnovel strong UNBIAS PUF that can be implemented purely by Register Transfer\nLanguage (RTL), such as verilog, without imposing any physical design\nconstraints or delay characterization effort to solve the aforementioned\nissues. Efficient inspection bit prediction models for unbiased response\nextraction are proposed and validated. Our experimental results of the strong\nUNBIAS PUF show 5.9% intra-Fractional Hamming Distance (FHD) and 45.1%\ninter-FHD on 7 Field Programmable Gate Array (FPGA) boards without applying any\nphysical layout constraints or additional XOR gates. The UNBIAS PUF is also\nscalable because no characterization cost is required for each challenge to\ncompensate the implementation bias. The averaged intra-FHD measured at worst\ntemperature and voltage variation conditions is 12%, which is still below the\nmargin of practical Error Correction Code (ECC) with error reduction techniques\nfor PUFs.",
    "published_date": "2017-03-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10725v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.10579v1",
    "title": "Evaluating Complex Task through Crowdsourcing: Multiple Views Approach",
    "authors": [
      "Lingyu Lyu",
      "Mehmed Kantardzic"
    ],
    "author_ids": [],
    "abstract": "With the popularity of massive open online courses, grading through\ncrowdsourcing has become a prevalent approach towards large scale classes.\nHowever, for getting grades for complex tasks, which require specific skills\nand efforts for grading, crowdsourcing encounters a restriction of insufficient\nknowledge of the workers from the crowd. Due to knowledge limitation of the\ncrowd graders, grading based on partial perspectives becomes a big challenge\nfor evaluating complex tasks through crowdsourcing. Especially for those tasks\nwhich not only need specific knowledge for grading, but also should be graded\nas a whole instead of being decomposed into smaller and simpler subtasks. We\npropose a framework for grading complex tasks via multiple views, which are\ndifferent grading perspectives defined by experts for the task, to provide\nuniformity. Aggregation algorithm based on graders variances are used to\ncombine the grades for each view. We also detect bias patterns of the graders,\nand debias them regarding each view of the task. Bias pattern determines how\nthe behavior is biased among graders, which is detected by a statistical\ntechnique. The proposed approach is analyzed on a synthetic data set. We show\nthat our model gives more accurate results compared to the grading approaches\nwithout different views and debiasing algorithm.",
    "published_date": "2017-03-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10579v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.10530v1",
    "title": "Efficient optimization for Hierarchically-structured Interacting Segments (HINTS)",
    "authors": [
      "Hossam Isack",
      "Olga Veksler",
      "Ipek Oguz",
      "Milan Sonka",
      "Yuri Boykov"
    ],
    "author_ids": [],
    "abstract": "We propose an effective optimization algorithm for a general hierarchical\nsegmentation model with geometric interactions between segments. Any given tree\ncan specify a partial order over object labels defining a hierarchy. It is\nwell-established that segment interactions, such as inclusion/exclusion and\nmargin constraints, make the model significantly more discriminant. However,\nexisting optimization methods do not allow full use of such models. Generic\n-expansion results in weak local minima, while common binary multi-layered\nformulations lead to non-submodularity, complex high-order potentials, or polar\ndomain unwrapping and shape biases. In practice, applying these methods to\narbitrary trees does not work except for simple cases. Our main contribution is\nan optimization method for the Hierarchically-structured Interacting Segments\n(HINTS) model with arbitrary trees. Our Path-Moves algorithm is based on\nmulti-label MRF formulation and can be seen as a combination of well-known\na-expansion and Ishikawa techniques. We show state-of-the-art biomedical\nsegmentation for many diverse examples of complex trees.",
    "published_date": "2017-03-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10530v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.10090v1",
    "title": "A Short Review of Ethical Challenges in Clinical Natural Language Processing",
    "authors": [
      "Simon Šuster",
      "Stéphan Tulkens",
      "Walter Daelemans"
    ],
    "author_ids": [],
    "abstract": "Clinical NLP has an immense potential in contributing to how clinical\npractice will be revolutionized by the advent of large scale processing of\nclinical records. However, this potential has remained largely untapped due to\nslow progress primarily caused by strict data access policies for researchers.\nIn this paper, we discuss the concern for privacy and the measures it entails.\nWe also suggest sources of less sensitive data. Finally, we draw attention to\nbiases that can compromise the validity of empirical research and lead to\nsocially harmful applications.",
    "published_date": "2017-03-29T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.10090v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.09625v4",
    "title": "Learning and Refining of Privileged Information-based RNNs for Action Recognition from Depth Sequences",
    "authors": [
      "Zhiyuan Shi",
      "Tae-Kyun Kim"
    ],
    "author_ids": [],
    "abstract": "Existing RNN-based approaches for action recognition from depth sequences\nrequire either skeleton joints or hand-crafted depth features as inputs. An\nend-to-end manner, mapping from raw depth maps to action classes, is\nnon-trivial to design due to the fact that: 1) single channel map lacks texture\nthus weakens the discriminative power; 2) relatively small set of depth\ntraining data. To address these challenges, we propose to learn an RNN driven\nby privileged information (PI) in three-steps: An encoder is pre-trained to\nlearn a joint embedding of depth appearance and PI (i.e. skeleton joints). The\nlearned embedding layers are then tuned in the learning step, aiming to\noptimize the network by exploiting PI in a form of multi-task loss. However,\nexploiting PI as a secondary task provides little help to improve the\nperformance of a primary task (i.e. classification) due to the gap between\nthem. Finally, a bridging matrix is defined to connect two tasks by discovering\nlatent PI in the refining step. Our PI-based classification loss maintains a\nconsistency between latent PI and predicted distribution. The latent PI and\nnetwork are iteratively estimated and updated in an expectation-maximization\nprocedure. The proposed learning process provides greater discriminative power\nto model subtle depth difference, while helping avoid overfitting the scarcer\ntraining data. Our experiments show significant performance gains over\nstate-of-the-art methods on three public benchmark datasets and our newly\ncollected Blanket dataset.",
    "published_date": "2017-03-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.09625v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.09480v1",
    "title": "Simulated Data Experiments for Time Series Classification Part 1: Accuracy Comparison with Default Settings",
    "authors": [
      "Anthony Bagnall",
      "Aaron Bostrom",
      "James Large",
      "Jason Lines"
    ],
    "author_ids": [],
    "abstract": "There are now a broad range of time series classification (TSC) algorithms\ndesigned to exploit different representations of the data. These have been\nevaluated on a range of problems hosted at the UCR-UEA TSC Archive\n(www.timeseriesclassification.com), and there have been extensive comparative\nstudies. However, our understanding of why one algorithm outperforms another is\nstill anecdotal at best. This series of experiments is meant to help provide\ninsights into what sort of discriminatory features in the data lead one set of\nalgorithms that exploit a particular representation to be better than other\nalgorithms. We categorise five different feature spaces exploited by TSC\nalgorithms then design data simulators to generate randomised data from each\nrepresentation. We describe what results we expected from each class of\nalgorithm and data representation, then observe whether these prior beliefs are\nsupported by the experimental evidence. We provide an open source\nimplementation of all the simulators to allow for the controlled testing of\nhypotheses relating to classifier performance on different data\nrepresentations. We identify many surprising results that confounded our\nexpectations, and use these results to highlight how an over simplified view of\nclassifier structure can often lead to erroneous prior beliefs. We believe\nensembling can often overcome prior bias, and our results support the belief by\nshowing that the ensemble approach adopted by the Hierarchical Collective of\nTransform based Ensembles (HIVE-COTE) is significantly better than the\nalternatives when the data representation is unknown, and is significantly\nbetter than, or not significantly significantly better than, or not\nsignificantly worse than, the best other approach on three out of five of the\nindividual simulators.",
    "published_date": "2017-03-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.09480v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.09430v4",
    "title": "Polling bias and undecided voter allocations: US Presidential elections, 2004 - 2016",
    "authors": [
      "Joshua J Bon",
      "Timothy Ballard",
      "Bernard Baffour"
    ],
    "author_ids": [],
    "abstract": "Accounting for undecided and uncertain voters is a challenging issue for\npredicting election results from public opinion polls. Undecided voters typify\nthe uncertainty of swing voters in polls but are often ignored or allocated to\neach candidate in a simple, deterministic manner. Historically this may have\nbeen adequate because the undecided were comparatively small enough to assume\nthat they do not affect the relative proportions of the decided voters.\nHowever, in the presence of high numbers of undecided voters, these static\nrules may in fact bias election predictions from election poll authors and\nmeta-poll analysts. In this paper, we examine the effect of undecided voters in\nthe 2016 US presidential election to the previous three presidential elections.\nWe show there were a relatively high number of undecided voters over the\ncampaign and on election day, and that the allocation of undecided voters in\nthis election was not consistent with two-party proportional (or even)\nallocations. We find evidence that static allocation regimes are inadequate for\nelection prediction models and that probabilistic allocations may be superior.\nWe also estimate the bias attributable to polling agencies, often referred to\nas \"house effects\".",
    "published_date": "2017-03-28T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.09430v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.08776v1",
    "title": "Assortative Mixing Equilibria in Social Network Games",
    "authors": [
      "Chen Avin",
      "Hadassa Daltrophe",
      "Zvi Lotker",
      "David Peleg"
    ],
    "author_ids": [],
    "abstract": "It is known that individuals in social networks tend to exhibit homophily\n(a.k.a. assortative mixing) in their social ties, which implies that they\nprefer bonding with others of their own kind. But what are the reasons for this\nphenomenon? Is it that such relations are more convenient and easier to\nmaintain? Or are there also some more tangible benefits to be gained from this\ncollective behaviour?\n  The current work takes a game-theoretic perspective on this phenomenon, and\nstudies the conditions under which different assortative mixing strategies lead\nto equilibrium in an evolving social network. We focus on a biased preferential\nattachment model where the strategy of each group (e.g., political or social\nminority) determines the level of bias of its members toward other group\nmembers and non-members. Our first result is that if the utility function that\nthe group attempts to maximize is the degree centrality of the group,\ninterpreted as the sum of degrees of the group members in the network, then the\nonly strategy achieving Nash equilibrium is a perfect homophily, which implies\nthat cooperation with other groups is harmful to this utility function. A\nsecond, and perhaps more surprising, result is that if a reward for inter-group\ncooperation is added to the utility function (e.g., externally enforced by an\nauthority as a regulation), then there are only two possible equilibria,\nnamely, perfect homophily or perfect heterophily, and it is possible to\ncharacterize their feasibility spaces. Interestingly, these results hold\nregardless of the minority-majority ratio in the population.\n  We believe that these results, as well as the game-theoretic perspective\npresented herein, may contribute to a better understanding of the forces that\nshape the groups and communities of our society.",
    "published_date": "2017-03-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.GT",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.08776v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.08497v1",
    "title": "Local Deep Neural Networks for Age and Gender Classification",
    "authors": [
      "Zukang Liao",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "author_ids": [],
    "abstract": "Local deep neural networks have been recently introduced for gender\nrecognition. Although, they achieve very good performance they are very\ncomputationally expensive to train. In this work, we introduce a simplified\nversion of local deep neural networks which significantly reduces the training\ntime. Instead of using hundreds of patches per image, as suggested by the\noriginal method, we propose to use 9 overlapping patches per image which cover\nthe entire face region. This results in a much reduced training time, since\njust 9 patches are extracted per image instead of hundreds, at the expense of a\nslightly reduced performance. We tested the proposed modified local deep neural\nnetworks approach on the LFW and Adience databases for the task of gender and\nage classification. For both tasks and both databases the performance is up to\n1% lower compared to the original version of the algorithm. We have also\ninvestigated which patches are more discriminative for age and gender\nclassification. It turns out that the mouth and eyes regions are useful for age\nclassification, whereas just the eye region is useful for gender\nclassification.",
    "published_date": "2017-03-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.08497v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.08150v2",
    "title": "Competitive Equilibrium with Indivisible Goods and Generic Budgets",
    "authors": [
      "Moshe Babaioff",
      "Noam Nisan",
      "Inbal Talgam-Cohen"
    ],
    "author_ids": [],
    "abstract": "Competitive equilibrium from equal incomes (CEEI) is a classic solution to\nthe problem of fair and efficient allocation of goods [Foley'67, Varian'74].\nEvery agent receives an equal budget of artificial currency with which to\npurchase goods, and prices match demand and supply. However, a CEEI is not\nguaranteed to exist when the goods are indivisible, even in the simple\ntwo-agent, single-item market. Yet, it is easy to see that once the two budgets\nare slightly perturbed (made generic), a competitive equilibrium does exist.\n  In this paper we aim to extend this approach beyond the single-item case, and\nstudy the existence of equilibria in markets with two agents and additive\npreferences over multiple items. We show that for agents with equal budgets,\nmaking the budgets generic -- by adding vanishingly small random perturbations\n-- ensures the existence of an equilibrium. We further consider agents with\narbitrary non-equal budgets, representing non-equal entitlements for goods. We\nshow that competitive equilibrium guarantees a new notion of fairness among\nnon-equal agents, and that it exists in cases of interest (like when the agents\nhave identical preferences) if budgets are perturbed. Our results open\nopportunities for future research on generic equilibrium existence and fair\ntreatment of non-equals.",
    "published_date": "2017-03-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.08150v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.08071v1",
    "title": "Quantifying and suppressing ranking bias in a large citation network",
    "authors": [
      "Giacomo Vaccario",
      "Matus Medo",
      "Nicolas Wider",
      "Manuel Sebastian Mariani"
    ],
    "author_ids": [],
    "abstract": "It is widely recognized that citation counts for papers from different fields\ncannot be directly compared because different scientific fields adopt different\ncitation practices. Citation counts are also strongly biased by paper age since\nolder papers had more time to attract citations. Various procedures aim at\nsuppressing these biases and give rise to new normalized indicators, such as\nthe relative citation count. We use a large citation dataset from Microsoft\nAcademic Graph and a new statistical framework based on the Mahalanobis\ndistance to show that the rankings by well known indicators, including the\nrelative citation count and Google's PageRank score, are significantly biased\nby paper field and age. We propose a general normalization procedure motivated\nby the $z$-score which produces much less biased rankings when applied to\ncitation count and PageRank score.",
    "published_date": "2017-03-23T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cs.DL",
      "cs.IR",
      "physics.data-an",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.08071v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.07757v1",
    "title": "Ethical issues of ISPs in the modern web",
    "authors": [
      "Leonardo Regano",
      "Ali Safari Khatouni",
      "Martino Trevisan",
      "Alessio Viticchie"
    ],
    "author_ids": [],
    "abstract": "In recent years, ethical issues in the networking field are getting\nmoreimportant. In particular, there is a consistent debate about how Internet\nService Providers (ISPs) should collect and treat network measurements. This\nkind of information, such as flow records, carry interesting knowledge from\nmultiple points of view: research, traffic engineering and e-commerce can\nbenefit from measurements retrievable through inspection of network traffic.\nNevertheless, in some cases they can carry personal information about the users\nexposed to monitoring, and so generates several ethical issues. Modern web is\nvery different from the one we could experience few years ago; web services\nconverged to few protocols (i.e., HyperText Transfer Protocol (HTTP) and HTTPS)\nand always bigger share of encrypted traffic. The aim of this work is to\nprovide an insight about which information is still visible to ISPs in the\nmodern web and to what extent it carries personal information. We show ethical\nissues deriving by this new situation and provide general guidelines and\nbest-practices to cope with the collection of network traffic measurements.",
    "published_date": "2017-03-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.07757v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.07707v2",
    "title": "Existence of Stein Kernels under a Spectral Gap, and Discrepancy Bound",
    "authors": [
      "Thomas A. Courtade",
      "Max Fathi",
      "Ashwin Pananjady"
    ],
    "author_ids": [],
    "abstract": "We establish existence of Stein kernels for probability measures on\n$\\mathbb{R}^d$ satisfying a Poincar\\'e inequality, and obtain bounds on the\nStein discrepancy of such measures. Applications to quantitative central limit\ntheorems are discussed, including a new CLT in Wasserstein distance $W_2$ with\noptimal rate and dependence on the dimension. As a byproduct, we obtain a\nstability version of an estimate of the Poincar\\'e constant of probability\nmeasures under a second moment constraint. The results extend more generally to\nthe setting of converse weighted Poincar\\'e inequalities. The proof is based on\nsimple arguments of calculus of variations.\n  Further, we establish two general properties enjoyed by the Stein\ndiscrepancy, holding whenever a Stein kernel exists: Stein discrepancy is\nstrictly decreasing along the CLT, and it controls the skewness of a random\nvector.",
    "published_date": "2017-03-22T00:00:00",
    "year": 2017,
    "categories": [
      "math.PR",
      "cs.IT",
      "math.FA",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.07707v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.07518v1",
    "title": "Early Detection of Promoted Campaigns on Social Media",
    "authors": [
      "Onur Varol",
      "Emilio Ferrara",
      "Filippo Menczer",
      "Alessandro Flammini"
    ],
    "author_ids": [],
    "abstract": "Social media expose millions of users every day to information campaigns ---\nsome emerging organically from grassroots activity, others sustained by\nadvertising or other coordinated efforts. These campaigns contribute to the\nshaping of collective opinions. While most information campaigns are benign,\nsome may be deployed for nefarious purposes. It is therefore important to be\nable to detect whether a meme is being artificially promoted at the very moment\nit becomes wildly popular. This problem has important social implications and\nposes numerous technical challenges. As a first step, here we focus on\ndiscriminating between trending memes that are either organic or promoted by\nmeans of advertisement. The classification is not trivial: ads cause bursts of\nattention that can be easily mistaken for those of organic trends. We designed\na machine learning framework to classify memes that have been labeled as\ntrending on Twitter.After trending, we can rely on a large volume of activity\ndata. Early detection, occurring immediately at trending time, is a more\nchallenging problem due to the minimal volume of activity data that is\navailable prior to trending.Our supervised learning framework exploits hundreds\nof time-varying features to capture changing network and diffusion patterns,\ncontent and sentiment information, timing signals, and user meta-data. We\nexplore different methods for encoding feature time series. Using millions of\ntweets containing trending hashtags, we achieve 75% AUC score for early\ndetection, increasing to above 95% after trending. We evaluate the robustness\nof the algorithms by introducing random temporal shifts on the trend time\nseries. Feature selection analysis reveals that content cues provide\nconsistently useful signals; user features are more informative for early\ndetection, while network and timing features are more helpful once more data is\navailable.",
    "published_date": "2017-03-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.07518v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.07442v1",
    "title": "Comment on the Equality Condition for the I-MMSE Proof of Entropy Power Inequality",
    "authors": [
      "Alex Dytso",
      "Ronit Bustin",
      "H. Vincent Poor",
      "Shlomo Shamai"
    ],
    "author_ids": [],
    "abstract": "The paper establishes the equality condition in the I-MMSE proof of the\nentropy power inequality (EPI). This is done by establishing an exact\nexpression for the deficit between the two sides of the EPI. Interestingly, a\nnecessary condition for the equality is established by making a connection to\nthe famous Cauchy functional equation.",
    "published_date": "2017-03-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.07442v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.07043v1",
    "title": "Energy Efficient Power Control for the Two-tier Networks with Small Cells and Massive MIMO",
    "authors": [
      "Ningning Lu",
      "Yanxiang Jiang",
      "Fuchun Zheng",
      "Xiaohu You"
    ],
    "author_ids": [],
    "abstract": "In this paper, energy efficient power control for the uplink two-tier\nnetworks where a macrocell tier with a massive multiple-input multiple-output\n(MIMO) base station is overlaid with a small cell tier is investigated. We\npropose a distributed energy efficient power control algorithm which allows\neach user in the two-tier network taking individual decisions to optimize its\nown energy efficiency (EE) for the multi-user and multi-cell scenario. The\ndistributed power control algorithm is implemented by decoupling the EE\noptimization problem into two steps. In the first step, we propose to assign\nthe users on the same resource into the same group and each group can optimize\nits own EE, respectively. In the second step, multiple power control games\nbased on evolutionary game theory (EGT) are formulated for each group, which\nallows each user optimizing its own EE. In the EGT-based power control games,\neach player selects a strategy giving a higher payoff than the average payoff,\nwhich can improve the fairness among the users. The proposed algorithm has a\nlinear complexity with respect to the number of subcarriers and the number of\ncells in comparison with the brute force approach which has an exponential\ncomplexity. Simulation results show the remarkable improvements in terms of\nfairness by using the proposed algorithm.",
    "published_date": "2017-03-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI",
      "cs.GT",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.07043v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.06856v3",
    "title": "Counterfactual Fairness",
    "authors": [
      "Matt J. Kusner",
      "Joshua R. Loftus",
      "Chris Russell",
      "Ricardo Silva"
    ],
    "author_ids": [],
    "abstract": "Machine learning can impact people with legal or ethical consequences when it\nis used to automate decisions in areas such as insurance, lending, hiring, and\npredictive policing. In many of these scenarios, previous decisions have been\nmade that are unfairly biased against certain subpopulations, for example those\nof a particular race, gender, or sexual orientation. Since this past data may\nbe biased, machine learning predictors must account for this to avoid\nperpetuating or creating discriminatory practices. In this paper, we develop a\nframework for modeling fairness using tools from causal inference. Our\ndefinition of counterfactual fairness captures the intuition that a decision is\nfair towards an individual if it is the same in (a) the actual world and (b) a\ncounterfactual world where the individual belonged to a different demographic\ngroup. We demonstrate our framework on a real-world problem of fair prediction\nof success in law school.",
    "published_date": "2017-03-20T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.06856v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.06853v1",
    "title": "Modulus consensus in discrete-time signed networks and properties of special recurrent inequalities",
    "authors": [
      "Anton V. Proskurnikov",
      "Ming Cao"
    ],
    "author_ids": [],
    "abstract": "Recently the dynamics of signed networks, where the ties among the agents can\nbe both positive (attractive) or negative (repulsive) have attracted\nsubstantial attention of the research community. Examples of such networks are\nmodels of opinion dynamics over signed graphs, recently introduced by Altafini\n(2012,2013) and extended to discrete-time case by Meng et al. (2014). It has\nbeen shown that under mild connectivity assumptions these protocols provide the\nconvergence of opinions in absolute value, whereas their signs may differ. This\n\"modulus consensus\" may correspond to the polarization of the opinions (or\nbipartite consensus, including the usual consensus as a special case), or their\nconvergence to zero. In this paper, we demonstrate that the phenomenon of\nmodulus consensus in the discrete-time Altafini model is a manifestation of a\nmore general and profound fact, regarding the solutions of a special recurrent\ninequality. Although such a recurrent inequality does not provide the\nuniqueness of a solution, it can be shown that, under some natural assumptions,\neach of its bounded solutions has a limit and, moreover, converges to\nconsensus. A similar property has previously been established for special\ncontinuous-time differential inequalities (Proskurnikov, Cao, 2016). Besides\nanalysis of signed networks, we link the consensus properties of recurrent\ninequalities to the convergence analysis of distributed optimization algorithms\nand the problems of Schur stability of substochastic matrices.",
    "published_date": "2017-03-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "cs.MA",
      "math.OC",
      "nlin.AO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.06853v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.06660v1",
    "title": "Economic Analysis of Ransomware",
    "authors": [
      "Julio Hernandez-Castro",
      "Edward Cartwright",
      "Anna Stepanova"
    ],
    "author_ids": [],
    "abstract": "We present in this work an economic analysis of ransomware, with relevant\ndata from Cryptolocker, CryptoWall, TeslaCrypt and other major strands. We\ninclude a detailed study of the impact that different price discrimination\nstrategies can have on the success of a ransomware family, examining uniform\npricing, optimal price discrimination and bargaining strategies and analysing\ntheir advantages and limitations. In addition, we present results of a\npreliminary survey that can helps in estimating an optimal ransom value. We\ndiscuss at each stage whether the different schemes we analyse have been\nencountered already in existing malware, and the likelihood of them being\nimplemented and becoming successful. We hope this work will help to gain some\nuseful insights for predicting how ransomware may evolve in the future and be\nbetter prepared to counter its current and future threat.",
    "published_date": "2017-03-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.06660v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.05175v2",
    "title": "Prototypical Networks for Few-shot Learning",
    "authors": [
      "Jake Snell",
      "Kevin Swersky",
      "Richard S. Zemel"
    ],
    "author_ids": [],
    "abstract": "We propose prototypical networks for the problem of few-shot classification,\nwhere a classifier must generalize to new classes not seen in the training set,\ngiven only a small number of examples of each new class. Prototypical networks\nlearn a metric space in which classification can be performed by computing\ndistances to prototype representations of each class. Compared to recent\napproaches for few-shot learning, they reflect a simpler inductive bias that is\nbeneficial in this limited-data regime, and achieve excellent results. We\nprovide an analysis showing that some simple design decisions can yield\nsubstantial improvements over recent approaches involving complicated\narchitectural choices and meta-learning. We further extend prototypical\nnetworks to zero-shot learning and achieve state-of-the-art results on the\nCU-Birds dataset.",
    "published_date": "2017-03-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.05175v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.05065v1",
    "title": "Joint Epipolar Tracking (JET): Simultaneous optimization of epipolar geometry and feature correspondences",
    "authors": [
      "Henry Bradler",
      "Matthias Ochs",
      "Rudolf Mester"
    ],
    "author_ids": [],
    "abstract": "Traditionally, pose estimation is considered as a two step problem. First,\nfeature correspondences are determined by direct comparison of image patches,\nor by associating feature descriptors. In a second step, the relative pose and\nthe coordinates of corresponding points are estimated, most often by minimizing\nthe reprojection error (RPE). RPE optimization is based on a loss function that\nis merely aware of the feature pixel positions but not of the underlying image\nintensities. In this paper, we propose a sparse direct method which introduces\na loss function that allows to simultaneously optimize the unscaled relative\npose, as well as the set of feature correspondences directly considering the\nimage intensity values. Furthermore, we show how to integrate statistical prior\ninformation on the motion into the optimization process. This constructive\ninclusion of a Bayesian bias term is particularly efficient in application\ncases with a strongly predictable (short term) dynamic, e.g. in a driving\nscenario. In our experiments, we demonstrate that the JET algorithm we propose\noutperforms the classical reprojection error optimization on two synthetic\ndatasets and on the KITTI dataset. The JET algorithm runs in real-time on a\nsingle CPU thread.",
    "published_date": "2017-03-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.05065v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.06063v1",
    "title": "Outcome-Based Quality Assessment Framework for Higher Education",
    "authors": [
      "Samiya Khan",
      "Mansaf Alam"
    ],
    "author_ids": [],
    "abstract": "This research paper proposes a quality framework for higher education that\nevaluates the performance of institutions on the basis of performance of\noutgoing students. Literature was surveyed to evaluate existing quality\nframeworks and develop a framework that provides insights on an unexplored\ndimension of quality. In order to implement and test the framework, cloud-based\nbig data technology, BigQuery, was used with R to perform analytics. It was\nfound that how the students fair after passing out of a course is the outcome\nof educational process. This aspect can also be used as a quality metric for\nperformance evaluation and management of educational organizations. However, it\nhas not been taken into account in existing research. The lack of an integrated\ndata collection system and rich datasets for educational intelligence\napplications, are some of the limitations that plague this area of research.\nEducational organizations are responsible for the performance of their students\neven after they complete their course. The inclusion of this dimension to\nquality assessment shall allow evaluation of educational institutions on these\ngrounds. Assurance of this quality dimension shall boost enrolments in\npostgraduate and research degrees. Moreover, educational institutions will be\nmotivated to groom students for placements or higher studies.",
    "published_date": "2017-03-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.06063v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04959v1",
    "title": "Fairness Comparison of Uplink NOMA and OMA",
    "authors": [
      "Zhiqiang Wei",
      "Jiajia Guo",
      "Derrick Wing Kwan Ng",
      "Jinhong Yuan"
    ],
    "author_ids": [],
    "abstract": "In this paper, we compare the resource allocation fairness of uplink\ncommunications between non-orthogonal multiple access (NOMA) schemes and\northogonal multiple access (OMA) schemes. Through characterizing the\ncontribution of the individual user data rate to the system sum rate, we\nanalyze the fundamental reasons that NOMA offers a more fair resource\nallocation than that of OMA in asymmetric channels. Furthermore, a fairness\nindicator metric based on Jain's index is proposed to measure the asymmetry of\nmultiuser channels. More importantly, the proposed metric provides a selection\ncriterion for choosing between NOMA and OMA for fair resource allocation. Based\non this discussion, we propose a hybrid NOMA-OMA scheme to further enhance the\nusers fairness. Simulation results confirm the accuracy of the proposed metric\nand demonstrate the fairness enhancement of the proposed hybrid NOMA-OMA scheme\ncompared to the conventional OMA and NOMA schemes.",
    "published_date": "2017-03-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04959v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04741v3",
    "title": "Towards Moral Autonomous Systems",
    "authors": [
      "Vicky Charisi",
      "Louise Dennis",
      "Michael Fisher",
      "Robert Lieck",
      "Andreas Matthias",
      "Marija Slavkovik",
      "Janina Sombetzki",
      "Alan F. T. Winfield",
      "Roman Yampolskiy"
    ],
    "author_ids": [],
    "abstract": "Both the ethics of autonomous systems and the problems of their technical\nimplementation have by now been studied in some detail. Less attention has been\ngiven to the areas in which these two separate concerns meet. This paper,\nwritten by both philosophers and engineers of autonomous systems, addresses a\nnumber of issues in machine ethics that are located at precisely the\nintersection between ethics and engineering. We first discuss the main\nchallenges which, in our view, machine ethics posses to moral philosophy. We\nthem consider different approaches towards the conceptual design of autonomous\nsystems and their implications on the ethics implementation in such systems.\nThen we examine problematic areas regarding the specification and verification\nof ethical behavior in autonomous systems, particularly with a view towards the\nrequirements of future legislation. We discuss transparency and accountability\nissues that will be crucial for any future wide deployment of autonomous\nsystems in society. Finally we consider the, often overlooked, possibility of\nintentional misuse of AI systems and the possible dangers arising out of\ndeliberately unethical design, implementation, and use of autonomous robots.",
    "published_date": "2017-03-14T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04741v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.04482v1",
    "title": "Social Fingerprinting: detection of spambot groups through DNA-inspired behavioral modeling",
    "authors": [
      "Stefano Cresci",
      "Roberto Di Pietro",
      "Marinella Petrocchi",
      "Angelo Spognardi",
      "Maurizio Tesconi"
    ],
    "author_ids": [],
    "abstract": "Spambot detection in online social networks is a long-lasting challenge\ninvolving the study and design of detection techniques capable of efficiently\nidentifying ever-evolving spammers. Recently, a new wave of social spambots has\nemerged, with advanced human-like characteristics that allow them to go\nundetected even by current state-of-the-art algorithms. In this paper, we show\nthat efficient spambots detection can be achieved via an in-depth analysis of\ntheir collective behaviors exploiting the digital DNA technique for modeling\nthe behaviors of social network users. Inspired by its biological counterpart,\nin the digital DNA representation the behavioral lifetime of a digital account\nis encoded in a sequence of characters. Then, we define a similarity measure\nfor such digital DNA sequences. We build upon digital DNA and the similarity\nbetween groups of users to characterize both genuine accounts and spambots.\nLeveraging such characterization, we design the Social Fingerprinting\ntechnique, which is able to discriminate among spambots and genuine accounts in\nboth a supervised and an unsupervised fashion. We finally evaluate the\neffectiveness of Social Fingerprinting and we compare it with three\nstate-of-the-art detection algorithms. Among the peculiarities of our approach\nis the possibility to apply off-the-shelf DNA analysis techniques to study\nonline users behaviors and to efficiently rely on a limited number of\nlightweight account characteristics.",
    "published_date": "2017-03-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CR",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04482v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.04367v3",
    "title": "Towards Efficient Verification of Population Protocols",
    "authors": [
      "Michael Blondin",
      "Javier Esparza",
      "Stefan Jaax",
      "Philipp J. Meyer"
    ],
    "author_ids": [],
    "abstract": "Population protocols are a well established model of computation by\nanonymous, identical finite state agents. A protocol is well-specified if from\nevery initial configuration, all fair executions reach a common consensus. The\ncentral verification question for population protocols is the\nwell-specification problem: deciding if a given protocol is well-specified.\nEsparza et al. have recently shown that this problem is decidable, but with\nvery high complexity: it is at least as hard as the Petri net reachability\nproblem, which is EXPSPACE-hard, and for which only algorithms of non-primitive\nrecursive complexity are currently known.\n  In this paper we introduce the class WS3 of well-specified strongly-silent\nprotocols and we prove that it is suitable for automatic verification. More\nprecisely, we show that WS3 has the same computational power as general\nwell-specified protocols, and captures standard protocols from the literature.\nMoreover, we show that the membership problem for WS3 reduces to solving\nboolean combinations of linear constraints over N. This allowed us to develop\nthe first software able to automatically prove well-specification for all of\nthe infinitely many possible inputs.",
    "published_date": "2017-03-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO",
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04367v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04225v1",
    "title": "New algorithms for matching problems",
    "authors": [
      "Jacky Lo",
      "Mark C. Wilson"
    ],
    "author_ids": [],
    "abstract": "The standard two-sided and one-sided matching problems, and the closely\nrelated school choice problem, have been widely studied from an axiomatic\nviewpoint. A small number of algorithms dominate the literature. For two-sided\nmatching, the Gale-Shapley algorithm; for one-sided matching, (random) Serial\nDictatorship and Probabilistic Serial rule; for school choice, Gale-Shapley and\nthe Boston mechanisms.\n  The main reason for the dominance of these algorithms is their good\n(worst-case) axiomatic behaviour with respect to notions of efficiency and\nstrategyproofness. However if we shift the focus to fairness, social welfare,\ntradeoffs between incompatible axioms, and average-case analysis, it is far\nfrom clear that these algorithms are optimal.\n  We investigate new algorithms several of which have not appeared (to our\nknowledge) in the literature before. We give a unified presentation in which\nalgorithms for 2-sided matching yield 1-sided matching algorithms in a\nsystematic way. In addition to axiomatic properties, we investigate agent\nwelfare using both theoretical and computational approaches. We find that some\nof the new algorithms are worthy of consideration for certain applications. In\nparticular, when considering welfare under truthful preferences, some of the\nnew algorithms outperform the classic ones.",
    "published_date": "2017-03-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "91B68",
      "J.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04225v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04143v2",
    "title": "Bernoulli Factories and Black-Box Reductions in Mechanism Design",
    "authors": [
      "Shaddin Dughmi",
      "Jason Hartline",
      "Robert Kleinberg",
      "Rad Niazadeh"
    ],
    "author_ids": [],
    "abstract": "We provide a polynomial time reduction from Bayesian incentive compatible\nmechanism design to Bayesian algorithm design for welfare maximization\nproblems. Unlike prior results, our reduction achieves exact incentive\ncompatibility for problems with multi-dimensional and continuous type spaces.\nThe key technical barrier preventing exact incentive compatibility in prior\nblack-box reductions is that repairing violations of incentive constraints\nrequires understanding the distribution of the mechanism's output, which is\ntypically #P-hard to compute. Reductions that instead estimate the output\ndistribution by sampling inevitably suffer from sampling error, which typically\nprecludes exact incentive compatibility.\n  We overcome this barrier by employing and generalizing the computational\nmodel in the literature on $\\textit{Bernoulli factories}$. In a Bernoulli\nfactory problem, one is given a function mapping the bias of an \"input coin\" to\nthat of an \"output coin\", and the challenge is to efficiently simulate the\noutput coin given only sample access to the input coin. This is the key\ningredient in designing an incentive compatible mechanism for bipartite\nmatching, which can be used to make the approximately incentive compatible\nreduction of Hartline et al. (2015) exactly incentive compatible.",
    "published_date": "2017-03-12T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.CC",
      "cs.DS",
      "math.PR"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04143v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04010v3",
    "title": "Data-Driven Estimation of Travel Latency Cost Functions via Inverse Optimization in Multi-Class Transportation Networks",
    "authors": [
      "Jing Zhang",
      "Ioannis Ch. Paschalidis"
    ],
    "author_ids": [],
    "abstract": "We develop a method to estimate from data travel latency cost functions in\nmulti-class transportation networks, which accommodate different types of\nvehicles with very different characteristics (e.g., cars and trucks).\nLeveraging our earlier work on inverse variational inequalities, we develop a\ndata-driven approach to estimate the travel latency cost functions. Extensive\nnumerical experiments using benchmark networks, ranging from moderate-sized to\nlarge-sized, demonstrate the effectiveness and efficiency of our approach.",
    "published_date": "2017-03-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "math.OC",
      "90C33, 90C90, 90C30"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04010v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.04001v1",
    "title": "Language Use Matters: Analysis of the Linguistic Structure of Question Texts Can Characterize Answerability in Quora",
    "authors": [
      "Suman Kalyan Maity",
      "Aman Kharb",
      "Animesh Mukherjee"
    ],
    "author_ids": [],
    "abstract": "Quora is one of the most popular community Q&A sites of recent times.\nHowever, many question posts on this Q&A site often do not get answered. In\nthis paper, we quantify various linguistic activities that discriminates an\nanswered question from an unanswered one. Our central finding is that the way\nusers use language while writing the question text can be a very effective\nmeans to characterize answerability. This characterization helps us to predict\nearly if a question remaining unanswered for a specific time period t will\neventually be answered or not and achieve an accuracy of 76.26% (t = 1 month)\nand 68.33% (t = 3 months). Notably, features representing the language use\npatterns of the users are most discriminative and alone account for an accuracy\nof 74.18%. We also compare our method with some of the similar works (Dror et\nal., Yang et al.) achieving a maximum improvement of ~39% in terms of accuracy.",
    "published_date": "2017-03-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.04001v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.03442v2",
    "title": "The cognitive roots of regularization in language",
    "authors": [
      "Vanessa Ferdinand",
      "Simon Kirby",
      "Kenny Smith"
    ],
    "author_ids": [],
    "abstract": "Regularization occurs when the output a learner produces is less variable\nthan the linguistic data they observed. In an artificial language learning\nexperiment, we show that there exist at least two independent sources of\nregularization bias in cognition: a domain-general source based on cognitive\nload and a domain-specific source triggered by linguistic stimuli. Both of\nthese factors modulate how frequency information is encoded and produced, but\nonly the production-side modulations result in regularization (i.e. cause\nlearners to eliminate variation from the observed input). We formalize the\ndefinition of regularization as the reduction of entropy and find that entropy\nmeasures are better at identifying regularization behavior than frequency-based\nanalyses. Using our experimental data and a model of cultural transmission, we\ngenerate predictions for the amount of regularity that would develop in each\nexperimental condition if the artificial language were transmitted over several\ngenerations of learners. Here we find that the effect of cognitive constraints\ncan become more complex when put into the context of cultural evolution:\nalthough learning biases certainly carry information about the course of\nlanguage evolution, we should not expect a one-to-one correspondence between\nthe micro-level processes that regularize linguistic datasets and the\nmacro-level evolution of linguistic regularity.",
    "published_date": "2017-03-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "q-bio.NC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.03442v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.03126v1",
    "title": "DeepSD: Generating High Resolution Climate Change Projections through Single Image Super-Resolution",
    "authors": [
      "Thomas Vandal",
      "Evan Kodra",
      "Sangram Ganguly",
      "Andrew Michaelis",
      "Ramakrishna Nemani",
      "Auroop R Ganguly"
    ],
    "author_ids": [],
    "abstract": "The impacts of climate change are felt by most critical systems, such as\ninfrastructure, ecological systems, and power-plants. However, contemporary\nEarth System Models (ESM) are run at spatial resolutions too coarse for\nassessing effects this localized. Local scale projections can be obtained using\nstatistical downscaling, a technique which uses historical climate observations\nto learn a low-resolution to high-resolution mapping. Depending on statistical\nmodeling choices, downscaled projections have been shown to vary significantly\nterms of accuracy and reliability. The spatio-temporal nature of the climate\nsystem motivates the adaptation of super-resolution image processing techniques\nto statistical downscaling. In our work, we present DeepSD, a generalized\nstacked super resolution convolutional neural network (SRCNN) framework for\nstatistical downscaling of climate variables. DeepSD augments SRCNN with\nmulti-scale input channels to maximize predictability in statistical\ndownscaling. We provide a comparison with Bias Correction Spatial\nDisaggregation as well as three Automated-Statistical Downscaling approaches in\ndownscaling daily precipitation from 1 degree (~100km) to 1/8 degrees (~12.5km)\nover the Continental United States. Furthermore, a framework using the NASA\nEarth Exchange (NEX) platform is discussed for downscaling more than 20 ESM\nmodels with multiple emission scenarios.",
    "published_date": "2017-03-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.03126v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.01916v1",
    "title": "Joint Pilot Sequence Design and Power Control for Max-Min Fairness in Uplink Massive MIMO",
    "authors": [
      "Trinh Van Chien",
      "Emil Björnson",
      "Erik G. Larsson"
    ],
    "author_ids": [],
    "abstract": "This paper optimizes the pilot assignment and pilot transmit powers to\nmitigate pilot contamination in Massive MIMO (multiple-input multiple-output)\nsystems. While prior works have treated pilot assignment as a combinatorial\nproblem, we achieve a more tractable problem formulation by directly optimizing\nthe pilot sequences. To this end, we compute a lower bound on the uplink (UL)\nspectral efficiency (SE), for Rayleigh fading channels with maximum ratio (MR)\ndetection and arbitrary pilot sequences. We optimize the max-min SE with\nrespect to the pilot sequences and pilot powers, under power budget\nconstraints. This becomes an NP-hard signomial problem, but we propose an\nefficient algorithm to obtain a local optimum with polynomial complexity.\nNumerical results manifest the near optimality of the proposed algorithm and\nshow significant gains over existing suboptimal algorithms.",
    "published_date": "2017-03-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01916v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.01671v2",
    "title": "Controlling for Unobserved Confounds in Classification Using Correlational Constraints",
    "authors": [
      "Virgile Landeiro",
      "Aron Culotta"
    ],
    "author_ids": [],
    "abstract": "As statistical classifiers become integrated into real-world applications, it\nis important to consider not only their accuracy but also their robustness to\nchanges in the data distribution. In this paper, we consider the case where\nthere is an unobserved confounding variable $z$ that influences both the\nfeatures $\\mathbf{x}$ and the class variable $y$. When the influence of $z$\nchanges from training to testing data, we find that the classifier accuracy can\ndegrade rapidly. In our approach, we assume that we can predict the value of\n$z$ at training time with some error. The prediction for $z$ is then fed to\nPearl's back-door adjustment to build our model. Because of the attenuation\nbias caused by measurement error in $z$, standard approaches to controlling for\n$z$ are ineffective. In response, we propose a method to properly control for\nthe influence of $z$ by first estimating its relationship with the class\nvariable $y$, then updating predictions for $z$ to match that estimated\nrelationship. By adjusting the influence of $z$, we show that we can build a\nmodel that exceeds competing baselines on accuracy as well as on robustness\nover a range of confounding relationships.",
    "published_date": "2017-03-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01671v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.06824v1",
    "title": "Energy Efficient Non-Cooperative Power Control in Small Cell Networks",
    "authors": [
      "Yanxiang Jiang",
      "Ningning Lu",
      "Yan Chen",
      "Mehdi Bennis",
      "Fuchun Zheng",
      "Xiqi Gao",
      "Xiaohu You"
    ],
    "author_ids": [],
    "abstract": "In this paper, energy efficient power control for small cells underlaying a\nmacro cellular network is investigated. We formulate the power control problem\nin self-organizing small cell networks as a non-cooperative game, and propose a\ndistributed energy efficient power control scheme, which allows the small base\nstations (SBSs) to take individual decisions for attaining the Nash equilibrium\n(NE) with minimum information exchange. Specially, in the non-cooperative power\ncontrol game, a non-convex optimization problem is formulated for each SBS to\nmaximize their energy efficiency (EE). By exploiting the properties of\nparameter-free fractional programming and the concept of perspective function,\nthe non-convex optimization problem for each SBS is transformed into an\nequivalent constrained convex optimization problem. Then, the constrained\nconvex optimization problem is converted into an unconstrained convex\noptimization problem by exploiting the mixed penalty function method. The\ninequality constraints are eliminated by introducing the logarithmic barrier\nfunctions and the equality constraint is eliminated by introducing the\nquadratic penalty function. We also theoretically show the existence and the\nuniqueness of the NE in the non-cooperative power control game. Simulation\nresults show remarkable improvements in terms of EE by using the proposed\nscheme.",
    "published_date": "2017-03-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.06824v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.01501v1",
    "title": "Opinion dynamics model based on cognitive biases",
    "authors": [
      "Pawel Sobkowicz"
    ],
    "author_ids": [],
    "abstract": "We present an introduction to a novel model of an individual and group\nopinion dynamics, taking into account different ways in which different sources\nof information are filtered due to cognitive biases. The agent based model,\nusing Bayesian updating of the individual belief distribution, is based on the\nrecent psychology work by Dan Kahan. Open nature of the model allows to study\nthe effects of both static and time-dependent biases and information processing\nfilters. In particular, the paper compares the effects of two important\npsychological mechanisms: the confirmation bias and the politically motivated\nreasoning. Depending on the effectiveness of the information filtering (agent\nbias), the agents confronted with an objective information source may either\nreach a consensus based on the truth, or remain divided despite the evidence.\nIn general, the model might provide an understanding into the increasingly\npolarized modern societies, especially as it allows mixing of different types\nof filters: psychological, social, and algorithmic.",
    "published_date": "2017-03-04T00:00:00",
    "year": 2017,
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01501v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.01469v1",
    "title": "Scientific wealth and inequality within nations",
    "authors": [
      "Gangan Prathap"
    ],
    "author_ids": [],
    "abstract": "We show that the greater the scientific wealth of a nation, the more likely\nthat it will tend to concentrate this excellence in a few premier institutions.\nThat is, great wealth implies great inequality of distribution. The scientific\nwealth is interpreted in terms of citation data harvested by Google Scholar\nCitations for profiled institutions from all countries in the world.",
    "published_date": "2017-03-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01469v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.01168v2",
    "title": "Sum-set Inequalities from Aligned Image Sets: Instruments for Robust GDoF Bounds",
    "authors": [
      "Arash Gholami Davoodi",
      "Syed A. Jafar"
    ],
    "author_ids": [],
    "abstract": "We present sum-set inequalities specialized to the generalized degrees of\nfreedom (GDoF) framework. These are information theoretic lower bounds on the\nentropy of bounded density linear combinations of discrete, power-limited\ndependent random variables in terms of the joint entropies of arbitrary linear\ncombinations of new random variables that are obtained by power level\npartitioning of the original random variables. These bounds generalize the\naligned image sets approach, and are useful instruments to obtain GDoF\ncharacterizations for wireless networks, especially with multiple antenna\nnodes, subject to arbitrary channel strength and channel uncertainty levels. To\ndemonstrate the utility of these bounds, we consider a non-trivial instance of\nwireless networks - a two user interference channel with different number of\nantennas at each node, and different levels of partial channel knowledge\navailable to the transmitters. We obtain tight GDoF characterization for\nspecific instance of this channel with the aid of sum-set inequalities.",
    "published_date": "2017-03-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01168v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.00707v1",
    "title": "Unveiling Bias Compensation in Turbo-Based Algorithms for (Discrete) Compressed Sensing",
    "authors": [
      "Susanne Sparrer",
      "Robert F. H. Fischer"
    ],
    "author_ids": [],
    "abstract": "In Compressed Sensing, a real-valued sparse vector has to be recovered from\nan underdetermined system of linear equations. In many applications, however,\nthe elements of the sparse vector are drawn from a finite set. Adapted\nalgorithms incorporating this additional knowledge are required for the\ndiscrete-valued setup. In this paper, turbo-based algorithms for both cases are\nelucidated and analyzed from a communications engineering perspective, leading\nto a deeper understanding of the algorithm. In particular, we gain the\nintriguing insight that the calculation of extrinsic values is equal to the\nunbiasing of a biased estimate and present an improved algorithm.",
    "published_date": "2017-03-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00707v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.00619v1",
    "title": "Reflections on Cyberethics Education for Millennial Software Engineers",
    "authors": [
      "Claudia de O. Melo",
      "Thiago C. de Sousa"
    ],
    "author_ids": [],
    "abstract": "Software is a key component of solutions for 21st Century problems. These\nproblems are often \"wicked\", complex, and unpredictable. To provide the best\npossible solution, millennial software engineers must be prepared to make\nethical decisions, thinking critically, and acting systematically. This reality\ndemands continuous changes in educational systems and curricula delivery, as\nmisjudgment might have serious social impact. This study aims to investigate\nand reflect on Software Engineering (SE) Programs, proposing a conceptual\nframework for analyzing cyberethics education and a set of suggestions on how\nto integrate it into the SE undergraduate curriculum.",
    "published_date": "2017-03-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SE",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00619v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.00532v1",
    "title": "Stability and optimality of distributed secondary frequency control schemes in power networks",
    "authors": [
      "Andreas Kasis",
      "Nima Monshizadeh",
      "Eoin Devane",
      "Ioannis Lestas"
    ],
    "author_ids": [],
    "abstract": "We present a systematic method for designing distributed generation and\ndemand control schemes for secondary frequency regulation in power networks\nsuch that stability and an economically optimal power allocation can be\nguaranteed. A dissipativity condition is imposed on net power supply variables\nto provide stability guarantees. Furthermore, economic optimality is achieved\nby explicit decentralized steady state conditions on the generation and\ncontrollable demand. We discuss how various classes of dynamics used in recent\nstudies fit within our framework and give examples of higher order generation\nand controllable demand dynamics that can be included within our analysis. In\ncase of linear dynamics, we discuss how the proposed dissipativity condition\ncan be efficiently verified using an appropriate linear matrix inequality.\nMoreover, it is shown how the addition of a suitable observer layer can relax\nthe requirement for demand measurements in the employed controller. The\nefficiency and practicality of the proposed results are demonstrated with a\nsimulation on the Northeast Power Coordinating Council (NPCC) 140-bus system.",
    "published_date": "2017-03-01T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00532v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.00403v2",
    "title": "Preserving Differential Privacy Between Features in Distributed Estimation",
    "authors": [
      "Christina Heinze-Deml",
      "Brian McWilliams",
      "Nicolai Meinshausen"
    ],
    "author_ids": [],
    "abstract": "Privacy is crucial in many applications of machine learning. Legal, ethical\nand societal issues restrict the sharing of sensitive data making it difficult\nto learn from datasets that are partitioned between many parties. One important\ninstance of such a distributed setting arises when information about each\nrecord in the dataset is held by different data owners (the design matrix is\n\"vertically-partitioned\").\n  In this setting few approaches exist for private data sharing for the\npurposes of statistical estimation and the classical setup of differential\nprivacy with a \"trusted curator\" preparing the data does not apply. We work\nwith the notion of $(\\epsilon,\\delta)$-distributed differential privacy which\nextends single-party differential privacy to the distributed,\nvertically-partitioned case. We propose PriDE, a scalable framework for\ndistributed estimation where each party communicates perturbed random\nprojections of their locally held features ensuring\n$(\\epsilon,\\delta)$-distributed differential privacy is preserved. For\n$\\ell_2$-penalized supervised learning problems PriDE has bounded estimation\nerror compared with the optimal estimates obtained without privacy constraints\nin the non-distributed setting. We confirm this empirically on real world and\nsynthetic datasets.",
    "published_date": "2017-03-01T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00403v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.00196v1",
    "title": "Incorporating Intra-Class Variance to Fine-Grained Visual Recognition",
    "authors": [
      "Yan Bai",
      "Feng Gao",
      "Yihang Lou",
      "Shiqi Wang",
      "Tiejun Huang",
      "Ling-Yu Duan"
    ],
    "author_ids": [],
    "abstract": "Fine-grained visual recognition aims to capture discriminative\ncharacteristics amongst visually similar categories. The state-of-the-art\nresearch work has significantly improved the fine-grained recognition\nperformance by deep metric learning using triplet network. However, the impact\nof intra-category variance on the performance of recognition and robust feature\nrepresentation has not been well studied. In this paper, we propose to leverage\nintra-class variance in metric learning of triplet network to improve the\nperformance of fine-grained recognition. Through partitioning training images\nwithin each category into a few groups, we form the triplet samples across\ndifferent categories as well as different groups, which is called Group\nSensitive TRiplet Sampling (GS-TRS). Accordingly, the triplet loss function is\nstrengthened by incorporating intra-class variance with GS-TRS, which may\ncontribute to the optimization objective of triplet network. Extensive\nexperiments over benchmark datasets CompCar and VehicleID show that the\nproposed GS-TRS has significantly outperformed state-of-the-art approaches in\nboth classification and retrieval tasks.",
    "published_date": "2017-03-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00196v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.00064v2",
    "title": "Ending the Anomaly: Achieving Low Latency and Airtime Fairness in WiFi",
    "authors": [
      "Toke Høiland-Jørgensen",
      "Michał Kazior",
      "Dave Täht",
      "Per Hurtig",
      "Anna Brunstrom"
    ],
    "author_ids": [],
    "abstract": "With more devices connected, delays and jitter at the WiFi hop become more\nprevalent, and correct functioning during network congestion becomes more\nimportant. However, two important performance issues prevent modern WiFi from\nreaching its potential: Increased latency under load caused by excessive\nqueueing (i.e. bufferbloat) and the 802.11 performance anomaly.\n  To remedy these issues, we present a novel two-part solution: We design a new\nqueueing scheme that eliminates bufferbloat in the wireless setting. Leveraging\nthis queueing scheme, we then design an airtime fairness scheduler that\noperates at the access point and doesn't require any changes to clients.\n  We evaluate our solution using both a theoretical model and experiments in a\ntestbed environment, formulating a suitable analytical model in the process. We\nshow that our solution achieves an order of magnitude reduction in latency\nunder load, large improvements in multi-station throughput, and nearly perfect\nairtime fairness for both TCP and downstream UDP traffic. Further experiments\nwith application traffic confirm that the solution provides significant\nperformance gains for real-world traffic.We develop a production quality\nimplementation of our solution in the Linux kernel, the platform powering most\naccess points outside of the managed enterprise setting. The implementation has\nbeen accepted into the mainline kernel distribution, making it available for\ndeployment on billions of devices running Linux today.",
    "published_date": "2017-02-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00064v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1703.00060v2",
    "title": "Achieving non-discrimination in prediction",
    "authors": [
      "Lu Zhang",
      "Yongkai Wu",
      "Xintao Wu"
    ],
    "author_ids": [],
    "abstract": "Discrimination-aware classification is receiving an increasing attention in\ndata science fields. The pre-process methods for constructing a\ndiscrimination-free classifier first remove discrimination from the training\ndata, and then learn the classifier from the cleaned data. However, they lack a\ntheoretical guarantee for the potential discrimination when the classifier is\ndeployed for prediction. In this paper, we fill this gap by mathematically\nbounding the probability of the discrimination in prediction being within a\ngiven interval in terms of the training data and classifier. We adopt the\ncausal model for modeling the data generation mechanism, and formally defining\ndiscrimination in population, in a dataset, and in prediction. We obtain two\nimportant theoretical results: (1) the discrimination in prediction can still\nexist even if the discrimination in the training data is completely removed;\nand (2) not all pre-process methods can ensure non-discrimination in prediction\neven though they can achieve non-discrimination in the modified training data.\nBased on the results, we develop a two-phase framework for constructing a\ndiscrimination-free classifier with a theoretical guarantee. The experiments\ndemonstrate the theoretical results and show the effectiveness of our two-phase\nframework.",
    "published_date": "2017-02-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00060v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1703.00056v1",
    "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments",
    "authors": [
      "Alexandra Chouldechova"
    ],
    "author_ids": [],
    "abstract": "Recidivism prediction instruments (RPI's) provide decision makers with an\nassessment of the likelihood that a criminal defendant will reoffend at a\nfuture point in time. While such instruments are gaining increasing popularity\nacross the country, their use is attracting tremendous controversy. Much of the\ncontroversy concerns potential discriminatory bias in the risk assessments that\nare produced. This paper discusses several fairness criteria that have recently\nbeen applied to assess the fairness of recidivism prediction instruments. We\ndemonstrate that the criteria cannot all be simultaneously satisfied when\nrecidivism prevalence differs across groups. We then show how disparate impact\ncan arise when a recidivism prediction instrument fails to satisfy the\ncriterion of error rate balance.",
    "published_date": "2017-02-28T00:00:00",
    "year": 2017,
    "categories": [
      "stat.AP",
      "cs.CY",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00056v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.08817v4",
    "title": "Privacy-enhancing Aggregation of Internet of Things Data via Sensors Grouping",
    "authors": [
      "Stefano Bennati",
      "Evangelos Pournaras"
    ],
    "author_ids": [],
    "abstract": "Big data collection practices using Internet of Things (IoT) pervasive\ntechnologies are often privacy-intrusive and result in surveillance, profiling,\nand discriminatory actions over citizens that in turn undermine the\nparticipation of citizens to the development of sustainable smart cities.\nNevertheless, real-time data analytics and aggregate information from IoT\ndevices open up tremendous opportunities for managing smart city\ninfrastructures. The privacy-enhancing aggregation of distributed sensor data,\nsuch as residential energy consumption or traffic information, is the research\nfocus of this paper. Citizens have the option to choose their privacy level by\nreducing the quality of the shared data at a cost of a lower accuracy in data\nanalytics services. A baseline scenario is considered in which IoT sensor data\nare shared directly with an untrustworthy central aggregator. A grouping\nmechanism is introduced that improves privacy by sharing data aggregated first\nat a group level compared as opposed to sharing data directly to the central\naggregator. Group-level aggregation obfuscates sensor data of individuals, in a\nsimilar fashion as differential privacy and homomorphic encryption schemes,\nthus inference of privacy-sensitive information from single sensors becomes\ncomputationally harder compared to the baseline scenario. The proposed system\nis evaluated using real-world data from two smart city pilot projects. Privacy\nunder grouping increases, while preserving the accuracy of the baseline\nscenario. Intra-group influences of privacy by one group member on the other\nones are measured and fairness on privacy is found to be maximized between\ngroup members with similar privacy choices. Several grouping strategies are\ncompared. Grouping by proximity of privacy choices provides the highest privacy\ngains. The implications of the strategy on the design of incentives mechanisms\nare discussed.",
    "published_date": "2017-02-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08817v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.08789v2",
    "title": "Nash and Wardrop equilibria in aggregative games with coupling constraints",
    "authors": [
      "Dario Paccagnan",
      "Basilio Gentile",
      "Francesca Parise",
      "Maryam Kamgarpour",
      "John Lygeros"
    ],
    "author_ids": [],
    "abstract": "We consider the framework of aggregative games, in which the cost function of\neach agent depends on his own strategy and on the average population strategy.\nAs first contribution, we investigate the relations between the concepts of\nNash and Wardrop equilibrium. By exploiting a characterization of the two\nequilibria as solutions of variational inequalities, we bound their distance\nwith a decreasing function of the population size. As second contribution, we\npropose two decentralized algorithms that converge to such equilibria and are\ncapable of coping with constraints coupling the strategies of different agents.\nFinally, we study the applications of charging of electric vehicles and of\nroute choice on a road network.",
    "published_date": "2017-02-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY",
      "cs.GT",
      "math.OC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08789v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.08536v3",
    "title": "Fast Threshold Tests for Detecting Discrimination",
    "authors": [
      "Emma Pierson",
      "Sam Corbett-Davies",
      "Sharad Goel"
    ],
    "author_ids": [],
    "abstract": "Threshold tests have recently been proposed as a useful method for detecting\nbias in lending, hiring, and policing decisions. For example, in the case of\ncredit extensions, these tests aim to estimate the bar for granting loans to\nwhite and minority applicants, with a higher inferred threshold for minorities\nindicative of discrimination. This technique, however, requires fitting a\ncomplex Bayesian latent variable model for which inference is often\ncomputationally challenging. Here we develop a method for fitting threshold\ntests that is two orders of magnitude faster than the existing approach,\nreducing computation from hours to minutes. To achieve these performance gains,\nwe introduce and analyze a flexible family of probability distributions on the\ninterval [0, 1] -- which we call discriminant distributions -- that is\ncomputationally efficient to work with. We demonstrate our technique by\nanalyzing 2.7 million police stops of pedestrians in New York City.",
    "published_date": "2017-02-27T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08536v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.08291v1",
    "title": "A Manifesto for Web Science @ 10",
    "authors": [
      "Wendy Hall",
      "Jim Hendler",
      "Steffen Staab"
    ],
    "author_ids": [],
    "abstract": "Twenty-seven years ago, one of the biggest societal changes in human history\nbegan slowly when the technical foundations for the World Wide Web were defined\nby Tim Berners-Lee. Ever since, the Web has grown exponentially, reaching far\nbeyond its original technical foundations and deeply affecting the world today\n- and even more so the society of the future. We have seen that the Web can\ninfluence the realization of human rights and even the pursuit of happiness.\nThe Web provides an infrastructure to help us to learn, to work, to communicate\nwith loved ones, and to provide entertainment. However, it also creates an\nenvironment affected by the digital divide between those who have and those who\ndo not have access. Additionally, the Web provides challenges we must\nunderstand if we are to find a viable balance between data ownership and\nprivacy protection, between over-whelming surveillance and the prevention of\nterrorism. For the Web to succeed, we need to understand its societal\nchallenges including increased crime, the impact of social platforms and\nsocio-economic discrimination, and we must work towards fairness, social\ninclusion, and open governance.\n  Ten Yars ago, the field of Web Science was created to explore the science\nunderlying the Web from a socio-technical perspective including its\nmathematical properties, engineering principles, and social impacts. Ten years\nlater, we are learning much as the interdisciplinary endeavor to understand the\nWeb's global information space continues to grow.\n  In this article we want to elicit the major lessons we have learned through\nWeb Science and make some cautious predictions of what to expect next.",
    "published_date": "2017-02-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "H.0; K.4.0"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08291v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.08286v2",
    "title": "Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange",
    "authors": [
      "Duncan C. McElfresh",
      "John P. Dickerson"
    ],
    "author_ids": [],
    "abstract": "Balancing fairness and efficiency in resource allocation is a classical\neconomic and computational problem. The price of fairness measures the\nworst-case loss of economic efficiency when using an inefficient but fair\nallocation rule; for indivisible goods in many settings, this price is\nunacceptably high. One such setting is kidney exchange, where needy patients\nswap willing but incompatible kidney donors. In this work, we close an open\nproblem regarding the theoretical price of fairness in modern kidney exchanges.\nWe then propose a general hybrid fairness rule that balances a strict\nlexicographic preference ordering over classes of agents, and a utilitarian\nobjective that maximizes economic efficiency. We develop a utility function for\nthis rule that favors disadvantaged groups lexicographically; but if cost to\noverall efficiency becomes too high, it switches to a utilitarian objective.\nThis rule has only one parameter which is proportional to a bound on the price\nof fairness, and can be adjusted by policymakers. We apply this rule to real\ndata from a large kidney exchange and show that our hybrid rule produces more\nreliable outcomes than other fairness rules.",
    "published_date": "2017-02-27T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.AI",
      "I.2.11; J.4; G.1.6"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08286v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.08019v1",
    "title": "Support vector machine and its bias correction in high-dimension, low-sample-size settings",
    "authors": [
      "Yugo Nakayama",
      "Kazuyoshi Yata",
      "Makoto Aoshima"
    ],
    "author_ids": [],
    "abstract": "In this paper, we consider asymptotic properties of the support vector\nmachine (SVM) in high-dimension, low-sample-size (HDLSS) settings. We show that\nthe hard-margin linear SVM holds a consistency property in which\nmisclassification rates tend to zero as the dimension goes to infinity under\ncertain severe conditions. We show that the SVM is very biased in HDLSS\nsettings and its performance is affected by the bias directly. In order to\novercome such difficulties, we propose a bias-corrected SVM (BC-SVM). We show\nthat the BC-SVM gives preferable performances in HDLSS settings. We also\ndiscuss the SVMs in multiclass HDLSS settings. Finally, we check the\nperformance of the classifiers in actual data analyses.",
    "published_date": "2017-02-26T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG",
      "62H30, 62G20"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.08019v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.07984v3",
    "title": "Iterative Local Voting for Collective Decision-making in Continuous Spaces",
    "authors": [
      "Nikhil Garg",
      "Vijay Kamble",
      "Ashish Goel",
      "David Marn",
      "Kamesh Munagala"
    ],
    "author_ids": [],
    "abstract": "Many societal decision problems lie in high-dimensional continuous spaces not\namenable to the voting techniques common for their discrete or\nsingle-dimensional counterparts. These problems are typically discretized\nbefore running an election or decided upon through negotiation by\nrepresentatives. We propose a algorithm called {\\sc Iterative Local Voting} for\ncollective decision-making in this setting. In this algorithm, voters are\nsequentially sampled and asked to modify a candidate solution within some local\nneighborhood of its current value, as defined by a ball in some chosen norm,\nwith the size of the ball shrinking at a specified rate.\n  We first prove the convergence of this algorithm under appropriate choices of\nneighborhoods to Pareto optimal solutions with desirable fairness properties in\ncertain natural settings: when the voters' utilities can be expressed in terms\nof some form of distance from their ideal solution, and when these utilities\nare additively decomposable across dimensions. In many of these cases, we\nobtain convergence to the societal welfare maximizing solution.\n  We then describe an experiment in which we test our algorithm for the\ndecision of the U.S. Federal Budget on Mechanical Turk with over 2,000 workers,\nemploying neighborhoods defined by $\\mathcal{L}^1, \\mathcal{L}^2$ and\n$\\mathcal{L}^\\infty$ balls. We make several observations that inform future\nimplementations of such a procedure.",
    "published_date": "2017-02-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.MA",
      "cs.CY",
      "cs.GT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.07984v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.07911v1",
    "title": "The natural algorithmic approach of mixed trigonometric-polynomial problems",
    "authors": [
      "Tatjana Lutovac",
      "Branko Malesevic",
      "Cristinel Mortici"
    ],
    "author_ids": [],
    "abstract": "The aim of this paper is to present a new algorithm for proving mixed\ntrigonometric-polynomial inequalities by reducing to polynomial inequalities.\nFinally, we show the great applicability of this algorithm and as examples, we\nuse it to analyze some new rational (Pade) approximations of the function\n$\\cos^2(x)$, and to improve a class of inequalities by Z.-H. Yang. The results\nof our analysis could be implemented by means of an automated proof assistant,\nso our work is a contribution to the library of automatic support tools for\nproving various analytic inequalities.",
    "published_date": "2017-02-25T00:00:00",
    "year": 2017,
    "categories": [
      "math.CA",
      "cs.SC",
      "41A10, 26D05, 12L05, 41A58"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.07911v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.07784v1",
    "title": "Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying",
    "authors": [
      "Despoina Chatzakou",
      "Nicolas Kourtellis",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro",
      "Gianluca Stringhini",
      "Athena Vakali"
    ],
    "author_ids": [],
    "abstract": "Over the past few years, online aggression and abusive behaviors have\noccurred in many different forms and on a variety of platforms. In extreme\ncases, these incidents have evolved into hate, discrimination, and bullying,\nand even materialized into real-world threats and attacks against individuals\nor groups. In this paper, we study the Gamergate controversy. Started in August\n2014 in the online gaming world, it quickly spread across various social\nnetworking platforms, ultimately leading to many incidents of cyberbullying and\ncyberaggression. We focus on Twitter, presenting a measurement study of a\ndataset of 340k unique users and 1.6M tweets to study the properties of these\nusers, the content they post, and how they differ from random Twitter users. We\nfind that users involved in this \"Twitter war\" tend to have more friends and\nfollowers, are generally more engaged and post tweets with negative sentiment,\nless joy, and more hate than random users. We also perform preliminary\nmeasurements on how the Twitter suspension mechanism deals with such abusive\nbehaviors. While we focus on Gamergate, our methodology to collect and analyze\ntweets related to aggressive and bullying activities is of independent\ninterest.",
    "published_date": "2017-02-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.07784v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.07134v2",
    "title": "Diverse Weighted Bipartite b-Matching",
    "authors": [
      "Faez Ahmed",
      "John P. Dickerson",
      "Mark Fuge"
    ],
    "author_ids": [],
    "abstract": "Bipartite matching, where agents on one side of a market are matched to\nagents or items on the other, is a classical problem in computer science and\neconomics, with widespread application in healthcare, education, advertising,\nand general resource allocation. A practitioner's goal is typically to maximize\na matching market's economic efficiency, possibly subject to some fairness\nrequirements that promote equal access to resources. A natural balancing act\nexists between fairness and efficiency in matching markets, and has been the\nsubject of much research.\n  In this paper, we study a complementary goal---balancing diversity and\nefficiency---in a generalization of bipartite matching where agents on one side\nof the market can be matched to sets of agents on the other. Adapting a\nclassical definition of the diversity of a set, we propose a quadratic\nprogramming-based approach to solving a supermodular minimization problem that\nbalances diversity and total weight of the solution. We also provide a scalable\ngreedy algorithm with theoretical performance bounds. We then define the price\nof diversity, a measure of the efficiency loss due to enforcing diversity, and\ngive a worst-case theoretical bound. Finally, we demonstrate the efficacy of\nour methods on three real-world datasets, and show that the price of diversity\nis not bad in practice.",
    "published_date": "2017-02-23T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.07134v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.07030v1",
    "title": "Net-Zero Settlement in Distribution Markets",
    "authors": [
      "Sina Parhizi",
      "Alireza Majzoobi",
      "Amin Khodaei"
    ],
    "author_ids": [],
    "abstract": "Introduction of market mechanisms in distribution systems is currently\nsubject to extensive studies. One of the challenges facing Distribution Market\nOperators (DMOs) is to implement a fair and economically efficient pricing\nmechanism that can incentivize consumers to positively contribute to grid\noperations and to improve economic performance of the distribution system. This\npaper studies a penalty-based pricing mechanism in distribution markets and\nfurther investigates the interrelationship between the locational marginal\nprices (LMPs) at transmission and distribution levels. As a result, a\nclosed-form relationship between these LMPs is derived. The possibility of\nzeroing out the settlement profit is further investigated under the proposed\npricing mechanism.",
    "published_date": "2017-02-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.07030v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.06672v1",
    "title": "Calculating Probabilities Simplifies Word Learning",
    "authors": [
      "Aida Nematzadeh",
      "Barend Beekhuizen",
      "Shanshan Huang",
      "Suzanne Stevenson"
    ],
    "author_ids": [],
    "abstract": "Children can use the statistical regularities of their environment to learn\nword meanings, a mechanism known as cross-situational learning. We take a\ncomputational approach to investigate how the information present during each\nobservation in a cross-situational framework can affect the overall acquisition\nof word meanings. We do so by formulating various in-the-moment learning\nmechanisms that are sensitive to different statistics of the environment, such\nas counts and conditional probabilities. Each mechanism introduces a unique\nsource of competition or mutual exclusivity bias to the model; the mechanism\nthat maximally uses the model's knowledge of word meanings performs the best.\nMoreover, the gap between this mechanism and others is amplified in more\nchallenging learning scenarios, such as learning from few examples.",
    "published_date": "2017-02-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.06672v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.06492v2",
    "title": "Automated Assistants to Identify and Prompt Action on Visual News Bias",
    "authors": [
      "Vishwajeet Narwal",
      "Mohamed Hashim Salih",
      "Jose Angel Lopez",
      "Angel Ortega",
      "John O'Donovan",
      "Tobias Höllerer",
      "Saiph Savage"
    ],
    "author_ids": [],
    "abstract": "Bias is a common problem in today's media, appearing frequently in text and\nin visual imagery. Users on social media websites such as Twitter need better\nmethods for identifying bias. Additionally, activists --those who are motivated\nto effect change related to some topic, need better methods to identify and\ncounteract bias that is contrary to their mission. With both of these use cases\nin mind, in this paper we propose a novel tool called UnbiasedCrowd that\nsupports identification of, and action on bias in visual news media. In\nparticular, it addresses the following key challenges (1) identification of\nbias; (2) aggregation and presentation of evidence to users; (3) enabling\nactivists to inform the public of bias and take action by engaging people in\nconversation with bots. We describe a preliminary study on the Twitter platform\nthat explores the impressions that activists had of our tool, and how people\nreacted and engaged with online bots that exposed visual bias. We conclude by\ndiscussing design and implication of our findings for creating future systems\nto identify and counteract the effects of news bias.",
    "published_date": "2017-02-21T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC",
      "K.4.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.06492v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.06375v2",
    "title": "Scalable computation for optimal control of cascade systems with constraints",
    "authors": [
      "Michael Cantoni",
      "Farhad Farokhi",
      "Eric C. Kerrigan",
      "Iman Shames"
    ],
    "author_ids": [],
    "abstract": "A method is devised for numerically solving a class of finite-horizon optimal\ncontrol problems subject to cascade linear discrete-time dynamics. It is\nassumed that the linear state and input inequality constraints, and the\nquadratic measure of performance, are all separable with respect to the spatial\ndimension of the underlying cascade of sub-systems, as well as the temporal\ndimension of the dynamics. By virtue of this structure, the computation cost of\nan interior-point method for an equivalent quadratic programming formulation of\nthe optimal control problem can be made to scale linearly with the number of\nsub-systems. However, the complexity of this approach grows cubically with the\ntime horizon. As such, computational advantage becomes apparent in situations\nwhere the number of sub-systems is relatively large. In any case, the method is\namenable to distributed computation with low communication overhead and only\nimmediate upstream neighbour sharing of partial model data among processing\nagents. An example is presented to illustrate an application of the main\nresults to model data for the cascade dynamics of an automated irrigation\nchannel.",
    "published_date": "2017-02-21T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.06375v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.06016v2",
    "title": "Public discourse and news consumption on online social media: A quantitative, cross-platform analysis of the Italian Referendum",
    "authors": [
      "Michela Del Vicario",
      "Sabrina Gaito",
      "Walter Quattrociocchi",
      "Matteo Zignani",
      "Fabiana Zollo"
    ],
    "author_ids": [],
    "abstract": "The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.",
    "published_date": "2017-02-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.06016v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.05985v3",
    "title": "Fano's inequality for random variables",
    "authors": [
      "Sebastien Gerchinovitz",
      "Pierre Ménard",
      "Gilles Stoltz"
    ],
    "author_ids": [],
    "abstract": "We extend Fano's inequality, which controls the average probability of events\nin terms of the average of some $f$--divergences, to work with arbitrary events\n(not necessarily forming a partition) and even with arbitrary $[0,1]$--valued\nrandom variables, possibly in continuously infinite number. We provide two\napplications of these extensions, in which the consideration of random\nvariables is particularly handy: we offer new and elegant proofs for existing\nlower bounds, on Bayesian posterior concentration (minimax or\ndistribution-dependent) rates and on the regret in non-stochastic sequential\nlearning.",
    "published_date": "2017-02-20T00:00:00",
    "year": 2017,
    "categories": [
      "math.ST",
      "cs.IT",
      "math.IT",
      "stat.TH"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05985v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.05977v1",
    "title": "On the Spectral Efficiency and Fairness in Full-Duplex Cellular Networks",
    "authors": [
      "Jose Mairton B. da Silva Jr.",
      "Gabor Fodor",
      "Carlo Fischione"
    ],
    "author_ids": [],
    "abstract": "To increase the spectral efficiency of wireless networks without requiring\nfull-duplex capability of user devices, a potential solution is the recently\nproposed three-node full-duplex mode. To realize this potential, networks\nemploying three-node full-duplex transmissions must deal with self-interference\nand user-to-user interference, which can be managed by frequency channel and\npower allocation techniques. Whereas previous works investigated either\nspectral efficient or fair mechanisms, a scheme that balances these two metrics\namong users is investigated in this paper. This balancing scheme is based on a\nnew solution method of the multi-objective optimization problem to maximize the\nweighted sum of the per-user spectral efficiency and the minimum spectral\nefficiency among users. The mixed integer non-linear nature of this problem is\ndealt by Lagrangian duality. Based on the proposed solution approach, a\nlow-complexity centralized algorithm is developed, which relies on large scale\nfading measurements that can be advantageously implemented at the base station.\nNumerical results indicate that the proposed algorithm increases the spectral\nefficiency and fairness among users without the need of weighting the spectral\nefficiency. An important conclusion is that managing user-to-user interference\nby resource assignment and power control is crucial for ensuring spectral\nefficient and fair operation of full-duplex networks.",
    "published_date": "2017-02-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05977v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.05901v1",
    "title": "Reducing the Computational Complexity of Multicasting in Large-Scale Antenna Systems",
    "authors": [
      "Meysam Sadeghi",
      "Luca Sanguinetti",
      "Romain Couillet",
      "Chau Yuen"
    ],
    "author_ids": [],
    "abstract": "In this paper, we study the physical layer multicasting to multiple\nco-channel groups in large-scale antenna systems. The users within each group\nare interested in a common message and different groups have distinct messages.\nIn particular, we aim at designing the precoding vectors solving the so-called\nquality of service (QoS) and weighted max-min fairness (MMF) problems, assuming\nthat the channel state information is available at the base station (BS). To\nsolve both problems, the baseline approach exploits the semidefinite relaxation\n(SDR) technique. Considering a BS with $N$ antennas, the SDR complexity is more\nthan $\\mathcal{O}(N^{6})$, which prevents its application in large-scale\nantenna systems. To overcome this issue, we present two new classes of\nalgorithms that, not only have significantly lower computational complexity\nthan existing solutions, but also largely outperform the SDR based methods.\nMoreover, we present a novel duality between transformed versions of the QoS\nand the weighted MMF problems. The duality explicitly determines the solution\nto the weighted MMF problem given the solution to the QoS problem, and vice\nversa. Numerical results are used to validate the effectiveness of the proposed\nsolutions and to make comparisons with existing alternatives under different\noperating conditions.",
    "published_date": "2017-02-20T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05901v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.05792v2",
    "title": "Improving Localization Accuracy in Connected Vehicle Networks Using Rao-Blackwellized Particle Filters: Theory, Simulations, and Experiments",
    "authors": [
      "Macheng Shen",
      "Ding Zhao",
      "Jing Sun",
      "Huei Peng"
    ],
    "author_ids": [],
    "abstract": "A crucial function for automated vehicle technologies is accurate\nlocalization. Lane-level accuracy is not readily available from low-cost Global\nNavigation Satellite System (GNSS) receivers because of factors such as\nmultipath error and atmospheric bias. Approaches such as Differential GNSS can\nimprove localization accuracy, but usually require investment in expensive base\nstations. Connected vehicle technologies provide an alternative approach to\nimproving the localization accuracy. It will be shown in this paper that\nlocalization accuracy can be enhanced using crude GNSS measurements from a\ngroup of connected vehicles, by matching their locations to a digital map. A\nRao-Blackwellized particle filter (RBPF) is used to jointly estimate the common\nbiases of the pseudo-ranges and the vehicle positions. Multipath biases, which\nintroduce receiver-specific (non-common) error, are mitigated by a\nmulti-hypothesis detection-rejection approach. The temporal correlation of the\nestimations is exploited through the prediction-update process. The proposed\napproach is compared to existing methods using both simulations and\nexperimental results. It was found that the proposed algorithm can eliminate\nthe common biases and reduce the localization error to below 1 meter under open\nsky conditions.",
    "published_date": "2017-02-19T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05792v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.05437v2",
    "title": "Quantifying Program Bias",
    "authors": [
      "Aws Albarghouthi",
      "Loris D'Antoni",
      "Samuel Drews",
      "Aditya Nori"
    ],
    "author_ids": [],
    "abstract": "With the range and sensitivity of algorithmic decisions expanding at a\nbreak-neck speed, it is imperative that we aggressively investigate whether\nprograms are biased. We propose a novel probabilistic program analysis\ntechnique and apply it to quantifying bias in decision-making programs.\nSpecifically, we (i) present a sound and complete automated verification\ntechnique for proving quantitative properties of probabilistic programs; (ii)\nshow that certain notions of bias, recently proposed in the fairness\nliterature, can be phrased as quantitative correctness properties; and (iii)\npresent FairSquare, the first verification tool for quantifying program bias,\nand evaluate it on a range of decision-making programs.",
    "published_date": "2017-02-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05437v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.05222v2",
    "title": "Direct Estimation of Information Divergence Using Nearest Neighbor Ratios",
    "authors": [
      "Morteza Noshad",
      "Kevin R. Moon",
      "Salimeh Yasaei Sekeh",
      "Alfred O. Hero III"
    ],
    "author_ids": [],
    "abstract": "We propose a direct estimation method for R\\'{e}nyi and f-divergence measures\nbased on a new graph theoretical interpretation. Suppose that we are given two\nsample sets $X$ and $Y$, respectively with $N$ and $M$ samples, where\n$\\eta:=M/N$ is a constant value. Considering the $k$-nearest neighbor ($k$-NN)\ngraph of $Y$ in the joint data set $(X,Y)$, we show that the average powered\nratio of the number of $X$ points to the number of $Y$ points among all $k$-NN\npoints is proportional to R\\'{e}nyi divergence of $X$ and $Y$ densities. A\nsimilar method can also be used to estimate f-divergence measures. We derive\nbias and variance rates, and show that for the class of $\\gamma$-H\\\"{o}lder\nsmooth functions, the estimator achieves the MSE rate of\n$O(N^{-2\\gamma/(\\gamma+d)})$. Furthermore, by using a weighted ensemble\nestimation technique, for density functions with continuous and bounded\nderivatives of up to the order $d$, and some extra conditions at the support\nset boundary, we derive an ensemble estimator that achieves the parametric MSE\nrate of $O(1/N)$. Our estimators are more computationally tractable than other\ncompeting estimators, which makes them appealing in many practical\napplications.",
    "published_date": "2017-02-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.05222v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.04921v1",
    "title": "Ignore or Comply? On Breaking Symmetry in Consensus",
    "authors": [
      "Petra Berenbrink",
      "Andrea Clementi",
      "Robert Elsässer",
      "Peter Kling",
      "Frederik Mallmann-Trenn",
      "Emanuele Natale"
    ],
    "author_ids": [],
    "abstract": "We study consensus processes on the complete graph of $n$ nodes. Initially,\neach node supports one from up to n opinions. Nodes randomly and in parallel\nsample the opinions of constant many nodes. Based on these samples, they use an\nupdate rule to change their own opinion.\n  The goal is to reach consensus, a configuration where all nodes support the\nsame opinion. We compare two well-known update rules: 2-Choices and 3-Majority.\nIn the former, each node samples two nodes and adopts their opinion if they\nagree. In the latter, each node samples three nodes: If an opinion is supported\nby at least two samples the node adopts it, otherwise it randomly adopts one of\nthe sampled opinions. Known results for these update rules focus on initial\nconfigurations with a limited number of colors (say $n^{1/3}$ ), or typically\nassume a bias, where one opinion has a much larger support than any other. For\nsuch biased configurations, the time to reach consensus is roughly the same for\n2-Choices and 3-Majority.\n  Interestingly, we prove that this is no longer true for configurations with a\nlarge number of initial colors. In particular, we show that 3-Majority reaches\nconsensus with high probability in $O(n^{3/4}\\log^{7/8}n)$ rounds, while\n2-Choices can need $\\Omega(n/\\log n)$ rounds. We thus get the first\nunconditional sublinear bound for 3-Majority and the first result separating\nthe consensus time of these processes. Along the way, we develop a framework\nthat allows a fine-grained comparison between consensus processes from a\nspecific class. We believe that this framework might help to classify the\nperformance of more consensus processes.",
    "published_date": "2017-02-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.04921v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.04837v4",
    "title": "Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging",
    "authors": [
      "Shusen Wang",
      "Alex Gittens",
      "Michael W. Mahoney"
    ],
    "author_ids": [],
    "abstract": "We address the statistical and optimization impacts of the classical sketch\nand Hessian sketch used to approximately solve the Matrix Ridge Regression\n(MRR) problem. Prior research has quantified the effects of classical sketch on\nthe strictly simpler least squares regression (LSR) problem. We establish that\nclassical sketch has a similar effect upon the optimization properties of MRR\nas it does on those of LSR: namely, it recovers nearly optimal solutions. By\ncontrast, Hessian sketch does not have this guarantee, instead, the\napproximation error is governed by a subtle interplay between the \"mass\" in the\nresponses and the optimal objective value.\n  For both types of approximation, the regularization in the sketched MRR\nproblem results in significantly different statistical properties from those of\nthe sketched LSR problem. In particular, there is a bias-variance trade-off in\nsketched MRR that is not present in sketched LSR. We provide upper and lower\nbounds on the bias and variance of sketched MRR, these bounds show that\nclassical sketch significantly increases the variance, while Hessian sketch\nsignificantly increases the bias. Empirically, sketched MRR solutions can have\nrisks that are higher by an order-of-magnitude than those of the optimal MRR\nsolutions.\n  We establish theoretically and empirically that model averaging greatly\ndecreases the gap between the risks of the true and sketched solutions to the\nMRR problem. Thus, in parallel or distributed settings, sketching combined with\nmodel averaging is a powerful technique that quickly obtains near-optimal\nsolutions to the MRR problem while greatly mitigating the increased statistical\nrisk incurred by sketching.",
    "published_date": "2017-02-16T00:00:00",
    "year": 2017,
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NA"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.04837v4",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.04459v2",
    "title": "Robust Stochastic Configuration Networks with Kernel Density Estimation",
    "authors": [
      "Dianhui Wang",
      "Ming Li"
    ],
    "author_ids": [],
    "abstract": "Neural networks have been widely used as predictive models to fit data\ndistribution, and they could be implemented through learning a collection of\nsamples. In many applications, however, the given dataset may contain noisy\nsamples or outliers which may result in a poor learner model in terms of\ngeneralization. This paper contributes to a development of robust stochastic\nconfiguration networks (RSCNs) for resolving uncertain data regression\nproblems. RSCNs are built on original stochastic configuration networks with\nweighted least squares method for evaluating the output weights, and the input\nweights and biases are incrementally and randomly generated by satisfying with\na set of inequality constrains. The kernel density estimation (KDE) method is\nemployed to set the penalty weights for each training samples, so that some\nnegative impacts, caused by noisy data or outliers, on the resulting learner\nmodel can be reduced. The alternating optimization technique is applied for\nupdating a RSCN model with improved penalty weights computed from the kernel\ndensity estimation function. Performance evaluation is carried out by a\nfunction approximation, four benchmark datasets and a case study on engineering\napplication. Comparisons to other robust randomised neural modelling\ntechniques, including the probabilistic robust learning algorithm for neural\nnetworks with random weights and improved RVFL networks, indicate that the\nproposed RSCNs with KDE perform favourably and demonstrate good potential for\nreal-world applications.",
    "published_date": "2017-02-15T00:00:00",
    "year": 2017,
    "categories": [
      "cs.NE",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.04459v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.03849v3",
    "title": "Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis",
    "authors": [
      "Maxim Raginsky",
      "Alexander Rakhlin",
      "Matus Telgarsky"
    ],
    "author_ids": [],
    "abstract": "Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of\nStochastic Gradient Descent, where properly scaled isotropic Gaussian noise is\nadded to an unbiased estimate of the gradient at each iteration. This modest\nchange allows SGLD to escape local minima and suffices to guarantee asymptotic\nconvergence to global minimizers for sufficiently regular non-convex objectives\n(Gelfand and Mitter, 1991). The present work provides a nonasymptotic analysis\nin the context of non-convex learning problems, giving finite-time guarantees\nfor SGLD to find approximate minimizers of both empirical and population risks.\nAs in the asymptotic setting, our analysis relates the discrete-time SGLD\nMarkov chain to a continuous-time diffusion process. A new tool that drives the\nresults is the use of weighted transportation cost inequalities to quantify the\nrate of convergence of SGLD to a stationary distribution in the Euclidean\n$2$-Wasserstein distance.",
    "published_date": "2017-02-13T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "math.OC",
      "math.PR",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.03849v3",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.03051v1",
    "title": "Density Functional Estimators with k-Nearest Neighbor Bandwidths",
    "authors": [
      "Weihao Gao",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "author_ids": [],
    "abstract": "Estimating expected polynomials of density functions from samples is a basic\nproblem with numerous applications in statistics and information theory.\nAlthough kernel density estimators are widely used in practice for such\nfunctional estimation problems, practitioners are left on their own to choose\nan appropriate bandwidth for each application in hand. Further, kernel density\nestimators suffer from boundary biases, which are prevalent in real world data\nwith lower dimensional structures. We propose using the fixed-k nearest\nneighbor distances for the bandwidth, which adaptively adjusts to local\ngeometry. Further, we propose a novel estimator based on local likelihood\ndensity estimators, that mitigates the boundary biases. Although such a choice\nof fixed-k nearest neighbor distances to bandwidths results in inconsistent\nestimators, we provide a simple debiasing scheme that precomputes the\nasymptotic bias and divides off this term. With this novel correction, we show\nconsistency of this debiased estimator. We provide numerical experiments\nsuggesting that it improves upon competing state-of-the-art methods.",
    "published_date": "2017-02-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.03051v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.03041v2",
    "title": "Reconstruction-Based Disentanglement for Pose-invariant Face Recognition",
    "authors": [
      "Xi Peng",
      "Xiang Yu",
      "Kihyuk Sohn",
      "Dimitris Metaxas",
      "Manmohan Chandraker"
    ],
    "author_ids": [],
    "abstract": "Deep neural networks (DNNs) trained on large-scale datasets have recently\nachieved impressive improvements in face recognition. But a persistent\nchallenge remains to develop methods capable of handling large pose variations\nthat are relatively underrepresented in training data. This paper presents a\nmethod for learning a feature representation that is invariant to pose, without\nrequiring extensive pose coverage in training data. We first propose to\ngenerate non-frontal views from a single frontal face, in order to increase the\ndiversity of training data while preserving accurate facial details that are\ncritical for identity discrimination. Our next contribution is to seek a rich\nembedding that encodes identity features, as well as non-identity ones such as\npose and landmark locations. Finally, we propose a new feature reconstruction\nmetric learning to explicitly disentangle identity and pose, by demanding\nalignment between the feature reconstructions through various combinations of\nidentity and pose features, which is obtained from two images of the same\nsubject. Experiments on both controlled and in-the-wild face datasets, such as\nMultiPIE, 300WLP and the profile view database CFP, show that our method\nconsistently outperforms the state-of-the-art, especially on images with large\nhead pose variations. Detail results and resource are referred to\nhttps://sites.google.com/site/xipengcshomepage/iccv2017",
    "published_date": "2017-02-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.03041v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.02873v1",
    "title": "Multi-feature classifiers for burst detection in single EEG channels from preterm infants",
    "authors": [
      "X. Navarro",
      "F. Porée",
      "M. Kuchenbuch",
      "M. Chavez",
      "A. Beuchée",
      "G. Carrault"
    ],
    "author_ids": [],
    "abstract": "The study of electroencephalographic (EEG) bursts in preterm infants provides\nvaluable information about maturation or prognostication after perinatal\nasphyxia. Over the last two decades, a number of works proposed algorithms to\nautomatically detect EEG bursts in preterm infants, but they were designed for\npopulations under 35 weeks of post menstrual age (PMA). However, as the brain\nactivity evolves rapidly during postnatal life, these solutions might be\nunder-performing with increasing PMA. In this work we focused on preterm\ninfants reaching term ages (PMA $\\geq$ 36 weeks) using multi-feature\nclassification on a single EEG channel. Five EEG burst detectors relying on\ndifferent machine learning approaches were compared: Logistic regression (LR),\nlinear discriminant analysis (LDA), k-nearest neighbors (kNN), support vector\nmachines (SVM) and thresholding (Th). Classifiers were trained by visually\nlabeled EEG recordings from 14 very preterm infants (born after 28 weeks of\ngestation) with 36 - 41 weeks PMA. The most performing classifiers reached\nabout 95\\% accuracy (kNN, SVM and LR) whereas Th obtained 84\\%. Compared to\nhuman-automatic agreements, LR provided the highest scores (Cohen's kappa =\n0.71) and the best computational efficiency using only three EEG features.\nApplying this classifier in a test database of 21 infants $\\geq$ 36 weeks PMA,\nwe show that long EEG bursts and short inter-bust periods are characteristic of\ninfants with the highest PMA and weights. In view of these results, LR-based\nburst detection could be a suitable tool to study maturation in monitoring or\nportable devices using a single EEG channel.",
    "published_date": "2017-02-08T00:00:00",
    "year": 2017,
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.02873v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.01807v2",
    "title": "How well can machine learning predict demographics of social media users?",
    "authors": [
      "Nina Cesare",
      "Christan Grant",
      "Quynh Nguyen",
      "Hedwig Lee",
      "Elaine O. Nsoesie"
    ],
    "author_ids": [],
    "abstract": "The wide use of social media sites and other digital technologies have\nresulted in an unprecedented availability of digital data that are being used\nto study human behavior across research domains. Although unsolicited opinions\nand sentiments are available on these platforms, demographic details are\nusually missing. Demographic information is pertinent in fields such as\ndemography and public health, where significant differences can exist across\nsex, racial and socioeconomic groups. In an attempt to address this\nshortcoming, a number of academic studies have proposed methods for inferring\nthe demographics of social media users using details such as names, usernames,\nand network characteristics. Gender is the easiest trait to accurately infer,\nwith measures of accuracy higher than 90 percent in some studies. Race,\nethnicity and age tend to be more challenging to predict for a variety of\nreasons including the novelty of social media to certain age groups and a lack\nof significant deviations in user details across racial and ethnic groups.\nAlthough the endeavor to predict user demographics is plagued with ethical\nquestions regarding privacy and data ownership, knowing the demographics in a\ndata sample can aid in addressing issues of bias and population representation,\nso that existing societal inequalities are not exacerbated.",
    "published_date": "2017-02-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.01807v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1702.01677v1",
    "title": "On the Value of Penalties in Time-Inconsistent Planning",
    "authors": [
      "Susanne Albers",
      "Dennis Kraft"
    ],
    "author_ids": [],
    "abstract": "People tend to behave inconsistently over time due to an inherent present\nbias. As this may impair performance, social and economic settings need to be\nadapted accordingly. Common tools to reduce the impact of time-inconsistent\nbehavior are penalties and prohibition. Such tools are called commitment\ndevices. In recent work Kleinberg and Oren connect the design of\nprohibition-based commitment devices to a combinatorial problem in which edges\nare removed from a task graph $G$ with $n$ nodes. However, this problem is\nNP-hard to approximate within a ratio less than $\\sqrt{n}/3$. To address this\nissue, we propose a penalty-based commitment device that does not delete edges\nbut raises their cost. The benefits of our approach are twofold. On the\nconceptual side, we show that penalties are up to $1/\\beta$ times more\nefficient than prohibition, where $\\beta \\in (0,1]$ parameterizes the present\nbias. On the computational side, we significantly improve approximability by\npresenting a $2$-approximation algorithm for allocating the penalties. To\ncomplement this result, we prove that optimal penalties are NP-hard to\napproximate within a ratio of $1.08192$.",
    "published_date": "2017-02-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.01677v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.01398v1",
    "title": "Evolution of Ego-networks in Social Media with Link Recommendations",
    "authors": [
      "Luca Maria Aiello",
      "Nicola Barbieri"
    ],
    "author_ids": [],
    "abstract": "Ego-networks are fundamental structures in social graphs, yet the process of\ntheir evolution is still widely unexplored. In an online context, a key\nquestion is how link recommender systems may skew the growth of these networks,\npossibly restraining diversity. To shed light on this matter, we analyze the\ncomplete temporal evolution of 170M ego-networks extracted from Flickr and\nTumblr, comparing links that are created spontaneously with those that have\nbeen algorithmically recommended. We find that the evolution of ego-networks is\nbursty, community-driven, and characterized by subsequent phases of explosive\ndiameter increase, slight shrinking, and stabilization. Recommendations favor\npopular and well-connected nodes, limiting the diameter expansion. With a\nmatching experiment aimed at detecting causal relationships from observational\ndata, we find that the bias introduced by the recommendations fosters global\ndiversity in the process of neighbor selection. Last, with two link prediction\nexperiments, we show how insights from our analysis can be used to improve the\neffectiveness of social recommender systems.",
    "published_date": "2017-02-05T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "91D30",
      "H.3.5"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.01398v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.01284v2",
    "title": "New cardinality estimation algorithms for HyperLogLog sketches",
    "authors": [
      "Otmar Ertl"
    ],
    "author_ids": [],
    "abstract": "This paper presents new methods to estimate the cardinalities of data sets\nrecorded by HyperLogLog sketches. A theoretically motivated extension to the\noriginal estimator is presented that eliminates the bias for small and large\ncardinalities. Based on the maximum likelihood principle a second unbiased\nmethod is derived together with a robust and efficient numerical algorithm to\ncalculate the estimate. The maximum likelihood approach can also be applied to\nmore than a single HyperLogLog sketch. In particular, it is shown that it gives\nmore precise cardinality estimates for union, intersection, or relative\ncomplements of two sets that are both represented by HyperLogLog sketches\ncompared to the conventional technique using the inclusion-exclusion principle.\nAll the new methods are demonstrated and verified by extensive simulations.",
    "published_date": "2017-02-04T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DS",
      "68W15, 68W25, 62-07",
      "E.1; I.1.2; H.2.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.01284v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.01112v3",
    "title": "Optimal Input Design for Affine Model Discrimination with Applications in Intention-Aware Vehicles",
    "authors": [
      "Yuhao Ding",
      "Farshad Harirchi",
      "Sze Zheng Yong",
      "Emil Jacobsen",
      "Necmiye Ozay"
    ],
    "author_ids": [],
    "abstract": "This paper considers the optimal design of input signals for the purpose of\ndiscriminating among a finite number of affine models with uncontrolled inputs\nand noise. Each affine model represents a different system operating mode,\ncorresponding to unobserved intents of other drivers or robots, or to fault\ntypes or attack strategies, etc. The input design problem aims to find optimal\nseparating/discriminating (controlled) inputs such that the output trajectories\nof all the affine models are guaranteed to be distinguishable from each other,\ndespite uncertainty in the initial condition and uncontrolled inputs as well as\nthe presence of process and measurement noise. We propose a novel formulation\nto solve this problem, with an emphasis on guarantees for model discrimination\nand optimality, in contrast to a previously proposed conservative formulation\nusing robust optimization. This new formulation can be recast as a bilevel\noptimization problem and further reformulated as a mixed-integer linear program\n(MILP). Moreover, our fairly general problem setting allows the incorporation\nof objectives and/or responsibilities among rational agents. For instance, each\ndriver has to obey traffic rules, while simultaneously optimizing for safety,\ncomfort and energy efficiency. Finally, we demonstrate the effectiveness of our\napproach for identifying the intention of other vehicles in several driving\nscenarios.",
    "published_date": "2017-02-03T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.01112v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.00829v1",
    "title": "Measuring Gender Inequalities of German Professions on Wikipedia",
    "authors": [
      "Olga Zagovora"
    ],
    "author_ids": [],
    "abstract": "Wikipedia is a community-created online encyclopedia; arguably, it is the\nmost popular and largest knowledge resource on the Internet. Thus, reliability\nand neutrality are of high importance for Wikipedia. Previous research [3]\nreveals gender bias in Google search results for many professions and\noccupations. Also, Wikipedia was criticized for existing gender bias in\nbiographies [4] and gender gap in the editor community [5, 6]. Thus, one could\nexpect that gender bias related to professions and occupations may be present\nin Wikipedia. The term gender bias is used here in the sense of conscious or\nunconscious favoritism towards one gender over another [47] with respect to\nprofessions and occupations. The objective of this work is to identify and\nassess gender bias. To this end, the German Wikipedia articles about\nprofessions and occupations were analyzed on three dimensions: redirections,\nimages, and people mentioned in the articles. This work provides evidence for\nsystematic overrepresentation of men in all three dimensions; female bias is\nonly present for a few professions.",
    "published_date": "2017-02-02T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.SI",
      "G.3; H.3.1; H.5.3; I.2.7; J.4"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.00829v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.00802v1",
    "title": "A Class of Exponential Sequences with Shift-Invariant Discriminators",
    "authors": [
      "Sajed Haque",
      "Jeffrey Shallit"
    ],
    "author_ids": [],
    "abstract": "The discriminator of an integer sequence s = (s(i))_{i>=0}, introduced by\nArnold, Benkoski, and McCabe in 1985, is the function D_s(n) that sends n to\nthe least integer m such that the numbers s(0), s(1), ..., s(n-1) are pairwise\nincongruent modulo m. In this note we present a class of exponential sequences\nthat have the special property that their discriminators are shift-invariant,\ni.e., that the discriminator of the sequence is the same even if the sequence\nis shifted by any positive constant.",
    "published_date": "2017-02-02T00:00:00",
    "year": 2017,
    "categories": [
      "math.NT",
      "cs.DM"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.00802v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1702.00137v1",
    "title": "Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program",
    "authors": [
      "Eric Eaton",
      "Sven Koenig",
      "Claudia Schulz",
      "Francesco Maurelli",
      "John Lee",
      "Joshua Eckroth",
      "Mark Crowley",
      "Richard G. Freedman",
      "Rogelio E. Cardona-Rivera",
      "Tiago Machado",
      "Tom Williams"
    ],
    "author_ids": [],
    "abstract": "The 7th Symposium on Educational Advances in Artificial Intelligence\n(EAAI'17, co-chaired by Sven Koenig and Eric Eaton) launched the EAAI New and\nFuture AI Educator Program to support the training of early-career university\nfaculty, secondary school faculty, and future educators (PhD candidates or\npostdocs who intend a career in academia). As part of the program, awardees\nwere asked to address one of the following \"blue sky\" questions:\n  * How could/should Artificial Intelligence (AI) courses incorporate ethics\ninto the curriculum?\n  * How could we teach AI topics at an early undergraduate or a secondary\nschool level?\n  * AI has the potential for broad impact to numerous disciplines. How could we\nmake AI education more interdisciplinary, specifically to benefit\nnon-engineering fields?\n  This paper is a collection of their responses, intended to help motivate\ndiscussion around these issues in AI education.",
    "published_date": "2017-02-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1702.00137v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.09039v1",
    "title": "Ties That Bind - Characterizing Classes by Attributes and Social Ties",
    "authors": [
      "Aria Rezaei",
      "Bryan Perozzi",
      "Leman Akoglu"
    ],
    "author_ids": [],
    "abstract": "Given a set of attributed subgraphs known to be from different classes, how\ncan we discover their differences? There are many cases where collections of\nsubgraphs may be contrasted against each other. For example, they may be\nassigned ground truth labels (spam/not-spam), or it may be desired to directly\ncompare the biological networks of different species or compound networks of\ndifferent chemicals.\n  In this work we introduce the problem of characterizing the differences\nbetween attributed subgraphs that belong to different classes. We define this\ncharacterization problem as one of partitioning the attributes into as many\ngroups as the number of classes, while maximizing the total attributed quality\nscore of all the given subgraphs.\n  We show that our attribute-to-class assignment problem is NP-hard and an\noptimal $(1 - 1/e)$-approximation algorithm exists. We also propose two\ndifferent faster heuristics that are linear-time in the number of attributes\nand subgraphs. Unlike previous work where only attributes were taken into\naccount for characterization, here we exploit both attributes and social ties\n(i.e. graph structure).\n  Through extensive experiments, we compare our proposed algorithms, show\nfindings that agree with human intuition on datasets from Amazon co-purchases,\nCongressional bill sponsorships, and DBLP co-authorships. We also show that our\napproach of characterizing subgraphs is better suited for sense-making than\ndiscriminating classification approaches.",
    "published_date": "2017-01-31T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "cs.IR",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.09039v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.08671v1",
    "title": "The perceived assortativity of social networks: Methodological problems and solutions",
    "authors": [
      "David N Fisher",
      "Matthew J Silk",
      "Daniel W Franks"
    ],
    "author_ids": [],
    "abstract": "Networks describe a range of social, biological and technical phenomena. An\nimportant property of a network is its degree correlation or assortativity,\ndescribing how nodes in the network associate based on their number of\nconnections. Social networks are typically thought to be distinct from other\nnetworks in being assortative (possessing positive degree correlations);\nwell-connected individuals associate with other well-connected individuals, and\npoorly-connected individuals associate with each other. We review the evidence\nfor this in the literature and find that, while social networks are more\nassortative than non-social networks, only when they are built using\ngroup-based methods do they tend to be positively assortative. Non-social\nnetworks tend to be disassortative. We go on to show that connecting\nindividuals due to shared membership of a group, a commonly used method, biases\ntowards assortativity unless a large enough number of censuses of the network\nare taken. We present a number of solutions to overcoming this bias by drawing\non advances in sociological and biological fields. Adoption of these methods\nacross all fields can greatly enhance our understanding of social networks and\nnetworks in general.",
    "published_date": "2017-01-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph",
      "q-bio.QM",
      "stat.ME"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.08671v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.08534v2",
    "title": "Optimal Transportation to the Entropy-Power Inequality",
    "authors": [
      "Olivier Rioul"
    ],
    "author_ids": [],
    "abstract": "We present a simple proof of the entropy-power inequality using an optimal\ntransportation argument which takes the form of a simple change of variables.\nThe same argument yields a reverse inequality involving a conditional\ndifferential entropy which has its own interest. It can also be generalized in\nvarious ways. The equality case is easily captured by this method and the proof\nis formally identical in one and several dimensions.",
    "published_date": "2017-01-30T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.08534v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.08230v4",
    "title": "Algorithmic decision making and the cost of fairness",
    "authors": [
      "Sam Corbett-Davies",
      "Emma Pierson",
      "Avi Feller",
      "Sharad Goel",
      "Aziz Huq"
    ],
    "author_ids": [],
    "abstract": "Algorithms are now regularly used to decide whether defendants awaiting trial\nare too dangerous to be released back into the community. In some cases, black\ndefendants are substantially more likely than white defendants to be\nincorrectly classified as high risk. To mitigate such disparities, several\ntechniques recently have been proposed to achieve algorithmic fairness. Here we\nreformulate algorithmic fairness as constrained optimization: the objective is\nto maximize public safety while satisfying formal fairness constraints designed\nto reduce racial disparities. We show that for several past definitions of\nfairness, the optimal algorithms that result require detaining defendants above\nrace-specific risk thresholds. We further show that the optimal unconstrained\nalgorithm requires applying a single, uniform threshold to all defendants. The\nunconstrained algorithm thus maximizes public safety while also satisfying one\nimportant understanding of equality: that all individuals are held to the same\nstandard, irrespective of race. Because the optimal constrained and\nunconstrained algorithms generally differ, there is tension between improving\npublic safety and satisfying prevailing notions of algorithmic fairness. By\nexamining data from Broward County, Florida, we show that this trade-off can be\nlarge in practice. We focus on algorithms for pretrial release decisions, but\nthe principles we discuss apply to other domains, and also to human decision\nmakers carrying out structured decision rules.",
    "published_date": "2017-01-28T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "stat.AP"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.08230v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.07769v1",
    "title": "Ethical Considerations in Artificial Intelligence Courses",
    "authors": [
      "Emanuelle Burton",
      "Judy Goldsmith",
      "Sven Koenig",
      "Benjamin Kuipers",
      "Nicholas Mattei",
      "Toby Walsh"
    ],
    "author_ids": [],
    "abstract": "The recent surge in interest in ethics in artificial intelligence may leave\nmany educators wondering how to address moral, ethical, and philosophical\nissues in their AI courses. As instructors we want to develop curriculum that\nnot only prepares students to be artificial intelligence practitioners, but\nalso to understand the moral, ethical, and philosophical impacts that\nartificial intelligence will have on society. In this article we provide\npractical case studies and links to resources for use by AI educators. We also\nprovide concrete suggestions on how to integrate AI ethics into a general\nartificial intelligence course and how to teach a stand-alone artificial\nintelligence ethics course.",
    "published_date": "2017-01-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GL",
      "K.3.2; K.4.1; K.7.m"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.07769v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.07765v1",
    "title": "Contextual Consent: Ethical Mining of Social Media for Health Research",
    "authors": [
      "Chris Norval",
      "Tristan Henderson"
    ],
    "author_ids": [],
    "abstract": "Social media are a rich source of insight for data mining and user-centred\nresearch, but the question of consent arises when studying such data without\nthe express knowledge of the creator. Case studies that mine social data from\nusers of online services such as Facebook and Twitter are becoming increasingly\ncommon. This has led to calls for an open discussion into how researchers can\nbest use these vast resources to make innovative findings while still\nrespecting fundamental ethical principles. In this position paper we highlight\nsome key considerations for this topic and argue that the conditions of\ninformed consent are often not being met, and that using social media data that\nsome deem free to access and analyse may result in undesirable consequences,\nparticularly within the domain of health research and other sensitive topics.\nWe posit that successful exploitation of online personal data, particularly for\nhealth and other sensitive research, requires new and usable methods of\nobtaining consent from the user.",
    "published_date": "2017-01-26T00:00:00",
    "year": 2017,
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.07765v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.06811v3",
    "title": "Socio-technical Smart Grid Optimization via Decentralized Charge Control of Electric Vehicles",
    "authors": [
      "Evangelos Pournaras",
      "Seoho Jung",
      "Srivatsan Yadhunathan",
      "Huiting Zhang",
      "Xingliang Fang"
    ],
    "author_ids": [],
    "abstract": "The penetration of electric vehicles becomes a catalyst for the\nsustainability of Smart Cities. However, unregulated battery charging remains a\nchallenge causing high energy costs, power peaks or even blackouts. This paper\nstudies this challenge from a socio-technical perspective: social dynamics such\nas the participation in demand-response programs, the discomfort experienced by\nalternative suggested vehicle usage times and even the fairness in terms of how\nequally discomfort is experienced among the population are highly intertwined\nwith Smart Grid reliability. To address challenges of such a socio-technical\nnature, this paper introduces a fully decentralized and participatory learning\nmechanism for privacy-preserving coordinated charging control of electric\nvehicles that regulates three Smart Grid socio-technical aspects: (i)\nreliability, (ii) discomfort and (iii) fairness. In contrast to related work, a\nnovel autonomous software agent exclusively uses local knowledge to generate\nenergy demand plans for its vehicle that encode different battery charging\nregimes. Agents interact to learn and make collective decisions of which plan\nto execute so that power peaks and energy cost are reduced system-wide.\nEvaluation with real-world data confirms the improvement of drivers' comfort\nand fairness using the proposed planning method, while this improvement is\nassessed in terms of reliability and cost reduction under a varying number of\nparticipating vehicles. These findings have a significant relevance and impact\nfor power utilities and system operator on designing more reliable and socially\nresponsible Smart Grids with high penetration of electric vehicles.",
    "published_date": "2017-01-24T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SY"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.06811v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.06233v1",
    "title": "What the Language You Tweet Says About Your Occupation",
    "authors": [
      "Tianran Hu",
      "Haoyuan Xiao",
      "Thuy-vy Thi Nguyen",
      "Jiebo Luo"
    ],
    "author_ids": [],
    "abstract": "Many aspects of people's lives are proven to be deeply connected to their\njobs. In this paper, we first investigate the distinct characteristics of major\noccupation categories based on tweets. From multiple social media platforms, we\ngather several types of user information. From users' LinkedIn webpages, we\nlearn their proficiencies. To overcome the ambiguity of self-reported\ninformation, a soft clustering approach is applied to extract occupations from\ncrowd-sourced data. Eight job categories are extracted, including Marketing,\nAdministrator, Start-up, Editor, Software Engineer, Public Relation, Office\nClerk, and Designer. Meanwhile, users' posts on Twitter provide cues for\nunderstanding their linguistic styles, interests, and personalities. Our\nresults suggest that people of different jobs have unique tendencies in certain\nlanguage styles and interests. Our results also clearly reveal distinctive\nlevels in terms of Big Five Traits for different jobs. Finally, a classifier is\nbuilt to predict job types based on the features extracted from tweets. A high\naccuracy indicates a strong discrimination power of language features for job\nprediction task.",
    "published_date": "2017-01-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.06233v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.06232v1",
    "title": "Election Bias: Comparing Polls and Twitter in the 2016 U.S. Election",
    "authors": [
      "David Anuta",
      "Josh Churchin",
      "Jiebo Luo"
    ],
    "author_ids": [],
    "abstract": "While the polls have been the most trusted source for election predictions\nfor decades, in the recent presidential election they were called inaccurate\nand biased. How inaccurate were the polls in this election and can social media\nbeat the polls as an accurate election predictor? Polls from several news\noutlets and sentiment analysis on Twitter data were used, in conjunction with\nthe results of the election, to answer this question and outline further\nresearch on the best method for predicting the outcome of future elections.",
    "published_date": "2017-01-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.06232v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.09057v3",
    "title": "Fairness-Aware Caching and Radio Resource Allocation for the Downlink of Multi-Cell OFDMA Systems",
    "authors": [
      "Sepehr Rezvani",
      "Nader Mokari",
      "Mohammad R. Javan"
    ],
    "author_ids": [],
    "abstract": "The unprecedented growth of internet contents, specially social media,\ninvoking a challenge to the load of cellular networks. In addition, nowadays,\nthe demands of quality of experience (QoE) became a more practical norm in\ncontrast of quality of service (QoS), in which downloading delay is an\nimportant factor of it. To satisfy this demand, we propose two resource\nallocation (RA) algorithms to optimize the place of social media in the cache\nof the Base stations (BSs) and radio resources (i.e., transmit powers and\nsubcarriers), jointly in a multi-cell Orthogonal Frequency Division Multiple\nAccess (OFDMA) based system. In the first scheme, the total downloading delay\nof the network is minimized, while in the second scheme, a fairness-aware\nscheme is proposed in which the maximum downloading delays is minimized. We\npropose iterative algorithms to solve each problem, where the content placement\nproblem and the joint subcarrier and transmit power allocation problem will be\niteratively optimized. We also prove that the proposed approaches converges to\na near-optimal solution, as well as the number of iterations increases.",
    "published_date": "2017-01-22T00:00:00",
    "year": 2017,
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT",
      "90C11",
      "F.2.2"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.09057v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.04906v1",
    "title": "Quantifying the distribution of editorial power and manuscript decision bias at the mega-journal PLOS ONE",
    "authors": [
      "Alexander M. Petersen"
    ],
    "author_ids": [],
    "abstract": "We analyzed the longitudinal activity of nearly 7,000 editors at the\nmega-journal PLOS ONE over the 10-year period 2006-2015. Using the\narticle-editor associations, we develop editor-specific measures of power,\nactivity, article acceptance time, citation impact, and editorial renumeration\n(an analogue to self-citation). We observe remarkably high levels of power\ninequality among the PLOS ONE editors, with the top-10 editors responsible for\n3,366 articles -- corresponding to 2.4% of the 141,986 articles we analyzed.\nSuch high inequality levels suggest the presence of unintended incentives,\nwhich may reinforce unethical behavior in the form of decision-level biases at\nthe editorial level. Our results indicate that editors may become apathetic in\njudging the quality of articles and susceptible to modes of power-driven\nmisconduct. We used the longitudinal dimension of editor activity to develop\ntwo panel regression models which test and verify the presence of editor-level\nbias. In the first model we analyzed the citation impact of articles, and in\nthe second model we modeled the decision time between an article being\nsubmitted and ultimately accepted by the editor. We focused on two variables\nthat represent social factors that capture potential conflicts-of-interest: (i)\nwe accounted for the social ties between editors and authors by developing a\nmeasure of repeat authorship among an editor's article set, and (ii) we\naccounted for the rate of citations directed towards the editor's own\npublications in the reference list of each article he/she oversaw. Our results\nindicate that these two factors play a significant role in the editorial\ndecision process. Moreover, these two effects appear to increase with editor\nage, which is consistent with behavioral studies concerning the evolution of\nmisbehavior and response to temptation in power-driven environments.",
    "published_date": "2017-01-18T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DL",
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04906v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.04869v2",
    "title": "3D Morphology Prediction of Progressive Spinal Deformities from Probabilistic Modeling of Discriminant Manifolds",
    "authors": [
      "Samuel Kadoury",
      "William Mandel",
      "Marjolaine Roy-Beaudry",
      "Marie-Lyne Nault",
      "Stefan Parent"
    ],
    "author_ids": [],
    "abstract": "We introduce a novel approach for predicting the progression of adolescent\nidiopathic scoliosis from 3D spine models reconstructed from biplanar X-ray\nimages. Recent progress in machine learning have allowed to improve\nclassification and prognosis rates, but lack a probabilistic framework to\nmeasure uncertainty in the data. We propose a discriminative probabilistic\nmanifold embedding where locally linear mappings transform data points from\nhigh-dimensional space to corresponding low-dimensional coordinates. A\ndiscriminant adjacency matrix is constructed to maximize the separation between\nprogressive and non-progressive groups of patients diagnosed with scoliosis,\nwhile minimizing the distance in latent variables belonging to the same class.\nTo predict the evolution of deformation, a baseline reconstruction is projected\nonto the manifold, from which a spatiotemporal regression model is built from\nparallel transport curves inferred from neighboring exemplars. Rate of\nprogression is modulated from the spine flexibility and curve magnitude of the\n3D spine deformation. The method was tested on 745 reconstructions from 133\nsubjects using longitudinal 3D reconstructions of the spine, with results\ndemonstrating the discriminatory framework can identify between progressive and\nnon-progressive of scoliotic patients with a classification rate of 81% and\nprediction differences of 2.1$^{o}$ in main curve angulation, outperforming\nother manifold learning methods. Our method achieved a higher prediction\naccuracy and improved the modeling of spatiotemporal morphological changes in\nhighly deformed spines compared to other learning methods.",
    "published_date": "2017-01-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04869v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.04626v1",
    "title": "Circuit Treewidth, Sentential Decision, and Query Compilation",
    "authors": [
      "Simone Bova",
      "Stefan Szeider"
    ],
    "author_ids": [],
    "abstract": "The evaluation of a query over a probabilistic database boils down to\ncomputing the probability of a suitable Boolean function, the lineage of the\nquery over the database. The method of query compilation approaches the task in\ntwo stages: first, the query lineage is implemented (compiled) in a circuit\nform where probability computation is tractable; and second, the desired\nprobability is computed over the compiled circuit. A basic theoretical quest in\nquery compilation is that of identifying pertinent classes of queries whose\nlineages admit compact representations over increasingly succinct, tractable\ncircuit classes. Fostering previous work by Jha and Suciu (2012) and Petke and\nRazgon (2013), we focus on queries whose lineages admit circuit implementations\nwith small treewidth, and investigate their compilability within tame classes\nof decision diagrams. In perfect analogy with the characterization of bounded\ncircuit pathwidth by bounded OBDD width, we show that a class of Boolean\nfunctions has bounded circuit treewidth if and only if it has bounded SDD\nwidth. Sentential decision diagrams (SDDs) are central in knowledge\ncompilation, being essentially as tractable as OBDDs but exponentially more\nsuccinct. By incorporating constant width SDDs and polynomial size SDDs, we\nrefine the panorama of query compilation for unions of conjunctive queries with\nand without inequalities.",
    "published_date": "2017-01-17T00:00:00",
    "year": 2017,
    "categories": [
      "cs.LO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04626v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.04395v3",
    "title": "Linear Matrix Inequalities for Physically-Consistent Inertial Parameter Identification: A Statistical Perspective on the Mass Distribution",
    "authors": [
      "Patrick M. Wensing",
      "Sangbae Kim",
      "Jean-Jacques Slotine"
    ],
    "author_ids": [],
    "abstract": "With the increased application of model-based whole-body control in legged\nrobots, there has been a resurgence of research interest into methods for\naccurate system identification. An important class of methods focuses on the\ninertial parameters of rigid-body systems. These parameters consist of the\nmass, first mass moment (related to center of mass location), and rotational\ninertia matrix of each link. The main contribution of this paper is to\nformulate physical-consistency constraints on these parameters as Linear Matrix\nInequalities (LMIs). The use of these constraints in identification can\naccelerate convergence and increase robustness to noisy data. It is critically\nobserved that the proposed LMIs are expressed in terms of the covariance of the\nmass distribution, rather than its rotational moments of inertia. With this\nperspective, connections to the classical problem of moments in mathematics are\nshown to yield new bounding-volume constraints on the mass distribution of each\nlink. While previous work ensured physical plausibility or used convex\noptimization in identification, the LMIs here uniquely enable both advantages.\nConstraints are applied to identification of a leg for the MIT Cheetah 3 robot.\nDetailed properties of transmission components are identified alongside link\ninertias, with parameter optimization carried out to global optimality through\nsemidefinite programming.",
    "published_date": "2017-01-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.RO"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04395v3",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.04341v1",
    "title": "On Bezout Inequalities for non-homogeneous Polynomial Ideals",
    "authors": [
      "Amir Hashemi",
      "Joos Heintz",
      "Luis Miguel Pardo",
      "Pablo Solernó"
    ],
    "author_ids": [],
    "abstract": "We introduce a \"workable\" notion of degree for non-homogeneous polynomial\nideals and formulate and prove ideal theoretic B\\'ezout Inequalities for the\nsum of two ideals in terms of this notion of degree and the degree of\ngenerators. We compute probabilistically the degree of an equidimensional\nideal.",
    "published_date": "2017-01-16T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SC",
      "cs.CC",
      "math.AC",
      "math.AG",
      "13F20, 14A10, 13P10"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04341v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.04055v2",
    "title": "Scenario Aggregation using Binary Decision Diagrams for Stochastic Programs with Endogenous Uncertainty",
    "authors": [
      "Utz-Uwe Haus",
      "Carla Michini",
      "Marco Laumanns"
    ],
    "author_ids": [],
    "abstract": "Modeling decision-dependent scenario probabilities in stochastic programs is\ndifficult and typically leads to large and highly non-linear MINLPs that are\nvery difficult to solve. In this paper, we develop a new approach to obtain a\ncompact representation of the recourse function using a set of binary decision\ndiagrams (BDDs) that encode a nested cover of the scenario set. The resulting\nBDDs can then be used to efficiently characterize the decision-dependent\nscenario probabilities by a set of linear inequalities, which essentially\nfactorizes the probability distribution and thus allows to reformulate the\nentire problem as a small mixed-integer linear program. The approach is\napplicable to a large class of stochastic programs with multivariate binary\nscenario sets, such as stochastic network design, network reliability, or\nstochastic network interdiction problems. Computational results show that the\nBDD-based scenario representation reduces the problem size, and hence the\ncomputation time, significant compared to previous approaches.",
    "published_date": "2017-01-15T00:00:00",
    "year": 2017,
    "categories": [
      "math.OC",
      "cs.DM",
      "90C15 (Primary) 90C11, 90C35, 05C30 (Secondary)"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.04055v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.03813v1",
    "title": "Quantum and Super-quantum enhancements to two-sender, two-receiver channels",
    "authors": [
      "Yihui Quek",
      "Peter Shor"
    ],
    "author_ids": [],
    "abstract": "We study the consequences of 'super-quantum non-local correlations' as\nrepresented by the PR-box model of Popescu and Rohrlich, and show PR-boxes can\nenhance the capacity of noisy interference channels between two senders and two\nreceivers. PR-box correlations violate Bell/CHSH inequalities and are thus\nstronger -- more non-local -- than quantum mechanics; yet weak enough to\nrespect special relativity in prohibiting faster-than-light communication.\nUnderstanding their power will yield insight into the non-locality of quantum\nmechanics. We exhibit two proof-of-concept channels: first, we show a channel\nbetween two sender-receiver pairs where the senders are not allowed to\ncommunicate, for which a shared super-quantum bit (a PR-box) allows perfect\ncommunication. This feat is not achievable with the best classical (senders\nshare no resources) or quantum entanglement-assisted (senders share\nentanglement) strategies. Second, we demonstrate a class of channels for which\na tunable parameter achieves a double separation of capacities; for some range\nof \\epsilon, the super-quantum assisted strategy does better than the\nentanglement-assisted strategy, which in turn does better than the classical\none.",
    "published_date": "2017-01-13T00:00:00",
    "year": 2017,
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.03813v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.03153v2",
    "title": "Looking Beyond Appearances: Synthetic Training Data for Deep CNNs in Re-identification",
    "authors": [
      "Igor Barros Barbosa",
      "Marco Cristani",
      "Barbara Caputo",
      "Aleksander Rognhaugen",
      "Theoharis Theoharis"
    ],
    "author_ids": [],
    "abstract": "Re-identification is generally carried out by encoding the appearance of a\nsubject in terms of outfit, suggesting scenarios where people do not change\ntheir attire. In this paper we overcome this restriction, by proposing a\nframework based on a deep convolutional neural network, SOMAnet, that\nadditionally models other discriminative aspects, namely, structural attributes\nof the human figure (e.g. height, obesity, gender). Our method is unique in\nmany respects. First, SOMAnet is based on the Inception architecture, departing\nfrom the usual siamese framework. This spares expensive data preparation\n(pairing images across cameras) and allows the understanding of what the\nnetwork learned. Second, and most notably, the training data consists of a\nsynthetic 100K instance dataset, SOMAset, created by photorealistic human body\ngeneration software. Synthetic data represents a good compromise between\nrealistic imagery, usually not required in re-identification since surveillance\ncameras capture low-resolution silhouettes, and complete control of the\nsamples, which is useful in order to customize the data w.r.t. the surveillance\nscenario at-hand, e.g. ethnicity. SOMAnet, trained on SOMAset and fine-tuned on\nrecent re-identification benchmarks, outperforms all competitors, matching\nsubjects even with different apparel. The combination of synthetic data with\nInception architectures opens up new research avenues in re-identification.",
    "published_date": "2017-01-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "I.2.10; I.4.8"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.03153v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.03017v2",
    "title": "The paradigm-shift of social spambots: Evidence, theories, and tools for the arms race",
    "authors": [
      "Stefano Cresci",
      "Roberto Di Pietro",
      "Marinella Petrocchi",
      "Angelo Spognardi",
      "Maurizio Tesconi"
    ],
    "author_ids": [],
    "abstract": "Recent studies in social media spam and automation provide anecdotal\nargumentation of the rise of a new generation of spambots, so-called social\nspambots. Here, for the first time, we extensively study this novel phenomenon\non Twitter and we provide quantitative evidence that a paradigm-shift exists in\nspambot design. First, we measure current Twitter's capabilities of detecting\nthe new social spambots. Later, we assess the human performance in\ndiscriminating between genuine accounts, social spambots, and traditional\nspambots. Then, we benchmark several state-of-the-art techniques proposed by\nthe academic literature. Results show that neither Twitter, nor humans, nor\ncutting-edge applications are currently capable of accurately detecting the new\nsocial spambots. Our results call for new approaches capable of turning the\ntide in the fight against this raising phenomenon. We conclude by reviewing the\nlatest literature on spambots detection and we highlight an emerging common\nresearch trend based on the analysis of collective behaviors. Insights derived\nfrom both our extensive experimental campaign and survey shed light on the most\npromising directions of research and lay the foundations for the arms race\nagainst the novel social spambots. Finally, to foster research on this novel\nphenomenon, we make publicly available to the scientific community all the\ndatasets used in this study.",
    "published_date": "2017-01-11T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.03017v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.02694v4",
    "title": "Limited individual attention and online virality of low-quality information",
    "authors": [
      "Xiaoyan Qiu",
      "Diego F. M. Oliveira",
      "Alireza Sahami Shirazi",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "author_ids": [],
    "abstract": "Social media are massive marketplaces where ideas and news compete for our\nattention. Previous studies have shown that quality is not a necessary\ncondition for online virality and that knowledge about peer choices can distort\nthe relationship between quality and popularity. However, these results do not\nexplain the viral spread of low-quality information, such as the digital\nmisinformation that threatens our democracy. We investigate quality\ndiscrimination in a stylized model of online social network, where individual\nagents prefer quality information, but have behavioral limitations in managing\na heavy flow of information. We measure the relationship between the quality of\nan idea and its likelihood to become prevalent at the system level. We find\nthat both information overload and limited attention contribute to a\ndegradation in the market's discriminative power. A good tradeoff between\ndiscriminative power and diversity of information is possible according to the\nmodel. However, calibration with empirical data characterizing information load\nand finite attention in real social media reveals a weak correlation between\nquality and popularity of information. In these realistic conditions, the model\npredicts that high-quality information has little advantage over low-quality\ninformation.",
    "published_date": "2017-01-10T00:00:00",
    "year": 2017,
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.02694v4",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.02388v2",
    "title": "Stoic Ethics for Artificial Agents",
    "authors": [
      "Gabriel Murray"
    ],
    "author_ids": [],
    "abstract": "We present a position paper advocating the notion that Stoic philosophy and\nethics can inform the development of ethical A.I. systems. This is in sharp\ncontrast to most work on building ethical A.I., which has focused on\nUtilitarian or Deontological ethical theories. We relate ethical A.I. to\nseveral core Stoic notions, including the dichotomy of control, the four\ncardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on\nemotion or affect. More generally, we put forward an ethical view of A.I. that\nfocuses more on internal states of the artificial agent rather than on external\nactions of the agent. We provide examples relating to near-term A.I. systems as\nwell as hypothetical superintelligent agents.",
    "published_date": "2017-01-09T00:00:00",
    "year": 2017,
    "categories": [
      "cs.AI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.02388v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.01963v1",
    "title": "Resource Management in Cloud Networking Using Economic Analysis and Pricing Models: A Survey",
    "authors": [
      "Nguyen Cong Luong",
      "Ping Wang",
      "Dusit Niyato",
      "Wen Yonggang",
      "Zhu Han"
    ],
    "author_ids": [],
    "abstract": "This paper presents a comprehensive literature review on applications of\neconomic and pricing models for resource management in cloud networking. To\nachieve sustainable profit advantage, cost reduction, and flexibility in\nprovisioning of cloud resources, resource management in cloud networking\nrequires adaptive and robust designs to address many issues, e.g., resource\nallocation, bandwidth reservation, request allocation, and workload allocation.\nEconomic and pricing models have received a lot of attention as they can lead\nto desirable performance in terms of social welfare, fairness, truthfulness,\nprofit, user satisfaction, and resource utilization. This paper reviews\napplications of the economic and pricing models to develop adaptive algorithms\nand protocols for resource management in cloud networking. Besides, we survey a\nvariety of incentive mechanisms using the pricing strategies in sharing\nresources in edge computing. In addition, we consider using pricing models in\ncloud-based Software Defined Wireless Networking (cloud-based SDWN). Finally,\nwe highlight important challenges, open issues and future research directions\nof applying economic and pricing models to cloud networking",
    "published_date": "2017-01-08T00:00:00",
    "year": 2017,
    "categories": [
      "cs.GT",
      "cs.DC",
      "cs.NI"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.01963v1",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.01833v2",
    "title": "Oriented Response Networks",
    "authors": [
      "Yanzhao Zhou",
      "Qixiang Ye",
      "Qiang Qiu",
      "Jianbin Jiao"
    ],
    "author_ids": [],
    "abstract": "Deep Convolution Neural Networks (DCNNs) are capable of learning\nunprecedentedly effective image representations. However, their ability in\nhandling significant local and global image rotations remains limited. In this\npaper, we propose Active Rotating Filters (ARFs) that actively rotate during\nconvolution and produce feature maps with location and orientation explicitly\nencoded. An ARF acts as a virtual filter bank containing the filter itself and\nits multiple unmaterialised rotated versions. During back-propagation, an ARF\nis collectively updated using errors from all its rotated versions. DCNNs using\nARFs, referred to as Oriented Response Networks (ORNs), can produce\nwithin-class rotation-invariant deep features while maintaining inter-class\ndiscrimination for classification tasks. The oriented response produced by ORNs\ncan also be used for image and object orientation estimation tasks. Over\nmultiple state-of-the-art DCNN architectures, such as VGG, ResNet, and STN, we\nconsistently observe that replacing regular filters with the proposed ARFs\nleads to significant reduction in the number of network parameters and\nimprovement in classification performance. We report the best results on\nseveral commonly used benchmarks.",
    "published_date": "2017-01-07T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.01833v2",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.01645v2",
    "title": "Sharing Means Renting?: An Entire-marketplace Analysis of Airbnb",
    "authors": [
      "Qing Ke"
    ],
    "author_ids": [],
    "abstract": "Airbnb, an online marketplace for accommodations, has experienced a\nstaggering growth accompanied by intense debates and scattered regulations\naround the world. Current discourses, however, are largely focused on opinions\nrather than empirical evidences. Here, we aim to bridge this gap by presenting\nthe first large-scale measurement study on Airbnb, using a crawled data set\ncontaining 2.3 million listings, 1.3 million hosts, and 19.3 million reviews.\nWe measure several key characteristics at the heart of the ongoing debate and\nthe sharing economy. Among others, we find that Airbnb has reached a global yet\nheterogeneous coverage. The majority of its listings across many countries are\nentire homes, suggesting that Airbnb is actually more like a rental marketplace\nrather than a spare-room sharing platform. Analysis on star-ratings reveals\nthat there is a bias toward positive ratings, amplified by a bias toward using\npositive words in reviews. The extent of such bias is greater than Yelp\nreviews, which were already shown to exhibit a positive bias. We investigate a\nkey issue---commercial hosts who own multiple listings on Airbnb---repeatedly\ndiscussed in the current debate. We find that their existence is prevalent,\nthey are early-movers towards joining Airbnb, and their listings are\ndisproportionately entire homes and located in the US. Our work advances the\ncurrent understanding of how Airbnb is being used and may serve as an\nindependent and empirical reference to inform the debate.",
    "published_date": "2017-01-06T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CY",
      "physics.soc-ph"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.01645v2",
    "is_ai_related": false
  },
  {
    "id": "http://arxiv.org/abs/1701.00851v1",
    "title": "Unsupervised neural and Bayesian models for zero-resource speech processing",
    "authors": [
      "Herman Kamper"
    ],
    "author_ids": [],
    "abstract": "In settings where only unlabelled speech data is available, zero-resource\nspeech technology needs to be developed without transcriptions, pronunciation\ndictionaries, or language modelling text. There are two central problems in\nzero-resource speech processing: (i) finding frame-level feature\nrepresentations which make it easier to discriminate between linguistic units\n(phones or words), and (ii) segmenting and clustering unlabelled speech into\nmeaningful units. In this thesis, we argue that a combination of top-down and\nbottom-up modelling is advantageous in tackling these two problems.\n  To address the problem of frame-level representation learning, we present the\ncorrespondence autoencoder (cAE), a neural network trained with weak top-down\nsupervision from an unsupervised term discovery system. By combining this\ntop-down supervision with unsupervised bottom-up initialization, the cAE yields\nmuch more discriminative features than previous approaches. We then present our\nunsupervised segmental Bayesian model that segments and clusters unlabelled\nspeech into hypothesized words. By imposing a consistent top-down segmentation\nwhile also using bottom-up knowledge from detected syllable boundaries, our\nsystem outperforms several others on multi-speaker conversational English and\nXitsonga speech data. Finally, we show that the clusters discovered by the\nsegmental Bayesian model can be made less speaker- and gender-specific by using\nfeatures from the cAE instead of traditional acoustic features.\n  In summary, the different models and systems presented in this thesis show\nthat both top-down and bottom-up modelling can improve representation learning,\nsegmentation and clustering of unlabelled speech data.",
    "published_date": "2017-01-03T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.00851v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.00294v1",
    "title": "The Geodesic Distance between $\\mathcal{G}_I^0$ Models and its Application to Region Discrimination",
    "authors": [
      "José Naranjo-Torres",
      "Juliana Gambini",
      "Alejandro C. Frery"
    ],
    "author_ids": [],
    "abstract": "The $\\mathcal{G}_I^0$ distribution is able to characterize different regions\nin monopolarized SAR imagery. It is indexed by three parameters: the number of\nlooks (which can be estimated in the whole image), a scale parameter and a\ntexture parameter. This paper presents a new proposal for feature extraction\nand region discrimination in SAR imagery, using the geodesic distance as a\nmeasure of dissimilarity between $\\mathcal{G}_I^0$ models. We derive geodesic\ndistances between models that describe several practical situations, assuming\nthe number of looks known, for same and different texture and for same and\ndifferent scale. We then apply this new tool to the problems of (i)~identifying\nedges between regions with different texture, and (ii)~quantify the\ndissimilarity between pairs of samples in actual SAR data. We analyze the\nadvantages of using the geodesic distance when compared to stochastic\ndistances.",
    "published_date": "2017-01-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.00294v1",
    "is_ai_related": true
  },
  {
    "id": "http://arxiv.org/abs/1701.00180v2",
    "title": "A scalable approach for tree segmentation within small-footprint airborne LiDAR data",
    "authors": [
      "Hamid Hamraz",
      "Marco A. Contreras",
      "Jun Zhang"
    ],
    "author_ids": [],
    "abstract": "This paper presents a distributed approach that scales up to segment tree\ncrowns within a LiDAR point cloud representing an arbitrarily large forested\narea. The approach uses a single-processor tree segmentation algorithm as a\nbuilding block in order to process the data delivered in the shape of tiles in\nparallel. The distributed processing is performed in a master-slave manner, in\nwhich the master maintains the global map of the tiles and coordinates the\nslaves that segment tree crowns within and across the boundaries of the tiles.\nA minimal bias was introduced to the number of detected trees because of trees\nlying across the tile boundaries, which was quantified and adjusted for.\nTheoretical and experimental analyses of the runtime of the approach revealed a\nnear linear speedup. The estimated number of trees categorized by crown class\nand the associated error margins as well as the height distribution of the\ndetected trees aligned well with field estimations, verifying that the\ndistributed approach works correctly. The approach enables providing\ninformation of individual tree locations and point cloud segments for a\nforest-level area in a timely manner, which can be used to create detailed\nremotely sensed forest inventories. Although the approach was presented for\ntree segmentation within LiDAR point clouds, the idea can also be generalized\nto scale up processing other big spatial datasets.\n  Highlights: - A scalable distributed approach for tree segmentation was\ndeveloped and theoretically analyzed. - ~2 million trees in a 7440 ha forest\nwas segmented in 2.5 hours using 192 cores. - 2% false positive trees were\nidentified as a result of the distributed run. - The approach can be used to\nscale up processing other big spatial data",
    "published_date": "2017-01-01T00:00:00",
    "year": 2017,
    "categories": [
      "cs.DC",
      "cs.CE"
    ],
    "pdf_url": "http://arxiv.org/pdf/1701.00180v2",
    "is_ai_related": false
  }
]